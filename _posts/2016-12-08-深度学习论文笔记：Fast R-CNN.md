---
layout: post
title: 深度学习论文笔记：Fast R-CNN
date: 2016-12-08 15:32:24.000000000 +09:00
---

## 知识点

* mAP：detection quality.

## Abstract

* 本文提出一种基于快速区域的卷积网络方法（快速R-CNN）用于对象检测。

* 快速R-CNN采用多项创新技术来提高训练和测试速度，同时提高检测精度。
* 采用VGG16的网络：VGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connected layers

## 1. Introduction

* 物体检测相对于图像分类是更复杂的，应为需要物体准确的位置。

  * 首先，必须处理许多候选对象位置（通常称为“proposal”）。
  * 其次，这些候选者只提供粗略的定位，必须进行精确定位才能实现精确定位。
  * 这些问题的解决方案经常损害 **速度** ， **准确性** 或 **简单性** 。

### 1.1. R-CNN and SPPnet

* R-CNN(Region-based Convolution Network)具有几个显著的缺点：

  * 训练是一个多级管道。
  * 训练在空间和时间上是昂贵的。
  * 物体检测速度很慢。

* R-CNN是慢的，因为它对每个对象proposal执行ConvNet正向传递，而不共享计算（sharing computation）。

* Spatial pyramid pooling networks（SPPnets），利用sharing computation对R-CNN进行了加速，但是SPPnets也具有明显的缺点，像R-CNN一样，SPPnets也需要：

  * 训练是一个多阶段流程，
  * 涉及提取特征，
  * 用对数损失精简网络
  * 训练SVM
  * 赋予边界框回归。
  * 特征也需要也写入磁盘。

* 但与R-CNN **不同** ，在[11]中提出的fine-tuning算法不能更新在空间金字塔池之前的卷积层。 不出所料，这种限制（固定的卷积层）限制了非常深的网络的精度。

### 1.2. Contributions

* Fast R-CNN优点：

1. 比R-CNN，SPPnet更高的检测质量（mAP）
2. 训练是单阶段的，使用多任务损失（multi-task loss）
3. 训练可以更新所有网络层
4. 特征缓存不需要磁盘存储

## 2. Fast R-CNN architecture and training

* 整体框架

![](https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7na6fij30jk0efdju.jpg)

* 快速R-CNN网络将整个图像和一组对象位置作为输入。

  * 网络首先使用几个卷积（conv）和最大池层来处理整个图像，以产生conv feature map。
  * 然后，对于每个对象proposal， **感兴趣区域（RoI）池层** 从特征图中抽取固定长度的特征向量。
  * 每个特征向量被馈送到完全连接（fc）层序列，其最终分支成两个同级输出层：

    * 一个产生对K个对象类加上全部捕获的“背景”类的softmax概率估计(one that produces softmax probability estimates over K object classes plus a catch-all “background” class)
    * 另一个对每个K对象类输出四个实数，每组4个值编码提炼定义K个类中的一个的的边界框位置。(another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes reﬁned bounding-box positions for one of the K classes.)

### 2.1. The RoI pooling layer

* Rol pooling layer的作用主要有两个：

  * 一个是将image中的RoI定位到feature map中对应patch
  * 另一个是用一个单层的SPP layer将这个feature map patch下采样为大小固定的feature再传入全连接层。

* RoI池层使用最大池化将任何有效的RoI区域内的特征转换成具有H×W（例如，7×7）的固定空间范围的小feature map，其中H和W是层超参数 它们独立于任何特定的RoI。
* 在本文中，RoI是conv feature map中的一个矩形窗口。
* 每个RoI由定义其左上角（r，c）及其高度和宽度（h，w）的四元组（r，c，h，w）定义。
* RoI层仅仅是Sppnets中的spatial pyramid pooling layer的特殊形式，其中只有一个金字塔层

### 2.2. Initializing from pre-trained networks

* 用了3个预训练的ImageNet网络（CaffeNet/ VGG_CNN_M_1024 /VGG16）。预训练的网络初始化Fast RCNN要经过三次变形：

1. 最后一个max pooling层替换为RoI pooling层，设置H’和W’与第一个全连接层兼容。
2. 最后一个全连接层和softmax（原本是1000个类）替换为softmax的对K+1个类别的分类层，和bounding box 回归层。
3. 输入修改为两种数据：一组N个图形，R个RoI，batch size和ROI数、图像分辨率都是可变的。

### 2.3. Fine-tuning for detection

* 利用反向传播算法进行训练所有网络的权重是Fast R-CNN很重要的一个能力。
* 我们提出了一种更有效的训练方法，利用在训练期间的特征共享（feature sharing during training）。
* 在Fast R-CNN训练中， **随机梯度下降（SGD）小批量分层采样** ，首先通过采样N个图像，然后通过从每个图像采样 **R/N个** RoIs。
* 关键的是，来自同一图像的RoI在向前和向后传递中 **共享计算** 和存储。
* 此外为了分层采样，Fast R-CNN使用了一个流水线训练过程，利用一个fine-tuning阶段来联合优化一个softmax分类器和bounding box回归，而非训练一个softmax分类器，SVMs，和regression在三个独立的阶段。
* Multi-task loss：

  * 两个loss，以下分别介绍：

    * 对于分类loss，是一个N+1路的softmax输出，其中的N是类别个数，1是背景。
    * 对于回归loss，是一个4xN路输出的regressor，也就是说对于每个类别都会训练一个单独的regressor的意思，比较有意思的是，这里regressor的loss不是L2的，而是一个平滑的L1，形式如下：

![](https://ww4.sinaimg.cn/large/006tKfTcgw1fbfo7oia0ij30bg05n74f.jpg)

* 我们利用一个multi-task loss L 在每个被标注的RoI上来联合训练分类器和bounding box regression

* Mini-batch sampling：在微调时，每个SGD的mini-batch是随机找两个图片，R为128，因此每个图上取样64个RoI。从object proposal中选25%的RoI，就是和ground-truth交叠至少为0.5的。剩下的作为背景。
* Back-propagation through RoI pooling layers：

  * RoI pooling层计算损失函数对每个输入变量x的偏导数，如下：

    ![](https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7owdcpj306q01mwee.jpg)

    y是pooling后的输出单元，x是pooling前的输入单元，如果y由x pooling而来，则将损失L对y的偏导计入累加值，最后累加完R个RoI中的所有输出单元。下面是我理解的x、y、r的关系：

    ![20151208163114338](https://ww3.sinaimg.cn/large/006tKfTcgw1fbfoo7cuv7j30qf0ardgq.jpg)

### 2.4. Scale invariance

* 这里讨论object的scale问题，就是网络对于object的scale应该是要不敏感的。这里还是引用了SPP的方法，有两种:

  * brute force （single scale），也就是简单认为object不需要预先resize到类似的scale再传入网络，直接将image定死为某种scale，直接输入网络来训练就好了，然后期望网络自己能够学习到scale-invariance的表达。
  * image pyramids （multi scale），也就是要生成一个金字塔，然后对于object，在金字塔上找到一个大小比较接近227x227的投影版本，然后用这个版本去训练网络。

* 可以看出，2应该比1更加好，作者也在5.2讨论了，2的表现确实比1好，但是好的不算太多，大概是1个mAP左右，但是时间要慢不少，所以作者实际采用的是第一个策略，也就是single scale。
* 这里，FRCN测试之所以比SPP快，很大原因是因为这里，因为SPP用了2，而FRCN用了1。

## 3. Fast R-CNN detection

* 大型全连接层很容易的可以通过将他们与 **truncated SVD(奇异值分解)** 压缩来加速计算。

## 4. Main results

* All Fast R-CNN results in this paper using VGG16 ﬁne-tune layers conv3 1 and up; all experments with models S and M ﬁne-tune layers conv2 and up.

## 5. Design evaluation

### 5.3. Do we need more training data?

* 在训练期间，作者做过的唯一一个数据增量的方式是水平翻转。 作者也试过将VOC12的数据也作为拓展数据加入到finetune的数据中，结果VOC07的mAP从66.9到了70.0，说明对于网络来说， **数据越多就是越好的。**
