<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JacobKong&#39;s Blog</title>
  <subtitle>è·¯æ¼«æ¼«å…¶ä¿®è¿œå…®......</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jacobkong.github.io/"/>
  <updated>2018-06-06T14:37:44.000Z</updated>
  <id>http://jacobkong.github.io/</id>
  
  <author>
    <name>Jacob Kong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ã€CleanMyMac 3 æœ€æ–°ç‰ˆ å®˜æ–¹æ­£ç‰ˆåºåˆ—å· å…¨ç½‘æœ€ä½ 85å…ƒã€‘ã€é€Office 365 è®¢é˜… æ°¸ä¹…å‡çº§ç‰ˆè´¦å· ä»…éœ€25å…ƒã€‘</title>
    <link href="http://jacobkong.github.io/posts/2173074278/"/>
    <id>http://jacobkong.github.io/posts/2173074278/</id>
    <published>2018-06-05T07:51:24.000Z</published>
    <updated>2018-06-06T14:37:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä½œä¸ºä¸€ä¸ªç»å¸¸æ½œæ°´äºè®ºå›çš„èŒæ–°ï¼Œä¹Ÿæ›¾ç»ä»è®ºå›æ”¶é›†åˆ°å„ç§ä¼˜ç§€çš„è½¯ä»¶ï¼Œæ”¶ç›Šé¢‡å¤šã€‚</p>
<h2 id="CleanMyMac-3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85"><a href="#CleanMyMac-3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85" class="headerlink" title="CleanMyMac 3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85"></a><strong>CleanMyMac 3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85</strong></h2><p>å…¶ä¸­<strong>CleanMyMac 3</strong>å¯ä»¥è¯´æ˜¯<strong>Macä¸Šæœ€å—æ¬¢è¿çš„ç³»ç»Ÿæ¸…ç†è½¯ä»¶</strong>ï¼Œä¹Ÿæ˜¯è®ºå›ä¸­æœç´¢å…³é”®è¯æœ€å¤šçš„è½¯ä»¶ï¼Œä¸‹è½½ä¹Ÿæ˜¯æœ€å¤šçš„ã€‚</p>
<p>ç„¶è€Œè¿™æ¬¾è½¯ä»¶å¯ä»¥è¯´æœ‰ä¸ªå¾ˆè›‹ç–¼çš„åœ°æ–¹ï¼Œå°±æ˜¯åªè¦macç³»ç»Ÿå‡çº§åˆ°æ–°ä¸€ç‰ˆçš„ç³»ç»Ÿï¼Œç ´jieç‰ˆçš„è½¯ä»¶å°±å¤±æ•ˆæ— æ³•ä½¿ç”¨ï¼Œ<strong>è€Œç›®å‰CleanMyMac 3å®˜æ–¹æ­£ç‰ˆï¿¥99çš„ä»·é’±ï¼Œå…¶å®ä½œä¸ºä¸€æ¬¾åƒåœ¾æ¸…ç†è½¯ä»¶ï¼Œè¿˜æ˜¯æœ‰ç‚¹å°è´µã€‚</strong></p>
<p>ä»Šå¤©ï¼Œã€ä¹”å¸ƒæ•°ç ã€‘æ­£å¼å¼€ä¸šï¼Œä¸ºäº†å›é¦ˆå¹¿å¤§è®ºå›å¥½å‹ä¹‹å‰åˆ†äº«çš„å„ç§ä¼˜ç§€è½¯ä»¶ï¼Œä¸è¿½æ±‚åˆ©æ¶¦ï¼Œåªè¿½æ±‚å£ç¢‘ï¼Œ<strong>CleanMyMac 3ä¸­æ–‡ç‰ˆç›®å‰ä»…éœ€ï¿¥85</strong>ï¼Œå¯ä»¥è¯´æ˜¯å…¨ç½‘æœ€ä½ä»·äº†ï¼ä¿è¯æ˜¯å®˜æ–¹æ­£ç‰ˆï¼Œä¸€æœºä¸€å·ï¼ŒåŒç‰ˆæœ¬æ°¸ä¹…å‡çº§ï¼Œå†ä¹Ÿä¸ç”¨æ€•ç³»ç»Ÿå‡çº§å¯¼è‡´è½¯ä»¶æ— æ³•ä½¿ç”¨äº†ï¼</p>
<a id="more"></a>
<p>ä¹‹å‰çŠ¹è±«å«Œè´µçš„æœ‹å‹æŠ“ç´§è¿™æ¬¡å¯ä»¥èº²ä¸€æ¬¡æ‰‹äº†ï¼Œå¾ˆå¿«å°†æ¢å¤åŸä»·ï¼</p>
<p>ç›®å‰è´­ä¹°è¯¥è½¯ä»¶å¯ä»¥<strong>é€Office 365æ­£ç‰ˆæ°¸ä¹…å‡çº§è´¦å·ä¸€ä¸ª</strong>ï¼Œç¦åˆ©å¤šå¤šï¼</p>
<p>è”ç³»å®¢æœï¼Œå‘é€æš—å·â€œè®ºå›â€æ”¹ä»·ï¼</p>
<p>ç”µè„‘ç‰ˆè®¿é—®ï¼š</p>
<p><a href="">https://item.taobao.com/item.htm?spm=a1z38n.10677092.0.0.4ca41debljWxbC&amp;id=570190131412</a></p>
<p>æ‰‹æœºç‰ˆç²˜è´´ä»¥ä¸‹å†…å®¹ï¼Œåœ¨æ‰‹æ·˜ä¸­æ‰“å¼€å³å¯ï¼š</p>
<p>ã€CleanMyMac 3æ¿€æ´»ç åºåˆ—å· clean my macä½ä»·æ³¨å†Œç é‡è£…æ›´æ–°ã€‘<a href="http://m.tb.cn/h.3ZaAKWb" target="_blank" rel="external">http://m.tb.cn/h.3ZaAKWb</a> ç‚¹å‡»é“¾æ¥ï¼Œå†é€‰æ‹©æµè§ˆå™¨å’‘é–ï¼›æˆ–å¾©Â·åˆ¶è¿™æ®µæè¿°â‚¬kr7z0wvz2ooâ‚¬ååˆ°ğŸ‘‰æ·˜â™‚å¯³â™€ğŸ‘ˆ</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fs1sgi4ni0j30of11xtdw.jpg" alt="IMG_2680"></p>
<p>++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</p>
<h2 id="Office-365-ä»…éœ€25å…ƒ"><a href="#Office-365-ä»…éœ€25å…ƒ" class="headerlink" title="Office 365 ä»…éœ€25å…ƒ"></a>Office 365 ä»…éœ€25å…ƒ</h2><p>æ›´æœ‰æ­£ç‰ˆ<strong>Office 365</strong>è´¦å·ï¼Œä¸€äººä¸€å·ï¼Œæ°¸ä¹…å‡çº§ï¼Œæ¯ä¸ªè´¦å·å¯ä»¥æ¿€æ´»5å°PC+Macä»¥åŠ5å°ç§»åŠ¨è®¾å¤‡ï¼Œç›®å‰ä»…éœ€<strong>ï¿¥25</strong>ï¼š</p>
<p>ç”µè„‘ç‰ˆè®¿é—®ï¼š</p>
<p><a href="">https://item.taobao.com/item.htm?spm=a1z38n.10677092.0.0.4ca41debljWxbC&amp;id=570292742115</a></p>
<p>æ‰‹æœºç‰ˆç²˜è´´ä»¥ä¸‹å†…å®¹ï¼Œåœ¨æ‰‹æ·˜ä¸­æ‰“å¼€å³å¯ï¼š</p>
<p>ã€Office365 2016  è®¢é˜… win mac ipad å®¶åº­ä¸ªäºº word excel pptã€‘<a href="http://m.tb.cn/h.3ZdsIlS" target="_blank" rel="external">http://m.tb.cn/h.3ZdsIlS</a> ç‚¹å‡»é“¾æ¥ï¼Œå†é€‰æ‹©æµè§ˆå™¨å’‘é–ï¼›æˆ–å¾©Â·åˆ¶è¿™æ®µæè¿°â‚¬MOaA0wvy9ySâ‚¬ååˆ°ğŸ‘‰æ·˜â™‚å¯³â™€ğŸ‘ˆ</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fs1sgsiy5dj30of11xgqh.jpg" alt="IMG_2679"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä½œä¸ºä¸€ä¸ªç»å¸¸æ½œæ°´äºè®ºå›çš„èŒæ–°ï¼Œä¹Ÿæ›¾ç»ä»è®ºå›æ”¶é›†åˆ°å„ç§ä¼˜ç§€çš„è½¯ä»¶ï¼Œæ”¶ç›Šé¢‡å¤šã€‚&lt;/p&gt;
&lt;h2 id=&quot;CleanMyMac-3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85&quot;&gt;&lt;a href=&quot;#CleanMyMac-3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85&quot; class=&quot;headerlink&quot; title=&quot;CleanMyMac 3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85&quot;&gt;&lt;/a&gt;&lt;strong&gt;CleanMyMac 3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;å…¶ä¸­&lt;strong&gt;CleanMyMac 3&lt;/strong&gt;å¯ä»¥è¯´æ˜¯&lt;strong&gt;Macä¸Šæœ€å—æ¬¢è¿çš„ç³»ç»Ÿæ¸…ç†è½¯ä»¶&lt;/strong&gt;ï¼Œä¹Ÿæ˜¯è®ºå›ä¸­æœç´¢å…³é”®è¯æœ€å¤šçš„è½¯ä»¶ï¼Œä¸‹è½½ä¹Ÿæ˜¯æœ€å¤šçš„ã€‚&lt;/p&gt;
&lt;p&gt;ç„¶è€Œè¿™æ¬¾è½¯ä»¶å¯ä»¥è¯´æœ‰ä¸ªå¾ˆè›‹ç–¼çš„åœ°æ–¹ï¼Œå°±æ˜¯åªè¦macç³»ç»Ÿå‡çº§åˆ°æ–°ä¸€ç‰ˆçš„ç³»ç»Ÿï¼Œç ´jieç‰ˆçš„è½¯ä»¶å°±å¤±æ•ˆæ— æ³•ä½¿ç”¨ï¼Œ&lt;strong&gt;è€Œç›®å‰CleanMyMac 3å®˜æ–¹æ­£ç‰ˆï¿¥99çš„ä»·é’±ï¼Œå…¶å®ä½œä¸ºä¸€æ¬¾åƒåœ¾æ¸…ç†è½¯ä»¶ï¼Œè¿˜æ˜¯æœ‰ç‚¹å°è´µã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ä»Šå¤©ï¼Œã€ä¹”å¸ƒæ•°ç ã€‘æ­£å¼å¼€ä¸šï¼Œä¸ºäº†å›é¦ˆå¹¿å¤§è®ºå›å¥½å‹ä¹‹å‰åˆ†äº«çš„å„ç§ä¼˜ç§€è½¯ä»¶ï¼Œä¸è¿½æ±‚åˆ©æ¶¦ï¼Œåªè¿½æ±‚å£ç¢‘ï¼Œ&lt;strong&gt;CleanMyMac 3ä¸­æ–‡ç‰ˆç›®å‰ä»…éœ€ï¿¥85&lt;/strong&gt;ï¼Œå¯ä»¥è¯´æ˜¯å…¨ç½‘æœ€ä½ä»·äº†ï¼ä¿è¯æ˜¯å®˜æ–¹æ­£ç‰ˆï¼Œä¸€æœºä¸€å·ï¼ŒåŒç‰ˆæœ¬æ°¸ä¹…å‡çº§ï¼Œå†ä¹Ÿä¸ç”¨æ€•ç³»ç»Ÿå‡çº§å¯¼è‡´è½¯ä»¶æ— æ³•ä½¿ç”¨äº†ï¼&lt;/p&gt;
    
    </summary>
    
      <category term="è½¯ä»¶åˆ†äº«" scheme="http://jacobkong.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="è½¯ä»¶åˆ†äº«" scheme="http://jacobkong.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/"/>
    
      <category term="CleanMyMac" scheme="http://jacobkong.github.io/tags/CleanMyMac/"/>
    
      <category term="Office" scheme="http://jacobkong.github.io/tags/Office/"/>
    
  </entry>
  
  <entry>
    <title>è¡Œä¸ºæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šOne-shot Action Localization by Learning Sequence Matching Network</title>
    <link href="http://jacobkong.github.io/posts/3531717168/"/>
    <id>http://jacobkong.github.io/posts/3531717168/</id>
    <published>2018-05-30T07:51:24.000Z</published>
    <updated>2018-05-31T08:49:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„å¦ä¸€ç¯‡ï¼ŒåŸºäºå­¦ä¹ çš„æ—¶é—´è½´åŠ¨ä½œå®šä½æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ã€‚ ç„¶è€Œï¼Œè¿™æ ·çš„å¤§è§„æ¨¡è§†é¢‘æ•°æ®é›†ä¸ä»…éå¸¸éš¾ä»¥è·å¾—è€Œä¸”å¯èƒ½å› ä¸ºå­˜åœ¨æ— æ•°çš„åŠ¨ä½œç±»åˆ«è€Œä¸å®ç”¨ã€‚ å½“è®­ç»ƒæ ·æœ¬å°‘ä¸”ç½•è§æ—¶ï¼Œå½“å‰æ–¹æ³•çš„å¼Šç«¯å°±æš´éœ²å‡ºæ¥äº†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨åŒ¹é…ç½‘ç»œçš„One-shotå­¦ä¹ æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨ç›¸å…³æ€§æ¥æŒ–æ˜å’Œå®šä½ä»¥å‰æ²¡æœ‰çœ‹è¿‡ç±»åˆ«çš„è¡Œä¸ºã€‚ æœ¬æ–‡åœ¨THUMOS14å’ŒActivityNetæ•°æ®é›†ä¸Šè¯„ä¼°äº†æœ¬æ–‡çš„one-shotåŠ¨ä½œå®šä½æ–¹æ³•ã€‚</p>
<a id="more"></a>
<h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><ul>
<li>ç°åœ¨æ˜¾å­˜çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è¡Œä¸ºå®šä½çš„æ–¹æ³•éƒ½é‡‡ç”¨å¾ˆå¼ºçš„ç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œéå¸¸è€—æ—¶å»æ”¶é›†ã€‚</li>
<li>è™½ç„¶è½¬ç§»å­¦ä¹ æˆ–æ¨¡å‹é¢„è®­ç»ƒå¯èƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å¤„ç†æ–°çš„åŠ¨ä½œç±»åˆ«å’Œå°†å­¦ä¹ çš„ç½‘ç»œæ¨¡å‹ä»¥é«˜æ•°æ®æ•ˆç‡é€‚åº”åˆ°æ–°åœºæ™¯ä¸­ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>åœ¨æœ¬æ–‡ä¸­ï¼Œè€ƒè™‘one(few)-shotçš„åŠ¨ä½œå®šä½å­¦ä¹ åœºæ™¯ï¼šç»™å‡ºä¸€ä¸ªï¼ˆæˆ–å‡ ä¸ªï¼‰æ–°åŠ¨ä½œç±»çš„ä¾‹å­ï¼Œé€šå¸¸æ¯ä¸ªç±»ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ£€æµ‹æœªä¿®å‰ªè§†é¢‘ä¸­æ‰€æœ‰å‡ºç°çš„æ¯ä¸ªç±»ã€‚</li>
<li>ç›®å‰å¾ˆå°‘æœ‰å·¥ä½œå°†one-shot learningåº”ç”¨åˆ°æ£€æµ‹æ—¶ç©ºç‰¹å¾ç›®æ ‡ä¸­ã€‚</li>
</ul>
<h3 id="ç›®çš„"><a href="#ç›®çš„" class="headerlink" title="ç›®çš„"></a>ç›®çš„</h3><p>ä¸ºç¼“è§£ç›®å‰ç”¨æ¥è®­ç»ƒçš„åŠ¨ä½œè§†é¢‘æ•°æ®é‡ç¨€å°‘ä¸”éš¾ä»¥è·å–çš„é—®é¢˜ï¼Œåˆ©ç”¨one(few)-shot learningçš„æ–¹æ³•ï¼Œé€šè¿‡å°‘é‡è®­ç»ƒæ ·æœ¬å³å¯è¾¾åˆ°æ—¶é—´è½´å®šä½ä»¥åŠæœªè§è¿‡çš„åŠ¨ä½œçš„é¢„æµ‹ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>è®ºæ–‡æ¡†æ¶å¦‚ä¸‹ï¼š</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1frto52bt5ej30rj0e0gpp.jpg" alt=""></p>
<ul>
<li><p>æœ¬æ–‡å¼€å‘äº†ä¸€ç§æ–°é¢–çš„<strong>å…ƒå­¦ä¹ ï¼ˆmeta-learningï¼‰ç­–ç•¥</strong>ï¼Œå°†<strong>è§†é¢‘åºåˆ—åŒ¹é…</strong>çš„ä»»åŠ¡çº§å…ˆéªŒçŸ¥è¯†é›†æˆåˆ°å­¦ä¹ åŠ¨ä½œå®šä½ä¸­ã€‚ æˆ‘ä»¬çš„ä¸€æ¬¡å­¦ä¹ ç­–ç•¥çš„å…³é”®æ€æƒ³æ˜¯åŠ¨ä½œè§†é¢‘çš„ç›´è§‚ï¼Œç»“æ„åŒ–è¡¨ç¤ºé€‚åˆäºç”¨æ¥åŒ¹é…ï¼ˆéƒ¨åˆ†ï¼‰åºåˆ—ï¼ˆmatching  sequencesï¼‰ï¼Œä»¥åŠä¸€ç§ç›¸ä¼¼æ€§åº¦é‡ï¼Œå®ƒå…è®¸æˆ‘ä»¬å°†åŠ¨ä½œç¤ºä¾‹çš„æ ‡ç­¾è½¬æ¢ä¸ºæœªä¿®å‰ªè§†é¢‘ä¸­çš„<strong>åŠ¨ä½œæè®®</strong>ã€‚</p>
</li>
<li><p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„Matching Networkç»“æ„ï¼Œé¦–å…ˆç”Ÿæˆè®¸å¤šproposalï¼Œç„¶åè¿™äº›proposalé€å…¥åˆ°ä¸‰ä¸ªç½‘ç»œç»„ä»¶ä¸­è¿›è¡ŒåŠ¨ä½œæ ‡ç­¾é¢„æµ‹ï¼š</p>
<ul>
<li><p><strong>Video Encoder Networkï¼š</strong>å®ƒä¸ºæ¯ä¸ªè¡ŒåŠ¨å»ºè®®å’Œå‚è€ƒè¡ŒåŠ¨è®¡ç®—ä¸€ä¸ªsegment-basedçš„åŠ¨ä½œè¡¨ç¤ºï¼Œå®ƒç»´æŠ¤è¡ŒåŠ¨çš„æ—¶é—´ç»“æ„å¹¶ç”¨äºå‡†ç¡®å®šä½ã€‚</p>
<ul>
<li>è¯¥ç½‘ç»œçš„æ€§èƒ½ä¾èµ–äºå€™é€‰proposalå’Œå‚è€ƒè§†é¢‘ä¹‹é—´çš„èƒ½å¦è‰¯å¥½å¯¹åº”ï¼Œä¸ºäº†å®ç°å‡†ç¡®å¯¹é½ï¼Œæˆ‘ä»¬æ‰“ç®—åœ¨è¡ŒåŠ¨è¡¨ç¤ºä¸­ä¿ç•™åŠ¨ä½œè§†é¢‘çš„æ—¶é—´ç»“æ„ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåˆ©ç”¨ranking LSTMæ¥è·å¾—segment-basedçš„è§†é¢‘è¡¨ç¤ºï¼Œä»¥ä¾¿å°†æ¯ä¸ªåŠ¨ä½œå®ä¾‹ç¼–ç ä¸ºå›ºå®šé•¿åº¦åºåˆ—çš„è§†é¢‘ç‰‡æ®µç‰¹å¾ã€‚</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1frua9d9df8j30fs0b8q5p.jpg" alt=""></p>
</li>
<li><p><strong>Similarity Network:</strong> å°†è¡ŒåŠ¨å»ºè®®åˆ©ç”¨ç›¸ä¼¼æ€§ç½‘ç»œä¸æ¯ä¸ªå‚è€ƒè¡ŒåŠ¨ï¼ˆreference actionï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œè¯¥ç½‘ç»œåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ç”Ÿæˆä¸€ç»„ç›¸å…³åˆ†æ•°ã€‚</p>
<ul>
<li><p>ç±»ä¼¼äºMatching Networkï¼Œç½‘ç»œé¦–å…ˆè®¡ç®—æ¯ä¸ªå•ç‹¬ç¤ºä¾‹$x_i$ç›¸å¯¹äºæ•´ä¸ªæ”¯æŒé›†ï¼ˆsupport setï¼‰çš„å®Œæ•´ä¸Šä¸‹æ–‡åµŒå…¥</p>
</li>
<li><p>ç„¶åç»™å®šä¸€ä¸ªè¡ŒåŠ¨å»ºè®®$\hat{x}$åŠå…¶ç¼–ç å‘é‡$g(x_i)$ï¼Œç›¸ä¼¼æ€§ç½‘ç»œè®¡ç®—æè®®è¡¨ç¤ºä¸æ‰€æœ‰ç¤ºä¾‹ä¹‹é—´çš„<strong>ä½™å¼¦è·ç¦»</strong>ï¼š</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fruajf2q51j30b701wwej.jpg" alt="mage-20180531100105"></p>
</li>
<li><p>æ¥ç€åŸºäºä¸Šè¿°è·ç¦»ï¼ŒåŸå§‹åŒ¹é…ç½‘ç»œä½¿ç”¨å…³æ³¨æœºåˆ¶å’ŒæŠ•ç¥¨ç­–ç•¥å°†æµ‹è¯•æ•°æ®åˆ†ç±»åˆ°æ”¯æŒé›†ä¸­çš„ä¸€ä¸ªç±»ä¸­</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1frub8m9vjtj309t029weg.jpg" alt="mage-20180531102522"></p>
</li>
<li><p>æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œç”±äºæ”¯æŒé›†åªç”±å‰æ™¯ç±»ç»„æˆï¼Œè¿™ç§åˆ†ç±»æ–¹æ³•ä¸é€‚ç”¨äºå®šä½ä»»åŠ¡ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»åŒºåˆ†å‰æ™¯å’ŒèƒŒæ™¯ã€‚ å› æ­¤ï¼Œåœ¨æœ¬æ–‡çš„ one-shot action localization æ¶æ„ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸ä¼¼æ€§ç½‘ç»œè®¡ç®—ç›¸å…³åˆ†æ•°ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªå•ç‹¬çš„æ ‡ç­¾ç½‘ç»œæ¥æ¨æ–­æ¯ä¸ªææ¡ˆçš„ç±»åˆ«æ ‡ç­¾ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰ã€‚</p>
</li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1frua9w27e6j30fs0b2di1.jpg" alt=""></p>
</li>
<li><p><strong>Labeling Network:</strong> è®¾ç½®ä¸åŒé•¿åº¦çš„æ—¶é—´çª—å£ï¼Œæ ¹æ®æ—¶é—´çª—å£å†…çš„encoding vectorå’Œcorrelation scoresï¼Œç¬¬ä¸‰ä¸ªç½‘ç»œä¼šåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­é¢„æµ‹ææ¡ˆçš„åŠ¨ä½œç±»åˆ«æ ‡ç­¾ï¼ˆä½œä¸ºå‰æ™¯ç±»åˆ«æˆ–èƒŒæ™¯ä¹‹ä¸€ï¼‰ã€‚</p>
<ul>
<li>æ ‡è®°ç½‘ç»œç›´æ¥åº”ç”¨äºç›¸å…³çŸ©é˜µã€‚ ç±»ä¼¼äºé€šè¿‡æ¯”è¾ƒä½™å¼¦è·ç¦»è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨çŸ­æš‚çš„æ—¶é—´è·¨åº¦ä¸Šåœ¨ç›¸å…³çŸ©é˜µä¸Šåº”ç”¨å…¨è¿æ¥å±‚æ¥æ¯”è¾ƒç›¸å…³çŸ©é˜µçš„ç›¸åŒåˆ—çš„ä¸åŒè¡Œï¼Œå¹¶ä¸”è¾“å‡ºåœ¨å‰æ™¯å’Œé€šè¿‡sigmoidæ¿€æ´»çš„èƒŒæ™¯ã€‚</li>
<li>å…¨è¿æ¥ç½‘ç»œæ²¿æ—¶é—´ç»´åº¦æ»‘è¿‡ç›¸å…³çŸ©é˜µï¼Œä¸ºæ¯ä¸ªææ¡ˆç¡®å®šå‰æ™¯/èƒŒæ™¯ã€‚ åœ¨æ ‡ç­¾ç½‘ç»œç¡®å®šä¸ºå‰æ™¯çš„æè®®ä¸­ï¼Œå…¬å¼6åº”ç”¨äºé¢„æµ‹åŠ¨ä½œæ ‡ç­¾ï¼Œå¦‚æ¡†æ¶å›¾çš„ä¸ŠåŠéƒ¨åˆ†æ‰€ç¤ºã€‚</li>
<li>ç›¸å…³çŸ©é˜µåŒ…å«æœ‰å…³ç‰¹å®šç‰¹å®šç±»çš„ä¿¡æ¯ä»¥åŠææ¡ˆæ˜¯å±äºèƒŒæ™¯è¿˜æ˜¯å±äºå‰æ™¯ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä¸ä¸€ä¸ªç¤ºä¾‹çš„å…³è”æ¯”å…¶ä»–ç¤ºä¾‹çš„å…³è”é«˜å¾—å¤šï¼Œé‚£ä¹ˆè¯¥æè®®å¾ˆå¯èƒ½å±äºå‰æ™¯å¹¶ä¸”ä¸ç¤ºä¾‹å…·æœ‰ç›¸åŒçš„åŠ¨ä½œæ ‡ç­¾; å¦‚æœä¸æ‰€æœ‰ä¾‹å­çš„ç›¸å…³æ€§éƒ½æ¯”è¾ƒä½ï¼Œé‚£ä¹ˆå®ƒå¯èƒ½å±äºèƒŒæ™¯ã€‚ <strong>æ ‡ç­¾ç½‘ç»œé€šè¿‡è®­ç»ƒå­¦ä¹ è¿™äº›æ ‡å‡†ã€‚</strong></li>
<li>è¿˜è¦æ³¨æ„æ ‡ç­¾ç½‘ç»œåœ¨æŸç§æ„ä¹‰ä¸Š<strong>ç‹¬ç«‹äºåŠ¨ä½œç±»åˆ«</strong>ï¼Œå› ä¸ºå®ƒåº”ç”¨äºç›¸å…³çŸ©é˜µè€Œä¸æ˜¯æ¯ä¸ªè§†é¢‘çš„ç‰¹å¾è¡¨ç¤ºã€‚ è¿™æ„å‘³ç€å®ƒå­¦åˆ°çš„æ ‡å‡†åº”è¯¥é€‚ç”¨äºè¾“å…¥æ¥è‡ªä¸åŒç±»åˆ«çš„è§†é¢‘ï¼Œ<strong>è¿™ä½¿å¾—å®ƒé€‚ç”¨äºä¸€æ¬¡æ€§é¢„æµ‹ã€‚</strong></li>
<li>åå¤„ç†é˜¶æ®µï¼šæˆ‘ä»¬ç»“åˆå¤šå°ºåº¦ proposal-level é¢„æµ‹æ¥è·å¾—frame-levelçš„å•å¸§çº§é¢„æµ‹ï¼Œå¹¶å°†ç›¸åŒæ ‡å·çš„ç›¸é‚»å¸§åˆ†ç»„ä»¥è·å¾—åŠ¨ä½œå®ä¾‹ã€‚</li>
</ul>
</li>
</ul>
</li>
<li><p>æœ¬æ–‡çš„å®šä½ç³»ç»Ÿæ˜¯é’ˆå¯¹ one-shot action localization è€Œè®¾è®¡çš„ï¼Œç›¸åº”çš„ Meta Learning Formulation å¯ç”¨äºæ¨¡å‹çš„è®­ç»ƒã€‚ ç³»ç»Ÿçš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½æ˜¯å¯å¯¼çš„ï¼Œå¹¶ä¸”å¯ä»¥å¯¹ç³»ç»Ÿè¿›è¡Œç«¯åˆ°ç«¯çš„åŸ¹è®­ã€‚ ç„¶è€Œï¼Œä¸ºäº†è·å¾—æ›´å¥½çš„åˆå§‹åŒ–å’Œæ€§èƒ½ï¼Œæˆ‘ä»¬å¯¹<strong>Video Encoder Network</strong>å’Œ<strong>Similarity Network</strong>è¿›è¡Œäº†é¢„è®­ç»ƒã€‚ </p>
<ul>
<li><p>Meta Learning Formulation</p>
<ul>
<li>åœ¨å…ƒå­¦ä¹ ä¸­ï¼Œæ¨¡å‹åœ¨ä¸€ç»„è®­ç»ƒä»»åŠ¡çš„å…ƒé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼Œå¹¶å¯¹å¦ä¸€ç»„æµ‹è¯•ä»»åŠ¡è¿›è¡Œè¯„ä¼°</li>
<li>å…ƒå­¦ä¹ çš„ç›®æ ‡æ˜¯åœ¨å…ƒæµ‹è¯•ä»»åŠ¡åˆ†å¸ƒä¸­æ‰¾åˆ°æœ€å°åŒ–æŸå¤±çš„æ¨¡å‹</li>
</ul>
</li>
<li><p>Optimization for the Localization System</p>
<ul>
<li><p>æŸå¤±å‡½æ•°ä¸ºï¼š</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1frujibjlk1j30bw01c748.jpg" alt=""></p>
<p>å…¶ä¸­ï¼Œä¸¤ä¸ªæŸå¤±å‡½æ•°åˆ†åˆ«å¦‚ä¸‹ï¼š</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1frujixrzcpj30dk03h74i.jpg" alt="mage-20180531151204"></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1frujj5jzvsj30cy02udfy.jpg" alt="mage-20180531151217"></p>
</li>
</ul>
</li>
<li><p>Pretraining for Video Encoder &amp; Similarity Net</p>
<ul>
<li><p>é¢„è®­ç»ƒä¸¤è€…çš„æŸå¤±å‡½æ•°ï¼š</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1frujmmshe5j30df01wq2y.jpg" alt="mage-20180531151538"></p>
</li>
<li><p>åˆ©ç”¨åˆ°äº†ä¸€ä¸ªRanking Lossï¼Œå…¶ç›´è§‚çš„æƒ³æ³•æ˜¯ï¼šå½“ç»™äºˆè¶Šæ¥è¶Šå¤šçš„è§†é¢‘å†…å®¹ï¼Œåˆ†ç±»å™¨ä¼šç”Ÿæˆè¶Šæ¥è¶Šç½®ä¿¡åº¦é«˜çš„é¢„æµ‹</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ul>
<li><p>å®éªŒåœ¨<strong>Thumos14</strong>å’Œ<strong>ActivityNet 1.2</strong>ä¸Šè¿›è¡Œè¯„ä¼°</p>
</li>
<li><p><strong>One-shoté—®é¢˜è®¾ç½®è¦æ±‚æµ‹è¯•æœŸé—´çš„ç±»åˆ«ä¸å¾—å­˜åœ¨åœ¨è®­ç»ƒæœŸé—´</strong>ï¼Œå› æ­¤åœ¨è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­éœ€è¦å¯¹ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œåˆ’åˆ†ï¼Œä»è€Œè¾¾åˆ°è¿™ä¸€è¦æ±‚</p>
</li>
<li><p>è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µæœ‰å¾ˆå¤šç»†èŠ‚ï¼Œå»ºè®®çœ‹è®ºæ–‡ï¼Œè¿™é‡Œä¸å†èµ˜è¿°</p>
</li>
<li><p>å’Œå¼ºç›‘ç£æ–¹æ³•çš„æ¯”è¾ƒï¼Œæˆ‘ä»¬ä»è¡¨1å’Œè¡¨2å¯ä»¥çœ‹å‡ºï¼Œè™½ç„¶one-shotå’Œå…¨ç›‘ç£è¡Œä¸ºæ£€æµ‹ä¹‹é—´ä»ç„¶å­˜åœ¨æ€§èƒ½å·®è·ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»¥one-shotè®¾ç½®è¿›è¡Œæµ‹è¯•æ—¶ï¼Œæ˜¾ç€ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ æˆ‘ä»¬åœ¨Thumos14æ•°æ®é›†ä¸Šä½¿ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œæ¯ç±»15ä¸ªæ ·æœ¬è¿›ä¸€æ­¥æµ‹è¯•æˆ‘ä»¬çš„æ–¹æ³•ã€‚ æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ€§èƒ½å‡ºç°æ˜æ˜¾æå‡ï¼Œè€ŒCDCåªæœ‰å¾ˆå°çš„æå‡ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•ç›¸å¯¹äºæ ·æœ¬æ•°é‡<strong>å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§</strong>ã€‚</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1frujw8cs54j30fz0a1q59.jpg" alt="mage-20180531152451"></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1frujwobo2qj30fw0ct40u.jpg" alt="mage-20180531152512"></p>
</li>
<li><p>è¿˜æœ‰ä¸€äº›æ¶ˆèæ¢ç©¶å®éªŒï¼Œè¿™é‡Œä¹Ÿä¸å†èµ˜è¿°</p>
</li>
</ul>
<h3 id="ä¼˜ç‚¹"><a href="#ä¼˜ç‚¹" class="headerlink" title="ä¼˜ç‚¹"></a>ä¼˜ç‚¹</h3><ul>
<li>é’ˆå¯¹ç›®å‰è§†é¢‘æ•°æ®é›†æ ‡æ³¨è´¹æ—¶ã€éš¾ä»¥è·å¾—ç­‰ç—›ç‚¹ï¼Œä½œè€…é¦–æ¬¡å°†one(few)-shotçš„æ–¹æ³•å¼•å…¥äº†æ—¶é—´è½´å®šä½ï¼Œå¾ˆæœ‰åˆ›æ–°ç‚¹ï¼Œå’Œå¼±ç›‘ç£å­¦ä¹ æœ‰å¼‚æ›²åŒå·¥ä¹‹å¦™</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºåŒ¹é…ç½‘ç»œæ¡†æ¶çš„åŠ¨ä½œå®šä½é—®é¢˜çš„<strong>å…ƒå­¦ä¹ æ–¹æ³•</strong>ï¼Œå®ƒèƒ½å¤Ÿæ•è·<strong>ä»»åŠ¡çº§åˆ«ï¼ˆtask-levelï¼‰çš„å…ˆéªŒçŸ¥è¯†</strong></li>
<li>åå¤„ç†ä¸­çš„groupingç­–ç•¥å¯ä»¥è¦ç”¨åœ¨æˆ‘ä¹‹å‰çš„å·¥ä½œä¸­</li>
</ul>
<h3 id="ç¼ºç‚¹"><a href="#ç¼ºç‚¹" class="headerlink" title="ç¼ºç‚¹"></a>ç¼ºç‚¹</h3><ul>
<li>æ€§èƒ½ç›®å‰çœ‹æ¥å¹¶ä¸æ˜¯ç‰¹åˆ«ç†æƒ³ï¼Œå’Œå…¨ç›‘ç£çš„æ–¹æ³•è¿˜æœ‰å·®è·ï¼Œè¿˜æœ‰å¾ˆå¤šæ”¹è¿›çš„ç©ºé—´ï¼Œè¿™å¯èƒ½éœ€è¦å¤šå»äº†è§£ä¸€äº›<strong>one-shot learningæˆ–transfer learning</strong>ç­‰æ–¹å‘çš„è®ºæ–‡ã€‚</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„å¦ä¸€ç¯‡ï¼ŒåŸºäºå­¦ä¹ çš„æ—¶é—´è½´åŠ¨ä½œå®šä½æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ã€‚ ç„¶è€Œï¼Œè¿™æ ·çš„å¤§è§„æ¨¡è§†é¢‘æ•°æ®é›†ä¸ä»…éå¸¸éš¾ä»¥è·å¾—è€Œä¸”å¯èƒ½å› ä¸ºå­˜åœ¨æ— æ•°çš„åŠ¨ä½œç±»åˆ«è€Œä¸å®ç”¨ã€‚ å½“è®­ç»ƒæ ·æœ¬å°‘ä¸”ç½•è§æ—¶ï¼Œå½“å‰æ–¹æ³•çš„å¼Šç«¯å°±æš´éœ²å‡ºæ¥äº†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨åŒ¹é…ç½‘ç»œçš„One-shotå­¦ä¹ æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨ç›¸å…³æ€§æ¥æŒ–æ˜å’Œå®šä½ä»¥å‰æ²¡æœ‰çœ‹è¿‡ç±»åˆ«çš„è¡Œä¸ºã€‚ æœ¬æ–‡åœ¨THUMOS14å’ŒActivityNetæ•°æ®é›†ä¸Šè¯„ä¼°äº†æœ¬æ–‡çš„one-shotåŠ¨ä½œå®šä½æ–¹æ³•ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Action Detection" scheme="http://jacobkong.github.io/tags/Action-Detection/"/>
    
      <category term="è¡Œä¸ºæ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E8%A1%8C%E4%B8%BA%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>è¡Œä¸ºæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šRethinking the Faster R-CNN Architecture for Temporal Action Localization</title>
    <link href="http://jacobkong.github.io/posts/3697434189/"/>
    <id>http://jacobkong.github.io/posts/3697434189/</id>
    <published>2018-05-29T07:51:24.000Z</published>
    <updated>2018-05-30T09:13:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„ä¸€ç¯‡ï¼Œè§£å†³äº†ç›®å‰ç°å­˜æ–¹æ³•ä¸­çš„3ä¸ªé—®é¢˜ï¼šï¼ˆ1ï¼‰Multi-scaleçš„åŠ¨ä½œç‰‡æ®µï¼›ï¼ˆ2ï¼‰Temproal contextçš„åˆ©ç”¨ï¼›ï¼ˆ3ï¼‰Multi-stream ç‰¹å¾èåˆã€‚æ–¹æ³•åœ¨THUMOSâ€™ 14æ•°æ®é›†ä¸Šçš„æè®®å’Œæ£€æµ‹ä»»åŠ¡ä¸Šè¾¾åˆ°ç›®å‰æœ€å¥½çš„æ•ˆæœï¼ˆmAP@tIoU=0.5è¾¾åˆ°42.8%ï¼‰ï¼Œåœ¨ActivityNetæ•°æ®åŠä¸Šå–å¾—äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•ˆæœã€‚</p>
<a id="more"></a>
<h3 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h3><ul>
<li><p>æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹å…¶å®å’Œç›®æ ‡æ£€æµ‹ç›¸ç±»ä¼¼ï¼Œå› æ­¤ç›®å‰è®¸å¤šè¡Œä¸ºæ£€æµ‹çš„æ–¹æ³•éƒ½å—å¯å‘äºç›®æ ‡æ£€æµ‹çš„ä¸€äº›å…ˆè¿›æ–¹æ³•ï¼Œæ¯”å¦‚R-CNNç³»åˆ—ï¼Œå…ˆä»æ•´ä¸ªè§†é¢‘ä¸­ç”Ÿæˆsegments proposalï¼Œç„¶åç”¨åˆ†ç±»å™¨å»å¯¹è¿™äº›proposalè¿›è¡Œåˆ†ç±»ã€‚</p>
</li>
<li><p>ç›®å‰æœ‰ä¸€äº›æ–¹æ³•å°†Faster R-CNNè¿ç§»åˆ°æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹ä¸­ï¼Œç„¶è€Œç›´æ¥è¿ç§»è¿‡æ¥å¼•å…¥ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚ä¸‹ï¼š</p>
<ul>
<li><p>å¦‚ä½•å¤„ç†è¡ŒåŠ¨æŒç»­æ—¶é—´çš„å·¨å¤§å˜åŒ–ï¼Ÿ</p>
<blockquote>
<p>å› ä¸ºè¡Œä¸ºä¼šæœ‰è®¸å¤šæ—¶é—´é•¿çŸ­ä¸ä¸€çš„æŒç»­æ—¶é—´ï¼Œä»å‡ ç§’åˆ°å‡ åˆ†é’Ÿçš„è¡Œä¸ºç‰‡æ®µéƒ½æœ‰ï¼Œè€ŒFaster R-CNNåˆ©ç”¨anchoræproposalä¼šåœ¨ç‰¹å¾çš„temporal scopeå’Œanchorçš„spanä¹‹é—´äº§ç”Ÿmisalignmentç°è±¡ã€‚<strong>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªmulti-towerç½‘ç»œå’Œåˆ©ç”¨æ‰©å¼ æ—¶é—´å·ç§¯ï¼ˆdilated temporal convolutionsï¼‰æ¥è§£å†³alignmentçš„é—®é¢˜ã€‚</strong></p>
</blockquote>
</li>
<li><p>å¦‚ä½•åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Ÿ</p>
<blockquote>
<p>åŠ¨ä½œå®ä¾‹ä¹‹å‰å’Œä¹‹åçš„æ—¶åˆ»åŒ…å«å…³äºå®šä½å’Œåˆ†ç±»çš„å…³é”®ä¿¡æ¯ï¼ˆå¯ä»¥è¯´æ¯”å¯¹è±¡çš„ç©ºé—´ä¸Šä¸‹æ–‡æ›´é‡è¦ï¼‰ã€‚Faster R-CNNæ²¡æœ‰åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚<strong>æˆ‘ä»¬å»ºè®®é€šè¿‡æ‰©å±•ææ¡ˆç”Ÿæˆå’ŒåŠ¨ä½œåˆ†ç±»ä¸­çš„æ„Ÿå—é‡æ¥æ˜ç¡®åœ°ç¼–ç æ—¶é—´ä¸Šä¸‹æ–‡ã€‚</strong></p>
</blockquote>
</li>
<li><p>å¦‚ä½•æœ€å¥½çš„å»èåˆmulti-streamçš„ç‰¹å¾ï¼Ÿ</p>
<blockquote>
<p>å¯¹äºFaster R-CNNæ¢ç´¢è¿™ç§RGBå’ŒFlowç‰¹å¾èåˆæ–¹é¢çš„å·¥ä½œæœ‰é™ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåæœŸèåˆæ–¹æ¡ˆï¼Œå¹¶ä¸”ç»éªŒæ€§åœ°è¯æ˜äº†å®ƒåœ¨ä¸€èˆ¬çš„æ—©æœŸèåˆæ–¹æ¡ˆä¸Šçš„ä¼˜åŠ¿ã€‚</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="ç›®çš„"><a href="#ç›®çš„" class="headerlink" title="ç›®çš„"></a>ç›®çš„</h3><p>è§£å†³Faster R-CNNç›´æ¥å¼•å…¥åˆ°æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹ä¸­çš„ä¸Šè¿°3ä¸ªæŒ‘æˆ˜,å¹¶ä»¥æ­¤æ¥æå‡Faster R-CNNåœ¨è¡Œä¸ºæ£€æµ‹ä¸­çš„æ€§èƒ½.</p>
<h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>è®ºæ–‡æ¡†æ¶å¦‚ä¸‹ï¼š</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1frr390sqxsj30ua0a4adx.jpg" alt="mage-20180528153210"></p>
<p>æœ¬æ–‡æå‡ºäº†TAL-Netï¼Œæœ‰ä¸‰ä¸ªåˆ›æ–°çš„ç»“æ„æ”¹å˜ï¼š</p>
<ul>
<li><p>Receptive Field Alignment</p>
<ul>
<li><p>ä¼ ç»Ÿçš„anchoræœºåˆ¶æœ‰ä¸€ä¸ªç¼ºç‚¹ï¼šæ¯ä¸ªæ—¶é—´ç‚¹çš„é”šç‚¹åˆ†ç±»éƒ½æœ‰ç›¸åŒçš„å•ä¸€çš„æ„Ÿå—é‡ã€‚</p>
</li>
<li><p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®å°†æ¯ä¸ªé”šç‚¹çš„æ„Ÿå—é‡ä¸å®ƒçš„æ—¶é—´è·¨åº¦å¯¹é½ã€‚ è¿™æ˜¯é€šè¿‡ä¸¤ä¸ªå…³é”®å› ç´ å®ç°çš„ï¼šmulti-towerç½‘ç»œå’Œæ‰©å¼ æ—¶é—´å·ç§¯ï¼ˆdilated temporal convolutionsï¼‰ã€‚</p>
</li>
<li><p>ç»™å®šä¸€ä¸ªä¸€ç»´feature mapï¼Œæˆ‘ä»¬çš„Segment Proposal Network ç”±Kä¸ªtemproal ConvNets ç»„æˆï¼Œæ¯ä¸ªKç½‘ç»œè´Ÿè´£å¯¹ç‰¹å®šæ¯”ä¾‹çš„é”šæ®µè¿›è¡Œåˆ†ç±».æœ€é‡è¦çš„æ˜¯ï¼Œæ¯ä¸ªæ—¶é—´ConvNetéƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä½¿å¾—å…¶æ¥å—çš„å­—æ®µå¤§å°ä¸ç›¸å…³çš„é”šç‚¹å°ºåº¦ä¸€è‡´ã€‚ åœ¨æ¯ä¸ªConvNetç»“æŸæ—¶ï¼Œæˆ‘ä»¬åˆ†åˆ«åº”ç”¨ä¸¤ä¸ªæ ¸å¿ƒå¤§å°ä¸º1çš„å¹³è¡Œå·ç§¯å±‚è¿›è¡Œé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›å½’ã€‚</p>
</li>
<li><p>å¦ä¸€é—®é¢˜ï¼šå¦‚ä½•è®¾è®¡å…·æœ‰å¯æ§æ„Ÿå—é‡sçš„æ—¶é—´å·ç§¯ï¼Ÿ</p>
<ul>
<li><p>æ–¹æ³•ä¸€ï¼šå¦‚æœs=2L+1ï¼Œåˆ™å åŠ Lå±‚å·ç§¯å±‚å¾—åˆ°ç›¸åº”çš„æ„Ÿå—é‡ã€‚ç¼ºç‚¹æ˜¯å±‚æ•°Léšç€sçº¿æ€§å¢åŠ ï¼Œå¾ˆå®¹æ˜“å¢åŠ å‚æ•°æ•°é‡ä½¿ç½‘ç»œè¿‡æ‹Ÿåˆã€‚</p>
</li>
<li><p>æ–¹æ³•äºŒï¼šåœ¨æ¯ä¸€å±‚å·ç§¯å±‚åæ·»åŠ ä¸€ä¸ªkernel sizeä¸º2çš„poolingå±‚ï¼Œåˆ™æ„Ÿå—é‡$s=2^{(L+1)}-1$ï¼Œæ­¤æ—¶å±‚æ•°éšç€sæˆlogå˜åŒ–ï¼Œä½†æ˜¯æ·»åŠ poolingå±‚ä¼šå‡å°è¾“å‡ºfeature mapçš„åˆ†è¾¨ç‡ï¼Œä¼šå½±å“å®šä½å‡†ç¡®ç‡ã€‚</p>
</li>
<li><p>æ–¹æ³•ä¸‰ï¼šä½¿ç”¨æ‰©å……æ—¶é—´å·ç§¯ï¼Œè¿™ç§å·ç§¯å¯ä»¥åœ¨æ‰©å……æ„Ÿå—é‡çš„åŒæ—¶ä¸æŸå¤±åˆ†è¾¨ç‡ã€‚åœ¨æˆ‘ä»¬çš„Segment Proposal Networkä¸­ï¼Œæ¯ä¸€ä¸ªtemporal ConvNetéƒ½åªç”±2ä¸ªdilated convolutional layersç»„æˆã€‚ä¸ºäº†è·å¾—ä¸€ä¸ªç›®æ ‡æ„Ÿå—é‡sï¼Œåˆ™ç¬¬ä¸€å±‚çš„dilated convolutional layersçš„dilation rate $r_1=s/6, r_2=(s/6)\times2$. </p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1frpy9obbp6j30g70bsjss.jpg" alt=""></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Context Feature Extraction</p>
<ul>
<li><p>æ—¶é—´è½´ä¸Šä¸‹æ–‡ä¿¡æ¯ååˆ†é‡è¦</p>
</li>
<li><p>ä¸ºäº†ç¡®ä¿ä¸Šä¸‹æ–‡ç‰¹å¾ç”¨äºé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›å½’ï¼Œæ„Ÿå—é‡å¿…é¡»è¦†ç›–æ—¶é—´è½´ä¸Šä¸‹æ–‡ä¿¡æ¯åŒºåŸŸï¼Œå¯ä»¥é€šè¿‡å°†dilation rateåŠ å€ï¼Œå³$r_1=s/6\times2, r_2=(s/6)\times2\times2$ï¼Œå¦‚ä¸‹ï¼š</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1frpysrksxjj30fq0b53zx.jpg" alt=""></p>
</li>
<li><p>åœ¨åŠ¨ä½œåˆ†ç±»é˜¶æ®µï¼Œæˆ‘ä»¬è¦åˆ©ç”¨SoI poolingæ¥ä¸ºæ¯ä¸ªproposalæå–ä¸€ä¸ªå›ºå®šå°ºå¯¸çš„feature map</p>
</li>
</ul>
</li>
<li><p>Late Feature Fusion</p>
<ul>
<li>ç›®å‰è®¸å¤šæ–¹æ³•éƒ½åœ¨ä½¿ç”¨RGBå’Œå…‰æµç‰¹å¾</li>
<li>æœ¬æ–‡ä¸ºåŒæµç‰¹å¾æå‡ºäº†ä¸€ä¸ªåèåˆçš„æœºåˆ¶</li>
<li>ä»¬é¦–å…ˆä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„ç½‘ç»œåˆ†åˆ«ä»RGBå¸§å’Œå åŠ çš„å…‰æµä¸­æå–ä¸¤ä¸ªä¸€ç»´ç‰¹å¾æ˜ å°„ã€‚ æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¸åŒçš„Segment Proposal Networkæ¥å¤„ç†æ¯ä¸ªfeature maï¼Œè¯¥ç½‘ç»œå¹¶è¡Œåœ°ç”Ÿæˆé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›å½’çš„é€»è¾‘ã€‚ æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªä¸¤ä¸ªç½‘ç»œçš„logitsçš„å…ƒç´ å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆçš„é€»è¾‘æ¥ç”Ÿæˆæè®®ã€‚ å¯¹äºæ¯ä¸ªææ¡ˆï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªç‰¹å¾æ˜ å°„ä¸Šå¹¶è¡Œæ‰§è¡ŒSoIæ± ï¼Œå¹¶åœ¨æ¯ä¸ªè¾“å‡ºä¸Šåº”ç”¨ä¸åŒçš„DNNåˆ†ç±»å™¨ã€‚</li>
</ul>
</li>
</ul>
<h3 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h3><ul>
<li><p>åŸºäºTensorFlowç›®æ ‡æ£€æµ‹API</p>
</li>
<li><p>9ä¸ªanchorï¼Œscalesä¸º{1, 2, 3, 4, 5, 6, 8, 11, 16}</p>
</li>
<li><p>NMSé˜ˆå€¼ä¸º0.7å»ç­›é€‰proposalï¼Œä¿ç•™å‰300ä¸ªproposalç”¨äºåˆ†ç±»</p>
</li>
<li><p>THUMOSâ€™ 14æ£€æµ‹ç»“æœ</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1frq0h25kllj30g20goadr.jpg" alt=""></p>
</li>
<li><p>ActivityNet v1.3åœ¨éªŒè¯é›†çš„æ£€æµ‹ç»“æœ</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1frq0m3der6j30ft07d0u2.jpg" alt=""></p>
</li>
</ul>
<h3 id="ä¼˜ç‚¹"><a href="#ä¼˜ç‚¹" class="headerlink" title="ä¼˜ç‚¹"></a>ä¼˜ç‚¹</h3><p>ç›¸æ¯”äºR-C3Dï¼Œæœ¬æ–‡çš„æ–¹æ³•è§£å†³äº†Multi-scaleçš„é—®é¢˜ï¼Œåˆ©ç”¨äº†ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥åŠé¢å¤–çš„å…‰æµä¿¡æ¯ï¼Œè§£å†³äº†ç›®å‰è®¸å¤šæ–¹æ³•ä¸­å­˜åœ¨çš„å¤§å¤§å°å°çš„ç¼ºé™·ï¼Œç»„åˆæˆäº†ä¸€ä¸ªè¾ƒä¸ºå®Œæ•´çš„æ¡†æ¶ï¼Œå› æ­¤åœ¨THUMOSâ€™ 14æ•°æ®é›†ä¸Šæ£€æµ‹æ•ˆæœè¾¾åˆ°æœ€å¥½ï¼Œåœ¨ActivityNetæ•°æ®é›†ä¸Šä¹Ÿå–å¾—äº†å¾ˆæœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œä½†æ˜¯è¿˜æ˜¯ä¸å¦‚SSNçš„ç»“æœã€‚æ–‡ä¸­åˆ†æï¼šTHUMOSâ€™ 14æ˜¯ä¸€ä¸ªæ›´å¥½çš„ç”¨æ¥è¯„ä¼°è¡Œä¸ºå®šä½çš„æ•°æ®é›†ï¼Œå› ä¸ºå…¶æ¯æ®µè§†é¢‘ä¸­åŒ…å«æœ‰æ›´å¤šçš„è¡Œä¸ºå®ä¾‹ï¼Œå¹¶ä¸”æ¯æ®µè§†é¢‘åŒ…å«å¤§é‡çš„èƒŒæ™¯æ´»åŠ¨ã€‚</p>
<h3 id="ç¼ºç‚¹"><a href="#ç¼ºç‚¹" class="headerlink" title="ç¼ºç‚¹"></a>ç¼ºç‚¹</h3><p>æˆ‘è®¤ä¸ºé™¤äº†ç¬¬ä¸€ç‚¹åˆ›æ–°ï¼šåˆ©ç”¨dilated temporal convlutionalç»„æˆæ„Ÿå—é‡å¯æ§çš„multi-towerç½‘ç»œæ¥è§£å†³multi-scaleé—®é¢˜æ¯”è¾ƒæœ‰åˆ›æ–°å¤–ï¼Œå¦å¤–ä¸¤ç‚¹åˆ›æ–°å…¶å®ä¸ç®—ç‰¹åˆ«æœ‰æ–°æ„ã€‚</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„ä¸€ç¯‡ï¼Œè§£å†³äº†ç›®å‰ç°å­˜æ–¹æ³•ä¸­çš„3ä¸ªé—®é¢˜ï¼šï¼ˆ1ï¼‰Multi-scaleçš„åŠ¨ä½œç‰‡æ®µï¼›ï¼ˆ2ï¼‰Temproal contextçš„åˆ©ç”¨ï¼›ï¼ˆ3ï¼‰Multi-stream ç‰¹å¾èåˆã€‚æ–¹æ³•åœ¨THUMOSâ€™ 14æ•°æ®é›†ä¸Šçš„æè®®å’Œæ£€æµ‹ä»»åŠ¡ä¸Šè¾¾åˆ°ç›®å‰æœ€å¥½çš„æ•ˆæœï¼ˆmAP@tIoU=0.5è¾¾åˆ°42.8%ï¼‰ï¼Œåœ¨ActivityNetæ•°æ®åŠä¸Šå–å¾—äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•ˆæœã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Action Detection" scheme="http://jacobkong.github.io/tags/Action-Detection/"/>
    
      <category term="è¡Œä¸ºæ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E8%A1%8C%E4%B8%BA%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡è°ƒç ”ï¼šICCV 2017è®ºæ–‡è°ƒç ”</title>
    <link href="http://jacobkong.github.io/posts/679115822/"/>
    <id>http://jacobkong.github.io/posts/679115822/</id>
    <published>2017-11-25T07:51:24.000Z</published>
    <updated>2018-05-28T07:34:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Visual-object-tracking"><a href="#Visual-object-tracking" class="headerlink" title="Visual object tracking"></a>Visual object tracking</h2><ul>
<li><h4 id="Learning-Policies-for-Adaptive-Tracking-with-Deep-Feature-Cascades"><a href="#Learning-Policies-for-Adaptive-Tracking-with-Deep-Feature-Cascades" class="headerlink" title="Learning Policies for Adaptive Tracking with Deep Feature Cascades"></a>Learning Policies for Adaptive Tracking with Deep Feature Cascades</h4><ul>
<li>Our fundamental insight is to take an adaptive approach, where easy frames are processed with cheap features (such as pixel values), while challenging frames are processed with invariant but expensive deep features.</li>
<li>Formulate the adaptive tracking problem as a decision-making process.</li>
<li>Learn an agent to decide whether to locate objects with high conï¬dence on an early layer, or continue processing subsequent layers of a network.</li>
</ul>
</li>
</ul>
<ul>
<li>Signiï¬cantly reduces the feedforward cost.</li>
<li>Train the agent ofï¬‚ine in a reinforcement learning fashion.</li>
<li>Obviously, the major computational burden comes from the forward pass through the entire network, and can be larger with deeper architectures.</li>
<li>However, when the object is visually distinct or barely moves, early layers are in most scenarios sufï¬cient for precise localization - offering the potential for substantial computational savings.</li>
<li>The agent learns to ï¬nd the target at each layer, and decides if it is conï¬dent enough to output and stop there.</li>
</ul>
<a id="more"></a>
<ul>
<li><h4 id="Tracking-The-Untrackable-Learning-to-Track-Multiple-Cues-with-Long-Term-Dependencies"><a href="#Tracking-The-Untrackable-Learning-to-Track-Multiple-Cues-with-Long-Term-Dependencies" class="headerlink" title="Tracking The Untrackable: Learning to Track Multiple Cues with Long-Term Dependencies"></a>Tracking The Untrackable: Learning to Track Multiple Cues with <strong>Long-Term Dependencies</strong></h4><ul>
<li>Combine cues in a coherent end-to-end fashion over a <strong>long period of time.</strong></li>
<li>Present a structure of Recurrent Neural Networks (RNN) that jointly reasons on multiple cues over a temporal window.</li>
<li>We are able to <strong>correct many data association errors</strong> and recover observations from an occluded state.</li>
</ul>
</li>
<li><h4 id="Tracking-as-Online-Decision-Making-Learning-a-Policy-from-Streaming-Videos-with-Reinforcement-Learning"><a href="#Tracking-as-Online-Decision-Making-Learning-a-Policy-from-Streaming-Videos-with-Reinforcement-Learning" class="headerlink" title="Tracking as Online Decision-Making: Learning a Policy from Streaming Videos with Reinforcement Learning"></a>Tracking as Online Decision-Making: Learning a Policy from Streaming Videos with Reinforcement Learning</h4><ul>
<li>A tracking agent must follow an object despite ambiguous image frames and a limited computational budget.</li>
<li>The agent must decide<ul>
<li>where to look in the upcoming frames</li>
<li>when to reinitialize because it believes the target has been lost</li>
<li>when to update its appearance model for the tracked object</li>
</ul>
</li>
<li>Formulating tracking as a partially observable decision-making process (POMDP).</li>
<li><strong>Sparse rewards</strong> allow us to quickly train on massive datasets.</li>
<li>Challenges:<ul>
<li>First, the limited quantity of annotated video data impedes both training and evaluation.</li>
<li>Second, as vision (re)integrates with robotics, video processing must be done in an online, streaming fashion.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Face-detection"><a href="#Face-detection" class="headerlink" title="Face detection"></a>Face detection</h3><ul>
<li><h4 id="S3FD-Single-Shot-Scale-invariant-Face-Detector"><a href="#S3FD-Single-Shot-Scale-invariant-Face-Detector" class="headerlink" title="S3FD - Single Shot Scale-invariant Face Detector."></a>S3FD - Single Shot Scale-invariant Face Detector.</h4><ul>
<li>Use a single deep neural network, especially for small faces.</li>
<li>Contribution<ul>
<li>æå‡ºä¸€ä¸ªå°ºåº¦å…¬å¹³çš„äººè„¸æ£€æµ‹æ¡†æ¶æ¥å¤„ç†ä¸åŒå°ºåº¦çš„äººè„¸ã€‚æˆ‘ä»¬åœ¨å„ç§å„æ ·çš„å›¾å±‚ä¸Šæ‹¼è´´anchorï¼Œä»¥ç¡®ä¿æ‰€æœ‰äººè„¸çš„æ¯”ä¾‹å°ºéƒ½å…·æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”¨äºæ£€æµ‹ã€‚åŸºäºæœ‰æ•ˆæ¥æ”¶åŸŸ<strong>ï¼ˆeffective receptive ï¬eldï¼‰</strong>å’Œç­‰æ¯”ä¾‹åŒºé—´åŸåˆ™<strong>ï¼ˆequal proportion interval principleï¼‰</strong>è®¾è®¡anchor</li>
<li>ç”¨å°ºåº¦è¡¥å¿anchoråŒ¹é…ç­–ç•¥<strong>ï¼ˆ a scale compensation anchor matching strategyï¼‰</strong>æé«˜å°è„¸çš„å¬å›ç‡; </li>
<li>é€šè¿‡æœ€å¤§åŒ–èƒŒæ™¯æ ‡ç­¾<strong>ï¼ˆ max-out background labelï¼‰</strong>å‡å°‘å°è„¸çš„è¯¯æŠ¥ç‡ã€‚</li>
<li>effective receptive ï¬eld: Understanding the effective receptive ï¬eld in deep convolutional neural networks.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Salient-Object-Detection"><a href="#Salient-Object-Detection" class="headerlink" title="Salient Object Detection"></a>Salient Object Detection</h3><ul>
<li><h4 id="Amulet-Aggregating-Multi-level-Convolutional-Features-for-Salient-Object-Detection"><a href="#Amulet-Aggregating-Multi-level-Convolutional-Features-for-Salient-Object-Detection" class="headerlink" title="Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection"></a>Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection</h4><ul>
<li>How to better aggregate multi-level convolutional feature maps for salient object detection is <strong>underexplored</strong>.</li>
<li>Our framework:<ul>
<li>First integrates multi-level feature maps into multiple resolutions, which simultaneously incorporate coarse semantics and ï¬ne details. </li>
<li>Then it adaptively learns to combine these feature maps at each resolution and <strong>predict saliency maps with the combined features.</strong> </li>
<li>Finally, the predicted results are efï¬ciently fused to generate the <strong>ï¬nal saliency map</strong>.</li>
</ul>
</li>
<li>In addition, edge-aware maps and high-level predictions are embedded into the framework.</li>
</ul>
</li>
<li><h4 id="Learning-Uncertain-Convolutional-Features-for-Accurate-Saliency-Detection"><a href="#Learning-Uncertain-Convolutional-Features-for-Accurate-Saliency-Detection" class="headerlink" title="Learning Uncertain Convolutional Features for Accurate Saliency Detection"></a><a href="http://openaccess.thecvf.com/content_iccv_2017/html/Zhang_Learning_Uncertain_Convolutional_ICCV_2017_paper.html" target="_blank" rel="external">Learning Uncertain Convolutional Features for Accurate Saliency Detection</a></h4><ul>
<li>The key contribution of this work is to learn deep uncertain convolutional features (UCF), which encourage the robustness and accuracy of saliency detection.</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ··åˆä¸Šé‡‡æ ·æ–¹æ³•æ¥å‡å°‘æˆ‘ä»¬çš„è§£ç å™¨ç½‘ç»œä¸­å»å·ç§¯ç®—å­çš„æ£‹ç›˜ä¼ªå½±ã€‚</li>
<li>We ï¬nd that the actual cause of these artifacts is the upsampling mechanism, which generally utilizes the deconvolution operation.</li>
</ul>
</li>
</ul>
<h3 id="Action-Related"><a href="#Action-Related" class="headerlink" title="Action Related"></a>Action Related</h3><ul>
<li><h4 id="Encouraging-LSTMs-to-Anticipate-Actions-Very-Early"><a href="#Encouraging-LSTMs-to-Anticipate-Actions-Very-Early" class="headerlink" title="Encouraging LSTMs to Anticipate Actions Very Early"></a>Encouraging LSTMs to Anticipate Actions Very Early</h4><ul>
<li>Action anticipation - identify the action from only partially available videos.</li>
<li>To this end, we develop a <strong>multi-stage LSTM architecture</strong> that leverages <strong>context-aware</strong> and <strong>action-aware</strong> features, and introduce <strong>a novel loss function</strong> that encourages the model to predict the correct class as early as possible.</li>
<li>Intuitive: our loss models the intuition that some actions, such as running and high jump, are highly ambiguous after seeing only the ï¬rst few frames, and <strong>false positives</strong> should therefore not be penalized too strongly in the early stages.</li>
<li>We would like to predict a high probability for the correct class <strong>as early as possible</strong>, and thus penalize <strong>false negatives</strong> from the beginning of the sequence.</li>
<li>Contribute a novel multi-stage Long Short Term Memory (LSTM) architecture for action anticipation. This model effectively extracts and jointly exploits context- and action-aware features.</li>
<li>Existing method drawbacks:<ul>
<li>This is in contrast to existing methods that typically extract either <strong>global representations</strong> for the entire image or video sequence thus <strong>not focusing on the action itself, or localize the feature extraction process to the action itself</strong> via dense trajectories  optical ï¬‚ow or actionness, thus <strong>failing to exploit contextual information.</strong></li>
<li>åˆ©ç”¨å…‰æµä¸å…è®¸è¿™äº›æ–¹æ³•åœ¨localizationè¿‡ç¨‹ä¸­æ˜ç¡®åœ°åˆ©ç”¨å¤–è§‚ã€‚</li>
<li>Computing optical ï¬‚ow is typically expensive.</li>
</ul>
</li>
<li>In the future, we intend to study new ways to incorporate additional sources of information, such as <strong>dense trajectories</strong> and <strong>human skeletons</strong> in our framework.</li>
</ul>
</li>
<li><h4 id="Unsupervised-Action-Discovery-and-Localization-in-Videos"><a href="#Unsupervised-Action-Discovery-and-Localization-in-Videos" class="headerlink" title="Unsupervised Action Discovery and Localization in Videos"></a>Unsupervised Action Discovery and Localization in Videos</h4><ul>
<li>åˆ›æ–°ï¼šæ— ç›‘ç£çš„action localizationã€‚</li>
<li>First to address the problem of unsupervised action localization in videos.</li>
<li><p>We propose a novel approach that:</p>
<ul>
<li>Discovers action class labels</li>
<li>Spatio-temporally localizes actions in videos.</li>
</ul>
</li>
<li><p>Method:</p>
<ul>
<li>It begins by computing local video features to apply <strong>spectral clustering</strong> on a set of unlabeled training videos.<ul>
<li>For each cluster of videos, an <strong>undirected graph</strong> is constructed to extract a dominant set, which are known for <strong>high internal homogeneity</strong> and <strong>in-homogeneity</strong> between vertices outside it.</li>
</ul>
</li>
<li>Next, a <strong>discriminative clustering approach</strong> is applied, by training a classiï¬er for each cluster, to iteratively select videos from the non-dominant set and obtain complete video action classes.<ul>
<li>Once classes are discovered, training videos within each cluster are selected to perform <strong>automatic spatio-temporal annotations</strong>, by ï¬rst over-segmenting videos in each discovered class into <strong>supervoxels</strong>ï¼ˆè¶…ä½“ç´ ï¼‰ and constructing a <strong>directed graph</strong> ï¼ˆæœ‰å‘å›¾ï¼‰to apply a variant of knapsack problem with temporal constraints. ï¼ˆå¹¶æ„å»ºæœ‰å‘å›¾ä»¥åº”ç”¨å…·æœ‰æ—¶é—´çº¦æŸçš„èƒŒåŒ…é—®é¢˜çš„å˜ä½“ã€‚ï¼‰</li>
</ul>
</li>
<li>èƒŒåŒ…ä¼˜åŒ–è”åˆæ”¶é›†è¶…ä½“ç´ çš„ä¸€ä¸ªå­é›†ï¼Œé€šè¿‡å¼ºåˆ¶æ³¨é‡Šçš„åŠ¨ä½œè¿›è¡Œæ—¶ç©ºè¿æ¥ï¼Œå…¶ä½“ç§¯æ˜¯ä¸€ä¸ªactorçš„å¤§å°ã€‚These annotations are used to train SVM action classiï¬ers.</li>
</ul>
</li>
<li>åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæ“ä½œä½¿ç”¨ç±»ä¼¼çš„èƒŒåŒ…æ–¹æ³•æ¥è¿›è¡Œlocalizeï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­å°†è¶…ä½“ç´ åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ä½¿ç”¨æ¥è‡ªå‘ç°çš„åŠ¨ä½œç±»çš„è§†é¢‘å­¦ä¹ çš„SVMè¢«ç”¨äºè¯†åˆ«è¿™äº›åŠ¨ä½œã€‚</li>
<li>However, supervised algorithms have some disadvantages compared to unsupervised approaches, due to the difï¬culty of video annotation.</li>
<li>Contributionsï¼š<ul>
<li>Automatic discovery of action class labels using <strong>a new discriminative clustering approach</strong> with dominant sets (Sec. 3).</li>
<li>We propose a novel <strong>Knapsack approach</strong> with <strong>graph-based temporal constraints</strong> to <strong>annotate actions</strong> in training videos</li>
<li>The annotations within each cluster of videos are jointly selected by <strong>Binary Integer Quadratic Programming (BIQP)</strong> optimization to train action classiï¬ers.</li>
<li><strong>Structural SVM</strong> is used to learn the pairwise relations of supervoxels within foreground action and foreground-background, which enforces that the supervoxels belonging to the action to be simultaneously selected.</li>
<li>Lastly, we address a new problem of <strong>Unsupervised Action Localization</strong> (Sec. 5.2).</li>
</ul>
</li>
</ul>
</li>
<li><h4 id="Dense-Captioning-Events-in-Videos"><a href="#Dense-Captioning-Events-in-Videos" class="headerlink" title="Dense-Captioning Events in Videos"></a>Dense-Captioning Events in Videos</h4><ul>
<li>We introduce the task of dense-captioning events, which involves both detecting and describing events in a video.</li>
<li>Our model introduces a variant of an existing proposal module that is designed to capture both short as well as long events that span minutes.</li>
<li>To <strong>capture the dependencies between the events in a video</strong>, our model introduces a <strong>new captioning module</strong> that uses <strong>contextual information</strong> from past and future events to jointly describe all events.</li>
<li>While the success of these methods is encouraging, they all share one key limitation: <strong>detail.</strong></li>
<li>We introduce the task of <strong>dense-captioning events</strong>, which requires a model to generate a set of descriptions for multiple events occurring in the video and localize them in time.</li>
<li>However, we observe that densecaptioning events comes with its own set of challenges distinct from the image case.<ul>
<li>One observation is that events in videos can range across multiple time scales and can even overlap.<ul>
<li>Past captioning works have circumvented this problem by encoding the entire video sequence by <strong>mean-pooling</strong> [50] or by using a <strong>recurrent neural network (RNN)</strong> [49].</li>
<li>To overcome this limitation, we extend recent work on generating action proposals [10] to <strong>multi-scale detection of events.</strong></li>
</ul>
</li>
<li>Another key observation is that the events in a given video <strong>are usually related to one another.</strong> <ul>
<li>We introduce a <strong>captioning module</strong> that utilizes the context from all the events from our proposal module to generate each sentence.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><h4 id="Learning-long-term-dependencies-for-action-recognition-with-a-biologically-inspired-deep-network"><a href="#Learning-long-term-dependencies-for-action-recognition-with-a-biologically-inspired-deep-network" class="headerlink" title="Learning long-term dependencies for action recognition with a biologically-inspired deep network"></a>Learning long-term dependencies for action recognition with a biologically-inspired deep network</h4><ul>
<li>How to efï¬ciently learn long-term dependencies from sequences still remains a pretty challenging task.</li>
<li>As one of the key models for sequence learning, <strong>recurrent neural network (RNN)</strong> and its variants such as <strong>long short term memory (LSTM)</strong> and <strong>gated recurrent unit (GRU)</strong> are still not powerful enough in practice.<ul>
<li>One possible reason is that they have only feedforward connections, which is different from the biological neural system that is typically composed of <strong>both feedforward and feedback connections.</strong>(æ—¢æœ‰å‰ä¼ ï¼Œä¹Ÿæœ‰åé¦ˆ)</li>
</ul>
</li>
<li>Propose <strong>shuttleNet technologically.</strong></li>
<li>The shuttleNet <strong>consists of several processors</strong>, each of which is a GRU while <strong>associated with multiple groups of cells and states.</strong></li>
<li><strong>Attention mechanism</strong> is then employed to select the best information ï¬‚ow pathway.</li>
</ul>
</li>
<li><h4 id="Adaptive-RNN-Tree-for-Large-Scale-Human-Action-Recognition"><a href="#Adaptive-RNN-Tree-for-Large-Scale-Human-Action-Recognition" class="headerlink" title="Adaptive RNN Tree for Large-Scale Human Action Recognition"></a>Adaptive RNN Tree for Large-Scale Human Action Recognition</h4><ul>
<li>We present the RNN Tree (RNN-T), an adaptive learning framework for <strong>skeleton based human action recognition.</strong></li>
<li>Our method categorizes action classes and <strong>uses multiple Recurrent Neural Networks (RNNs)</strong> in a <strong>treelike hierarchy.</strong></li>
<li>åœ¨éª¨æ¶è¡¨ç¤ºä¸­çš„è¡Œä¸ºæ˜¯é€šè¿‡<strong>åˆ†å±‚æ¨ç†</strong>è¿‡ç¨‹æ¥è¯†åˆ«çš„ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œå•ç‹¬çš„RNNå°†ç»†åŒ–çš„è¡Œä¸ºç±»åˆ«ä¸å¢åŠ çš„ç½®ä¿¡åº¦</li>
<li>RNN-T effectively addresses two main challenges of large-scale action recognition:<ul>
<li>able to distinguish ï¬ne-grained action classes that are intractable using a single network</li>
<li>adaptive to new action classes by augmenting an existing model.</li>
</ul>
</li>
</ul>
</li>
<li><h4 id="Ensemble-Deep-Learning-for-Skeleton-based-Action-Recognition-using-Temporal-Sliding-LSTM-networks"><a href="#Ensemble-Deep-Learning-for-Skeleton-based-Action-Recognition-using-Temporal-Sliding-LSTM-networks" class="headerlink" title="Ensemble Deep Learning for Skeleton-based Action Recognition using Temporal Sliding LSTM networks"></a>Ensemble Deep Learning for Skeleton-based Action Recognition using Temporal Sliding LSTM networks</h4><ul>
<li>Traditional methods generally use relative coordinate systems dependent on some joints, and model <strong>only the long-term dependency</strong>, while excluding <strong>short-term and medium term dependencies.</strong></li>
<li>We transform the skeletons into <strong>another coordinate system</strong> to obtain the robustness to scale, rotation and translation and then extract salient motion features from them.</li>
<li>We propose novel ensemble <strong>Temporal Sliding LSTM (TS-LSTM) networks</strong> for skeleton-based action recognition. The proposed network is composed of multiple parts containing <strong>short-term, medium-term and long-term TS-LSTM networks</strong>.</li>
<li>With a rapid development of 3D data acquisition over the past few decades, lots of researches on <strong>human activity recognition from 3D data</strong> can have been actively performed.</li>
<li>For the modeling of human actions, recent researches show tha<strong>t Long Short-Term Memory (LSTM) networks</strong> are <strong>superior to</strong> temporal pyramids and hidden markov models.</li>
<li>Overall Methodï¼š<ul>
<li>Firstly, we transform the coordinates of input skeleton sequences so that the data can be <strong>robust to scale, rotation and translation.</strong> </li>
<li>Secondly, instead of using the simple joint positions, we employ the <strong>motion features</strong> in terms of temporal differences, which help our networks to be focused on the actual skeleton movements. </li>
<li>Thirdly, the motion features are processed with <strong>multi-term LSTMs containing short-term, medium-term and long-term LSTMs</strong>, which allow robustness to variable temporal dynamics. </li>
<li>Finally, the multi-term LSTMs <strong>capture a variety of action dynamics through ensemble.</strong></li>
</ul>
</li>
</ul>
</li>
<li><h4 id="What-Actions-are-Needed-for-Understanding-Human-Actions-in-Videos"><a href="#What-Actions-are-Needed-for-Understanding-Human-Actions-in-Videos" class="headerlink" title="What Actions are Needed for Understanding Human Actions in Videos?"></a>What Actions are Needed for Understanding Human Actions in Videos?</h4><ul>
<li>We analyze the current state of human activity understanding in videos.</li>
<li>The goal of this paper is to examine datasets, evaluation metrics, algorithms, and potential future directions.</li>
<li>The results demonstrate that while there is inherent ambiguity in the temporal extent of activities, current datasets still permit effective benchmarking.</li>
<li>æˆ‘ä»¬å‘ç°ï¼Œå½“ä¸æ—¶é—´æ¨ç†ç›¸ç»“åˆæ—¶ï¼Œå¯¹ç‰©ä½“å’Œå§¿æ€çš„ç»†ç²’åº¦ç†è§£å¾ˆå¯èƒ½åœ¨ç®—æ³•ç²¾åº¦ä¸Šäº§ç”Ÿå®è´¨æ€§çš„æ”¹å–„ã€‚</li>
<li>Some questions:<ul>
<li>What is an activity and how should we represent it? </li>
<li>Do activities have well-deï¬ned spatial and temporal extent? </li>
<li>What role do goals and intentions play in deï¬ning and understanding activities?</li>
<li>What does the data show about the right categories for recognition in case of activities? </li>
<li>Do existing approaches scale with increasing complexity of activities categories, video data, or temporal relationships between activities? </li>
<li>Are the hypothesized new avenues of studying context, objects, or intentions worthwhile: Do these really help in understanding videos?</li>
</ul>
</li>
<li>This paper provides an in-depth analysis of the <strong>new generation of video datasets</strong>, <strong>human annotators</strong>, <strong>activity categories</strong>, <strong>recognition approaches</strong>, and above all possible new cues for video understanding.</li>
<li>We found that people considered verbs to be relatively more ambiguous.</li>
<li>This suggests that despite boundary ambiguity, current datasets allow us to understand, learn from, and evaluate the temporal extents of activities.</li>
<li>That is, a perfect classiï¬er would automatically do 5 times better than current state-of-the-art [30] on activity localization.</li>
<li>This suggests that focusing our attention on gaining more insight into activity classiï¬cation would naturally yield signiï¬cant improvements in localization accuracy as well.</li>
<li>Having concluded that:<ul>
<li>(1) we should be reasoning about activities as (verb,object) pairs rather than just verb,</li>
<li>(2) temporal boundaries of activities are ambiguous but nevertheless meaningful, and</li>
<li>(3) classiï¬cation of short videos is a reasonable proxy for temporal localization</li>
</ul>
</li>
<li>This suggests that moving forward ï¬ne-grained discrimination between activities with similar objects and verbs is needed.</li>
</ul>
</li>
<li><h4 id="Lattice-Long-Short-Term-Memory-for-Human-Action-Recognition"><a href="#Lattice-Long-Short-Term-Memory-for-Human-Action-Recognition" class="headerlink" title="Lattice Long Short-Term Memory for Human Action Recognition"></a>Lattice Long Short-Term Memory for Human Action Recognition</h4><ul>
<li>However, naively applying RNNs to video sequences in a convolutional manner implicitly assumes that motions in videos are <strong>stationary</strong> across different spatial locations. <strong>This assumption is valid for short-term motions but invalid when the duration of the motion is long.</strong></li>
<li>In this work, we propose Lattice-LSTM (L^2STM), which extends LSTM by learning <strong>independent hidden state transitions</strong> of memory cells for individual spatial locations.</li>
<li>Additionally, we introduce a novel multi-modal training procedure for training our network.</li>
<li>An accurate action recognition should:<ul>
<li>(1) have a high capacity for learning and capturing as many motion dynamics as possible</li>
<li>(2) when an action appears in sequential images, the neurons should properly decide what kind of spatio-temporal dynamics should be encoded into the memory for distinguishing actions.</li>
</ul>
</li>
</ul>
</li>
<li><h4 id="Common-Action-Discovery-and-Localization-in-Unconstrained-Videos"><a href="#Common-Action-Discovery-and-Localization-in-Unconstrained-Videos" class="headerlink" title="Common Action Discovery and Localization in Unconstrained Videos"></a>Common Action Discovery and Localization in Unconstrained Videos</h4><ul>
<li>In this work, we tackle the problem of <strong>common action discovery</strong> and <strong>localization</strong> in unconstrained videos, where we do not assume to know the types, numbers or locations of the common actions in the videos.</li>
<li>To perform automatic discovery and localization in such challenging scenarios, we ï¬rst generate action proposals using human prior.</li>
<li>By building an afï¬nity graph among all action proposals, we formulate the common action discovery as <strong>a subgraph density maximization problem</strong> to select the proposals containing common actions.</li>
<li>ä¸ºäº†é¿å…åœ¨æŒ‡æ•°çº§å¤§çš„è§£ç©ºé—´ä¸­æšä¸¾ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„å¤šé¡¹å¼æ—¶é—´ä¼˜åŒ–ç®—æ³•ã€‚</li>
<li>It solves the problem up to a user speciï¬ed error bound with respect to the global optimal solution.</li>
<li>Action discoveryçš„å›°éš¾ï¼š<ul>
<li>é¦–å…ˆï¼Œç”±äºæˆ‘ä»¬äº‹å…ˆä¸çŸ¥é“åœ¨ç»™å®šçš„æ•°æ®é›†ä¸­å¸¸è§çš„åŠ¨ä½œç±»å‹æˆ–ä½ç½®ï¼Œæˆ‘ä»¬å¿…é¡»åŒæ—¶è¿›è¡Œå‘ç°å’Œå®šä½ã€‚ ç»™å®šä¸€ç»„æœªæ ‡è®°çš„è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦è‡ªåŠ¨è¯†åˆ«ä¸€ç»„æ•è·å¸¸è§æ“ä½œçš„æ—¶ç©ºè¾¹ç•Œæ¡†ã€‚</li>
<li>å…¶æ¬¡ï¼Œç±»ä¼¼çš„è¡Œä¸ºä¹Ÿå¯èƒ½ç”±äºè§†ç‚¹å˜åŒ–ï¼Œå°ºåº¦å˜åŒ–æˆ–ç›¸æœºè¿åŠ¨è€Œå‡ºç°ä¸åŒã€‚ è‡ªåŠ¨å…³è”è¿™äº›å¸¸è§æ“ä½œå¹¶ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ã€‚</li>
<li>æœ€åï¼Œé™¤äº†å¸¸è§çš„åŠ¨ä½œä¹‹å¤–ï¼Œè§†é¢‘è¿˜å¯èƒ½åŒ…å«åŠ¨æ€èƒŒæ™¯æˆ–ä¸å¸¸è§çš„åŠ¨ä½œï¼Œå› æ­¤å°†è¿™ç§â€œnoisy motionsâ€ä¸å¸¸è§åŠ¨ä½œåŒºåˆ†å¼€æ¥æ˜¯è‡³å…³é‡è¦çš„ã€‚</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Pedestrian-Related"><a href="#Pedestrian-Related" class="headerlink" title="Pedestrian Related"></a>Pedestrian Related</h3><ul>
<li><h4 id="HydraPlus-Net-Attentive-Deep-Features-for-Pedestrian-Analysis"><a href="#HydraPlus-Net-Attentive-Deep-Features-for-Pedestrian-Analysis" class="headerlink" title="HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis"></a>HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis</h4><ul>
<li>Learning of comprehensive features of pedestrians for ï¬ne-grained tasks remains an open problem.</li>
<li>HydraPlus-Net: multi-directionally feeds the multi-level attention maps to different feature layers.</li>
<li>Advantages: <ul>
<li>(1) the model is capable of capturing <strong>multiple attentions</strong> from low-level to semantic-level</li>
<li>(2) it explores the <strong>multi-scale selectiveness of attentive features</strong> to enrich the ï¬nal feature representations for a pedestrian image.</li>
</ul>
</li>
<li>We demonstrate the effectiveness and generality of the proposed HP-net for pedestrian analysis on two tasks, i.e. <strong>pedestrian attribute recognition</strong> and <strong>person reidentiï¬cation.</strong></li>
<li>However, the learning of feature representation for pedestrian images, as the backbone for all those applications, still confronts critical challenges and needs profound studies.</li>
<li>However, existing arts merely extract global features [13, 24, 30] and are hardly effective to location-aware semantic pattern extraction.</li>
<li><strong>Multidirectional attention (MDA) modules</strong></li>
<li>Reliable 3D <strong>skeleton-based action recognition (SAR)</strong> is now feasible [1].</li>
<li>Although much progress has been achieved, these methods are still facing two challenges.<ul>
<li>We term the ï¬rst one as the <strong>discriminative challenge.</strong></li>
<li>We term the second challenge as <strong>adaptability</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Pose-Estimation"><a href="#Pose-Estimation" class="headerlink" title="Pose Estimation"></a>Pose Estimation</h3><ul>
<li><h4 id="Towards-3D-Human-Pose-Estimation-in-the-Wild-A-Weakly-Supervised-Approach"><a href="#Towards-3D-Human-Pose-Estimation-in-the-Wild-A-Weakly-Supervised-Approach" class="headerlink" title="Towards 3D Human Pose Estimation in the Wild: A Weakly-Supervised Approach"></a><a href="http://openaccess.thecvf.com/content_iccv_2017/html/Zhou_Towards_3D_Human_ICCV_2017_paper.html" target="_blank" rel="external">Towards 3D Human Pose Estimation in the Wild: A Weakly-Supervised Approach</a></h4><ul>
<li>We propose a <strong>weakly-supervised transfer learning</strong> method that uses mixed 2D and 3D labels in a uniï¬ed deep neutral network that presents two-stage cascaded structure.</li>
</ul>
</li>
</ul>
<h3 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h3><ul>
<li><h4 id="Flow-Guided-Feature-Aggregation-for-Video-Object-Detection"><a href="#Flow-Guided-Feature-Aggregation-for-Video-Object-Detection" class="headerlink" title="Flow-Guided Feature Aggregation for Video Object Detection"></a>Flow-Guided Feature Aggregation for Video Object Detection</h4><ul>
<li>Video object detection</li>
<li>The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc.</li>
<li>We present ï¬‚ow-guided feature aggregation, an accurate and <strong>end-to-end</strong> learning framework for <strong>video object detection.</strong></li>
<li>It leverages <strong>temporal coherence</strong> on feature level instead.</li>
<li>å®ƒé€šè¿‡æ²¿ç€è¿åŠ¨è·¯å¾„èšé›†é™„è¿‘çš„ç‰¹å¾æ¥æ”¹è¿›æ¯å¸§ç‰¹å¾ï¼Œä»è€Œæé«˜äº†è§†é¢‘è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚</li>
<li>Fast moving objects.</li>
</ul>
</li>
<li><h4 id="DeNet-Scalable-Real-time-Object-Detection-with-Directed-Sparse-Sampling"><a href="#DeNet-Scalable-Real-time-Object-Detection-with-Directed-Sparse-Sampling" class="headerlink" title="DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling"></a>DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</h4><ul>
<li>We deï¬ne the object detection from imagery problem as estimating a very large but <strong>extremely sparse bounding box</strong> dependent probability distribution. ï¼ˆæˆ‘ä»¬å°†å›¾åƒé—®é¢˜ä¸­çš„ç›®æ ‡æ£€æµ‹å®šä¹‰ä¸ºä¼°è®¡éå¸¸å¤§ä½†æå…¶ç¨€ç–çš„è¾¹ç•Œæ¡†ç›¸å…³æ¦‚ç‡åˆ†å¸ƒã€‚ï¼‰</li>
<li>Two novelties:<ul>
<li>a <strong>corner based</strong> region-of-interest estimator</li>
<li>a <strong>deconvolution based</strong> CNN model</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Image-Recognition"><a href="#Image-Recognition" class="headerlink" title="Image Recognition"></a>Image Recognition</h3><ul>
<li><h4 id="Multi-label-Image-Recognition-by-Recurrently-Discovering-Attentional-Regions"><a href="#Multi-label-Image-Recognition-by-Recurrently-Discovering-Attentional-Regions" class="headerlink" title="Multi-label Image Recognition by Recurrently Discovering Attentional Regions"></a>Multi-label Image Recognition by Recurrently Discovering Attentional Regions</h4><ul>
<li>Current solutions for this task usually rely on an extra step of extracting hypothesis regions (i.e., region proposals), resulting in <strong>redundant computation</strong> and <strong>sub-optimal performance.</strong></li>
<li>Developing a recurrent memorized-attention module.</li>
<li>This module consists of two alternately performed components:<ul>
<li>a spatial transformer layer to locate attentional regions from the convolutional feature maps in a region-proposal-free way</li>
<li>an LSTM (Long-Short Term Memory) sub-network to sequentially predict semantic labeling scores on the located regions while capturing the global dependencies of these regions.</li>
</ul>
</li>
<li>Despite acknowledged successes, these methods take the redundant computational cost of extracting region proposals and usually over-simplify the contextual dependencies among foreground objects, leading to a sub-optimal performance in complex scenarios.</li>
</ul>
</li>
</ul>
<p>  â€‹<br>  â€‹<br>  â€‹<br>  â€‹    </p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Visual-object-tracking&quot;&gt;&lt;a href=&quot;#Visual-object-tracking&quot; class=&quot;headerlink&quot; title=&quot;Visual object tracking&quot;&gt;&lt;/a&gt;Visual object tracking&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h4 id=&quot;Learning-Policies-for-Adaptive-Tracking-with-Deep-Feature-Cascades&quot;&gt;&lt;a href=&quot;#Learning-Policies-for-Adaptive-Tracking-with-Deep-Feature-Cascades&quot; class=&quot;headerlink&quot; title=&quot;Learning Policies for Adaptive Tracking with Deep Feature Cascades&quot;&gt;&lt;/a&gt;Learning Policies for Adaptive Tracking with Deep Feature Cascades&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Our fundamental insight is to take an adaptive approach, where easy frames are processed with cheap features (such as pixel values), while challenging frames are processed with invariant but expensive deep features.&lt;/li&gt;
&lt;li&gt;Formulate the adaptive tracking problem as a decision-making process.&lt;/li&gt;
&lt;li&gt;Learn an agent to decide whether to locate objects with high conï¬dence on an early layer, or continue processing subsequent layers of a network.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Signiï¬cantly reduces the feedforward cost.&lt;/li&gt;
&lt;li&gt;Train the agent ofï¬‚ine in a reinforcement learning fashion.&lt;/li&gt;
&lt;li&gt;Obviously, the major computational burden comes from the forward pass through the entire network, and can be larger with deeper architectures.&lt;/li&gt;
&lt;li&gt;However, when the object is visually distinct or barely moves, early layers are in most scenarios sufï¬cient for precise localization - offering the potential for substantial computational savings.&lt;/li&gt;
&lt;li&gt;The agent learns to ï¬nd the target at each layer, and decides if it is conï¬dent enough to output and stop there.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="è®ºæ–‡è°ƒç ”" scheme="http://jacobkong.github.io/tags/%E8%AE%BA%E6%96%87%E8%B0%83%E7%A0%94/"/>
    
  </entry>
  
  <entry>
    <title>è¡Œä¸ºè¯†åˆ«è®ºæ–‡ç¬”è®°ï¼šè¡Œä¸ºåˆ†ç±»æ·±åº¦æ¨¡å‹çš„æ€»ç»“.md</title>
    <link href="http://jacobkong.github.io/posts/679115822/"/>
    <id>http://jacobkong.github.io/posts/679115822/</id>
    <published>2017-11-24T07:51:24.000Z</published>
    <updated>2017-11-29T08:42:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ¬¡ä¸»è¦æ€»ç»“äº†ç›®å‰å¸¸è§ä¸€äº›ç»å…¸çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è¡Œä¸ºåˆ†ç±»æ¨¡å‹ã€‚å…¶ä¸­çš„ä¸»è¦å†…å®¹æ¥è‡ªäºè®ºæ–‡ã€ŠQuo Vadis, Action Recognition? A New Model and the Kinetics Datasetã€‹ä¸­çš„Related Workéƒ¨åˆ†çš„æ€»ç»“ã€‚</p>
<a id="more"></a>
<p>è™½ç„¶è¿‘å¹´æ¥å›¾åƒè¡¨ç¤ºä½“ç³»ç»“æ„çš„å‘å±•å·²ç»è¿…é€Ÿæˆç†Ÿï¼Œä½†è§†é¢‘çš„å‰ç«¯è¿è¡Œæ¶æ„ä»ç„¶ä¸å¤Ÿæ¸…æ™°ã€‚å½“å‰è§†é¢‘ä½“ç³»ç»“æ„ä¸­çš„ä¸€äº›ä¸»è¦å·®å¼‚åœ¨äºconvolutional and layers operatorsæ˜¯ä½¿ç”¨2Dï¼ˆåŸºäºå›¾åƒçš„ï¼‰è¿˜æ˜¯3Dï¼ˆåŸºäºè§†é¢‘çš„ï¼‰kernels; æ— è®ºç½‘ç»œè¾“å…¥æ˜¯RGBè§†é¢‘æˆ–è€…è¿˜æ˜¯åŒ…å«é¢„å…ˆè®¡ç®—çš„å…‰æµï¼Œåœ¨2D ConvNetsçš„æƒ…å†µä¸‹ï¼Œå¯¹äºä¿¡æ¯å¦‚ä½•è·¨å¸§ä¼ æ’­ï¼Œè¿™å¯ä»¥é€šè¿‡ä½¿ç”¨è¯¸å¦‚LSTMä¹‹ç±»çš„temporally-recurrent layersæˆ–è€…éšç€æ—¶é—´çš„æ¨ç§»è¿›è¡Œç‰¹å¾èšåˆæ¥å®Œæˆã€‚</p>
<p>å›¾1æ˜¾ç¤ºäº†æˆ‘ä»¬è¯„ä¼°çš„äº”ç§ä½“ç³»ç»“æ„çš„å›¾å½¢æ¦‚è¿°ã€‚<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fly3z4y2x1j316f0cxaf1.jpg" alt="å›¾ 1. å„ç§è§†é¢‘æ¶æ„ã€‚å…¶ä¸­Kè¡¨ç¤ºä¸€ä¸ªè§†é¢‘ä¸­å…¨éƒ¨çš„å¸§æ•°ï¼ŒNè¡¨ç¤ºä¸€æ®µè§†é¢‘ç›¸é‚»å¸§å­é›†"></p>
<h3 id="æ¨¡å‹1ï¼šConvNet-LSTM"><a href="#æ¨¡å‹1ï¼šConvNet-LSTM" class="headerlink" title="æ¨¡å‹1ï¼šConvNet+LSTM"></a>æ¨¡å‹1ï¼šConvNet+LSTM</h3><p>å›¾åƒåˆ†ç±»ç½‘ç»œçš„é«˜æ€§èƒ½ä½¿å¾—æˆ‘ä»¬å°è¯•åªéœ€å¾ˆå°‘çš„æ”¹å˜å°±èƒ½å°†å…¶é‡ç”¨äºè§†é¢‘ä¸­ã€‚ é€šè¿‡ä½¿ç”¨å®ƒä»¬é’ˆå¯¹æ¯ä¸ªç‹¬ç«‹å¸§æå–ç‰¹å¾ï¼Œç„¶åé›†ä¸­åœ¨æ•´ä¸ªè§†é¢‘ä¸­æ¥æå–é¢„æµ‹ç»“æœæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ è¿™æ˜¯bag of wordså›¾åƒå»ºæ¨¡æ–¹æ³•çš„ç²¾ç¥; ä½†æ˜¯åœ¨å®è·µä¸­ä½¿ç”¨æ–¹ä¾¿çš„åŒæ—¶ï¼Œè¿˜å­˜åœ¨å®Œå…¨å¿½ç•¥æ—¶é—´ç»“æ„çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œæ¨¡å‹ä¸èƒ½å¾ˆå¥½çš„åŒºåˆ†å¼€é—¨å’Œå…³é—¨ï¼‰ã€‚</p>
<p>ç†è®ºä¸Šï¼Œæ›´ä»¤äººæ»¡æ„çš„æ–¹æ³•æ˜¯å‘æ¨¡å‹æ·»åŠ ä¸€ä¸ªrecurrent layerï¼Œä¾‹å¦‚å¯ä»¥å¯¹çŠ¶æ€è¿›è¡Œç¼–ç çš„LSTMï¼Œå¹¶æ•è·<strong>æ—¶é—´é¡ºåº</strong>å’Œ<strong>é•¿ç¨‹ä¾èµ–æ€§</strong>ã€‚ æœ¬æ–‡åœ¨æœ‰512ä¸ªéšè—å•å…ƒçš„Inception-V1çš„æœ€åçš„å¹³å‡æ± åŒ–å±‚ä¹‹åé˜²æ­¢äº†ä¸€ä¸ªæœ‰ç€BNçš„LSTMå±‚ï¼Œ ä¸€ä¸ªå…¨è¿æ¥å±‚è¢«æ·»åŠ åˆ°åˆ†ç±»å™¨çš„é¡¶éƒ¨ã€‚</p>
<p>è¯¥æ¨¡å‹å¯¹æ‰€æœ‰æ—¶é—´æ­¥éª¤çš„è¾“å‡ºä¸Šä½¿ç”¨äº¤å‰ç†µæŸå¤±è¿›è¡Œè®­ç»ƒã€‚ åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªè€ƒè™‘æœ€åä¸€å¸§çš„è¾“å‡ºã€‚</p>
<h3 id="æ¨¡å‹2ï¼š3D-ConvNets"><a href="#æ¨¡å‹2ï¼š3D-ConvNets" class="headerlink" title="æ¨¡å‹2ï¼š3D ConvNets"></a>æ¨¡å‹2ï¼š3D ConvNets</h3><p>3D ConvNetsä¼¼ä¹æ˜¯ä¸€ç§æ›´è‡ªç„¶çš„è§†é¢‘å»ºæ¨¡æ–¹æ³•ï¼Œå…¶å°±åƒæ ‡å‡†çš„å·ç§¯ç½‘ç»œä¸€æ ·ï¼Œä½†æ˜¯å…·æœ‰æ—¶ç©ºå·ç§¯æ ¸ã€‚<strong>å®ƒä»¬æœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„ç‰¹å¾</strong>ï¼šå®ƒä»¬ç›´æ¥åˆ›å»ºæ—¶ç©ºæ•°æ®çš„åˆ†å±‚è¡¨ç¤ºã€‚è¿™äº›æ¨¡å‹çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œç”±äºé™„åŠ çš„å†…æ ¸ç»´åº¦ï¼Œå®ƒä»¬æ¯”2D ConvNets<strong>æœ‰æ›´å¤šçš„å‚æ•°</strong>ï¼Œè¿™ä½¿å¾—å®ƒä»¬<strong>æ›´éš¾ä»¥è®­ç»ƒ</strong>ã€‚å¦å¤–ï¼Œå®ƒä»¬ä¼¼ä¹æ’é™¤äº†ImageNeté¢„è®­ç»ƒçš„å¥½å¤„ï¼Œå› æ­¤ä»¥å‰çš„å·¥ä½œå®šä¹‰äº†ç›¸å¯¹è¾ƒæµ…çš„æ¶æ„ï¼Œå¹¶ä¸”éƒ½æ˜¯train from scratchã€‚åŸºå‡†æµ‹è¯•çš„ç»“æœå…·æœ‰æå‡çš„å‰æ™¯ï¼Œä½†æ˜¯ä¸æœ€æ–°çš„æŠ€æœ¯æ°´å¹³ç›¸æ¯”è¿˜ä¸å…·æœ‰ç«äº‰æ€§ï¼Œä½¿å¾—è¿™ç§ç±»å‹çš„æ¨¡å‹æˆä¸ºè¯„ä¼°æˆ‘ä»¬å¤§å‹æ•°æ®é›†çš„å¥½é€‰æ‹©ã€‚</p>
<p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªC3Dæ¨¡å‹çš„å°å˜ä½“ï¼Œå®ƒåœ¨é¡¶éƒ¨æœ‰8ä¸ªå·ç§¯å±‚ï¼Œ5ä¸ªæ± åŒ–å±‚å’Œ2ä¸ªå®Œå…¨è¿æ¥çš„å±‚ã€‚æ¨¡å‹çš„è¾“å…¥ä¸åŸå§‹å®ç°ç›¸åŒï¼Œä½¿ç”¨112Ã—112åƒç´ å…±16å¸§ã€‚ä¸åŸå§‹C3Dä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨æ‰€æœ‰å·ç§¯å’Œå…¨è¿æ¥å±‚ä¹‹åä½¿ç”¨äº†batch normalizationã€‚å¦ä¸€ä¸ªåŒºåˆ«åœ¨äºå¯¹äºç¬¬ä¸€ä¸ªæ± åŒ–å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨stride=2è€Œä¸æ˜¯stride=1ï¼Œè¿™å‡å°‘äº†å†…å­˜å ç”¨ï¼Œå¹¶å…è®¸æ›´å¤§æ‰¹é‡ - è¿™å¯¹äºæ‰¹é‡æ ‡å‡†åŒ–éå¸¸é‡è¦ã€‚ä½¿ç”¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨æ ‡å‡†çš„K40 GPUåœ¨æ¯ä¸ªGPUä¸Šæ¯æ‰¹å¤„ç†15ä¸ªè§†é¢‘ã€‚</p>
<h3 id="æ¨¡å‹3ï¼šTwo-Stream-Networks"><a href="#æ¨¡å‹3ï¼šTwo-Stream-Networks" class="headerlink" title="æ¨¡å‹3ï¼šTwo-Stream Networks"></a>æ¨¡å‹3ï¼šTwo-Stream Networks</h3><p>æ¥è‡ªConvNetsæœ€åå±‚çš„ç‰¹å¾ï¼ŒLSTMå¯ä»¥æ¨¡æ‹Ÿé«˜å±‚æ¬¡çš„å˜åŒ–ï¼Œä½†æ˜¯å¯èƒ½æ— æ³•æ•è·åœ¨è®¸å¤šæƒ…å†µä¸‹éå¸¸å…³é”®çš„ç²¾ç»†çš„low-levelåŠ¨ä½œã€‚è®­ç»ƒä¹Ÿæ˜¯æ˜‚è´µçš„ï¼Œå› ä¸ºå®ƒéœ€è¦é€šè¿‡å¤šå¸§æ¥å±•å¼€ç½‘ç»œä»¥ä¾¿åå‘ä¼ æ’­ã€‚</p>
<p>Simonyanå’ŒZissermanä»‹ç»äº†ä¸€ç§ä¸åŒçš„éå¸¸å®ç”¨çš„æ–¹æ³•ï¼Œåœ¨é€šè¿‡ä¸¤ä¸ªå‰¯æœ¬ImageNeté¢„å…ˆè®­ç»ƒçš„ConvNetåï¼Œé€šè¿‡å¯¹æ¥è‡ªå•ä¸ªRGBå¸§çš„é¢„æµ‹å’Œ10ä¸ªå¤–éƒ¨è®¡ç®—çš„å…‰æµå¸§çš„é¢„æµ‹è¿›è¡Œå¹³å‡ï¼Œæ¥å¯¹è§†é¢‘çš„çŸ­æ—¶é—´å¿«ç…§è¿›è¡Œå»ºæ¨¡ã€‚å…‰æµ streamæœ‰ä¸€ä¸ªè‡ªé€‚åº”çš„è¾“å…¥å·ç§¯å±‚ï¼Œè¾“å…¥é€šé“çš„æ•°é‡æ˜¯å…‰æµå¸§çš„ä¸¤å€ï¼ˆå› ä¸ºæµé‡æœ‰ä¸¤ä¸ªé€šé“ï¼Œæ°´å¹³å’Œå‚ç›´ï¼‰ï¼Œåœ¨æµ‹è¯•æ—¶ï¼Œå¤šä¸ªå¿«ç…§ä»è§†é¢‘ä¸­é‡‡æ ·ï¼Œå¹¶å¯¹åŠ¨ä½œé¢„æµ‹è¿›è¡Œå¹³å‡ã€‚è¿™è¢«è¯æ˜åœ¨ç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸­å¾—åˆ°äº†éå¸¸é«˜çš„æ€§èƒ½ï¼ŒåŒæ—¶éå¸¸æœ‰æ•ˆåœ°è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚</p>
<p>æœ€è¿‘çš„ä¸€ä¸ªæ‰©å±•[8]å°†æœ€åä¸€ä¸ªç½‘ç»œå·ç§¯å±‚ä¹‹åçš„ç©ºé—´æµå’Œå…‰æµèåˆèµ·æ¥ï¼Œæ˜¾ç¤ºå‡ºå¯¹HMDBçš„ä¸€äº›æ”¹è¿›ï¼ŒåŒæ—¶éœ€è¦è¾ƒå°‘çš„æµ‹è¯•æ—¶é—´å¢é‡ï¼ˆå¿«ç…§é‡‡æ ·ï¼‰ã€‚æˆ‘ä»¬çš„å®ç°å¤§è‡´ä½¿ç”¨äº†Inception-V1ã€‚ç½‘ç»œçš„è¾“å…¥æ˜¯5ä¸ªè¿ç»­çš„RGBå¸§ï¼Œç›¸éš”10å¸§ï¼Œä»¥åŠç›¸åº”çš„å…‰æµç‰‡æ®µã€‚ Inception-V1ï¼ˆ5Ã—7Ã—7ç‰¹å¾ç½‘æ ¼ï¼Œå¯¹åº”äºæ—¶é—´xå’Œyç»´åº¦ï¼‰çš„æœ€åä¸€ä¸ªå¹³å‡æ±‡èšå±‚ä¹‹å‰çš„ç©ºé—´å’Œè¿åŠ¨ç‰¹å¾é€šè¿‡å…·æœ‰512ä¸ªè¾“å‡ºé€šé“çš„3Ã—3Ã—3çš„3Då·ç§¯å±‚ï¼Œç„¶åæ˜¯3Ã—3Ã—3çš„3Dæœ€å¤§æ± å±‚ï¼Œå¹¶é€šè¿‡æœ€ç»ˆçš„å®Œå…¨è¿æ¥å±‚ã€‚è¿™äº›æ–°å±‚çš„æƒé‡ç”¨é«˜æ–¯å™ªå£°åˆå§‹åŒ–ã€‚</p>
<p>ä¸¤ç§æ¨¡å‹ï¼ˆåŸå§‹åŒæµå’Œ3Dèåˆç‰ˆæœ¬ï¼‰éƒ½æ˜¯ç«¯å¯¹ç«¯è®­ç»ƒï¼ˆåŒ…æ‹¬åŸå§‹æ¨¡å‹ä¸­çš„åŒæµå¹³å‡æµç¨‹ï¼‰ã€‚</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æœ¬æ¬¡ä¸»è¦æ€»ç»“äº†ç›®å‰å¸¸è§ä¸€äº›ç»å…¸çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è¡Œä¸ºåˆ†ç±»æ¨¡å‹ã€‚å…¶ä¸­çš„ä¸»è¦å†…å®¹æ¥è‡ªäºè®ºæ–‡ã€ŠQuo Vadis, Action Recognition? A New Model and the Kinetics Datasetã€‹ä¸­çš„Related Workéƒ¨åˆ†çš„æ€»ç»“ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Action Recognition" scheme="http://jacobkong.github.io/tags/Action-Recognition/"/>
    
      <category term="è¡Œä¸ºè¯†åˆ«" scheme="http://jacobkong.github.io/tags/%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šDSSD</title>
    <link href="http://jacobkong.github.io/posts/2938514597/"/>
    <id>http://jacobkong.github.io/posts/2938514597/</id>
    <published>2017-03-31T07:51:24.000Z</published>
    <updated>2017-04-01T02:16:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºåœ¨å½“å‰æœ€å¥½çš„é€šç”¨ç›®æ ‡æ£€æµ‹å™¨ä¸­åŠ å…¥äº†é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>ä¸ºå®ç°è¿™ä¸€ç›®çš„ï¼šæˆ‘ä»¬é€šè¿‡å°†<strong>ResNet-101</strong>ä¸<strong>SSD</strong>ç»“åˆã€‚ç„¶åï¼Œæˆ‘ä»¬ç”¨<strong>deconvolution layers</strong>æ¥ä¸°å¯Œäº†SSD + Residual-101ï¼Œä»¥ä¾¿åœ¨ç‰©ä½“æ£€æµ‹ä¸­å¼•å…¥é¢å¤–çš„large-scaleçš„ä¸Šä¸‹æ–‡ï¼Œå¹¶æé«˜å‡†ç¡®æ€§ï¼Œ<strong>ç‰¹åˆ«æ˜¯å¯¹äºå°ç‰©ä½“</strong>ï¼Œä»è€Œç§°ä¹‹ä¸º<strong>DSSD</strong>ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡ä»”ç»†çš„åŠ å…¥é¢å¤–çš„<strong>learned transformationsé˜¶æ®µ</strong>ï¼Œå…·ä½“æ¥è¯´æ˜¯ä¸€ä¸ªç”¨äºåœ¨deconvolutionä¸­å‰å‘ä¼ é€’è¿æ¥çš„æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªæ–°çš„è¾“å‡ºæ¨¡å‹ï¼Œä½¿å¾—è¿™ä¸ªæ–°çš„æ–¹æ³•å˜å¾—å¯è¡Œï¼Œå¹¶ä¸ºä¹‹åçš„ç ”ç©¶æä¾›ä¸€ä¸ªæ½œåœ¨çš„é“è·¯ã€‚</li>
<li>æˆ‘ä»¬çš„DSSDå…·æœ‰513Ã—513çš„è¾“å…¥ï¼Œåœ¨VOC2007æµ‹è¯•ä¸­è¾¾åˆ°81.5ï¼…deçš„mAPï¼ŒVOC2012æµ‹è¯•ä¸º80.0ï¼…deçš„mAPï¼ŒCOCOä¸º33.2ï¼…çš„mAPï¼Œ<strong>åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„R-FCN</strong> ã€‚</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>æœ€è¿‘çš„ä¸€äº›ç›®æ ‡æ£€æµ‹æ–¹æ³•å›å½’åˆ°äº†<strong>æ»‘åŠ¨çª—å£æŠ€æœ¯</strong>ï¼Œè¿™ç§æŠ€æœ¯éšç€æ›´å¼ºå¤§çš„æ•´åˆäº†æ·±åº¦å­¦ä¹ çš„æœºå™¨å­¦ä¹ æ¡†æ¶è€Œå›å½’ã€‚</li>
<li>Faster RCNN -&gt; YOLO -&gt; SSD.</li>
<li>å›é¡¾æœ€è¿‘çš„è¿™äº›ä¼˜ç§€çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œè¦æƒ³æé«˜æ£€æµ‹å‡†ç¡®ç‡ï¼Œä¸€ä¸ªå¾ˆæ˜æ˜¾çš„ç›®æ ‡å°±æ˜¯ï¼šåˆ©ç”¨æ›´å¥½çš„ç‰¹å¾ç½‘ç»œå¹¶ä¸”æ·»åŠ æ›´å¤šçš„ä¸Šä¸‹æ–‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°ç‰©ä½“ï¼Œå¦å¤–è¿˜è¦æé«˜è¾¹ç•Œæ¡†é¢„æµ‹è¿‡ç¨‹çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚</li>
<li>åœ¨ç›®æ ‡æ£€æµ‹ä¹‹å¤–ï¼Œæœ€è¿‘æœ‰ä¸€ä¸ªé›†æˆä¸Šä¸‹æ–‡çš„å·¥ä½œï¼Œåˆ©ç”¨æ‰€è°“çš„<strong>â€œencoder-decoderâ€ç½‘ç»œ</strong>ã€‚è¯¥ç½‘ç»œä¸­é—´çš„bottleneck layerç”¨äºç¼–ç å…³äºè¾“å…¥å›¾åƒçš„ä¿¡æ¯ï¼Œç„¶åé€æ¸åœ°æ›´å¤§çš„å±‚å°†å…¶è§£ç åˆ°æ•´ä¸ªå›¾åƒçš„mapä¸­ã€‚æ‰€å½¢æˆçš„wideï¼Œnarrowï¼Œwideçš„ç½‘ç»œç»“æ„é€šå¸¸è¢«ç§°ä¸ºæ²™æ¼ã€‚</li>
<li>ä½†æ˜¯æœ‰å¿…è¦ä»”ç»†æ„å»ºç”¨äºé›†æˆåå·ç§¯çš„ç»„åˆæ¨¡å—å’Œè¾“å‡ºæ¨¡å—ï¼Œä»¥åœ¨è®­ç»ƒæœŸé—´éš”ç»ResNet-101å±‚ï¼Œä»è€Œå…è®¸æœ‰æ•ˆçš„å­¦ä¹ ã€‚</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>SPPnet, Fast R-CNN, Faster R-CNN, R-FCN, YOLOï¼šä½¿ç”¨å·ç§¯ç½‘ç»œçš„æœ€ä¸Šé¢çš„å±‚æ¥è¿›è¡Œä¸åŒå°ºåº¦çš„ç‰©ä½“æ£€æµ‹ã€‚</li>
<li>é€šè¿‡åœ¨ConvNetä¸­å¼€å‘å¤šå±‚æ¥æé«˜æ£€æµ‹ç²¾åº¦çš„æ–¹æ³•æœ‰å¤šé‡ã€‚<ul>
<li>ç¬¬ä¸€ç§æ–¹æ³•ï¼šç»„åˆäº†ConvNetä¸åŒå±‚çš„ç‰¹å¾å›¾ï¼Œå¹¶ä½¿ç”¨ç»„åˆç‰¹å¾å›¾è¿›è¡Œé¢„æµ‹ã€‚</li>
<li>IONåˆ©ç”¨L2 normalizationæ¥ç»“åˆå¤šä¸ªVGGNetå’Œæ± åŒ–å±‚çš„ç‰¹å¾æ¥è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚<ul>
<li>HyperNetä¹Ÿæ˜¯ä½¿ç”¨ç±»ä¼¼äºIONçš„æ–¹æ³•ã€‚</li>
<li>ä½†æ˜¯è¿™ç§ç»“åˆå¤šå±‚ç‰¹å¾çš„æ–¹æ³•ä¸ä»…å¢åŠ å†…å­˜ï¼Œè€Œä¸”é™ä½äº†æ¨¡å‹çš„é€Ÿåº¦ã€‚</li>
</ul>
</li>
<li>ç¬¬äºŒç§æ–¹æ³•ï¼šä½¿ç”¨ConvNetä¸­çš„ä¸åŒå±‚æ¥é¢„æµ‹ä¸åŒå°ºåº¦çš„å¯¹è±¡ã€‚<ul>
<li>å› ä¸ºä¸åŒå±‚ä¸­çš„èŠ‚ç‚¹å…·æœ‰ä¸åŒçš„æ¥æ”¶åŸŸï¼Œæ‰€ä»¥è‡ªç„¶ä¼š<strong>ä»å…·æœ‰å¤§å‹æ¥æ”¶åœºçš„å±‚é¢„æµ‹å¤§å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨å…·æœ‰å°æ¥æ”¶åœºçš„å±‚æ¥é¢„æµ‹å°ç‰©ä½“ã€‚</strong></li>
<li>SSDå°†ä¸åŒå°ºåº¦çš„é»˜è®¤æ¡†æ‰©å±•åˆ°ConvNetä¸­çš„å¤šä¸ªå±‚ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œæ¯ä¸€å±‚ä¸“æ³¨äºé¢„æµ‹ä¸€å®šè§„æ¨¡çš„å¯¹è±¡ã€‚</li>
<li>S-CNN [2]åœ¨ConvNetçš„å¤šå±‚åº”ç”¨å»å·ç§¯ï¼Œä»¥åœ¨ä½¿ç”¨å±‚å»å­¦ä¹ region proposalå’Œpool featureä¹‹å‰<strong>å¢åŠ feature mapsçš„åˆ†è¾¨ç‡ã€‚</strong></li>
<li>ç„¶è€Œï¼Œä¸ºäº†å¾ˆå¥½åœ°æ£€æµ‹å°ç‰©ä½“ï¼Œè¿™äº›æ–¹æ³•éœ€è¦ä»å…·æœ‰å°çš„æ¥æ”¶åœºå’Œå¯†é›†ç‰¹å¾å›¾çš„æµ…å±‚ä¸­ä½¿ç”¨ä¸€äº›ä¿¡æ¯ï¼Œè¿™å¯èƒ½å¯¼è‡´åœ¨æ£€æµ‹å°å¯¹è±¡æ€§èƒ½è¾ƒä½ï¼Œå› ä¸ºæµ…å±‚å…·æœ‰è¾ƒå°‘çš„å…³äºå¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨deconvolution layerså’Œskip connections,ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¯†é›†ï¼ˆå»å·ç§¯ï¼‰ç‰¹å¾å›¾ä¸­æ³¨å…¥æ›´å¤šçš„ä¿¡æ¯ï¼Œä»è€Œæœ‰åŠ©äºé¢„æµ‹å°ç‰©ä½“ã€‚</li>
</ul>
</li>
<li>å¦å¤–è¿˜æœ‰ä¸€ä¸ªå·¥ä½œæ–¹æ³•ï¼Œå°½é‡å»åŒ…æ‹¬é¢„æµ‹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚<ul>
<li>Multi-Region CNN</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Deconvolutional-DSSD-model-Single-Shot-Detection"><a href="#Deconvolutional-DSSD-model-Single-Shot-Detection" class="headerlink" title="Deconvolutional (DSSD) model Single Shot Detection"></a>Deconvolutional (DSSD) model Single Shot Detection</h3><h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p><img src="https://ww1.sinaimg.cn/large/006tNc79gy1fe6cf9kja4j30wd0beta0.jpg" alt=""></p>
<ul>
<li>SSDæ„å»ºäºbase networkä¹‹ä¸Šï¼Œæ·»åŠ äº†ä¸€äº›é€æ¸è§æ•ˆçš„å·ç§¯å±‚ï¼Œå¦‚ä¸Šå›¾è“è‰²éƒ¨åˆ†ã€‚</li>
<li>æ¯ä¸ªæ·»åŠ çš„å±‚å’Œä¸€äº›è¾ƒæ—©çš„åŸºæœ¬ç½‘ç»œå±‚ç”¨äºé¢„æµ‹æŸäº›é¢„å®šä¹‰çš„è¾¹ç•Œæ¡†çš„åˆ†æ•°å’Œåç§»ã€‚ </li>
<li>è¿™äº›é¢„æµ‹ç”±3x3xï¼ƒä¸ªé€šé“ç»´æ•°çš„æ»¤æ³¢å™¨æ‰§è¡Œï¼Œä¸€ä¸ªæ»¤æ³¢å™¨ç”¨äºäº§ç”Ÿæ¯ä¸ªç±»åˆ«åˆ†æ•°ï¼Œä¸€ä¸ªç”¨äºå›å½’è¾¹ç•Œæ¡†çš„æ¯ä¸ªç»´åº¦ã€‚ </li>
<li>å®ƒä½¿ç”¨éæœ€å¤§æŠ‘åˆ¶ï¼ˆNMSï¼‰å¯¹é¢„æµ‹è¿›è¡Œåå¤„ç†ï¼Œä»¥è·å¾—æœ€ç»ˆæ£€æµ‹ç»“æœã€‚ </li>
</ul>
<h3 id="Using-Residual-101-in-place-of-VGG"><a href="#Using-Residual-101-in-place-of-VGG" class="headerlink" title="Using Residual-101 in place of VGG"></a>Using Residual-101 in place of VGG</h3><p>å°†Base Networkä»VGG16æ¢ä¸ºResNet-101å¹¶æœªæå‡ç»“æœï¼Œä½†æ˜¯æ·»åŠ é¢å¤–çš„<strong>prediction module</strong>ä¼šæ˜¾è‘—åœ°ææˆæ€§èƒ½ã€‚</p>
<h3 id="prediction-module"><a href="#prediction-module" class="headerlink" title="prediction module"></a>prediction module</h3><p><img src="https://ww1.sinaimg.cn/large/006tNc79gy1fe6cpqgt1rj311z0gxtbt.jpg" alt=""></p>
<ul>
<li>åœ¨åŸå§‹SSDä¸­ï¼Œç›®æ ‡å‡½æ•°ç›´æ¥åº”ç”¨äºæ‰€é€‰æ‹©çš„ç‰¹å¾å›¾ï¼Œå¹¶ä¸”ç”±äºæ¢¯åº¦çš„å¤§å¹…åº¦ï¼Œä½¿ç”¨L2æ ‡å‡†åŒ–å±‚ç”¨äºconv4 3å±‚ã€‚</li>
<li>MS-CNNæŒ‡å‡ºï¼Œæ”¹è¿›æ¯ä¸ªä»»åŠ¡çš„å­ç½‘å¯ä»¥æé«˜å‡†ç¡®æ€§ï¼ŒæŒ‰ç…§è¿™ä¸ªåŸåˆ™ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªé¢„æµ‹å±‚æ·»åŠ ä¸€ä¸ªæ®‹å·®å—ï¼Œå¦‚å›¾2å˜ä½“ï¼ˆcï¼‰æ‰€ç¤ºã€‚</li>
<li>æˆ‘ä»¬è¿˜å°è¯•äº†åŸå§‹SSDæ–¹æ³•ï¼ˆaï¼‰å’Œå…·æœ‰è·³è¿‡è¿æ¥ï¼ˆbï¼‰çš„æ®‹ä½™å—çš„ç‰ˆæœ¬ä»¥åŠä¸¤ä¸ªé¡ºåºçš„æ®‹ä½™å—ï¼ˆdï¼‰ã€‚ æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œ<strong>ResNet-101å’Œé¢„æµ‹æ¨¡å—ä¼¼ä¹æ˜¾è‘—ä¼˜äºå¯¹äºè¾ƒé«˜åˆ†è¾¨ç‡è¾“å…¥å›¾åƒæ²¡æœ‰é¢„æµ‹æ¨¡å—çš„VGGã€‚</strong></li>
</ul>
<h3 id="Deconvolutional-SSD"><a href="#Deconvolutional-SSD" class="headerlink" title="Deconvolutional SSD"></a>Deconvolutional SSD</h3><p><img src="https://ww2.sinaimg.cn/large/006tNc79gy1fe6cyu3qi7j311j0f9aca.jpg" alt=""></p>
<ul>
<li>ä¸ºäº†åœ¨æ£€æµ‹ä¸­åŒ…å«æ›´å¤šçš„é«˜å±‚æ¬¡ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å°†prediction moduleè½¬ç§»åˆ°åœ¨åŸå§‹SSDè®¾ç½®ä¹‹åæ”¾ç½®çš„ä¸€ç³»åˆ—å»å·ç§¯å±‚ä¸­ï¼Œæœ‰æ•ˆåœ°åˆ¶ä½œäº†éå¯¹ç§°æ²™æ¼ç½‘ç»œç»“æ„ã€‚</li>
<li>æ·»åŠ é¢å¤–çš„å»å·ç§¯å±‚ï¼Œä»¥è¿ç»­å¢åŠ feature maps layersçš„åˆ†è¾¨ç‡ã€‚ä¸ºäº†åŠ å¼ºç‰¹å¾ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ²™æ¼æ¨¡å‹ä¸­â€œ<strong>è·³è·ƒè¿æ¥</strong>â€çš„æƒ³æ³•ã€‚</li>
<li>å°½ç®¡æ²™æ¼æ¨¡å‹åœ¨ç¼–ç å™¨å’Œè§£ç å™¨é˜¶æ®µå‡åŒ…å«å¯¹ç§°å±‚ï¼Œä½†ç”±äºä¸¤ä¸ªåŸå› ï¼Œæˆ‘ä»¬ä½¿è§£ç å™¨é˜¶æ®µéå¸¸æµ…ã€‚</li>
</ul>
<h3 id="Deconvolution-Module"><a href="#Deconvolution-Module" class="headerlink" title="Deconvolution Module"></a>Deconvolution Module</h3><p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fe6d85jld2j30ht0g9wfq.jpg" alt=""></p>
<ul>
<li>ä¸ºäº†å¸®åŠ©æ•´åˆæ—©æœŸç‰¹å¾å›¾å’Œå»å·ç§¯å±‚çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå»å·ç§¯æ¨¡å—ï¼Œå¦‚å›¾3æ‰€ç¤ºã€‚</li>
<li>é¦–å…ˆï¼Œåœ¨æ¯ä¸ªå·ç§¯å±‚ä¹‹åæ·»åŠ BNå±‚ã€‚</li>
<li>ç¬¬äºŒï¼Œæˆ‘ä»¬ä½¿ç”¨å­¦ä¹ çš„å»å·ç§¯å±‚ä»£æ›¿åŒçº¿æ€§ä¸Šé‡‡æ ·ã€‚</li>
<li>æœ€åï¼Œæˆ‘ä»¬æµ‹è¯•ä¸åŒçš„ç»„åˆæ–¹æ³•ï¼šelement-wise sum and element-wise productã€‚</li>
</ul>
<h3 id="Traning"><a href="#Traning" class="headerlink" title="Traning"></a>Traning</h3><ul>
<li>æˆ‘ä»¬éµå¾ªä¸SSDç›¸åŒçš„è®­ç»ƒæ”¿ç­–ã€‚</li>
<li>åœ¨åŸå§‹SSDæ¨¡å‹ä¸­ï¼Œé•¿å®½æ¯”ä¸º2å’Œ3çš„boxesä»å®éªŒä¸­è¯æ˜æ˜¯æœ‰ç”¨çš„ã€‚ä¸ºäº†äº†è§£è®­ç»ƒæ•°æ®ï¼ˆPASCAL VOC 2007å’Œ2012å¹´ trainvalï¼‰ä¸­è¾¹ç•Œæ¡†çš„çºµæ¨ªæ¯”ï¼Œæˆ‘ä»¬ä»¥training boxè¿è¡ŒK-meansèšç±»ï¼Œä»¥æ–¹æ ¼å¹³æ–¹æ ¹ä¸ºç‰¹å¾ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªé›†ç¾¤å¼€å§‹ï¼Œå¦‚æœé”™è¯¯å¯ä»¥æé«˜20ï¼…ä»¥ä¸Šï¼Œå°±ä¼šå¢åŠ é›†ç¾¤çš„æ•°é‡ã€‚ç»è¿‡è¯•éªŒå› æ­¤ï¼Œæˆ‘ä»¬å†³å®šåœ¨æ¯ä¸ªé¢„æµ‹å±‚æ·»åŠ ä¸€ä¸ªå®½é«˜æ¯”1.6ï¼Œå¹¶ä½¿ç”¨ï¼ˆ1.6, 2.0, 3.0ï¼‰ã€‚</li>
</ul>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ul>
<li>PASCAL VOC2007 test detection results.</li>
</ul>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79gy1fe6ykpyluhj30s30bgwlo.jpg" alt=""></p>
<ul>
<li>PASCAL 2012 test detection results.</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fe6yl98p6tj30rp080dka.jpg" alt=""></p>
<ul>
<li>COCO test-dev2015 detection results.</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fe6ylysfswj30s809ldjq.jpg" alt=""></p>
<ul>
<li>Comparison of Speed &amp; Accuracy on PASCAL VOC2007 test.</li>
</ul>
<p><img src="https://ww1.sinaimg.cn/large/006tNc79gy1fe6ymnt5vsj30rp0cnn1k.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºåœ¨å½“å‰æœ€å¥½çš„é€šç”¨ç›®æ ‡æ£€æµ‹å™¨ä¸­åŠ å…¥äº†é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚&lt;/li&gt;
&lt;li&gt;ä¸ºå®ç°è¿™ä¸€ç›®çš„ï¼šæˆ‘ä»¬é€šè¿‡å°†&lt;strong&gt;ResNet-101&lt;/strong&gt;ä¸&lt;strong&gt;SSD&lt;/strong&gt;ç»“åˆã€‚ç„¶åï¼Œæˆ‘ä»¬ç”¨&lt;strong&gt;deconvolution layers&lt;/strong&gt;æ¥ä¸°å¯Œäº†SSD + Residual-101ï¼Œä»¥ä¾¿åœ¨ç‰©ä½“æ£€æµ‹ä¸­å¼•å…¥é¢å¤–çš„large-scaleçš„ä¸Šä¸‹æ–‡ï¼Œå¹¶æé«˜å‡†ç¡®æ€§ï¼Œ&lt;strong&gt;ç‰¹åˆ«æ˜¯å¯¹äºå°ç‰©ä½“&lt;/strong&gt;ï¼Œä»è€Œç§°ä¹‹ä¸º&lt;strong&gt;DSSD&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬é€šè¿‡ä»”ç»†çš„åŠ å…¥é¢å¤–çš„&lt;strong&gt;learned transformationsé˜¶æ®µ&lt;/strong&gt;ï¼Œå…·ä½“æ¥è¯´æ˜¯ä¸€ä¸ªç”¨äºåœ¨deconvolutionä¸­å‰å‘ä¼ é€’è¿æ¥çš„æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªæ–°çš„è¾“å‡ºæ¨¡å‹ï¼Œä½¿å¾—è¿™ä¸ªæ–°çš„æ–¹æ³•å˜å¾—å¯è¡Œï¼Œå¹¶ä¸ºä¹‹åçš„ç ”ç©¶æä¾›ä¸€ä¸ªæ½œåœ¨çš„é“è·¯ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬çš„DSSDå…·æœ‰513Ã—513çš„è¾“å…¥ï¼Œåœ¨VOC2007æµ‹è¯•ä¸­è¾¾åˆ°81.5ï¼…deçš„mAPï¼ŒVOC2012æµ‹è¯•ä¸º80.0ï¼…deçš„mAPï¼ŒCOCOä¸º33.2ï¼…çš„mAPï¼Œ&lt;strong&gt;åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„R-FCN&lt;/strong&gt; ã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šDeep Residual Learning for Image Recognition</title>
    <link href="http://jacobkong.github.io/posts/3085218970/"/>
    <id>http://jacobkong.github.io/posts/3085218970/</id>
    <published>2017-03-23T07:51:24.000Z</published>
    <updated>2017-03-28T08:02:39.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>æœ¬æ–‡æ˜¯ä½•å‡¯æ˜å¤§ç¥çš„åˆä¸€ç¯‡CVPRæœ€ä½³è®ºæ–‡ã€‚</li>
<li>ç½‘ç»œè¶Šæ·±è¶Šéš¾è®­ç»ƒï¼Œæ‰€ä»¥æˆ‘ä»¬æå‡ºä¸€ä¸ªresidual learning frameworkä»è€Œå‡è½»ç½‘ç»œçš„è®­ç»ƒï¼Œè¯¥ç½‘ç»œæ¯”ä»¥å‰ä½¿ç”¨çš„ç½‘ç»œè¦æ·±å¾—å¤šã€‚</li>
<li>æˆ‘ä»¬æ˜ç¡®åœ°å°†å‚è€ƒå±‚çš„è¾“å…¥æ¥ä½œä¸ºå­¦ä¹ æ®‹å·®å‡½æ•°ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ— å‚è€ƒçš„å‡½æ•°ï¼ˆunreferenced functionsï¼‰ã€‚</li>
<li>æˆ‘ä»¬æä¾›å…¨é¢çš„ç»éªŒè¯æ®ï¼Œè¡¨æ˜è¿™äº›æ®‹ç•™ç½‘ç»œæ›´å®¹æ˜“ä¼˜åŒ–ï¼Œå¹¶å¯ä»¥ä»æ˜¾ç€å¢åŠ çš„æ·±åº¦ä¸­è·å¾—å‡†ç¡®æ€§ã€‚</li>
<li>è¿™äº›æ®‹ç•™ç½‘ç»œçš„é›†åˆåœ¨ImageNetæµ‹è¯•é›†ä¸Šè¾¾åˆ°3.57ï¼…çš„è¯¯å·®ã€‚ è¯¥ç»“æœåœ¨ILSVRC 2015åˆ†ç±»ä»»åŠ¡ä¸­è£è·ç¬¬ä¸€åã€‚</li>
<li><strong>æ·±åº¦å¯¹äºè®¸å¤šCVé¢†åŸŸçš„ä»»åŠ¡éƒ½ååˆ†é‡è¦çš„ã€‚</strong>ç”±äºæˆ‘ä»¬ç½‘ç»œå¾ˆæ·±ï¼Œæˆ‘ä»¬åœ¨COCOå¯¹è±¡æ£€æµ‹æ•°æ®é›†ä¸Šè·å¾—äº†28ï¼…çš„ç›¸å¯¹æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜è£è·äº†ImageNetæ£€æµ‹ï¼ŒImageNetå®šä½ï¼ŒCOCOæ£€æµ‹å’ŒCOCOåˆ†å‰²ä»»åŠ¡çš„ç¬¬ä¸€åã€‚</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>æ·±å±‚ç½‘ç»œè‡ªç„¶åœ°å°†ä½/ä¸­/é«˜å±‚ç‰¹å¾å’Œåˆ†ç±»å™¨ä»¥ç«¯åˆ°ç«¯å¤šå±‚æ–¹å¼è¿›è¡Œé›†æˆï¼Œå¹¶ä¸”ç‰¹å¾çš„â€œçº§åˆ«â€å¯ä»¥é€šè¿‡å †å å±‚æ•°ï¼ˆæ·±åº¦ï¼‰æ¥ä¸°å¯Œã€‚<strong>ç½‘ç»œçš„æ·±åº¦æœ‰ç€ååˆ†é‡è¦çš„ä½œç”¨ã€‚</strong></p>
</li>
<li><p>éšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œå¸¦æ¥ä¸€ä¸ªé—®é¢˜ï¼š<strong>å­¦ä¹ æ›´å¥½çš„ç½‘ç»œæ˜¯å¦å’Œå †å æ›´å¤šçš„å±‚ä¸€æ ·ç®€å•ï¼Ÿ</strong>å›ç­”è¿™ä¸ªé—®é¢˜çš„éšœç¢æ˜¯ï¼š<strong>é€æ¸æ¶ˆå¤±çš„æ¢¯åº¦é—®é¢˜</strong>ã€‚</p>
</li>
<li><p>å½“è¾ƒæ·±çš„ç½‘ç»œèƒ½å¤Ÿå¼€å§‹æ”¶æ•›æ—¶ï¼Œæš´éœ²äº†ä¸€ä¸ªé€€åŒ–é—®é¢˜ï¼š<strong>éšç€ç½‘ç»œæ·±åº¦çš„å¢åŠ ï¼Œç²¾åº¦é¥±å’Œï¼Œç„¶åè¿…é€Ÿä¸‹é™ã€‚</strong>è¿™ç§ä¸‹é™ä¸æ˜¯ç”±äºè¿‡æ‹Ÿåˆï¼Œæ·»åŠ å¤šå±‚ä¼šå¯¼è‡´æ›´é«˜çš„è®­ç»ƒé”™è¯¯ã€‚</p>
</li>
<li><p>ä»æµ…åˆ°æ·±çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼š</p>
<ul>
<li>é™„åŠ å±‚ï¼šè®¾ç½®ä¸ºâ€œæ’ç­‰â€ï¼ˆidentityï¼‰</li>
<li>åŸå§‹å±‚ï¼šç”±ä¸€ä¸ªå·²ç»å­¦ä¼šçš„è¾ƒæµ…æ¨¡å‹å¤åˆ¶å¾—æ¥ã€‚</li>
<li>è¿™ç§è§£å†³æ–¹æ¡ˆçš„å­˜åœ¨è¡¨æ˜ï¼Œè¾ƒæ·±çš„æ¨¡å‹ä¸åº”è¯¥äº§ç”Ÿæ¯”è¾ƒæµ…çš„æ¨¡å‹æ›´é«˜çš„è®­ç»ƒè¯¯å·®ã€‚è‡³å°‘å…·æœ‰ç›¸åŒçš„è®­ç»ƒè¯¯å·®ã€‚</li>
</ul>
</li>
<li><p>ä¼˜åŒ–éš¾é¢˜ï¼š<strong>éšç€ç½‘ç»œå±‚æ•°ä¸æ–­åŠ æ·±ï¼Œæ±‚è§£å™¨ä¸èƒ½æ‰¾åˆ°è§£å†³é€”å¾„ã€‚</strong></p>
</li>
<li><p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†<strong>æ·±åº¦æ®‹å·®å­¦ä¹ æ¡†æ¶</strong>ã€‚</p>
</li>
<li><p><strong>å¹³åŸç½‘ç»œ</strong>ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fdyd28cydnj30k706wt99.jpg" alt=""></p>
<p>H(x)æ˜¯ä»»æ„ä¸€ç§ç†æƒ³çš„æ˜ å°„</p>
<p>å¹³åŸç½‘ç»œå¸Œæœ›ç¬¬2å±‚æƒé‡å±‚èƒ½å¤Ÿ<strong>ä¸H(x)æ‹Ÿåˆ</strong>ã€‚</p>
</li>
<li><p><strong>æ®‹å·®ç½‘ç»œ</strong>ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fdyd3gt5c5j30ki076dgr.jpg" alt=""></p>
<p>H(x)æ˜¯ä»»æ„ä¸€ç§ç†æƒ³çš„æ˜ å°„</p>
<p>æ®‹å·®ç½‘ç»œå¸Œæœ›ç¬¬2ç±»æƒé‡å±‚èƒ½å¤Ÿä¸<strong>F(x)æ‹Ÿåˆä½¿å¾—H(x) = F(x) + x</strong></p>
</li>
<li><p>F(x)æ˜¯ä¸€ä¸ªæ®‹å·®æ˜ å°„w.r.t æ’</p>
<ul>
<li>å¦‚æœè¯´æ’ç­‰æ˜¯ç†æƒ³ï¼Œå¾ˆå®¹æ˜“å°†æƒé‡å€¼è®¾å®šä¸º0ï¼›</li>
<li>å¦‚æœç†æƒ³åŒ–æ˜ å°„æ›´æ¥è¿‘äºæ’ç­‰æ˜ å°„ï¼Œä¾¿æ›´å®¹æ˜“å‘ç°å¾®å°æ³¢åŠ¨ã€‚</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fdyd6l6pwhj30kl074my2.jpg" alt=""></p>
</li>
<li><p>æˆ‘ä»¬å‡è®¾ä¼˜åŒ–æ®‹å·®æ˜ å°„æ¯”ä¼˜åŒ–åŸå§‹çš„ï¼Œæ— å‚è€ƒæ˜ å°„(unreferenced mapping)æ›´å®¹æ˜“ã€‚åœ¨æç«¯æƒ…å†µä¸‹ï¼Œå¦‚æœä¸€ä¸ªidentity mappingæ˜¯æœ€ä½³çš„ï¼Œé‚£ä¹ˆå°†æ®‹å·®æ¨åˆ°é›¶æ¯”é€šè¿‡ä¸€å †éçº¿æ€§å±‚çš„identity mappingæ›´å®¹æ˜“ã€‚</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;æœ¬æ–‡æ˜¯ä½•å‡¯æ˜å¤§ç¥çš„åˆä¸€ç¯‡CVPRæœ€ä½³è®ºæ–‡ã€‚&lt;/li&gt;
&lt;li&gt;ç½‘ç»œè¶Šæ·±è¶Šéš¾è®­ç»ƒï¼Œæ‰€ä»¥æˆ‘ä»¬æå‡ºä¸€ä¸ªresidual learning frameworkä»è€Œå‡è½»ç½‘ç»œçš„è®­ç»ƒï¼Œè¯¥ç½‘ç»œæ¯”ä»¥å‰ä½¿ç”¨çš„ç½‘ç»œè¦æ·±å¾—å¤šã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬æ˜ç¡®åœ°å°†å‚è€ƒå±‚çš„è¾“å…¥æ¥ä½œä¸ºå­¦ä¹ æ®‹å·®å‡½æ•°ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ— å‚è€ƒçš„å‡½æ•°ï¼ˆunreferenced functionsï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬æä¾›å…¨é¢çš„ç»éªŒè¯æ®ï¼Œè¡¨æ˜è¿™äº›æ®‹ç•™ç½‘ç»œæ›´å®¹æ˜“ä¼˜åŒ–ï¼Œå¹¶å¯ä»¥ä»æ˜¾ç€å¢åŠ çš„æ·±åº¦ä¸­è·å¾—å‡†ç¡®æ€§ã€‚&lt;/li&gt;
&lt;li&gt;è¿™äº›æ®‹ç•™ç½‘ç»œçš„é›†åˆåœ¨ImageNetæµ‹è¯•é›†ä¸Šè¾¾åˆ°3.57ï¼…çš„è¯¯å·®ã€‚ è¯¥ç»“æœåœ¨ILSVRC 2015åˆ†ç±»ä»»åŠ¡ä¸­è£è·ç¬¬ä¸€åã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ·±åº¦å¯¹äºè®¸å¤šCVé¢†åŸŸçš„ä»»åŠ¡éƒ½ååˆ†é‡è¦çš„ã€‚&lt;/strong&gt;ç”±äºæˆ‘ä»¬ç½‘ç»œå¾ˆæ·±ï¼Œæˆ‘ä»¬åœ¨COCOå¯¹è±¡æ£€æµ‹æ•°æ®é›†ä¸Šè·å¾—äº†28ï¼…çš„ç›¸å¯¹æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜è£è·äº†ImageNetæ£€æµ‹ï¼ŒImageNetå®šä½ï¼ŒCOCOæ£€æµ‹å’ŒCOCOåˆ†å‰²ä»»åŠ¡çš„ç¬¬ä¸€åã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ç›®æ ‡æ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šR-FCN</title>
    <link href="http://jacobkong.github.io/posts/3678248031/"/>
    <id>http://jacobkong.github.io/posts/3678248031/</id>
    <published>2017-02-27T07:51:24.000Z</published>
    <updated>2018-05-28T07:35:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>æå‡ºäº†ä¸€ä¸ªregion-based, fully convolutionalçš„ç½‘ç»œæ¥å‡†ç¡®é«˜æ•ˆçš„è¿›è¡Œç‰©ä½“æ£€æµ‹ã€‚</li>
<li>ä¸åŒäºFast/Faster R-CNNï¼Œå…¶åº”ç”¨äº†è®¡ç®—æˆæœ¬å¾ˆé«˜çš„æ¯ä¸ªåŒºåŸŸå­ç½‘ç»œæ•°ç™¾æ¬¡ï¼Œæœ¬è®ºæ–‡çš„region-based detectoræ˜¯å®Œå…¨å·ç§¯åŒ–çš„ï¼Œå‡ ä¹ä¸€å¼ å›¾åƒä¸Šæ‰€æœ‰çš„è®¡ç®—éƒ½æ˜¯å…±äº«çš„ã€‚</li>
<li>ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºposition-sensitive score mapsï¼Œä»¥è§£å†³åœ¨å›¾åƒåˆ†ç±»çš„å¹³ç§»ä¸å˜æ€§ï¼ˆtranslation-invarianceï¼‰å’Œç‰©ä½“æ£€æµ‹ä¸­çš„å¹³ç§»å¯å˜æ€§ï¼ˆtranslation-varianceï¼‰ä¹‹é—´çš„å›°å¢ƒã€‚</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>æœ€è¿‘æµè¡Œçš„ç”¨äºç›®æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¾æ®RoIå±‚çš„ä¸åŒå¯ä»¥åˆ†ä¸ºä¸¤å¤§subnetworksï¼š<ul>
<li>ä¸€ç±»æ˜¯ç‹¬ç«‹äºRoIsçš„ã€å…±äº«çš„ã€fully convolutionalçš„subnetworkã€‚</li>
<li>å¦ä¸€ç±»æ˜¯RoI-wiseçš„subnetworkï¼Œä¸å…±äº«è®¡ç®—ã€‚</li>
</ul>
</li>
<li>åœ¨å›¾åƒåˆ†ç±»ç½‘ç»œä¸­ï¼Œä¸€ä¸ªconvolutional subnetworkä¼šä»¥ä¸€ä¸ªsptial pooling layerè·Ÿéšç€å‡ ä¸ªfully-connected  layeræœ€ä¸ºç»“å°¾ï¼Œæ‰€ä»¥å›¾åƒåˆ†ç±»ä¸­çš„sptial pooling layerè‡ªç„¶è½¬åŒ–ä¸ºç›®æ ‡æ£€æµ‹ä¸­çš„RoI pooling layerã€‚</li>
<li>ResNetå’ŒGoogleLeNetséƒ½è¢«è®¾è®¡æˆfully convolutionalçš„ã€‚</li>
<li>åœ¨ResNetè®ºæ–‡ä¸­ï¼ŒFaster R-CNNä¸­çš„RoI pooling layerè¢«ä¸è‡ªç„¶çš„æ’å…¥åˆ°ä¸¤ä¸ªå·ç§¯å±‚é›†ä¹‹é—´ï¼Œå¸¦æ¥äº†å‡†ç¡®ç‡çš„æå‡ï¼Œ<strong>ä½†æ˜¯é€Ÿåº¦ç”±äºunshared per-RoIè®¡ç®—é™ä½ã€‚</strong></li>
<li>å¯¹äº<strong>å›¾åƒåˆ†ç±»</strong>ä»»åŠ¡æ¥è¯´ï¼šæ›´å€¾å‘äºå¹³ç§»ä¸å˜æ€§ã€‚å¯¹äº<strong>å›¾åƒæ£€æµ‹</strong>ä»»åŠ¡æ¥è¯´ï¼šæ›´å€¾å‘äº<strong>å¹³ç§»å˜æ¢æ€§</strong>ã€‚</li>
<li>å‡è®¾å›¾åƒåˆ†ç±»ç½‘ç»œä¸­æ›´æ·±å±‚çš„å·ç§¯å±‚å¯¹translationä¸æ•æ„Ÿï¼Œæ‰€ä»¥ä¸ºäº†è§£å†³translation invarianceå’Œtranslation varianceä¹‹é—´çš„å›°éš¾ï¼ŒResNetå°†RoI pooling layeræ’å…¥åˆ°äº†å·ç§¯ç¥ç»ç½‘ç»œä¹‹é—´ã€‚è¿™ä¸ªåŒºåŸŸç‰¹å®šçš„æ“ä½œæ‰“ç ´äº†å¹³ç§»ä¸å˜æ€§ï¼Œå¹¶ä¸”åœ¨ä¸åŒåŒºåŸŸä¹‹é—´è¿›è¡Œè¯„ä¼°æ—¶ï¼ŒRoIä¹‹åçš„å·ç§¯å±‚ä¸å†æ˜¯å¹³ç§»ä¸å˜çš„ã€‚</li>
<li>ä¸ºäº†å°†translation varianceç»“åˆåˆ°FCNä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸€ç»„ä¸“ç”¨å·ç§¯å±‚ä½œä¸ºFCNè¾“å‡ºæ¥æ„é€ ä¸€ç»„ä½ç½®æ•æ„Ÿå¾—åˆ†å›¾ï¼ˆposition-sensitive score mapsï¼‰ã€‚æ¯ä¸€ä¸ªå¾—åˆ†å›¾å°†ç›¸å¯¹äºç›¸å¯¹ç©ºé—´ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œâ€œåœ¨å¯¹è±¡çš„å·¦è¾¹â€ï¼‰çš„ä½ç½®ä¿¡æ¯è¿›è¡Œç¼–ç ã€‚åœ¨è¿™ä¸ªFCNä¹‹ä¸Šï¼Œæˆ‘ä»¬é™„åŠ ä¸€ä¸ªä½ç½®æ•æ„Ÿçš„RoIæ± å±‚ï¼ˆposition-sensitive RoI pooling layerï¼‰ï¼Œä»è¿™äº›å¾—åˆ†å›¾ä¸­è·å–ä¿¡æ¯ï¼Œæ²¡æœ‰è·Ÿéšçš„æƒé‡çš„ï¼ˆå·ç§¯/ fcï¼‰å±‚ã€‚</li>
</ul>
<h2 id="Our-approach"><a href="#Our-approach" class="headerlink" title="Our approach"></a>Our approach</h2><ul>
<li><p>æœ¬è®ºæ–‡çš„æ–¹æ³•å‚è€ƒR-CNNï¼Œä¹Ÿæ˜¯ä½¿ç”¨two-stageçš„ç›®æ ‡æ£€æµ‹ç­–ç•¥ã€‚</p>
<ul>
<li>region proposal</li>
<li>region classification</li>
</ul>
</li>
<li><p>è™½ç„¶ä¸ä¾èµ–äºregion proposalçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ç¡®å®å­˜åœ¨ï¼Œå¦‚SSDä½•YOLOï¼Œä½†æ˜¯region-based systemä¾æ—§åœ¨å‡ ä¸ªåŸºå‡†ä¸Šä¿æŒé¢†å…ˆçš„å‡†ç¡®æ€§ã€‚</p>
</li>
<li><p>Overall architecture of R-FCN:</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgy1fd58i0j1icj30ql0dcmzl.jpg" alt=""></p>
<p>ç”¨RPNæ¥æå‡ºcandidate RoIsï¼Œç„¶åè¿™äº›RoIsè¢«åº”ç”¨åˆ°score mapsï¼Œåœ¨RPNå’ŒR-FCNä¹‹é—´å…±äº«ç‰¹å¾ã€‚</p>
<p>ç»™å®šä¸€ä¸ªRoIï¼ŒR-FCNæ¶æ„å¯¹RoIè¿›è¡Œåˆ†ç±»ï¼ˆåˆ†ä¸ºç‰©ä½“ç±»åˆ«æˆ–è€…èƒŒæ™¯ï¼‰ã€‚æ‰€æœ‰å¯å­¦ä¹ æƒå€¼çš„å±‚éƒ½æ˜¯å·ç§¯å±‚ï¼Œå¹¶ä¸”æ˜¯åœ¨æ•´å¼ å›¾ç‰‡ä¸Šè®¡ç®—å¾—åˆ°çš„æƒé‡ã€‚<strong>æœ€åå·ç§¯å±‚ä¸ºæ¯ä¸ªç±»åˆ«äº§ç”Ÿä¸€ä¸ª$k^2$ä¸ªposition-sensitive score maps</strong>ï¼Œå› æ­¤å…·æœ‰å¸¦æœ‰Cä¸ªå¯¹è±¡ç±»åˆ«ï¼ˆèƒŒæ™¯ä¸º+1ï¼‰çš„$k^2(C + 1)$é€šé“çš„è¾“å‡ºå±‚ã€‚</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79gy1fdvwup92g7j302p06e0sp.jpg" alt=""></p>
<p><strong>æ¯ä¸€ä¸ªcategoryæœ‰ä¸€ä¸ª$k^2$çš„score map</strong>ï¼Œå¯¹äºè¿™é‡Œæ¥è¯´k=3ï¼Œæ‰€ä»¥æœ€åRoI poolingå±‚äº§ç”Ÿ3x3x(C+1)ç»´çš„feature mapã€‚</p>
</li>
<li><p>RPNä»¥ä¸€ä¸ªposition-sensitive RoI pooling layerç»“æŸï¼Œè¯¥å±‚èšåˆæœ€åå·ç§¯å±‚çš„è¾“å‡ºå¹¶äº§ç”Ÿæ¯ä¸ªRoIçš„åˆ†æ•°ã€‚æˆ‘ä»¬çš„ä½ç½®æ•æ„Ÿçš„RoI pooling layerè¿›è¡Œé€‰æ‹©æ€§åˆå¹¶ï¼Œeach of the k Ã— k bin aggregates responses from only one score map out of the bank of k Ã— k score mapsã€‚åˆ©ç”¨ç«¯åˆ°ç«¯è®­ç»ƒï¼Œè¿™ä¸ªRoIå±‚ç®¡ç†æœ€åçš„å·ç§¯å±‚ä»¥å­¦ä¹ ä¸“é—¨çš„position-sensitive score mapsã€‚ </p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcly1fd597p3an8j30vs0en40p.jpg" alt=""></p>
</li>
</ul>
<h3 id="Backbone-architecture"><a href="#Backbone-architecture" class="headerlink" title="Backbone architecture"></a>Backbone architecture</h3><ul>
<li>æœ¬è®ºæ–‡R-FCNåŸºäºResNet-101ã€‚</li>
<li>ResNet-101å…·æœ‰100ä¸ªå·ç§¯å±‚ï¼Œåé¢æ˜¯global average poolingå’Œä¸€ä¸ª1000-classçš„fcå±‚ã€‚æˆ‘ä»¬ç§»å»äº†average pooling layer and the fc layerï¼Œä»…ä½¿ç”¨convolutional layeræ¥è®¡ç®—feature mapsã€‚</li>
<li>æˆ‘ä»¬ä½¿ç”¨ResNet-101ï¼Œåœ¨ImageNetä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒResNet-101ä¸­çš„æœ€åä¸€ä¸ªå·ç§¯å—æ˜¯2048-dï¼Œå¹¶ä¸”æˆ‘ä»¬é™„åŠ éšæœºåˆå§‹åŒ–çš„1024-d 1Ã—1å·ç§¯å±‚ä»¥å‡å°å°ºå¯¸ã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨$k^2(C + 1)$é€šé“å·ç§¯å±‚æ¥ç”Ÿæˆåˆ†æ•°å›¾ï¼Œå¦‚ä¸‹æ‰€è¿°ã€‚</li>
</ul>
<h3 id="Position-sensitive-score-maps-amp-Position-sensitive-RoI-pooling"><a href="#Position-sensitive-score-maps-amp-Position-sensitive-RoI-pooling" class="headerlink" title="Position-sensitive score maps &amp; Position-sensitive RoI pooling."></a>Position-sensitive score maps &amp; Position-sensitive RoI pooling.</h3><ul>
<li><p>ä¸ºäº†å°†ä½ç½®ä¿¡æ¯æ˜¾å¼ç¼–ç åˆ°æ¯ä¸ªRoIä¸­ï¼Œæˆ‘ä»¬å°†RoIçŸ©å½¢åˆ’åˆ†ä¸ºk x kä¸ªbinsã€‚</p>
</li>
<li><p>æœ€åçš„å·ç§¯å±‚ä¸ºæ¯ä¸ªç±»åˆ«äº§ç”Ÿçš„$k^2$ä¸ªåˆ†æ•°å›¾ã€‚åœ¨ç¬¬(i, j)ä¸ªbinå†…ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªä½ç½®æ•æ„Ÿçš„RoIæ± åŒ–æ“ä½œï¼Œä»è€Œåªåœ¨ç¬¬(i, j)ä¸ªscore mapä¸Šè¿›è¡Œæ± åŒ–ï¼š</p>
<script type="math/tex; mode=display">
r_c(i, j|\theta)=\sum_{(x,y)\in bin(i,j)}{z_{i,j,c}(x+x_0,y+y_0|\theta)/n}</script><ul>
<li>å…¶ä¸­$r_c(i, j)$è¡¨ç¤ºä»c-thç±»åˆ«ä¸­å¾—åˆ°çš„(i,j)-th binçš„æ± åŒ–å“åº”ã€‚</li>
<li>$z_{i,j,c}$æ˜¯$k^2(C+1)$ä¸ªscore mapsä¸­çš„ä¸€ä¸ªscore mapã€‚</li>
<li>$(x_0,y_0)$è¡¨ç¤ºä¸€ä¸ªRoIçš„å·¦ä¸Šè§’ã€‚</li>
<li>$n$è¡¨ç¤ºè¿™ä¸ªbinä¸­çš„åƒç´ çš„æ•°é‡ã€‚</li>
<li>$\theta$è¡¨ç¤ºè¿™ä¸ªç½‘ç»œä¸­æ‰€æœ‰çš„å¯å­¦ä¹ æƒé‡ã€‚</li>
<li>è¯¥poolingå±äºAVEï¼Œä¹Ÿå¯ä»¥ç”¨MAXã€‚</li>
</ul>
</li>
<li><p>å¯¹æ¯ä¸ªç±»åˆ«k*kçš„score mapè¿›è¡Œå¹³å‡ï¼Œæœ€åæ¯ä¸ªRoIå¾—åˆ°ä¸€ä¸ªC+1ç»´çš„å‘é‡ã€‚ç„¶åæ±‚lossï¼Œå®ƒä»¬ç”¨äºè¯„ä¼°è®­ç»ƒæœŸé—´çš„äº¤å‰ç†µæŸå¤±å’Œæ¨ç†æœŸé—´çš„RoIsæ’åã€‚</p>
</li>
<li><p>bounding boxes regressionã€‚å¯¹æ¯ä¸ªRoIäº§ç”Ÿä¸€ä¸ª$4k^2$ç»´çš„å‘é‡ã€‚ç„¶åé€šè¿‡average votingå°†å…¶èšåˆæˆ4ç»´å‘é‡ã€‚</p>
</li>
<li><p>åœ¨RoIå±‚ä¹‹åæ²¡æœ‰å¯å­¦ä¹ çš„å±‚æ¬¡ï¼Œå®ç°äº†å‡ ä¹æ— æˆæœ¬åœ°åŒºçš„è®¡ç®—ã€åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ã€‚</p>
</li>
</ul>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul>
<li><p>åˆ©ç”¨æå‰è®¡ç®—å¥½çš„region proposalï¼Œå¾ˆå®¹æ˜“æ¥ç«¯åˆ°ç«¯çš„R-FCNæ¶æ„è®­ç»ƒã€‚</p>
</li>
<li><p>loss function:</p>
<script type="math/tex; mode=display">
L(s,t_{x,y,w,h})=L_{cls}(s_{c^*})+\lambda[c^*>0]L_{reg}(t,t^*)</script></li>
<li><p>æœ¬æ¡†æ¶å¾ˆå®¹æ˜“åœ¨è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨online hard example mining (OHEM)ã€‚</p>
<ul>
<li>æˆ‘ä»¬çš„per-RoIè®¡ç®—å¯ä»¥è¿›è¡Œå‡ ä¹cost-freeçš„example miningã€‚</li>
<li>åœ¨å‰å‘ä¼ æ’­ä¸­ï¼šå‡è®¾æ¯å¼ å›¾ç‰‡Nä¸ªproposalsã€‚æˆ‘ä»¬è®¡ç®—æ‰€æœ‰Nä¸ªproposalçš„lossï¼Œæ’åºï¼Œé€‰æ‹©æœ€é«˜çš„Bä¸ªRoIsã€‚ç„¶ååœ¨é€‰ä¸­çš„proposalä¸Šè¿›è¡Œåå‘ä¼ æ’­ã€‚</li>
</ul>
</li>
<li><p>decayï¼š0.0005</p>
</li>
<li><p>momentumï¼š0.9</p>
</li>
<li><p>single-scale trainingã€‚</p>
</li>
<li><p>B=128</p>
</li>
<li><p>lr = 0.001 ~20k, 0.0001 ~ 10k</p>
</li>
<li><p>åŒFaster R-CNNä¸€è¶Ÿï¼Œä½¿ç”¨4æ­¥alternating trainingï¼Œåœ¨è®­ç»ƒRPNå’Œè®­ç»ƒR-FCNä¹‹é—´ã€‚</p>
</li>
</ul>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><ul>
<li>ä¸ºå…¬å¹³æœŸé—´ï¼Œåœ¨300ä¸ªRoIsä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æœä¹‹åç”¨NMSè¿›è¡Œå¤„ç†ï¼ŒIoUé˜ˆå€¼0.3</li>
</ul>
<h3 id="A-trous-and-stride"><a href="#A-trous-and-stride" class="headerlink" title="Ã€ trous and stride"></a>Ã€ trous and stride</h3><ul>
<li>å°†ResNet-10çš„æœ‰æ•ˆstrideä»32å‡ä¸º16åƒç´ ï¼Œæé«˜äº†score mapçš„åˆ†è¾¨ç‡ã€‚</li>
<li>conv4é˜¶æ®µä¹‹å‰ï¼ˆstride=16ï¼‰çš„æ‰€æœ‰å±‚éƒ½æ²¡æœ‰æ”¹å˜ã€‚</li>
<li>ç¬¬ä¸€ä¸ªconv5å—å„¿çš„strideä»2æ”¹ä¸º1ï¼Œå¹¶ä¸”conv5é˜¶æ®µçš„å·ç§¯æ ¸éƒ½è¢«æ”¹ä¸ºhole algorithmï¼Œï¼ˆAlgorithme Ã  trousï¼‰ä»¥è¡¥å¿å‡å°‘çš„æ­¥å¹…ã€‚</li>
<li>ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼ŒRPNåœ¨conv4ä¹‹ä¸Šè¿›è¡Œè®¡ç®—ã€‚ä»è€ŒRPNä¸è¢«Ã  trouså½±å“ã€‚</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>R-CNNå·²ç»è¯´æ˜äº†å¸¦æ·±åº¦ç½‘ç»œçš„åŒºåŸŸå€™é€‰çš„æœ‰æ•ˆæ€§ã€‚R-CNNè®¡ç®—é‚£äº›å…³äºè£å‰ªä¸æ­£å¸¸çš„è¦†ç›–åŒºåŸŸçš„å·ç§¯ç½‘ç»œï¼Œå¹¶ä¸”è®¡ç®—åœ¨åŒºåŸŸç›´æ¥æ˜¯ä¸å…±äº«çš„ã€‚SPPnetï¼ŒFast R-CNNå’ŒFaster R-CNNæ˜¯åŠå·ç§¯çš„ï¼ˆsemi-convolutionalï¼‰ï¼Œåœ¨å·ç§¯å­ç½‘ç»œä¸­æ˜¯è®¡ç®—å…±äº«çš„ï¼Œåœ¨å¦ä¸€ä¸ªå­ç½‘ç»œæ˜¯å„è‡ªè®¡ç®—ç‹¬ç«‹çš„åŒºåŸŸã€‚</p>
<p>ç‰©ä½“æ£€æµ‹å™¨å¯ä»¥è¢«è®¤ä¸ºæ˜¯å…¨å·ç§¯æ¨¡å‹ã€‚OverFeat æ£€æµ‹ç‰©ä½“é€šè¿‡åœ¨convolutional feature mapsä¸Šè¿›è¡Œå¤šå°ºåº¦çš„çª—å£æ»‘åŠ¨ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä»¥å°†å•ç²¾åº¦çš„æ»‘åŠ¨çª—å£æ”¹é€ æˆä¸€ä¸ªå•å±‚çš„å·ç§¯å±‚ã€‚åœ¨Faster R-CNNä¸­çš„RPNç»„ä»¶æ˜¯ä¸€ä¸ªå…¨å·ç§¯æ£€æµ‹å™¨ï¼Œç”¨æ¥é¢„æµ‹æ˜¯ä¸€ä¸ªå…³äºå¤šå°ºå¯¸çš„å‚è€ƒè¾¹æ¡†çš„å®é™…è¾¹æ¡†ã€‚åŸå§‹çš„RPNæ˜¯class-agnosticï¼ˆclassæ— å…³çš„ï¼‰ã€‚ä½†æ˜¯å¯¹åº”çš„class-specificæ˜¯å¯åº”ç”¨çš„ã€‚</p>
<p>å¦ä¸€ä¸ªç”¨äºç‰©ä½“æ£€æµ‹çš„æ˜¯fc layerï¼ˆfully-connectedï¼‰ç”¨æ¥åŸºäºæ•´å¹…å›¾ç‰‡çš„å®Œæ•´ç‰©ä½“æ£€æµ‹ã€‚</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;æå‡ºäº†ä¸€ä¸ªregion-based, fully convolutionalçš„ç½‘ç»œæ¥å‡†ç¡®é«˜æ•ˆçš„è¿›è¡Œç‰©ä½“æ£€æµ‹ã€‚&lt;/li&gt;
&lt;li&gt;ä¸åŒäºFast/Faster R-CNNï¼Œå…¶åº”ç”¨äº†è®¡ç®—æˆæœ¬å¾ˆé«˜çš„æ¯ä¸ªåŒºåŸŸå­ç½‘ç»œæ•°ç™¾æ¬¡ï¼Œæœ¬è®ºæ–‡çš„region-based detectoræ˜¯å®Œå…¨å·ç§¯åŒ–çš„ï¼Œå‡ ä¹ä¸€å¼ å›¾åƒä¸Šæ‰€æœ‰çš„è®¡ç®—éƒ½æ˜¯å…±äº«çš„ã€‚&lt;/li&gt;
&lt;li&gt;ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºposition-sensitive score mapsï¼Œä»¥è§£å†³åœ¨å›¾åƒåˆ†ç±»çš„å¹³ç§»ä¸å˜æ€§ï¼ˆtranslation-invarianceï¼‰å’Œç‰©ä½“æ£€æµ‹ä¸­çš„å¹³ç§»å¯å˜æ€§ï¼ˆtranslation-varianceï¼‰ä¹‹é—´çš„å›°å¢ƒã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šSSD</title>
    <link href="http://jacobkong.github.io/posts/3118967289/"/>
    <id>http://jacobkong.github.io/posts/3118967289/</id>
    <published>2017-02-13T09:53:54.000Z</published>
    <updated>2017-02-16T02:30:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="çŸ¥è¯†ç‚¹"><a href="#çŸ¥è¯†ç‚¹" class="headerlink" title="çŸ¥è¯†ç‚¹"></a>çŸ¥è¯†ç‚¹</h2><ul>
<li>Jaccard overlap, Jaccard similarity:<br>Jaccard coefficient:<script type="math/tex; mode=display">
J(A,B)=\frac{|A\cap B|}{|A\cup B|}</script>A,Båˆ†åˆ«ä»£è¡¨ç¬¦åˆæŸç§æ¡ä»¶çš„é›†åˆï¼šä¸¤ä¸ªé›†åˆäº¤é›†çš„å¤§å°/ä¸¤ä¸ªé›†åˆå¹¶é›†çš„å¤§å°ï¼Œäº¤é›†=å¹¶é›†æ„å‘³ç€2ä¸ªé›†åˆå®Œå…¨é‡åˆã€‚<br><strong>æ‰€ä»¥Jaccard overlapå…¶å®å°±æ˜¯IoUã€‚</strong><a id="more"></a>
</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>SSD: åˆ©ç”¨å•ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ã€‚å°†è¾¹ç•Œæ¡†çš„è¾“å‡ºç©ºé—´ç¦»æ•£åŒ–ä¸ºä¸€ç»„é»˜è®¤æ¡†ï¼Œåœ¨æ¯ä¸ªfeature mapä½ç½®ä¸Šæœ‰ç€ä¸åŒçš„å®½é«˜æ¯”å’Œå°ºåº¦ã€‚</li>
<li>åœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œç½‘ç»œé’ˆå¯¹æ¯ä¸ªé»˜è®¤æ¡†ä¸­çš„æ¯ä¸ªå­˜åœ¨çš„å¯¹è±¡ç±»åˆ«äº§ç”Ÿåˆ†æ•°ï¼Œå¹¶ä¸”å¯¹æ¡†çš„è¿›è¡Œè°ƒæ•´ä»¥æ›´å¥½åœ°åŒ¹é…å¯¹è±¡å½¢çŠ¶ã€‚</li>
<li><strong>åœ¨å¤šå°ºåº¦å›¾åƒå¤„ç†æ–¹é¢</strong>ï¼Œç½‘ç»œç»„åˆæ¥è‡ªå…·æœ‰ä¸åŒåˆ†è¾¨ç‡çš„å¤šä¸ªfeature mapçš„é¢„æµ‹ï¼Œä»¥è‡ªç„¶åœ°å¤„ç†å„ç§å°ºå¯¸çš„å¯¹è±¡ã€‚</li>
<li>ç›¸æ¯”äºåŸºäºobject proposalçš„æ–¹æ³•ï¼ŒSSDæ˜¯ç®€å•åœ°ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿ<strong>å®Œå…¨æ¶ˆé™¤</strong>proposal generationå’Œåç»­çš„<strong>åƒç´ æˆ–è€…ç‰¹å¾é‡å†²é‡‡æ ·é˜¶æ®µ</strong>ï¼Œæ‰€æœ‰çš„è®¡ç®—éƒ½å°è£…åœ¨å•ç‹¬çš„ç½‘ç»œä¸­ã€‚</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>ç›®å‰çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿæ˜¯ä»¥ä¸‹æ–¹æ³•çš„å˜ä½“ï¼šå‡è®¾è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰ï¼Œå¯¹æ¯ä¸ªæ¡†è¿›è¡Œåƒç´ æˆ–ç‰¹å¾é‡å–æ ·ï¼Œé‡‡ç”¨é«˜è´¨é‡åˆ†ç±»å™¨ã€‚</li>
<li>è¯„ä¼°é€Ÿåº¦æ–¹æ³•ï¼š<strong>SPF (seconds per frame)</strong>.</li>
<li>æå‡ºç¬¬ä¸€ä¸ªåŸºäºæ·±åº¦ç½‘ç»œçš„ä¸éœ€è¦ä¸ºBBè¿›è¡Œresample pixels or featuresçš„ç›®æ ‡æ£€æµ‹å™¨ï¼Œå¹¶èƒ½å¤ŸåŒæ ·è¾¾åˆ°é«˜å‡†ç¡®ç‡ã€‚</li>
<li>æœ¬è®ºæ–‡çš„è´¡çŒ®ï¼ˆå…·ä½“çœ‹è®ºæ–‡ï¼‰ï¼š<ul>
<li>å¼•å…¥äº†SSDã€‚</li>
<li>SSDçš„æ ¸å¿ƒã€‚</li>
<li>ä¸ºäº†å®ç°é«˜æ£€æµ‹å‡†ç¡®ç‡ï¼Œå¼•å…¥äº†åœ¨ä¸åŒå°ºåº¦å’Œæ¨ªçºµæ¯”çš„feature mapsä¸Šè¿›è¡Œé¢„æµ‹ã€‚</li>
<li>End-to-end training ä»¥åŠé«˜å‡†ç¡®ç‡ï¼Œæœºè¯•åœ¨ä½åˆ†è¾¨ç‡å›¾ç‰‡ã€‚</li>
<li>åœ¨PASCAL VOCã€COCOå’ŒILSVRCä¸Šè¿›è¡Œè¯•éªŒï¼Œå…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚</li>
</ul>
</li>
</ul>
<h2 id="The-Single-Shot-Detector-SSD"><a href="#The-Single-Shot-Detector-SSD" class="headerlink" title="The Single Shot Detector (SSD)"></a>The Single Shot Detector (SSD)</h2><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><ul>
<li>åŸºäºå‰å‘å·ç§¯ç¥ç»ç½‘ç»œï¼Œäº§ç”Ÿå›ºå®šå°ºå¯¸çš„BBé›†ï¼Œä»¥åŠè¿™äº›BBä¸­å­˜åœ¨ç‰©ä½“çš„åˆ†æ•°ï¼Œä¹‹åè·Ÿéšè€…ä¸€ä¸ªéæå¤§å€¼æŠ‘åˆ¶æ­¥éª¤æ¥äº§ç”Ÿæœ€ç»ˆæ£€æµ‹ã€‚</li>
<li><p>ç½‘ç»œå‰é¢çš„å‡ å±‚æ˜¯åŸºäºæ ‡å‡†çš„ç”¨äºäº§ç”Ÿé«˜è´¨é‡å›¾åƒåˆ†ç±»çš„æ¶æ„ï¼Œæˆ‘ä»¬æˆä¸º<strong>åŸºç¡€ç½‘ç»œ</strong>ã€‚æˆ‘ä»¬ç»™ç½‘ç»œç„¶åæ·»åŠ äº†<strong>è¾…åŠ©çš„ç»“æ„</strong>æ¥äº§ç”Ÿæ£€æµ‹ç»“æ„ã€‚è¾…åŠ©ç½‘ç»œå…·å¤‡ä»¥ä¸‹å…³é”®ç‰¹å¾ï¼š</p>
<ul>
<li><p><strong>ç”¨äºæ£€æµ‹çš„å¤šå°ºå¯¸ç‰¹å¾å›¾ã€‚</strong>åœ¨åŸºç¡€ç½‘ç»œåé¢<strong>æ·»åŠ é¢å¤–å‡ ä¸ªå·ç§¯å±‚</strong>ï¼Œåœ¨å°ºå¯¸ä¸Šé€å±‚é€’å‡ï¼Œä»è€Œèƒ½å¤Ÿåœ¨ä¸åŒå°ºå¯¸ä¸Šæ£€æµ‹ã€‚ï¼ˆOverfeatå’ŒYOLOéƒ½åªæ˜¯åœ¨å•ç‹¬å°ºå¯¸çš„feature mapä¸Šè¿›è¡Œæ“ä½œã€‚ï¼‰</p>
</li>
<li><p><strong>ç”¨æ¥é¢„æµ‹çš„å·ç§¯é¢„æµ‹å™¨</strong>ï¼ˆConvolutional predictorsï¼‰ã€‚</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgy1fcq4bw59jtj30j109i3zs.jpg" alt=""></p>
</li>
<li><p><strong>é»˜è®¤çš„boxeså’Œaspect ratiosã€‚</strong>æˆ‘ä»¬å°†ä¸€ç»„é»˜è®¤è¾¹ç•Œæ¡†ä¸æ¯ä¸ªfeature mapå•å…ƒå…³è”ï¼Œç”¨äºç½‘ç»œé¡¶éƒ¨çš„å¤šä¸ªç‰¹å¾æ˜ å°„ã€‚åœ¨æ¯ä¸ªfeature mapå•å…ƒæ ¼ä¸­ï¼Œæˆ‘ä»¬é¢„æµ‹ç›¸å¯¹äºå•å…ƒæ ¼ä¸­çš„é»˜è®¤æ¡†å½¢çŠ¶çš„åç§»ï¼Œä»¥åŠæŒ‡ç¤ºæ¯ä¸ªæ¡†ä¸­å­˜åœ¨ç±»å®ä¾‹çš„æ¯ç±»åˆ†æ•°ã€‚ï¼ˆæœ¬è®ºæ–‡ä¸­çš„default boxesç±»ä¼¼äºFaster R-CNNä¸­çš„anchor boxesï¼Œç„¶è€Œæˆ‘ä»¬å°†ä»–ç”¨äºä¸åŒåˆ†è¾¨ç‡çš„å‡ ä¸ªfeature mapsä¸­ï¼‰</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgy1fcp21vqfpgj30le0ey0xb.jpg" alt=""></p>
</li>
</ul>
</li>
</ul>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul>
<li><p>è®­ç»ƒSSDå’Œè®­ç»ƒä½¿ç”¨region proposalsçš„å…¸å‹æ£€æµ‹å™¨ä¹‹é—´çš„<strong>å…³é”®åŒºåˆ«æ˜¯</strong>ï¼šground truthä¿¡æ¯éœ€è¦åˆ†é…ç»™å›ºå®šçš„æ£€æµ‹å™¨è¾“å‡ºé›†åˆä¸­çš„ç‰¹å®šè¾“å‡ºã€‚</p>
</li>
<li><p>è®­ç»ƒæ¶‰åŠåˆ°ï¼š</p>
<ul>
<li>choosing the set of default boxes and scales for detectionã€‚</li>
<li>hard negative miningã€‚</li>
<li>data augmentation strategiesï¼ˆæ•°æ®å¢åŠ ç­–ç•¥ï¼‰ã€‚</li>
</ul>
</li>
</ul>
<h4 id="Matching-strategy"><a href="#Matching-strategy" class="headerlink" title="Matching strategy"></a><strong>Matching strategy</strong></h4><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯¹äºæ¯ä¸€ä¸ªground truthï¼Œæˆ‘ä»¬éƒ½ä»é»˜è®¤æ¡†ä¸­é€‰æ‹©æ¯ä¸ªä¸åŒçš„ä½ç½®ã€aspect ratioã€scaleçš„bounding boxesã€‚é¦–å…ˆåŒ¹é…æœ€å¥½çš„jaccard overlapçš„default boxï¼ˆç±»ä¼¼äºMultiBoxï¼‰ï¼Œä½†ä¸MultiBoxä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ç„¶ååŒ¹é…default boxä¸ä»»ä½•ground truthï¼Œåªè¦jaccard overlapé«˜äºé˜ˆå€¼ï¼ˆ0.5ï¼‰ã€‚<strong>è¿™æ ·ç®€åŒ–äº†å­¦ä¹ é—®é¢˜ã€‚</strong></p>
<h4 id="Training-objective"><a href="#Training-objective" class="headerlink" title="Training objective"></a><strong>Training objective</strong></h4><p>æ•´ä½“çš„ä»£ä»·å‡½æ•°æ˜¯localization losså’Œconfidence lossä¹‹å’Œï¼š</p>
<script type="math/tex; mode=display">
L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))</script><ul>
<li><p>Næ˜¯åŒ¹é…çš„default boxesçš„æ•°é‡ï¼ŒN=0æ—¶ï¼Œloss=0ã€‚</p>
</li>
<li><p>localization lossæ˜¯predicted boxå’Œground truth boxä¹‹é—´çš„<strong>Smooth L1 loss</strong>ï¼ˆç±»ä¼¼äºFaster R-CNNï¼‰ã€‚æˆ‘ä»¬é¢„æµ‹default boxçš„ä¸­å¿ƒ$(cx,cy)$ï¼Œä»¥åŠå®½åº¦$(w)$å’Œé•¿åº¦$(h)$ã€‚</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcjw1fcqyi2ogdnj30bj03l3yr.jpg" alt=""></p>
</li>
<li><p>confidence lossæ˜¯å¤šä¸ªç±»confidence$(c)$ä¹‹é—´çš„<strong>softmax loss</strong>ã€‚</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgy1fcqyjitcw7j30eh01kjrg.jpg" alt=""></p>
</li>
<li><p>æƒå€¼$\alpha$é€šè¿‡äº¤å‰éªŒè¯è®¾ä¸º1ã€‚</p>
</li>
</ul>
<h4 id="Choosing-scales-and-aspect-ratios-for-default-boxes"><a href="#Choosing-scales-and-aspect-ratios-for-default-boxes" class="headerlink" title="Choosing scales and aspect ratios for default boxes"></a>Choosing scales and aspect ratios for default boxes</h4><ul>
<li><p>ä¸åŒäºå°†ç…§ç‰‡å¤„ç†ä¸ºä¸åŒå°ºå¯¸å†ç»“åˆç»“æœçš„æ–¹æ³•ï¼Œæœ¬è®ºæ–‡é€šè¿‡åˆ©ç”¨å•ä¸ªç¥ç»ç½‘ç»œä¸­ä¸åŒå±‚çš„feature mapsï¼Œå¯ä»¥è¾¾åˆ°åŒæ ·çš„æ•ˆæœï¼ŒåŒæ—¶å¯ä»¥åœ¨æ‰€æœ‰å°ºå¯¸ä¸­å…±äº«æƒå€¼ã€‚</p>
</li>
<li><p><strong>åˆ©ç”¨è¾ƒä½å±‚çš„feature mapså¯ä»¥æé«˜semantic segmentationè´¨é‡ï¼Œåº”ä¸ºè¾ƒä½å±‚å¾€å¾€å¯ä»¥æ•æ‰åˆ°æ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚</strong></p>
</li>
<li><p>æˆ‘ä»¬åŒæ—¶ä½¿ç”¨è¾ƒä½å’Œè¾ƒé«˜å±‚çš„feature mapsæ¥è¿›è¡Œæ£€æµ‹ã€‚</p>
</li>
<li><p>ç½‘ç»œä¸­ä¸åŒå±‚çš„feature mapsæœ‰ç€ä¸åŒçš„æ¥å—åŸŸçš„å°ºå¯¸ã€‚</p>
</li>
<li><p>å‡è®¾æˆ‘ä»¬æƒ³è¦ä½¿ç”¨mä¸ªfeature mapsç”¨æ¥æ£€æµ‹ï¼Œåˆ™æ¯ä¸ªfeature mapçš„default boxesçš„scaleå¯ä»¥è¿™æ ·è®¡ç®—ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcjw1fcr0sa2183j308k0190sn.jpg" alt=""></p>
</li>
<li><p>é€šè¿‡ç»“åˆåœ¨è®¸å¤šfeature mapsä¸Šæ‰€æœ‰ä½ç½®ä¸Šçš„æ‰€æœ‰çš„æœ‰ç€ä¸åŒscaleå’Œaspect ratioçš„default boxesï¼Œæˆ‘ä»¬å¯ä»¥äº§ç”Ÿå¯¹ä¸åŒç‰©ä½“å¤§å°å’Œå½¢çŠ¶çš„å„ç§é¢„æµ‹ã€‚</p>
</li>
<li><p>å¦‚ä¸‹å›¾ä¸­ï¼Œç‹—åœ¨8x8çš„feature mapä¸­æ²¡æœ‰åŒ¹é…çš„default boxï¼Œå› æ­¤åœ¨è®­ç»ƒä¸­ä¼šè¢«ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œä½†æ˜¯åœ¨4x4çš„feature mapä¸­æœ‰ç€åŒ¹é…çš„feature mapã€‚</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fcr148r96xj30e70563zd.jpg" alt=""></p>
</li>
</ul>
<h4 id="Hard-negative-mining"><a href="#Hard-negative-mining" class="headerlink" title="Hard negative mining"></a>Hard negative mining</h4><ul>
<li>é€šè¿‡åŒ¹é…é˜¶æ®µåï¼Œdefault boxesä¸­ä¼šäº§ç”Ÿå¤§é‡çš„negativesï¼Œå°¤å…¶æ˜¯å½“å¯èƒ½çš„default boxesæ•°é‡éå¸¸å¤§æ—¶ã€‚<strong>è¿™å¯¼è‡´positiveå’Œnegativeæ—¶é—´ä¸¥é‡çš„ä¸å¹³è¡¡ã€‚</strong></li>
<li>æˆ‘ä»¬å°†negative examplesçš„default boxesé€šè¿‡å…¶æœ€é«˜çš„confidence lossè¿›è¡Œæ’åºï¼Œç„¶åé€‰æ‹©è¾ƒé«˜çš„å‡ ä¸ªï¼Œä½¿negative exampleså’Œpositive examplesä¹‹é—´çš„æ¯”ä¾‹ä¿æŒåœ¨3:1ä¹‹é—´ã€‚<strong>è¿™æ ·ä¼šæ›´å¿«çš„ä¼˜åŒ–å’Œæ›´ç¨³å®šçš„è®­ç»ƒã€‚</strong></li>
</ul>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><ul>
<li>æ‰€æœ‰çš„å®éªŒéƒ½æ˜¯åŸºäºVGG16ã€‚</li>
<li>å°†fc6å’Œfc7è½¬åŒ–ä¸ºå·ç§¯å±‚ï¼Œä»fc6å’Œfc7ä¸­å–æ ·å­å‚æ•°ã€‚</li>
<li>å°†pool5ä»2x2-s2è½¬åŒ–ä¸º3x3-s1ã€‚</li>
<li>ä½¿ç”¨a trous algorithmæ¥å¡«è¡¥â€œholesâ€ã€‚</li>
<li>ç§»å»äº†æ‰€æœ‰çš„dropoutå±‚å’Œfc8å±‚ã€‚</li>
<li>ç”¨SGDè¿›è¡Œå¾®è°ƒã€‚</li>
<li>å­¦ä¹ ç‡$10^{-3}$ï¼ŒåŠ¨é‡0.9ï¼Œweight decayæ˜¯0.0005ï¼Œbatch sizeæ˜¯32.</li>
</ul>
<h3 id="PASCAL-VOC2007"><a href="#PASCAL-VOC2007" class="headerlink" title="PASCAL VOC2007"></a>PASCAL VOC2007</h3><ul>
<li><strong>â€œxavierâ€ method</strong>æ¥åˆå§‹åŒ–æ–°åŠ å…¥çš„å±‚çš„å‚æ•°ã€‚</li>
<li>é€šè¿‡detection analysis toolåˆ†æåï¼Œæ˜¾ç¤ºSSDæœ‰ç€<strong>æ›´å°‘çš„localizationé”™è¯¯</strong>ï¼Œå› ä¸ºå…¶èƒ½å¤Ÿç›´æ¥å»å­¦ä¹ regressç‰©ä½“çš„å½¢çŠ¶ï¼Œå¹¶åˆ†ç±»ï¼Œè€Œéä½¿ç”¨ä¸¤ä¸ªäº’ç›¸è§£è€¦çš„æ­¥éª¤ã€‚</li>
<li>ç„¶è€Œï¼ŒSSDå¯¹äºç›¸ä¼¼çš„ç‰©ä½“ä¼šæœ‰æ›´å¤šçš„æ··æ·†ï¼Œç‰¹åˆ«æ˜¯animalsï¼Œä¸€éƒ¨åˆ†åŸå› ã€‚</li>
<li>SSDå¯¹bounding boxeså°ºå¯¸æ˜¯ååˆ†æ•æ„Ÿçš„ã€‚æå‡è¾“å…¥å°ºå¯¸å¯èƒ½ä¼šæå‡å°ç‰©ä½“æ£€æµ‹ï¼Œä½†ä¾æ—§æœ‰è®¸å¤šç©ºé—´æå‡ã€‚</li>
</ul>
<h3 id="Model-analysis"><a href="#Model-analysis" class="headerlink" title="Model analysis"></a>Model analysis</h3><ul>
<li>Data augmentationå¾ˆé‡è¦ã€‚</li>
<li>æ›´å¤šçš„default boxesçš„å½¢çŠ¶å¯èƒ½ä¼šæ›´å¥½ã€‚</li>
<li>Atrous is fasterï¼šå¦‚æœä¸ä½¿ç”¨æ›´æ”¹åçš„VGG-16ï¼Œè™½ç„¶ç»“æœä¸€æ ·ï¼Œä½†æ˜¯é€Ÿåº¦å›é™ä½20%ã€‚</li>
<li>ä¸åŒåˆ†è¾¨ç‡ä¸­å¤šä¸ªè¾“å‡ºå±‚ä¼šæ›´å¥½ã€‚<strong>SSDçš„ä¸»è¦è´¡çŒ®</strong>æ˜¯åœ¨ä¸åŒè¾“å‡ºå±‚ä¸Šä½¿ç”¨ä¸åŒå°ºåº¦çš„é»˜è®¤æ¡†ã€‚</li>
</ul>
<h3 id="PASCAL-VOC2012"><a href="#PASCAL-VOC2012" class="headerlink" title="PASCAL VOC2012"></a>PASCAL VOC2012</h3><ul>
<li>å’ŒPASCAL VOC2007ä¸€æ ·çš„å®éªŒè®¾ç½®ã€‚</li>
<li>åœ¨2012 trainval+2007 trainval+2007 testä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨2012 testä¸Šè¿›è¡Œæµ‹è¯•ã€‚</li>
</ul>
<h3 id="COCO"><a href="#COCO" class="headerlink" title="COCO"></a>COCO</h3><ul>
<li>COCOä¸­çš„ç‰©ä½“æ¯”PASCAL VOCä¸­çš„ç‰©ä½“å°ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨æ‰€æœ‰å±‚ä¸Šä½¿ç”¨æ›´å°çš„default boxes</li>
</ul>
<h3 id="Data-Augmentation-for-Small-Object-Accuracy"><a href="#Data-Augmentation-for-Small-Object-Accuracy" class="headerlink" title="Data Augmentation for Small Object Accuracy"></a>Data Augmentation for Small Object Accuracy</h3><ul>
<li>å¯¹SSDæ¥è¯´ï¼Œå¯¹å°ç‰©ä½“åˆ†ç±»çš„ä»»åŠ¡ç›¸å¯¹Faster R-CNNæ¥è¯´ä¼šæ›´éš¾ã€‚</li>
<li>Data augmentationå¯¹äºç‰¹é«˜æ€§èƒ½æ˜¯ååˆ†æ˜¾è‘—çš„ï¼Œå°¤å…¶æ˜¯å°æ•°æ®åŠã€‚</li>
<li>æ”¹è¿›SSDçš„å¦ä¸€ç§æ–¹æ³•æ˜¯è®¾è®¡æ›´å¥½çš„å¹³é“ºé»˜è®¤æ¡†ï¼ˆtiling of default boxesï¼‰ï¼Œä½¿å…¶ä½ç½®å’Œå°ºåº¦æ›´å¥½åœ°ä¸ç‰¹å¾å›¾ä¸Šæ¯ä¸ªä½ç½®çš„æ¥æ”¶åœºå¯¹å‡†ã€‚</li>
</ul>
<h3 id="Inference-time"><a href="#Inference-time" class="headerlink" title="Inference time"></a>Inference time</h3><ul>
<li>è€ƒè™‘åˆ°ä»æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„å¤§é‡æ¡†ï¼Œæœ‰å¿…è¦åœ¨æ¨ç†æœŸé—´æœ‰æ•ˆåœ°æ‰§è¡Œéæœ€å¤§æŠ‘åˆ¶ï¼ˆnmsï¼‰ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨0.01çš„é™åˆ¶é˜ˆå€¼ï¼Œæˆ‘ä»¬å¯ä»¥è¿‡æ»¤å¤§å¤šæ•°bounding boxesã€‚ ç„¶åæˆ‘ä»¬åº”ç”¨nmsï¼Œæ¯ä¸ªç±»åˆ«çš„jaccardé‡å 0.45ï¼Œå¹¶ä¿æŒæ¯ä¸ªå›¾åƒå‰200ä¸ªæ£€æµ‹ã€‚</li>
<li>80%çš„å‰å‘ä¼ é€’æ—¶é—´è¢«èŠ±è´¹åœ¨äº†base networkï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªæ›´å¿«çš„base networkå¯ä»¥æé«˜é€Ÿåº¦ã€‚</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>æœ‰ä¸¤ç§å·²å»ºç«‹çš„ç”¨äºå›¾åƒä¸­çš„å¯¹è±¡æ£€æµ‹çš„æ–¹æ³•ç±»åˆ«ï¼Œ<strong>ä¸€ç§åŸºäºæ»‘åŠ¨çª—å£ï¼Œå¦ä¸€ç§åŸºäºregion proposal classificationã€‚</strong></li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul>
<li>æˆ‘ä»¬æ¨¡å‹çš„ä¸€ä¸ª<strong>å…³é”®ç‰¹æ€§</strong>æ˜¯ä½¿ç”¨å¤šå°ºåº¦å·ç§¯è¾¹ç•Œæ¡†è¾“å‡ºé™„åŠ åˆ°ç½‘ç»œé¡¶éƒ¨çš„å¤šä¸ªç‰¹å¾å›¾ã€‚</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;a href=&quot;#çŸ¥è¯†ç‚¹&quot; class=&quot;headerlink&quot; title=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;/a&gt;çŸ¥è¯†ç‚¹&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Jaccard overlap, Jaccard similarity:&lt;br&gt;Jaccard coefficient:&lt;script type=&quot;math/tex; mode=display&quot;&gt;
J(A,B)=\frac{|A\cap B|}{|A\cup B|}&lt;/script&gt;A,Båˆ†åˆ«ä»£è¡¨ç¬¦åˆæŸç§æ¡ä»¶çš„é›†åˆï¼šä¸¤ä¸ªé›†åˆäº¤é›†çš„å¤§å°/ä¸¤ä¸ªé›†åˆå¹¶é›†çš„å¤§å°ï¼Œäº¤é›†=å¹¶é›†æ„å‘³ç€2ä¸ªé›†åˆå®Œå…¨é‡åˆã€‚&lt;br&gt;&lt;strong&gt;æ‰€ä»¥Jaccard overlapå…¶å®å°±æ˜¯IoUã€‚&lt;/strong&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šYOLO9000</title>
    <link href="http://jacobkong.github.io/posts/2102833929/"/>
    <id>http://jacobkong.github.io/posts/2102833929/</id>
    <published>2017-02-08T03:56:20.000Z</published>
    <updated>2018-05-18T04:04:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>YOLO9000: a state-of-the-art, real-time çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œå¯ä»¥æ£€æµ‹è¶…è¿‡9000ç§çš„ç‰©ä½“åˆ†ç±»ã€‚</li>
<li>æœ¬è®ºæ–‡æå‡ºä¸¤ä¸ªæ¨¡å‹ï¼Œ<strong>YOLOv2å’ŒYOLO9000</strong>ã€‚</li>
<li>YOLOv2ï¼š<ul>
<li>æ˜¯å¯¹YOLOæ”¹è¿›åçš„æå‡æ¨¡å‹ã€‚</li>
<li>åˆ©ç”¨æ–°é¢–çš„ï¼Œå¤šå°ºåº¦è®­ç»ƒçš„æ–¹æ³•ï¼ŒYOLOv2æ¨¡å‹å¯ä»¥åœ¨å¤šç§å°ºåº¦ä¸Šè¿è¡Œï¼Œåœ¨é€Ÿåº¦ä¸å‡†ç¡®æ€§ä¸Šæ›´å®¹æ˜“å»trade offã€‚</li>
</ul>
</li>
<li>YOLO9000ï¼š<ul>
<li>æ˜¯æå‡ºçš„ä¸€ç§è”åˆåœ¨æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œ<strong>è¿™ç§è”åˆè®­ç»ƒçš„æ–¹æ³•ä½¿å¾—YOLO9000èƒ½å¤Ÿä¸ºæ²¡æœ‰æ ‡ç­¾çš„æ£€æµ‹æ•°æ®ç›®æ ‡ç±»é¢„æµ‹</strong>ã€‚</li>
<li>å¯ä»¥æ£€æµ‹è¶…è¿‡9000ä¸ªç±»ã€‚</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>ç›®å‰ï¼Œè®¸å¤šæ£€æµ‹æ–¹æ³•ä¾æ—§çº¦æŸåœ¨å¾ˆå°çš„ç‰©ä½“é›†ä¸Šã€‚</li>
<li>ç›®å‰ï¼Œç›®æ ‡æ£€æµ‹æ•°æ®é›†ç›¸æ¯”äºç”¨äºåˆ†ç±»å’Œæ ‡æ³¨çš„æ•°æ®é›†æ¥è¯´ï¼Œæ˜¯æœ‰é™åˆ¶çš„ã€‚<ul>
<li>æœ€å¸¸è§çš„æ£€æµ‹æ•°æ®é›†åŒ…å«æ•°ååˆ°æ•°åä¸‡çš„å›¾åƒï¼Œå…·æœ‰å‡ ååˆ°å‡ ç™¾ä¸ªæ ‡ç­¾ï¼Œæ¯”å¦‚Pascalã€CoCoã€ImageNetã€‚ </li>
<li>åˆ†ç±»æ•°æ®é›†å…·æœ‰æ•°ä»¥ç™¾ä¸‡è®¡çš„å›¾åƒï¼Œå…·æœ‰æ•°ä¸‡æˆ–æ•°åä¸‡ç§ç±»åˆ«ï¼Œå¦‚ImageNetã€‚</li>
</ul>
</li>
<li>ç›®æ ‡æ£€æµ‹æ•°æ®é›†æ°¸è¿œä¸ä¼šè¾¾åˆ°å’Œåˆ†ç±»æ•°æ®é›†ä¸€æ ·çš„ç­‰çº§ã€‚</li>
<li>æœ¬è®ºæ–‡æå‡ºä¸€ç§æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†ç±»æ•°æ®é›†æ¥ä½œä¸ºæ£€æµ‹æ•°æ®é›†ï¼Œå°†ä¸¤ç§æˆªç„¶ä¸åŒçš„æ•°æ®é›†ç»“åˆã€‚</li>
<li>æœ¬è®ºæ–‡æå‡ºä¸€ä¸ªåœ¨ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè”åˆè®­ç»ƒçš„æ–¹æ³•ã€‚<strong>æ­¤æ–¹æ³•åˆ©ç”¨æ ‡è®°çš„æ£€æµ‹å›¾åƒå­¦ä¹ ç²¾ç¡®å®šä½å¯¹è±¡ï¼Œè€Œå®ƒä½¿ç”¨åˆ†ç±»å›¾åƒå¢åŠ å…¶è¯æ±‡å’Œé²æ£’æ€§ã€‚</strong></li>
</ul>
<h2 id="Better"><a href="#Better" class="headerlink" title="Better"></a>Better</h2><ul>
<li><p>YOLOäº§ç”Ÿå¾ˆå¤šçš„å®šä½é”™è¯¯ã€‚è€Œä¸”YOLOç›¸æ¯”äºregion proposal-basedæ–¹æ³•æœ‰ç€ç›¸å¯¹è¾ƒä½çš„recallï¼ˆæŸ¥å…¨ç‡ï¼‰ã€‚<strong>æ‰€ä»¥ä¸»è¦ä»»åŠ¡æ˜¯åœ¨ä¿æŒåˆ†ç±»å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œæé«˜recallå’Œå‡å°‘å®šä½é”™è¯¯ã€‚</strong></p>
</li>
<li><p>æˆ‘ä»¬ä»è¿‡å»çš„å·¥ä½œä¸­èåˆäº†æˆ‘ä»¬è‡ªå·±çš„å„ç§æ–°æƒ³æ³•ï¼Œä»¥æé«˜YOLOçš„æ€§èƒ½ã€‚ ç»“æœçš„æ‘˜è¦å¯ä»¥åœ¨è¡¨ä¸­æ‰¾åˆ°ï¼š</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fcizngrvjoj30eq05paas.jpg" alt=""></p>
</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a><strong>Batch Normalization</strong></h3><ul>
<li>å¾—åˆ°2%çš„mAPçš„æå‡ï¼Œä½¿ç”¨Batch Normalizationï¼Œæˆ‘ä»¬å¯ä»¥ä»æ¨¡å‹ä¸­åˆ é™¤dropoutï¼Œè€Œä¸ä¼šå‡ºç°è¿‡åº¦ç¼ºé™·ã€‚</li>
</ul>
<h3 id="High-Resolution-Classiï¬er"><a href="#High-Resolution-Classiï¬er" class="headerlink" title="High Resolution Classiï¬er"></a><strong>High Resolution Classiï¬er</strong></h3><ul>
<li>å¯¹äºYOLOv2ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ImageNetå¯¹å…¨éƒ¨448Ã—448åˆ†è¾¨ç‡å›¾åƒä¸Šè¿›è¡Œ10epochsçš„å¾®è°ƒæ¥è°ƒæ•´åˆ†ç±»ç½‘ç»œã€‚  ç„¶åæˆ‘ä»¬åœ¨æ£€æµ‹æ—¶è°ƒæ•´resulting networkã€‚ è¿™ç§é«˜åˆ†è¾¨ç‡åˆ†ç±»ç½‘ç»œä½¿æˆ‘ä»¬å¢åŠ äº†è¿‘4ï¼…çš„mAPã€‚</li>
</ul>
<h3 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a><strong>Convolutional With Anchor Boxes</strong></h3><ul>
<li>YOLOåˆ©ç”¨å·ç§¯ç‰¹å¾æå–å™¨æœ€é¡¶ç«¯çš„å…¨è¿æ¥å±‚æ¥ç›´æ¥é¢„æµ‹BBçš„åæ ‡ã€‚è€ŒFaster R-CNNæ˜¯åˆ©ç”¨é¦–é€‰çš„priorsæ¥é¢„æµ‹BBã€‚</li>
<li>é¢„æµ‹BBçš„åç§»è€Œä¸æ˜¯åæ ‡å¯ä»¥ç®€åŒ–é—®é¢˜ï¼Œå¹¶ä½¿ç½‘ç»œæ›´å®¹æ˜“å­¦ä¹ ã€‚æœ¬è®ºæ–‡ä»YOLOä¸­ç§»å»äº†å…¨è¿æ¥å±‚ï¼Œå¹¶ä¸”åˆ©ç”¨anchor boxæ¥é¢„æµ‹BBã€‚</li>
<li>æˆ‘ä»¬ç§»å»äº†poolingå±‚ï¼Œä½¿å¾—ç½‘ç»œçš„å·ç§¯å±‚çš„è¾“å‡ºæœ‰æ›´é«˜çš„åƒç´ ã€‚</li>
<li>åŒæ—¶å°†ç½‘ç»œç¼©å‡åˆ°åœ¨416*416åƒç´ çš„å›¾ç‰‡ä¸Šæ“ä½œã€‚ æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºæˆ‘ä»¬æƒ³è¦ç‰¹å¾å›¾ä¸­å…·æœ‰å¥‡æ•°ä¸ªä½ç½®ï¼Œå› æ­¤å­˜åœ¨å•ä¸ªä¸­å¿ƒå•å…ƒã€‚</li>
<li>å½“æˆ‘ä»¬ç§»åŠ¨åˆ°anchor boxesæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå°†class predictionæœºåˆ¶ä¸ç©ºé—´ä½ç½®è§£è€¦ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªanchor boxé¢„æµ‹çš„ç±»å’Œå¯¹è±¡ã€‚ åŒYOLOä¸€æ ·ï¼Œobjectness predictionä»ç„¶é¢„æµ‹ground truthå’Œæ‰€æå‡ºçš„æ¡†çš„IOUï¼Œå¹¶ä¸”class predictionsé¢„æµ‹è¯¥ç±»çš„æ¡ä»¶æ¦‚ç‡ï¼Œå‡å®šå­˜åœ¨å¯¹è±¡ã€‚(æ²¡å¤ªæ‡‚)</li>
</ul>
<h3 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a><strong>Dimension Clusters</strong></h3><ul>
<li><p>å°†YOLOä¸anchor boxesç»“åˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œ<strong>ç¬¬ä¸€ä¸ªæ˜¯anchor boxçš„é•¿å®½æ˜¯è®¤ä¸ºé€‰å®šçš„ã€‚</strong></p>
</li>
<li><p>æˆ‘ä»¬ä¸æ˜¯æ‰‹åŠ¨é€‰æ‹©å…ˆéªŒï¼ˆpriorsï¼‰ï¼Œè€Œæ˜¯åœ¨è®­ç»ƒé›†è¾¹ç•Œæ¡†ä¸Šè¿è¡Œk-meansèšç±»ï¼Œä»¥è‡ªåŠ¨æ‰¾åˆ°å¥½çš„å…ˆéªŒã€‚</p>
<ul>
<li><p>æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯å¯¼è‡´è‰¯å¥½çš„IOUåˆ†æ•°çš„priorsï¼Œè¿™æ˜¯ç‹¬ç«‹äºç›’å­çš„å¤§å°ã€‚ å› æ­¤ï¼Œå¯¹äºæˆ‘ä»¬çš„distance metricï¼Œæˆ‘ä»¬ä½¿ç”¨ï¼š</p>
<script type="math/tex; mode=display">
d(box, centroid) = 1-IOU(box,centroid)</script></li>
<li><p>æˆ‘ä»¬é€‰æ‹©<strong>k = 5</strong>ä½œä¸ºæ¨¡å‹å¤æ‚æ€§å’Œé«˜å¬å›ç‡ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚è¿™æ ·éå¸¸ä¸åŒäºç›¸æ¯”äºäººå·¥é€‰æ‹©çš„boxesã€‚æ›´å¤šçš„åˆé«˜åˆç˜¦çš„boxesã€‚</p>
</li>
</ul>
</li>
</ul>
<h3 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a><strong>Direct location prediction</strong></h3><ul>
<li><p>å°†YOLOä¸anchor boxesç»“åˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œ<strong>ç¬¬äºŒä¸ªæ¨¡å‹ä¸ç¨³å®šï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸè¿­ä»£ä¸­ã€‚</strong></p>
</li>
<li><p>å¹¶éé¢„æµ‹åç§»ï¼Œæˆ‘ä»¬éµå¾ªYOLOçš„æ–¹æ³•å¹¶é¢„æµ‹ç›¸å¯¹äºç½‘æ ¼å•å…ƒçš„ä½ç½®çš„ä½ç½®åæ ‡ã€‚ è¿™å°†ground truthé™åˆ¶åœ¨0å’Œ1ä¹‹é—´ã€‚æˆ‘ä»¬ä½¿ç”¨<strong>é€»è¾‘æ¿€æ´»</strong>æ¥çº¦æŸç½‘ç»œçš„é¢„æµ‹è½åœ¨è¯¥èŒƒå›´å†…ã€‚</p>
</li>
<li><p>ç½‘ç»œä¸ºæ¯ä¸€ä¸ªBBé¢„æµ‹5ä¸ªåæ ‡ï¼š$t_x, t_y, t_w, t_h, t_o$.</p>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcjw1fcjb6g0tdpj309203r0st.jpg" alt="">  <img src="https://ww1.sinaimg.cn/large/006tKfTcjw1fcjbl2jwc6j30bj09k3z4.jpg" alt=""></p>
</li>
<li><p>ç»“åˆDimension Clusterså’ŒDirect location predictionï¼ŒYOLOæå‡5%çš„mAPã€‚</p>
</li>
</ul>
<h3 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a><strong>Fine-Grained Features</strong></h3><ul>
<li>ä¿®æ”¹åçš„YOLOåœ¨13<em>13çš„feature mapä¸Šè¿›è¡Œæ£€æµ‹ã€‚ è™½ç„¶è¿™å¯¹äºå¤§å¯¹è±¡æ˜¯è¶³å¤Ÿçš„ï¼Œä½†æ˜¯å®ƒå¯ä»¥ä»ç”¨äºå®šä½è¾ƒå°å¯¹è±¡çš„<em>*ç»†ç²’åº¦ç‰¹å¾</em></em>ä¸­å—ç›Šã€‚</li>
<li>æ·»åŠ ä¸€ä¸ªä¼ é€’å±‚ï¼Œå°†åˆ†è¾¨ç‡ä»å‰é¢çš„å±‚å˜ä¸ºä»26 x 26åˆ†è¾¨ç‡ã€‚</li>
</ul>
<h3 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a><strong>Multi-Scale Training</strong></h3><ul>
<li>æˆ‘ä»¬å¸Œæœ›YOLOv2å¯ä»¥è¶³å¤Ÿé²é‚¦åœ¨ä¸åŒå°ºå¯¸çš„imagesä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>å¹¶éä½¿ç”¨å›ºå®šçš„è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œæˆ‘ä»¬åœ¨æ¯å‡ æ¬¡è¿­ä»£åæ”¹å˜ç½‘ç»œã€‚æ¯10batchesï¼Œæˆ‘ä»¬çš„ç½‘ç»œéšæœºé€‰æ‹©ä¸€ä¸ªæ–°çš„å›¾åƒå°ºå¯¸ã€‚</li>
</ul>
<h2 id="Faster"><a href="#Faster" class="headerlink" title="Faster"></a>Faster</h2><ul>
<li>å¤§å¤šæ•°æ£€æµ‹æ¡†æ¶ä¾èµ–VGG-16ä½œä¸ºåŸºæœ¬ç‰¹å¾æå–å™¨ã€‚VGG-16æ˜¯ä¸€ä¸ªå¼ºå¤§ã€å‡†ç¡®çš„åˆ†ç±»ç½‘ç»œï¼Œä½†æ˜¯ä¹Ÿå¾ˆå¤æ‚ã€‚</li>
<li>YOLOæ¡†æ¶ä½¿ç”¨çš„åŸºäºGooglenetæ¶æ„çš„ä¿®æ”¹åçš„ç½‘ç»œã€‚æ¯”VGG-16å¿«é€Ÿï¼Œä½†æ˜¯å‡†ç¡®æ€§æ¯”VGG-16ç¨å·®ã€‚</li>
</ul>
<h3 id="Darknet-19"><a href="#Darknet-19" class="headerlink" title="Darknet-19"></a>Darknet-19</h3><ul>
<li><p>ä¾›YOLOv2ä½¿ç”¨çš„æ–°çš„åˆ†ç±»æ¨¡å‹ã€‚</p>
</li>
<li><p>æœ€ç»ˆæ¨¡å‹å«åšdarknet-19ï¼Œæœ‰ç€19ä¸ªå·ç§¯å±‚å’Œ5ä¸ªmaxpoolingå±‚ã€‚</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fck21bicicj308j0byabg.jpg" alt=""></p>
</li>
<li><p>Darknet-19å¤„ç†æ¯å¼ å›¾ç‰‡åªéœ€è¦5.58 billionçš„æ“ä½œã€‚</p>
</li>
</ul>
<h3 id="Training-for-classification"><a href="#Training-for-classification" class="headerlink" title="Training for classification"></a>Training for classification</h3><ul>
<li>åœ¨æ ‡å‡†çš„ImageNet 1000ç±»çš„æ•°æ®é›†ä¸Šåˆ©ç”¨éšæœºæ¢¯åº¦ä¸‹é™è®­ç»ƒ160 epochsã€‚å¼€å§‹å­¦ä¹ ç‡ä¸º0.1ï¼Œpolynomial rate decay æ˜¯4ï¼Œweight decayæ˜¯0.0005ï¼ŒåŠ¨é‡æ˜¯0.9ã€‚</li>
<li>åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ‡å‡†çš„æ•°æ®å¢åŠ æŠ€å·§ï¼ŒåŒ…æ‹¬éšæœºè£å‰ªï¼Œæ—‹è½¬ï¼Œä»¥åŠè‰²è°ƒï¼Œé¥±å’Œåº¦å’Œæ›å…‰åç§»ã€‚</li>
<li>åœ¨224x224åˆ†è¾¨ç‡çš„å›¾åƒä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨448x448åˆ†è¾¨ç‡çš„å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒã€‚</li>
</ul>
<h3 id="Training-for-detection"><a href="#Training-for-detection" class="headerlink" title="Training for detection"></a>Training for detection</h3><ul>
<li>æˆ‘ä»¬é€šè¿‡å»é™¤æœ€åçš„å·ç§¯å±‚æ¥ä¿®æ”¹è¿™ä¸ªç½‘ç»œï¼Œå¹¶ä¸”æ›¿ä»£åœ°å¢åŠ å…·æœ‰1024ä¸ªæ»¤æ³¢å™¨çš„ä¸‰ä¸ª3Ã—3å·ç§¯å±‚ï¼Œæ¯ä¸ªè·Ÿéšç€å…·æœ‰æˆ‘ä»¬éœ€è¦æ£€æµ‹æ‰€éœ€çš„è¾“å‡ºæ•°é‡çš„æœ€åçš„1Ã—1å·ç§¯å±‚ã€‚</li>
<li><strong>passthroughå±‚</strong>çš„æ·»åŠ ï¼šä½¿ç½‘ç»œèƒ½å¤Ÿä½¿ç”¨fine grain featureã€‚</li>
</ul>
<h2 id="Stronger"><a href="#Stronger" class="headerlink" title="Stronger"></a>Stronger</h2><ul>
<li>æœ¬è®ºæ–‡æå‡ºä¸€ç§æœºåˆ¶ï¼Œç”¨æ¥å°†åˆ†ç±»å’Œæ£€æµ‹æ•°æ®ç»“åˆèµ·æ¥å†ä¸€èµ·è®­ç»ƒã€‚<ul>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“çœ‹åˆ°ç”¨äºæ£€æµ‹çš„è¢«æ ‡æ³¨çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨åŸºäºYOLOv2çš„ä»£ä»·å‡½æ•°è¿›è¡Œåå‘ä¼ æ’­ã€‚</li>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“çœ‹åˆ°åˆ†ç±»å›¾ç‰‡ï¼Œæˆ‘ä»¬åªä»æ¡†æ¶ä¸­ç”¨æ¥åˆ†ç±»éƒ¨åˆ†æ¥ä¼ é€’æŸå¤±ã€‚</li>
</ul>
</li>
<li>è¿™ç§æ–¹æ³•çš„challengeï¼š<ul>
<li>æ£€æµ‹æ•°æ®é›†ä¸­çš„æ ‡ç­¾æ˜¯å¤§åˆ†ç±»ï¼Œè€Œåˆ†ç±»æ•°æ®é›†çš„æ ‡ç­¾æ˜¯å°åˆ†ç±»ï¼Œ<strong>æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰¾ä¸€ä¸ªæ–¹æ³•æ¥èåˆè¿™äº›æ ‡ç­¾</strong>ã€‚</li>
<li>ç”¨æ¥åˆ†ç±»çš„è®¸å¤šæ–¹æ³•éƒ½æ˜¯ä½¿ç”¨softmaxå±‚æ¥è®¡ç®—æœ€åçš„æ¦‚ç‡åˆ†å¸ƒï¼Œ<strong>ä½¿ç”¨softmaxå±‚ä¼šå‡è®¾ç±»ä¹‹é—´æ˜¯äº’æ–¥çš„</strong>ï¼Œä½†æ˜¯å¦‚ä½•ç”¨æœ¬æ–¹æ³•èåˆæ•°æ®é›†ï¼Œç±»ä¹‹é—´æœ¬èº«ä¸æ˜¯äº’æ–¥çš„ã€‚</li>
</ul>
</li>
<li>æˆ‘ä»¬æ‰€ä»¥ä½¿ç”¨multi-labelæ¨¡å‹æ¥ç»“åˆæ•°æ®é›†ï¼Œä¸å‡è®¾ç±»ä¹‹é—´äº’æ–¥ã€‚<strong>è¿™ç§æ–¹æ³•å¿½ç•¥äº†æˆ‘ä»¬å·²çŸ¥çš„æ•°æ®çš„ç»“æ„ã€‚</strong></li>
</ul>
<h3 id="Hierarchical-classification"><a href="#Hierarchical-classification" class="headerlink" title="Hierarchical classification"></a>Hierarchical classification</h3><ul>
<li>ImageNetæ ‡ç­¾æ˜¯ä»<strong>WordNet</strong>ä¸­å¾—æ¥ï¼Œ<strong>ä¸€ç§ç»“æ„åŒ–æ¦‚å¿µå’Œæ ‡ç­¾ä¹‹é—´å¦‚ä½•è”ç³»çš„è¯­è¨€æ•°æ®åº“</strong>ã€‚</li>
<li>WordNetæ˜¯<strong>è¿æ¥å›¾ç»“æ„</strong>ï¼Œè€Œéæ ‘ã€‚æˆ‘ä»¬ç›¸åå¹¶ä¸å®ç”¨æ•´ä¸ªå›¾ç»“æ„ï¼Œæˆ‘ä»¬å°†é—®é¢˜ç®€åŒ–æˆä»ImageNetçš„æ¦‚å¿µä¸­æ„å»ºæœ‰ç»“æ„çš„æ ‘ã€‚</li>
<li>WordTree</li>
</ul>
<h3 id="Dataset-combination-with-WordTree"><a href="#Dataset-combination-with-WordTree" class="headerlink" title="Dataset combination with WordTree"></a>Dataset combination with WordTree</h3><ul>
<li><p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨WordTreeæ¥ä»‹ä¸ªæ•°æ®é›†ã€‚</p>
</li>
<li><p>å°†æ•°æ®é›†ä¸­åˆ†ç±»æ˜ å°„æˆæ ‘ä¸­çš„ä¸‹ä¹‰è¯ã€‚</p>
</li>
<li><p>ä¸¾ä¾‹ï¼šå°†ImageNetå’ŒCOCOæ•°æ®é›†ç»“åˆï¼š</p>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fckj905lbrj30bm0co75r.jpg" alt=""></p>
</li>
<li><p>WordNetååˆ†å¤šæ ·åŒ–ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ç§æŠ€æœ¯åˆ°å¤§å¤šæ•°æ•°æ®é›†ã€‚</p>
</li>
</ul>
<h3 id="Joint-classiï¬cation-and-detection"><a href="#Joint-classiï¬cation-and-detection" class="headerlink" title="Joint classiï¬cation and detection"></a>Joint classiï¬cation and detection</h3><ul>
<li>å°†COCOæ•°æ®é›†å’ŒImageNetæ•°æ®é›†ç»“åˆï¼Œè®­ç»ƒå¤„ä¸€ä¸ªç‰¹åˆ«å¤§è§„æ¨¡çš„æ£€æµ‹å™¨ã€‚</li>
<li>å¯¹åº”çš„WordTreeæœ‰9418ä¸ªç±»ã€‚</li>
<li>ImageNetæ˜¯ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡å¯¹COCOè¿›è¡Œè¿‡é‡‡æ ·æ¥å¹³è¡¡æ•°æ®é›†ï¼Œä½¿ImageNetåªä»¥4ï¼š1çš„å€æ•°æ¥å¢å¤§ã€‚</li>
<li>å½“æˆ‘ä»¬çš„ç½‘ç»œçœ‹è§ä¸€å¼ ç”¨æ¥æ£€æµ‹çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬æ­£å¸¸åå‘ä¼ æ’­lossã€‚å¯¹äºåˆ†ç±»lossï¼Œæˆ‘ä»¬åªåœ¨è¯¥labelå¯¹åº”å±‚æ¬¡ä¹‹ä¸Šåå‘ä¼ æ’­lossã€‚<strong>æ¯”å¦‚ï¼šå¦‚æœæ ‡ç­¾æ˜¯â€œdogâ€ï¼Œæˆ‘ä»¬ä¼šåœ¨æ ‘ä¸­çš„â€œGerman Shepherdâ€å’Œâ€œGolden Retrieverâ€ä¸­è¿›ä¸€æ­¥é¢„æµ‹é”™è¯¯ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰è¿™äº›ä¿¡æ¯ã€‚</strong></li>
<li>å½“æˆ‘ä»¬çš„ç½‘ç»œçœ‹è§ä¸€å¼ ç”¨æ¥åˆ†æ¥çš„ç…§ç‰‡ï¼Œæˆ‘ä»¬åªåå‘ä¼ é€’åˆ†ç±»lossã€‚</li>
<li>ä½¿ç”¨è¿™ç§è”åˆè®­ç»ƒï¼ŒYOLO 9000ä½¿ç”¨COCOä¸­çš„æ£€æµ‹æ•°æ®å­¦ä¹ æ‰¾åˆ°å›¾åƒä¸­çš„å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨ImageNetä¸­çš„æ•°æ®å­¦ä¹ åˆ†ç±»å„ç§å„æ ·çš„å¯¹è±¡ã€‚</li>
<li>åœ¨ImageNetä¸Šåˆ©ç”¨YOLO9000æ¥åšdetectionï¼Œä»è€Œè¿›è¡Œè¯„ä¼°ã€‚ImageNetå’ŒCOCOåªæœ‰44ä¸ªç›¸åŒçš„ç±»åˆ†ç±»ï¼Œæ„å‘³ç€YOLO9000åœ¨åˆ©ç”¨éƒ¨åˆ†ç›‘ç£æ¥è¿›è¡Œæ£€æµ‹ã€‚</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul>
<li>æœ¬è®ºæ–‡æå‡ºä¸¤ä¸ªæ¨¡å‹ï¼Œ<strong>YOLOv2å’ŒYOLO9000</strong>ã€‚<ul>
<li>YOLOv2ï¼šæ˜¯å¯¹YOLOæ”¹è¿›åçš„æå‡æ¨¡å‹ã€‚æ›´å¿«æ›´å…ˆè¿›ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥ä»¥å„ç§å›¾åƒå¤§å°è¿è¡Œï¼Œä»¥æä¾›é€Ÿåº¦å’Œç²¾åº¦ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>YOLO9000ï¼šæ˜¯æå‡ºçš„ä¸€ç§è”åˆåœ¨æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥ä¸ºæ²¡æœ‰ä»»ä½•æ ‡æ³¨æ£€æµ‹æ ‡ç­¾çš„æ•°æ®è¿›è¡Œæ£€æµ‹ã€‚å¯ä»¥æ£€æµ‹è¶…è¿‡9000ä¸ªç±»ã€‚ä½¿ç”¨WordTreeæŠ€æœ¯æ¥ç»„åˆä¸åŒæ¥æºçš„æ•°æ®ã€‚</li>
</ul>
</li>
<li>æˆ‘ä»¬åˆ›é€ å‡ºè®¸å¤šç›®æ ‡æ£€æµ‹ä¹‹å¤–çš„æŠ€æœ¯ï¼š<ul>
<li>WordTree representation.</li>
<li>Dataset combination.</li>
<li>Multi-scale training.</li>
</ul>
</li>
<li>ä¸‹ä¸€æ­¥å·¥ä½œï¼šæˆ‘ä»¬å¸Œæœ›åˆ©ç”¨ç›¸ä¼¼çš„æŠ€æœ¯æ¥è¿›è¡Œweakly supervised image segmentation.</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;YOLO9000: a state-of-the-art, real-time çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œå¯ä»¥æ£€æµ‹è¶…è¿‡9000ç§çš„ç‰©ä½“åˆ†ç±»ã€‚&lt;/li&gt;
&lt;li&gt;æœ¬è®ºæ–‡æå‡ºä¸¤ä¸ªæ¨¡å‹ï¼Œ&lt;strong&gt;YOLOv2å’ŒYOLO9000&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;YOLOv2ï¼š&lt;ul&gt;
&lt;li&gt;æ˜¯å¯¹YOLOæ”¹è¿›åçš„æå‡æ¨¡å‹ã€‚&lt;/li&gt;
&lt;li&gt;åˆ©ç”¨æ–°é¢–çš„ï¼Œå¤šå°ºåº¦è®­ç»ƒçš„æ–¹æ³•ï¼ŒYOLOv2æ¨¡å‹å¯ä»¥åœ¨å¤šç§å°ºåº¦ä¸Šè¿è¡Œï¼Œåœ¨é€Ÿåº¦ä¸å‡†ç¡®æ€§ä¸Šæ›´å®¹æ˜“å»trade offã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YOLO9000ï¼š&lt;ul&gt;
&lt;li&gt;æ˜¯æå‡ºçš„ä¸€ç§è”åˆåœ¨æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œ&lt;strong&gt;è¿™ç§è”åˆè®­ç»ƒçš„æ–¹æ³•ä½¿å¾—YOLO9000èƒ½å¤Ÿä¸ºæ²¡æœ‰æ ‡ç­¾çš„æ£€æµ‹æ•°æ®ç›®æ ‡ç±»é¢„æµ‹&lt;/strong&gt;ã€‚&lt;/li&gt;
&lt;li&gt;å¯ä»¥æ£€æµ‹è¶…è¿‡9000ä¸ªç±»ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šYOLO</title>
    <link href="http://jacobkong.github.io/posts/2094641206/"/>
    <id>http://jacobkong.github.io/posts/2094641206/</id>
    <published>2017-02-02T11:49:53.000Z</published>
    <updated>2017-02-08T03:57:58.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>ä¹‹å‰çš„ç‰©ä½“æ£€æµ‹çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆ†ç±»å™¨æ¥è¿›è¡Œæ£€æµ‹ã€‚</li>
<li>ç›¸åï¼Œæœ¬è®ºæ–‡å°†å¯¹è±¡æ£€æµ‹ä½œä¸ºç©ºé—´åˆ†ç¦»çš„è¾¹ç•Œæ¡†å’Œç›¸å…³ç±»æ¦‚ç‡çš„å›å½’é—®é¢˜ã€‚</li>
<li>æœ¬è®ºæ–‡çš„YOLOæ¨¡å‹èƒ½è¾¾åˆ°45fpsçš„å®æ—¶å›¾åƒå¤„ç†æ•ˆæœã€‚</li>
<li>Fast YOLOï¼šå°å‹çš„ç½‘ç»œç‰ˆæœ¬ï¼Œå¯è¾¾åˆ°155fpsã€‚</li>
<li>ä¸ç›®å‰çš„æ£€æµ‹ç³»ç»Ÿç›¸æ¯”ï¼ŒYOLOä¼šäº§ç”Ÿæ›´å¤šçš„å®šä½é”™è¯¯ï¼Œä½†æ˜¯ä¼šæ›´å°‘çš„å»åœ¨èƒŒæ™¯ä¸­äº§ç”Ÿfalse positiveã€‚</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>DPM: use a sliding window approach where the classiï¬er is run at evenly spaced locations over the entire image.</p>
</li>
<li><p>R-CNN: use region proposal methods to ï¬rst generate potential bounding boxes in an image and then run a classiï¬er on these proposed boxes. å…·æœ‰<strong>slow</strong>å’Œ<strong>hard to optimize</strong>çš„ç¼ºç‚¹ã€‚</p>
</li>
<li><p>æœ¬è®ºæ–‡å°†ç›®æ ‡æ£€æµ‹é—®é¢˜é‡æ–°ç»„ç»‡æˆ<strong>single regression problem</strong>. ä»å›¾åƒåƒç´ è½¬ä¸º<strong>bounding box coordinates</strong>å’Œ<strong>class probabilities</strong>.</p>
</li>
<li><p>YOLOæ¡†æ¶ï¼š</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgy1fcfslf8g7bj30bs06b756.jpg" alt=""></p>
<ul>
<li>A <strong>single convolutional network</strong> simultaneously predicts multiple bounding boxes and class probabilities for those boxes.</li>
<li>YOLO trains on full images and directly optimizes detection performance.</li>
</ul>
</li>
<li><p>YOLOæ¨¡å‹çš„ä¼˜åŠ¿ï¼š</p>
<ul>
<li>First, YOLO is extremely <strong>fast</strong>.<ul>
<li>regression problem.</li>
<li>no batch processing on a Titan X.</li>
</ul>
</li>
<li>Second, YOLO reasons globally about the image when making predictions.<ul>
<li>YOLO makes <strong>less than half</strong> the number of background errors compared to Fast R-CNN.</li>
</ul>
</li>
<li>Third, YOLO learns <strong>generalizable representations</strong> of objects.</li>
</ul>
</li>
<li><p>YOLOåœ¨å‡†ç¡®æ€§æ–¹é¢ä¾æ—§è½åä¸å…¶ä»–å…ˆè¿›çš„æ£€æµ‹ç³»ç»Ÿï¼Œä½†æ˜¯å¯ä»¥å¿«é€Ÿçš„æ ‡æ³¨å›¾ç‰‡ä¸­çš„ç‰©ä½“ï¼Œç‰¹åˆ«æ˜¯å°ç‰©ä½“ã€‚</p>
</li>
</ul>
<h2 id="Unified-Detection"><a href="#Unified-Detection" class="headerlink" title="Unified Detection"></a>Unified Detection</h2><ul>
<li><p>æœ¬è®ºæ–‡å°†ç‰©ä½“æ£€æµ‹ä¸­å•ç‹¬çš„ç»„ä»¶ç»Ÿä¸€åˆ°ä¸€ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œä¸­ã€‚ç½‘ç»œåˆ©ç”¨æ•´ä¸ªå›¾åƒçš„å„ä¸ªç‰¹å¾æ¥é¢„æµ‹æ¯ä¸€ä¸ªBBã€‚è€Œä¸”åŒæ—¶ä¸ºä¸€å¼ å›¾ç‰‡ä¸­æ‰€æœ‰çš„ç±»é¢„æµ‹æ‰€ç”¨çš„BBã€‚</p>
</li>
<li><p>YOLOå¯ä»¥<strong>end-to-end</strong>æ¥è®­ç»ƒï¼Œè€Œä¸”èƒ½åœ¨ä¿æŒé«˜å¹³å‡å‡†ç¡®ç‡çš„åŒæ—¶è¾¾åˆ°<strong>å®æ—¶è¦æ±‚</strong>ã€‚</p>
</li>
<li><p>ç³»ç»Ÿå°†è¾“å…¥å›¾ç‰‡åˆ†ä¸º$S*S$çš„ç½‘æ ¼å•å…ƒã€‚å¦‚æœç‰©ä½“çš„ä¸­å¿ƒè½å…¥æŸä¸ªæ ¼å­ï¼Œé‚£ä¹ˆè¿™ä¸ªæ ¼å­å°†ä¼šç”¨æ¥æ£€æµ‹è¿™ä¸ªç‰©ä½“ã€‚</p>
</li>
<li><p>æ¯ä¸ªç½‘æ ¼å•å…ƒä¼šé¢„æµ‹<strong>B</strong>ä¸ªbounding boxä»¥åŠè¿™äº›æ¡†çš„ç½®ä¿¡å€¼ã€‚</p>
</li>
<li><p>æ¯ä¸ªbounding boxä¼šæœ‰5ä¸ªé¢„æµ‹å€¼ï¼š$x,y,w,h$å’Œç½®ä¿¡å€¼confidenceï¼Œ$confidence = Pr(Object)*IOU^{truth}_{pred}$.</p>
</li>
<li><p>æ¯ä¸ªç½‘æ ¼å•å…ƒä¹Ÿé¢„æµ‹<strong>C</strong>ä¸ªæ¡ä»¶ç±»æ¦‚ç‡ï¼Œ$Pr(Class_i|Object)$ï¼Œ<strong>åœ¨ä¸€ä¸ªç½‘æ ¼å•å…ƒåŒ…å«ä¸€ä¸ªç‰©ä½“çš„å‰æä¸‹ï¼Œå®ƒå±äºæŸä¸ªç±»çš„æ¦‚ç‡</strong>ã€‚æˆ‘ä»¬åªä¸ºæ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹ä¸€ç»„ç±»æ¦‚ç‡ï¼Œè€Œä¸è€ƒè™‘æ¡†Bçš„æ•°é‡ã€‚</p>
</li>
<li><p>åœ¨æµ‹è¯•çš„æ—¶å€™ï¼Œé€šè¿‡å¦‚ä¸‹å…¬å¼æ¥ç»™å‡ºå¯¹æŸä¸€ä¸ªboxæ¥è¯´æŸä¸€ç±»çš„confidence scoreï¼š</p>
<script type="math/tex; mode=display">
Pr(Class_{i}|Object)*Pr(Object)*IOU^{truth}_{pred}=Pr(Class_{i})*IOU^{truth}_{pred}</script></li>
<li><p>Modelç¤ºä¾‹ï¼š</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fcgkqg2fdyj309608lgmg.jpg" alt=""></p>
<p>æ¯ä¸ªgrid cellé¢„æµ‹Bä¸ªbounding boxesï¼Œæ¯ä¸ªæ¡†çš„confidenceå’ŒCä¸ªç±»æ¦‚ç‡ã€‚</p>
</li>
</ul>
<h3 id="Network-Design"><a href="#Network-Design" class="headerlink" title="Network Design"></a>Network Design</h3><ul>
<li><p>YOLOç½‘ç»œç»“æ„å›¾ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgy1fcgkv58b9lj30oc0aota4.jpg" alt=""></p>
</li>
<li><p>èµ·åˆçš„<strong>å·ç§¯å±‚</strong>ç”¨æ¥ä»å›¾åƒä¸­æå–ç‰¹å¾ã€‚</p>
</li>
<li><p>å…¨è¿æ¥å±‚ç”¨æ¥é¢„æµ‹è¾“å‡ºçš„æ¦‚ç‡å’Œåæ ‡ã€‚</p>
</li>
<li><p>24ä¸ªå·ç§¯å±‚ï¼Œä¹‹åè·Ÿç€2ä¸ªå…¨è¿æ¥å±‚</p>
</li>
<li><p>æœ€ç»ˆè¾“å‡ºæ˜¯7 x 7 x 30çš„å¼ é‡ã€‚</p>
</li>
<li><p>Fast YOLOå’ŒYOLOä¹‹é—´æ‰€æœ‰çš„è®­ç»ƒå’Œæµ‹è¯•å‚æ•°ä¸€æ ·ã€‚</p>
</li>
<li><p>åœ¨ImageNetä¸Šè¿›è¡Œå·ç§¯å±‚çš„é¢„è®­ç»ƒã€‚</p>
</li>
</ul>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul>
<li><p>åœ¨ImageNetä¸Šé¢„è®­ç»ƒå·ç§¯å±‚ã€‚é¢„è®­ç»ƒå‰20å±‚å·ç§¯å±‚ï¼Œä¹‹åè·Ÿéšè€…ä¸€ä¸ªaverage-pooling layerå’Œä¸€ä¸ªfully connected layer.</p>
</li>
<li><p>å°†é¢„è®­ç»ƒçš„æ¨¡å‹ç”¨æ¥æ£€æµ‹ï¼Œ<strong>è®ºæ–‡Ren et al.æ˜¾ç¤ºç»™ä¸è®­ç»ƒå¥½çš„æ¨¡å‹æ·»åŠ å·ç§¯å’Œè¿æ¥å±‚èƒ½å¤Ÿæé«˜æ€§èƒ½ã€‚</strong>æ‰€ä»¥æ·»åŠ äº†<strong>é¢å¤–çš„4ä¸ªå·ç§¯å±‚å’Œ2ä¸ªå…¨è¿æ¥å±‚</strong>ï¼Œå…¶æƒå€¼éšæœºåˆå§‹åŒ–ã€‚</p>
</li>
<li><p>å°†åƒç´ ä»224x224æå‡åˆ°448x448ã€‚</p>
</li>
<li><p>æœ€åä¸€å±‚åŒæ—¶é¢„æµ‹class probabilitieså’Œbounding box coordinates. å…¶ä¸­æ¶‰åŠåˆ°BBçš„é•¿å®½è§„èŒƒåŒ–ã€‚</p>
</li>
<li><p>ç”±äºsum-squared errorçš„ç¼ºç‚¹ï¼Œå¢åŠ è¾¹ç•Œæ¡†åæ ‡é¢„æµ‹çš„æŸå¤±ï¼Œå¹¶å‡å°‘å¯¹ä¸åŒ…å«å¯¹è±¡çš„æ¡†çš„ç½®ä¿¡åº¦é¢„æµ‹çš„æŸå¤±ã€‚</p>
</li>
<li><p>large boxesä¸­çš„åå·®matter less than ä¸small boxesä¸­çš„åå·®ã€‚</p>
</li>
<li><p>YOLOä¸ºæ¯ä¸€ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹å¤šä¸ªBBï¼Œä½†æ˜¯åœ¨æµ‹è¯•æœŸé—´ï¼Œæˆ‘ä»¬åªæƒ³æ¯ä¸€ä¸ªç‰©ä½“æœ‰ä¸€ä¸ªBBé¢„æµ‹æ¡†æ¥åšå“åº”ï¼Œæˆ‘ä»¬é€‰æ‹©å…·æœ‰æœ€é«˜IOUçš„BBæ¥ä½œä¸ºå“åº”æ¡†ã€‚</p>
</li>
<li><p>æ€»çš„<strong>loss function</strong>:</p>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgy1fch1eth6atj30do08hdgg.jpg" alt=""></p>
</li>
<li><p>135 epochs</p>
</li>
<li><p>batch sizeï¼š64</p>
</li>
<li><p>åŠ¨é‡ï¼š0.9</p>
</li>
<li><p>decayï¼š0.0005</p>
</li>
<li><p>ä¸ºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬ä½¿ç”¨dropoutå’Œextensive data augmentationæŠ€æœ¯ã€‚</p>
</li>
</ul>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><ul>
<li>åœ¨æµ‹è¯•å›¾åƒä¸­é¢„æµ‹æ£€æµ‹åªéœ€è¦ä¸€ä¸ªç½‘ç»œè¯„ä¼°ï¼Œä¸ä¸€èˆ¬çš„classifier-based methodsä¸åŒã€‚</li>
<li>Non-maximal suppressionå¯ä»¥ç”¨æ¥ä¿®å¤multiple detectionsã€‚</li>
</ul>
<h2 id="Comparison-to-Other-Detection-Systems"><a href="#Comparison-to-Other-Detection-Systems" class="headerlink" title="Comparison to Other Detection Systems"></a>Comparison to Other Detection Systems</h2><ul>
<li>æ£€æµ‹æµæ°´çº¿å¾€å¾€å¼€å§‹äºæå–å¥å£®ç‰¹å¾é›†ï¼ˆHaar, SIFT, HOG, convolutional featuresï¼‰,ç„¶ååˆ†ç±»å™¨æˆ–è€…å®šä½å™¨ç”¨æ¥è¯†åˆ«ç‰¹å¾ç©ºé—´çš„ç‰©ä½“ï¼Œè¿™äº›åˆ†ç±»å™¨æˆ–è€…å®šä½å™¨å¾€å¾€åœ¨æ•´ä¸ªå›¾åƒä¸Šæˆ–è€…åœ¨å›¾åƒçš„å­åŒºåŸŸä¸­æ»‘åŠ¨çª—å£ã€‚</li>
<li>ä¸DPMçš„æ¯”è¾ƒã€‚</li>
<li>ä¸R-CNNçš„æ¯”è¾ƒã€‚æ¯ä¸ªå›¾ç‰‡å€¼é¢„æµ‹98ä¸ªbounding boxesã€‚</li>
<li>ä¸å…¶ä»–å¿«é€Ÿæ£€æµ‹å™¨çš„æ¯”è¾ƒã€‚ç›¸æ¯”äºå•ç±»æ£€æµ‹å™¨ï¼ŒYOLOå¯ä»¥åŒæ—¶æ£€æµ‹å¤šç§ç‰©ä½“ã€‚</li>
<li>ä¸Deep MultiBoxçš„æ¯”è¾ƒã€‚YOLOæ˜¯ä¸€ä¸ªå®Œæ•´çš„æ£€æµ‹ç³»ç»Ÿã€‚</li>
<li>ä¸OverFeatçš„æ¯”è¾ƒã€‚OverFeatæ˜¯ä¸€ä¸ªdisjointçš„ç³»ç»Ÿï¼ŒOverFeatä¼˜åŒ–å®šä½ï¼Œè€Œéæ£€æµ‹æ€§èƒ½ã€‚éœ€è¦å¤§é‡çš„åå¤„ç†ã€‚</li>
<li>ä¸MultiGraspçš„æ¯”è¾ƒã€‚æ‰§è¡Œæ¯”ç›®æ ‡æ£€æµ‹æ›´ç®€å•çš„ä»»åŠ¡ã€‚</li>
</ul>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;ä¹‹å‰çš„ç‰©ä½“æ£€æµ‹çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆ†ç±»å™¨æ¥è¿›è¡Œæ£€æµ‹ã€‚&lt;/li&gt;
&lt;li&gt;ç›¸åï¼Œæœ¬è®ºæ–‡å°†å¯¹è±¡æ£€æµ‹ä½œä¸ºç©ºé—´åˆ†ç¦»çš„è¾¹ç•Œæ¡†å’Œç›¸å…³ç±»æ¦‚ç‡çš„å›å½’é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;æœ¬è®ºæ–‡çš„YOLOæ¨¡å‹èƒ½è¾¾åˆ°45fpsçš„å®æ—¶å›¾åƒå¤„ç†æ•ˆæœã€‚&lt;/li&gt;
&lt;li&gt;Fast YOLOï¼šå°å‹çš„ç½‘ç»œç‰ˆæœ¬ï¼Œå¯è¾¾åˆ°155fpsã€‚&lt;/li&gt;
&lt;li&gt;ä¸ç›®å‰çš„æ£€æµ‹ç³»ç»Ÿç›¸æ¯”ï¼ŒYOLOä¼šäº§ç”Ÿæ›´å¤šçš„å®šä½é”™è¯¯ï¼Œä½†æ˜¯ä¼šæ›´å°‘çš„å»åœ¨èƒŒæ™¯ä¸­äº§ç”Ÿfalse positiveã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ å®è·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒCaltechæ•°æ®é›†â€”â€”è®­ç»ƒæ£€æµ‹</title>
    <link href="http://jacobkong.github.io/posts/464905881/"/>
    <id>http://jacobkong.github.io/posts/464905881/</id>
    <published>2017-01-16T22:32:24.000Z</published>
    <updated>2017-02-25T16:22:18.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><p>å‰é¢å·²ç»ä»‹ç»äº†å¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä¿®æ”¹æ•°æ®é›†è¯»å†™æ¥å£æ¥æ“ä½œæ•°æ®é›†ï¼Œæ¥ä¸‹æ¥æˆ‘æ¥è¯´æ˜ä¸€ä¸‹æ€ä¹ˆæ¥è®­ç»ƒç½‘ç»œå’Œä¹‹åçš„æ£€æµ‹è¿‡ç¨‹ã€‚</p>
<a id="more"></a>
<h2 id="ä¿®æ”¹æ¨¡å‹æ–‡ä»¶"><a href="#ä¿®æ”¹æ¨¡å‹æ–‡ä»¶" class="headerlink" title="ä¿®æ”¹æ¨¡å‹æ–‡ä»¶"></a>ä¿®æ”¹æ¨¡å‹æ–‡ä»¶</h2><p>faster rcnnæœ‰ä¸¤ç§å„ç§è®­ç»ƒæ–¹å¼:</p>
<ul>
<li>Alternative training(alt-opt)</li>
<li>Approximate joint training(end-to-end)</li>
</ul>
<p>ä¸¤ç§æ–¹æ³•æœ‰ä»€ä¹ˆä¸åŒï¼Œå¯ä»¥å‚è€ƒæˆ‘<a href="http://jacobkong.github.io/posts/3802700508/">è¿™ç¯‡åšå®¢</a>ï¼Œæ¨èä½¿ç”¨ç¬¬äºŒç§ï¼Œå› ä¸ºç¬¬äºŒç§ä½¿ç”¨çš„æ˜¾å­˜æ›´å°ï¼Œè€Œä¸”è®­ç»ƒä¼šæ›´å¿«ï¼ŒåŒæ—¶å‡†ç¡®ç‡å·®ä¸å¤šï¼Œä¸¤ç§æ–¹å¼éœ€è¦ä¿®æ”¹çš„ä»£ç æ˜¯ä¸ä¸€æ ·çš„ï¼ŒåŒæ—¶faster rcnnæä¾›äº†ä¸‰ç§è®­ç»ƒæ¨¡å‹ï¼Œå°å‹çš„ZF modelï¼Œä¸­å‹çš„VGG_CNN_M_1024å’Œå¤§å‹çš„VGG16,è®ºæ–‡ä¸­è¯´VGG16æ•ˆæœæ¯”å…¶ä»–ä¸¤ä¸ªå¥½ï¼Œä½†æ˜¯åŒæ—¶å ç”¨æ›´å¤§çš„GPUæ˜¾å­˜(~11GB)</p>
<p>æˆ‘ä½¿ç”¨çš„æ˜¯<strong>VGG model + alternative training</strong>ï¼Œéœ€è¦æ£€æµ‹çš„ç±»åˆ«åªæœ‰ä¸€ç±»ï¼ŒåŠ ä¸ŠèƒŒæ™¯æ‰€ä»¥æ€»å…±æ˜¯ä¸¤ç±»(background + person)ã€‚</p>
<p>ä¸‹é¢ä¿®æ”¹æ¨¡å‹æ–‡ä»¶ï¼š</p>
<ol>
<li><p>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &apos;data&apos;  </div><div class="line">  type: &apos;Python&apos;  </div><div class="line">  top: &apos;data&apos;  </div><div class="line">  top: &apos;rois&apos;  </div><div class="line">  top: &apos;labels&apos;  </div><div class="line">  top: &apos;bbox_targets&apos;  </div><div class="line">  top: &apos;bbox_inside_weights&apos;  </div><div class="line">  top: &apos;bbox_outside_weights&apos;  </div><div class="line">  python_param &#123;  </div><div class="line">    module: &apos;roi_data_layer.layer&apos;  </div><div class="line">    layer: &apos;RoIDataLayer&apos;  </div><div class="line">    param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &quot;cls_score&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;cls_score&quot;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 1.0</div><div class="line">  &#125;  </div><div class="line">  param &#123;</div><div class="line">  lr_mult: 2.0 </div><div class="line">  &#125;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">    weight_filler &#123;  </div><div class="line">      type: &quot;gaussian&quot;  </div><div class="line">      std: 0.01  </div><div class="line">    &#125;  </div><div class="line">    bias_filler &#123;  </div><div class="line">      type: &quot;constant&quot;  </div><div class="line">      value: 0  </div><div class="line">    &#125;  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &quot;bbox_pred&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;bbox_pred&quot;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 1.0 </div><div class="line">  &#125;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 2.0 </div><div class="line">  &#125;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 8 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4ï¼Œå››ä¸ªé¡¶ç‚¹åæ ‡  </div><div class="line">    weight_filler &#123;  </div><div class="line">      type: &quot;gaussian&quot;  </div><div class="line">      std: 0.001  </div><div class="line">    &#125;  </div><div class="line">    bias_filler &#123;  </div><div class="line">      type: &quot;constant&quot;  </div><div class="line">      value: 0  </div><div class="line">    &#125;  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage1_rpn_train.pt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &apos;input-data&apos;  </div><div class="line">  type: &apos;Python&apos;  </div><div class="line">  top: &apos;data&apos;  </div><div class="line">  top: &apos;im_info&apos;  </div><div class="line">  top: &apos;gt_boxes&apos;  </div><div class="line">  python_param &#123;  </div><div class="line">    module: &apos;roi_data_layer.layer&apos;  </div><div class="line">    layer: &apos;RoIDataLayer&apos;  </div><div class="line">    param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &apos;data&apos;  </div><div class="line">  type: &apos;Python&apos;  </div><div class="line">  top: &apos;data&apos;  </div><div class="line">  top: &apos;rois&apos;  </div><div class="line">  top: &apos;labels&apos;  </div><div class="line">  top: &apos;bbox_targets&apos;  </div><div class="line">  top: &apos;bbox_inside_weights&apos;  </div><div class="line">  top: &apos;bbox_outside_weights&apos;  </div><div class="line">  python_param &#123;  </div><div class="line">    module: &apos;roi_data_layer.layer&apos;  </div><div class="line">    layer: &apos;RoIDataLayer&apos;  </div><div class="line">    param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &quot;cls_score&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;cls_score&quot;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 1.0 </div><div class="line">  &#125;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 2.0 </div><div class="line">  &#125;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">    weight_filler &#123;  </div><div class="line">      type: &quot;gaussian&quot;  </div><div class="line">      std: 0.01  </div><div class="line">    &#125;  </div><div class="line">    bias_filler &#123;  </div><div class="line">      type: &quot;constant&quot;  </div><div class="line">      value: 0  </div><div class="line">    &#125;  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &quot;bbox_pred&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;bbox_pred&quot;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 1.0</div><div class="line">  &#125;  </div><div class="line">  param &#123; </div><div class="line">  lr_mult: 2.0 </div><div class="line">  &#125;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 8 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4,å››ä¸ªé¡¶ç‚¹åæ ‡  </div><div class="line">    weight_filler &#123;  </div><div class="line">      type: &quot;gaussian&quot;  </div><div class="line">      std: 0.001  </div><div class="line">    &#125;  </div><div class="line">    bias_filler &#123;  </div><div class="line">      type: &quot;constant&quot;  </div><div class="line">      value: 0  </div><div class="line">    &#125;  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage2_rpn_train.pt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &apos;input-data&apos;  </div><div class="line">  type: &apos;Python&apos;  </div><div class="line">  top: &apos;data&apos;  </div><div class="line">  top: &apos;im_info&apos;  </div><div class="line">  top: &apos;gt_boxes&apos;  </div><div class="line">  python_param &#123;  </div><div class="line">    module: &apos;roi_data_layer.layer&apos;  </div><div class="line">    layer: &apos;RoIDataLayer&apos;  </div><div class="line">    param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">layer &#123;  </div><div class="line">  name: &quot;cls_score&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;cls_score&quot;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1  </div><div class="line">  &#125;  </div><div class="line">&#125;  </div><div class="line"></div><div class="line">layer &#123;  </div><div class="line">  name: &quot;bbox_pred&quot;  </div><div class="line">  type: &quot;InnerProduct&quot;  </div><div class="line">  bottom: &quot;fc7&quot;  </div><div class="line">  top: &quot;bbox_pred&quot;  </div><div class="line">  inner_product_param &#123;  </div><div class="line">    num_output: 84 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4,å››ä¸ªé¡¶ç‚¹åæ ‡</div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="è®­ç»ƒæµ‹è¯•"><a href="#è®­ç»ƒæµ‹è¯•" class="headerlink" title="è®­ç»ƒæµ‹è¯•"></a>è®­ç»ƒæµ‹è¯•</h2><p>è®­ç»ƒå‰è¿˜éœ€è¦æ³¨æ„å‡ ä¸ªåœ°æ–¹ï¼š</p>
<ol>
<li><p>cacheé—®é¢˜ï¼š</p>
<p>å‡å¦‚ä½ ä¹‹å‰è®­ç»ƒäº†å®˜æ–¹çš„VOC2007çš„æ•°æ®é›†æˆ–å…¶ä»–çš„æ•°æ®é›†ï¼Œæ˜¯ä¼šäº§ç”Ÿcacheçš„é—®é¢˜çš„ï¼Œå»ºè®®åœ¨é‡æ–°è®­ç»ƒæ–°çš„æ•°æ®ä¹‹å‰å°†å…¶åˆ é™¤ã€‚</p>
<ul>
<li><code>py-faster-rcnn/output</code></li>
<li><code>py-faster-rcnn/data/cache</code></li>
</ul>
</li>
<li><p>è®­ç»ƒå‚æ•°</p>
<p>å‚æ•°æ”¾åœ¨å¦‚ä¸‹æ–‡ä»¶:</p>
<p><code>py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage_fast_rcnn_solver*.pt</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">base_lr: 0.001</div><div class="line">lr_policy: &apos;step&apos;</div><div class="line">step_size: 30000</div><div class="line">display: 20</div><div class="line">....</div></pre></td></tr></table></figure>
<p>è¿­ä»£æ¬¡æ•°åœ¨æ–‡ä»¶py-faster-rcnn/tools/train_faster_rcnn_alt_opt.pyä¸­è¿›è¡Œä¿®æ”¹:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">max_iters = [80000, 40000, 80000, 40000]</div></pre></td></tr></table></figure>
<p>åˆ†åˆ«å¯¹åº”rpnç¬¬1é˜¶æ®µï¼Œfast rcnnç¬¬1é˜¶æ®µï¼Œrpnç¬¬2é˜¶æ®µï¼Œfast rcnnç¬¬2é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°ï¼Œè‡ªå·±ä¿®æ”¹å³å¯ï¼Œä¸è¿‡æ³¨æ„è¿™é‡Œçš„å€¼ä¸è¦å°äºä¸Šé¢çš„solveré‡Œé¢çš„step_sizeçš„å¤§å°ï¼Œå¤§å®¶è‡ªå·±ä¿®æ”¹å§</p>
</li>
</ol>
<h3 id="å¼€å§‹è®­ç»ƒ"><a href="#å¼€å§‹è®­ç»ƒ" class="headerlink" title="å¼€å§‹è®­ç»ƒ"></a>å¼€å§‹è®­ç»ƒ</h3><p>é¦–å…ˆä¿®æ”¹<code>experiments/scripts/faster_rcnn_alt_opt.sh</code>æˆå¦‚ä¸‹ï¼Œä¿®æ”¹åœ°æ–¹å·²æ ‡æ³¨ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"><span class="comment"># Usage:</span></div><div class="line"><span class="comment"># ./experiments/scripts/faster_rcnn_alt_opt.sh GPU NET DATASET [options args to &#123;train,test&#125;_net.py]</span></div><div class="line"><span class="comment"># DATASET is only pascal_voc for now</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Example:</span></div><div class="line"><span class="comment"># ./experiments/scripts/faster_rcnn_alt_opt.sh 0 VGG_CNN_M_1024 pascal_voc \</span></div><div class="line"><span class="comment">#   --set EXP_DIR foobar RNG_SEED 42 TRAIN.SCALES "[400, 500, 600, 700]"</span></div><div class="line"></div><div class="line"><span class="built_in">set</span> -x</div><div class="line"><span class="built_in">set</span> <span class="_">-e</span></div><div class="line"></div><div class="line"><span class="built_in">export</span> PYTHONUNBUFFERED=<span class="string">"True"</span></div><div class="line"></div><div class="line">GPU_ID=<span class="variable">$1</span></div><div class="line">NET=<span class="variable">$2</span></div><div class="line">NET_lc=<span class="variable">$&#123;NET,,&#125;</span></div><div class="line">DATASET=<span class="variable">$3</span></div><div class="line"></div><div class="line">array=( <span class="variable">$@</span> )</div><div class="line">len=<span class="variable">$&#123;#array[@]&#125;</span></div><div class="line">EXTRA_ARGS=<span class="variable">$&#123;array[@]:3:$len&#125;</span></div><div class="line">EXTRA_ARGS_SLUG=<span class="variable">$&#123;EXTRA_ARGS// /_&#125;</span></div><div class="line"></div><div class="line"><span class="keyword">case</span> <span class="variable">$DATASET</span> <span class="keyword">in</span></div><div class="line">  caltech)                     <span class="comment"># è¿™é‡Œå°†pascal_vocæ”¹ä¸ºcaltech</span></div><div class="line">    TRAIN_IMDB=<span class="string">"caltech_train"</span> <span class="comment"># æ”¹ä¸ºä¸factor.pyä¸­å‘½åçš„nameæ ¼å¼ç›¸åŒï¼Œä¸ºcaltech_train</span></div><div class="line">    TEST_IMDB=<span class="string">"caltech_test"</span>   <span class="comment"># æ”¹ä¸ºä¸factor.pyä¸­å‘½åçš„nameæ ¼å¼ç›¸åŒï¼Œä¸ºcaltech_test</span></div><div class="line">    PT_DIR=<span class="string">"caltech"</span>           <span class="comment"># è¿™é‡Œå°†pascal_vocæ”¹ä¸ºcaltech</span></div><div class="line">    ITERS=40000</div><div class="line">    ;;</div><div class="line">  coco)</div><div class="line">    <span class="built_in">echo</span> <span class="string">"Not implemented: use experiments/scripts/faster_rcnn_end2end.sh for coco"</span></div><div class="line">    <span class="built_in">exit</span></div><div class="line">    ;;</div><div class="line">  *)</div><div class="line">    <span class="built_in">echo</span> <span class="string">"No dataset given"</span></div><div class="line">    <span class="built_in">exit</span></div><div class="line">    ;;</div><div class="line"><span class="keyword">esac</span></div><div class="line"></div><div class="line">LOG=<span class="string">"experiments/logs/faster_rcnn_alt_opt_<span class="variable">$&#123;NET&#125;</span>_<span class="variable">$&#123;EXTRA_ARGS_SLUG&#125;</span>.txt.`date +'%Y-%m-%d_%H-%M-%S'`"</span></div><div class="line"><span class="built_in">exec</span> &amp;&gt; &gt;(tee <span class="_">-a</span> <span class="string">"<span class="variable">$LOG</span>"</span>)</div><div class="line"><span class="built_in">echo</span> Logging output to <span class="string">"<span class="variable">$LOG</span>"</span></div><div class="line"></div><div class="line">time ./tools/train_faster_rcnn_alt_opt.py --gpu <span class="variable">$&#123;GPU_ID&#125;</span> \</div><div class="line">  --net_name <span class="variable">$&#123;NET&#125;</span> \</div><div class="line">  --weights data/imagenet_models/<span class="variable">$&#123;NET&#125;</span>.v2.caffemodel \</div><div class="line">  --imdb <span class="variable">$&#123;TRAIN_IMDB&#125;</span> \</div><div class="line">  --cfg experiments/cfgs/faster_rcnn_alt_opt.yml \</div><div class="line">  <span class="variable">$&#123;EXTRA_ARGS&#125;</span></div><div class="line"></div><div class="line"><span class="built_in">set</span> +x</div><div class="line">NET_FINAL=`grep <span class="string">"Final model:"</span> <span class="variable">$&#123;LOG&#125;</span> | awk <span class="string">'&#123;print $3&#125;'</span>`</div><div class="line"><span class="built_in">set</span> -x</div><div class="line"></div><div class="line">time ./tools/test_net.py --gpu <span class="variable">$&#123;GPU_ID&#125;</span> \</div><div class="line">  --def models/<span class="variable">$&#123;PT_DIR&#125;</span>/<span class="variable">$&#123;NET&#125;</span>/faster_rcnn_alt_opt/faster_rcnn_test.pt \</div><div class="line">  --net <span class="variable">$&#123;NET_FINAL&#125;</span> \</div><div class="line">  <span class="comment">#--net output/faster_rcnn_alt_opt/train/ZF_faster_rcnn_final.caffemodel \</span></div><div class="line">  --imdb <span class="variable">$&#123;TEST_IMDB&#125;</span> \</div><div class="line">  --cfg experiments/cfgs/faster_rcnn_alt_opt.yml \</div><div class="line">  <span class="variable">$&#123;EXTRA_ARGS&#125;</span></div></pre></td></tr></table></figure>
<p>è°ƒç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œè®­ç»ƒåŠæµ‹è¯•ï¼Œä»ä¸Šé¢ä»£ç å¯ä»¥çœ‹å‡ºï¼Œè¯¥shellæ–‡ä»¶åœ¨è®­ç»ƒå®Œåä¼šæ¥ç€è¿›è¡Œæµ‹è¯•ï¼Œä½†æ˜¯æˆ‘çš„æµ‹è¯•é›†æ²¡æœ‰æ ‡æ³¨ï¼Œæ‰€ä»¥æµ‹è¯•çš„æ—¶å€™ä¼šæŠ¥é”™ï¼Œä½†æ˜¯ç”±äºCaltechæ•°æ®é›†çš„æµ‹è¯•ç»“æœæœ‰ä¸“é—¨çš„è¯„ä¼°ä»£ç ï¼Œæ‰€ä»¥æˆ‘ä¸ç”¨faster r-cnnæä¾›çš„ä»£ç è¿›è¡Œæµ‹è¯•ï¼Œè€Œæ˜¯ç›´æ¥è¿›è¡Œæ£€æµ‹ç”Ÿæˆåæ ‡ï¼Œç”¨ä¸“é—¨çš„è¯„ä¼°ä»£ç è¿›è¡Œæ£€æµ‹ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn</div><div class="line">./experiments/scripts/faster_rcnn_alt_opt.sh 0 VGG16 caltech</div></pre></td></tr></table></figure>
<ul>
<li>å‚æ•°1ï¼šæŒ‡å®šgpu_idã€‚</li>
<li>å‚æ•°2ï¼šæŒ‡å®šç½‘ç»œæ¨¡å‹å‚æ•°ã€‚</li>
<li>å‚æ•°3ï¼šæ•°æ®é›†åç§°ï¼Œç›®å‰åªèƒ½ä¸º<code>pascal_voc</code>ã€‚</li>
</ul>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šè°ƒç”¨<code>py_faster_rcnn/tools/train_faster_rcnn_alt_opt.py</code>æ–‡ä»¶å¼€å§‹è®­ç»ƒç½‘ç»œã€‚</p>
<h3 id="å¯èƒ½ä¼šå‡ºç°çš„Bugs"><a href="#å¯èƒ½ä¼šå‡ºç°çš„Bugs" class="headerlink" title="å¯èƒ½ä¼šå‡ºç°çš„Bugs"></a>å¯èƒ½ä¼šå‡ºç°çš„Bugs</h3><h4 id="AssertionError-assert-boxes-2-gt-boxes-0-all"><a href="#AssertionError-assert-boxes-2-gt-boxes-0-all" class="headerlink" title="AssertionError: assert (boxes[:, 2] &gt;= boxes[:, 0]).all()"></a>AssertionError: assert (boxes[:, 2] &gt;= boxes[:, 0]).all()</h4><h5 id="é—®é¢˜é‡ç°"><a href="#é—®é¢˜é‡ç°" class="headerlink" title="é—®é¢˜é‡ç°"></a>é—®é¢˜é‡ç°</h5><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‡ºç°å¦‚ä¸‹æŠ¥é”™ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">File &quot;/py-faster-rcnn/tools/../lib/datasets/imdb.py&quot;, line 108, in </div><div class="line">append_flipped_images </div><div class="line">	assert (boxes[:, 2] &gt;= boxes[:, 0]).all() </div><div class="line">AssertionError</div></pre></td></tr></table></figure>
<h5 id="é—®é¢˜åˆ†æ"><a href="#é—®é¢˜åˆ†æ" class="headerlink" title="é—®é¢˜åˆ†æ"></a>é—®é¢˜åˆ†æ</h5><p>æ£€æŸ¥è‡ªå·±æ•°æ®å‘ç°ï¼Œå·¦ä¸Šè§’åæ ‡ (x, y) å¯èƒ½ä¸º0ï¼Œæˆ–æ ‡å®šåŒºåŸŸæº¢å‡ºå›¾ç‰‡ï¼ˆå³åæ ‡ä¸ºè´Ÿæ•°ï¼‰ï¼Œè€Œfaster rcnnä¼šå¯¹Xmin,Ymin,Xmax,Ymaxè¿›è¡Œå‡ä¸€æ“ä½œï¼Œå¦‚æœXminä¸º0ï¼Œå‡ä¸€åå˜ä¸º65535ï¼Œä»è€Œåœ¨å·¦å³ç¿»è½¬å›¾ç‰‡æ—¶å¯¼è‡´å¦‚ä¸Šé”™è¯¯å‘ç”Ÿã€‚</p>
<h5 id="é—®é¢˜è§£å†³"><a href="#é—®é¢˜è§£å†³" class="headerlink" title="é—®é¢˜è§£å†³"></a>é—®é¢˜è§£å†³</h5><ol>
<li><p>ä¿®æ”¹<code>lib/datasets/imdb.py</code>ä¸­çš„<code>append_flipped_images()</code>å‡½æ•°ï¼š</p>
<p>æ•°æ®æ•´ç†ï¼Œåœ¨ä¸€è¡Œä»£ç ä¸º <code>boxes[:, 2] = widths[i] - oldx1 - 1</code>ä¸‹åŠ å…¥ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> b <span class="keyword">in</span> range(len(boxes)):</div><div class="line">	<span class="keyword">if</span> boxes[b][<span class="number">2</span>]&lt; boxes[b][<span class="number">0</span>]:</div><div class="line">		boxes[b][<span class="number">0</span>] = <span class="number">0</span></div></pre></td></tr></table></figure>
</li>
<li><p>ä¿®æ”¹<code>lib/datasets/caltech.py</code>ï¼Œ<code>_load_pascal_annotation()</code>å‡½æ•°ï¼Œå°†å¯¹Xmin,Ymin,Xmax,Ymaxå‡ä¸€å»æ‰ï¼Œå˜ä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Load object bounding boxes into a data frame.</span></div><div class="line">        <span class="keyword">for</span> ix, obj <span class="keyword">in</span> enumerate(objs):</div><div class="line">            bbox = obj.find(<span class="string">'bndbox'</span>)</div><div class="line">            <span class="comment"># Make pixel indexes 0-based</span></div><div class="line">            <span class="comment"># è¿™é‡Œæˆ‘æŠŠâ€˜-1â€™å…¨éƒ¨åˆ é™¤æ‰äº†ï¼Œé˜²æ­¢æœ‰çš„æ•°æ®æ˜¯0å¼€å§‹ï¼Œç„¶åâ€˜-1â€™å¯¼è‡´å˜ä¸ºè´Ÿæ•°ï¼Œäº§ç”ŸAssertErroré”™è¯¯</span></div><div class="line">            x1 = float(bbox.find(<span class="string">'xmin'</span>).text)</div><div class="line">            y1 = float(bbox.find(<span class="string">'ymin'</span>).text)</div><div class="line">            x2 = float(bbox.find(<span class="string">'xmax'</span>).text)</div><div class="line">            y2 = float(bbox.find(<span class="string">'ymax'</span>).text)</div><div class="line">            cls = self._class_to_ind[obj.find(<span class="string">'name'</span>).text.lower().strip()]</div><div class="line">            boxes[ix, :] = [x1, y1, x2, y2]</div><div class="line">            gt_classes[ix] = cls</div><div class="line">            overlaps[ix, cls] = <span class="number">1.0</span></div><div class="line">            seg_areas[ix] = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>ï¼ˆå¯é€‰ï¼‰å¦‚æœ1å’Œ2å¯ä»¥è§£å†³é—®é¢˜ï¼Œå°±æ²¡å¿…è¦ç”¨æ–¹æ³•3ã€‚ä¿®æ”¹<code>lib/fast_rcnn/config.py</code>ï¼Œä¸ä½¿å›¾ç‰‡å®ç°ç¿»è½¬ï¼Œå¦‚ä¸‹æ”¹ä¸ºï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># Use horizontally-flipped images during training? </div><div class="line">__C.TRAIN.USE_FLIPPED = False</div></pre></td></tr></table></figure>
</li>
</ol>
<p>å¦‚æœå¦‚ä¸Šä¸‰ç§æ–¹æ³•éƒ½æ— æ³•è§£å†³è¯¥é—®é¢˜ï¼Œé‚£ä¹ˆè‚¯å®šæ˜¯ä½ çš„æ•°æ®é›†åæ ‡å‡ºç°å°äºç­‰äº0çš„æ•°ï¼Œä½ <strong>åº”è¯¥ä¸€ä¸€æ’æŸ¥</strong>ã€‚</p>
<h4 id="è®­ç»ƒfast-rcnnæ—¶å‡ºç°loss-nançš„æƒ…å†µã€‚"><a href="#è®­ç»ƒfast-rcnnæ—¶å‡ºç°loss-nançš„æƒ…å†µã€‚" class="headerlink" title="è®­ç»ƒfast rcnnæ—¶å‡ºç°loss=nançš„æƒ…å†µã€‚"></a>è®­ç»ƒfast rcnnæ—¶å‡ºç°loss=nançš„æƒ…å†µã€‚</h4><h5 id="é—®é¢˜é‡ç°-1"><a href="#é—®é¢˜é‡ç°-1" class="headerlink" title="é—®é¢˜é‡ç°"></a>é—®é¢˜é‡ç°</h5><p><img src="https://ww1.sinaimg.cn/large/006tNbRwly1fcuq2kgkwgj30v10hddsn.jpg" alt=""></p>
<h5 id="é—®é¢˜åˆ†æ-1"><a href="#é—®é¢˜åˆ†æ-1" class="headerlink" title="é—®é¢˜åˆ†æ"></a>é—®é¢˜åˆ†æ</h5><p>è¿™æ˜¯ç”±äºæ¨¡å‹ä¸æ”¶æ•›ï¼Œå¯¼è‡´lossè¿…é€Ÿå¢é•¿ã€‚</p>
<p>è€Œæˆ‘å‡ºç°ä»¥ä¸Šç°è±¡çš„åŸå› ä¸»è¦æ˜¯å› ä¸ºæˆ‘åœ¨å‡ºç°AssertionErrorçš„æ—¶å€™ç›´æ¥ä½¿ç”¨äº†ç¬¬ä¸‰ç§æ–¹æ³•å¯¼è‡´çš„ã€‚ä¹Ÿå°±æ˜¯ç¦ç”¨å›¾ç‰‡ç¿»è½¬ã€‚</p>
<h5 id="é—®é¢˜è§£å†³-1"><a href="#é—®é¢˜è§£å†³-1" class="headerlink" title="é—®é¢˜è§£å†³"></a>é—®é¢˜è§£å†³</h5><p>å¯ç”¨å›¾ç‰‡ç¿»è½¬ã€‚</p>
<h3 id="è®­ç»ƒç»“æœ"><a href="#è®­ç»ƒç»“æœ" class="headerlink" title="è®­ç»ƒç»“æœ"></a>è®­ç»ƒç»“æœ</h3><p>è®­ç»ƒåçš„æ¨¡å‹æ”¾åœ¨<code>output/faster_rcnn_alt_opt/train/VGG16_faster_rcnn_final.caffemodel</code>ï¼Œè¯¥æ¨¡å‹å¯ä»¥ç”¨äºä¹‹åçš„æ£€æµ‹ã€‚</p>
<h2 id="æ£€æµ‹"><a href="#æ£€æµ‹" class="headerlink" title="æ£€æµ‹"></a>æ£€æµ‹</h2><h3 id="æ£€æµ‹æ­¥éª¤"><a href="#æ£€æµ‹æ­¥éª¤" class="headerlink" title="æ£€æµ‹æ­¥éª¤"></a>æ£€æµ‹æ­¥éª¤</h3><p>ç»è¿‡ä»¥ä¸Šè®­ç»ƒåï¼Œå°±å¯ä»¥ç”¨å¾—åˆ°çš„æ¨¡å‹æ¥è¿›è¡Œæ£€æµ‹äº†ã€‚æ£€æµ‹æ‰€å‚è€ƒçš„ä»£ç æ˜¯<code>tools/demo.py</code>ï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li>å°†<code>output/faster_rcnn_alt_opt/train/VGG16_faster_rcnn_final.caffemodel</code>ï¼Œæ‹·è´åˆ°<code>data/faster_rcnn_models</code>ä¸‹ï¼Œå‘½åä¸º<code>VGG16_Caltech_faster_rcnn__final.caffemodel</code></li>
<li>è¿›å…¥<code>tools/</code>æ–‡ä»¶å¤¹ä¸­ï¼Œæ‹·è´<code>demo.py</code>ä¸º<code>demo_caltech.py</code>ã€‚</li>
<li>ä¿®æ”¹demo_caltech.pyä»£ç å¦‚ä¸‹ï¼š</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"><span class="comment"># Faster R-CNN</span></div><div class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></div><div class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></div><div class="line"><span class="comment"># Written by Ross Girshick</span></div><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> matplotlib</div><div class="line">matplotlib.use(<span class="string">'Agg'</span>);</div><div class="line"><span class="string">"""</span></div><div class="line">Demo script showing detections in sample images.</div><div class="line"></div><div class="line">See README.md for installation instructions before running.</div><div class="line">"""</div><div class="line"></div><div class="line"><span class="keyword">import</span> _init_paths</div><div class="line"><span class="keyword">from</span> fast_rcnn.config <span class="keyword">import</span> cfg</div><div class="line"><span class="keyword">from</span> fast_rcnn.test <span class="keyword">import</span> im_detect</div><div class="line"><span class="keyword">from</span> fast_rcnn.nms_wrapper <span class="keyword">import</span> nms</div><div class="line"><span class="keyword">from</span> utils.timer <span class="keyword">import</span> Timer</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</div><div class="line"><span class="keyword">import</span> caffe, os, sys, cv2</div><div class="line"><span class="keyword">import</span> argparse</div><div class="line"></div><div class="line">CLASSES = (<span class="string">'__background__'</span>, <span class="comment"># è¿™é‡Œæ”¹ä¸ºè‡ªå·±çš„ç±»åˆ«</span></div><div class="line">           <span class="string">'person'</span>)</div><div class="line"></div><div class="line">NETS = &#123;<span class="string">'vgg16'</span>: (<span class="string">'VGG16'</span>,</div><div class="line">                  <span class="string">'VGG16_Caltech_faster_rcnn_final.caffemodel'</span>), <span class="comment">#è¿™é‡Œéœ€è¦ä¿®æ”¹ä¸ºè®­ç»ƒåå¾—åˆ°çš„æ¨¡å‹çš„åç§°</span></div><div class="line">        <span class="string">'zf'</span>: (<span class="string">'ZF'</span>,</div><div class="line">                  <span class="string">'ZF_Caltech_faster_rcnn_final.caffemodel'</span>)&#125; <span class="comment">#è¿™é‡Œéœ€è¦ä¿®æ”¹ä¸ºè®­ç»ƒåå¾—åˆ°çš„æ¨¡å‹çš„åç§°</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_detections</span><span class="params">(im, image_name, class_name, dets, thresh=<span class="number">0.5</span>)</span>:</span></div><div class="line">    <span class="string">"""Draw detected bounding boxes."""</span></div><div class="line">    inds = np.where(dets[:, <span class="number">-1</span>] &gt;= thresh)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">if</span> len(inds) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    im = im[:, :, (<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>)]</div><div class="line">    fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">12</span>))</div><div class="line">    ax.imshow(im, aspect=<span class="string">'equal'</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> inds:</div><div class="line">        bbox = dets[i, :<span class="number">4</span>]</div><div class="line">        score = dets[i, <span class="number">-1</span>]</div><div class="line"></div><div class="line">        ax.add_patch(</div><div class="line">            plt.Rectangle((bbox[<span class="number">0</span>], bbox[<span class="number">1</span>]),</div><div class="line">                          bbox[<span class="number">2</span>] - bbox[<span class="number">0</span>],</div><div class="line">                          bbox[<span class="number">3</span>] - bbox[<span class="number">1</span>], fill=<span class="keyword">False</span>,</div><div class="line">                          edgecolor=<span class="string">'red'</span>, linewidth=<span class="number">3.5</span>)</div><div class="line">            )</div><div class="line">        ax.text(bbox[<span class="number">0</span>], bbox[<span class="number">1</span>] - <span class="number">2</span>,</div><div class="line">                <span class="string">'&#123;:s&#125; &#123;:.3f&#125;'</span>.format(class_name, score),</div><div class="line">                bbox=dict(facecolor=<span class="string">'blue'</span>, alpha=<span class="number">0.5</span>),</div><div class="line">                fontsize=<span class="number">14</span>, color=<span class="string">'white'</span>)</div><div class="line"></div><div class="line">    ax.set_title((<span class="string">'&#123;&#125; detections with '</span></div><div class="line">                  <span class="string">'p(&#123;&#125; | box) &gt;= &#123;:.1f&#125;'</span>).format(class_name, class_name,</div><div class="line">                                                  thresh),</div><div class="line">                  fontsize=<span class="number">14</span>)</div><div class="line">    plt.axis(<span class="string">'off'</span>)</div><div class="line">    plt.tight_layout()</div><div class="line">    plt.draw()</div><div class="line">    plt.savefig(<span class="string">'/home/jk/py-faster-rcnn/output/faster_rcnn_alt_opt/test/'</span>+image_name) <span class="comment">#å°†æ£€æµ‹åçš„å›¾ç‰‡ä¿å­˜åˆ°ç›¸åº”çš„è·¯å¾„</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">demo</span><span class="params">(net, image_name)</span>:</span></div><div class="line">    <span class="string">"""Detect object classes in an image using pre-computed object proposals."""</span></div><div class="line"></div><div class="line">    <span class="comment"># Load the demo image</span></div><div class="line">    im_file = os.path.join(cfg.DATA_DIR, <span class="string">'VOCdevkit/Caltech/JPEGImages'</span>, image_name)</div><div class="line">    im = cv2.imread(im_file)</div><div class="line"></div><div class="line">    <span class="comment"># Detect all object classes and regress object bounds</span></div><div class="line">    timer = Timer()</div><div class="line">    timer.tic()</div><div class="line">    scores, boxes = im_detect(net, im)</div><div class="line">    timer.toc()</div><div class="line">    <span class="keyword">print</span> (<span class="string">'Detection took &#123;:.3f&#125;s for '</span></div><div class="line">           <span class="string">'&#123;:d&#125; object proposals'</span>).format(timer.total_time, boxes.shape[<span class="number">0</span>])</div><div class="line"></div><div class="line">    <span class="comment"># Visualize detections for each class</span></div><div class="line">    CONF_THRESH = <span class="number">0.85</span> <span class="comment"># è®¾ç½®æƒå€¼ï¼Œè¶Šä½æ£€æµ‹å‡ºçš„æ¡†è¶Šå¤š</span></div><div class="line">    NMS_THRESH = <span class="number">0.3</span></div><div class="line">    <span class="keyword">for</span> cls_ind, cls <span class="keyword">in</span> enumerate(CLASSES[<span class="number">1</span>:]):</div><div class="line">        cls_ind += <span class="number">1</span> <span class="comment"># because we skipped background</span></div><div class="line">        cls_boxes = boxes[:, <span class="number">4</span>*cls_ind:<span class="number">4</span>*(cls_ind + <span class="number">1</span>)]</div><div class="line">        cls_scores = scores[:, cls_ind]</div><div class="line">        dets = np.hstack((cls_boxes,</div><div class="line">                          cls_scores[:, np.newaxis])).astype(np.float32)</div><div class="line">        keep = nms(dets, NMS_THRESH)</div><div class="line">        dets = dets[keep, :]</div><div class="line">        vis_detections(im, image_name, cls, dets, thresh=CONF_THRESH)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""Parse input arguments."""</span></div><div class="line">    parser = argparse.ArgumentParser(description=<span class="string">'Faster R-CNN demo'</span>)</div><div class="line">    parser.add_argument(<span class="string">'--gpu'</span>, dest=<span class="string">'gpu_id'</span>, help=<span class="string">'GPU device id to use [0]'</span>,</div><div class="line">                        default=<span class="number">0</span>, type=int)</div><div class="line">    parser.add_argument(<span class="string">'--cpu'</span>, dest=<span class="string">'cpu_mode'</span>,</div><div class="line">                        help=<span class="string">'Use CPU mode (overrides --gpu)'</span>,</div><div class="line">                        action=<span class="string">'store_true'</span>)</div><div class="line">    parser.add_argument(<span class="string">'--net'</span>, dest=<span class="string">'demo_net'</span>, help=<span class="string">'Network to use [vgg16]'</span>,</div><div class="line">                        choices=NETS.keys(), default=<span class="string">'vgg16'</span>)</div><div class="line"></div><div class="line">    args = parser.parse_args()</div><div class="line"></div><div class="line">    <span class="keyword">return</span> args</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    cfg.TEST.HAS_RPN = <span class="keyword">True</span>  <span class="comment"># Use RPN for proposals</span></div><div class="line"></div><div class="line">    args = parse_args()</div><div class="line"></div><div class="line">    prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][<span class="number">0</span>],</div><div class="line">                            <span class="string">'faster_rcnn_alt_opt'</span>, <span class="string">'faster_rcnn_test.pt'</span>)</div><div class="line">    caffemodel = os.path.join(cfg.DATA_DIR, <span class="string">'faster_rcnn_models'</span>,</div><div class="line">                              NETS[args.demo_net][<span class="number">1</span>])</div><div class="line"></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(caffemodel):</div><div class="line">        <span class="keyword">raise</span> IOError((<span class="string">'&#123;:s&#125; not found.\nDid you run ./data/script/'</span></div><div class="line">                       <span class="string">'fetch_faster_rcnn_models.sh?'</span>).format(caffemodel))</div><div class="line"></div><div class="line">    <span class="keyword">if</span> args.cpu_mode:</div><div class="line">        caffe.set_mode_cpu()</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        caffe.set_mode_gpu()</div><div class="line">        caffe.set_device(args.gpu_id)</div><div class="line">        cfg.GPU_ID = args.gpu_id</div><div class="line">    net = caffe.Net(prototxt, caffemodel, caffe.TEST)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'\n\nLoaded network &#123;:s&#125;'</span>.format(caffemodel)</div><div class="line"></div><div class="line">    <span class="comment"># Warmup on a dummy image</span></div><div class="line">    im = <span class="number">128</span> * np.ones((<span class="number">300</span>, <span class="number">500</span>, <span class="number">3</span>), dtype=np.uint8)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>):</div><div class="line">        _, _= im_detect(net, im)</div><div class="line"></div><div class="line">    testfile_path = <span class="string">'/home/jk/py-faster-rcnn/data/VOCdevkit/Caltech/ImageSets/Main/test.txt'</span></div><div class="line">    <span class="keyword">with</span> open(testfile_path) <span class="keyword">as</span> f:</div><div class="line">        im_names = [x.strip()+<span class="string">'.jpg'</span> <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()] <span class="comment"># ä»test.txtæ–‡ä»¶ä¸­è¯»å–å›¾ç‰‡æ–‡ä»¶åï¼Œæ‰¾åˆ°ç›¸åº”çš„å›¾ç‰‡è¿›è¡Œæ£€æµ‹ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„æ–¹æ³•ï¼ŒæŠŠé¡¹æ£€æµ‹çš„å›¾ç‰‡å­˜åˆ°tools/demo/æ–‡ä»¶å¤¹ä¸‹è¿›è¡Œè¯»å–æ£€æµ‹</span></div><div class="line"></div><div class="line">    <span class="comment">#im_names = ['set06_V002_I00023.jpg', 'set06_V002_I00072.jpg', 'set06_V002_I00097.jpg',</span></div><div class="line">    <span class="comment">#            'set06_V002_I00151.jpg', 'set07_V010_I00247.jpg']</span></div><div class="line">    <span class="keyword">for</span> im_name <span class="keyword">in</span> im_names:</div><div class="line">        <span class="keyword">print</span> <span class="string">'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'Demo for data/demo/&#123;&#125;'</span>.format(im_name)</div><div class="line">        demo(net, im_name)</div><div class="line"></div><div class="line">    plt.show()</div></pre></td></tr></table></figure>
<p>åœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥ä¸€ä¸‹å‘½ä»¤è¿›è¡Œæ£€æµ‹ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tools/demo_caltech.py</div></pre></td></tr></table></figure>
<h3 id="æ£€æµ‹ç»“æœ"><a href="#æ£€æµ‹ç»“æœ" class="headerlink" title="æ£€æµ‹ç»“æœ"></a>æ£€æµ‹ç»“æœ</h3><p>æ”¾å‡ å¼ æ£€æµ‹åçš„ç»“æœå›¾ï¼Œæ„Ÿè§‰æ£€æµ‹æ•ˆæœå¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œå¾ˆå¤šæŠŠèƒŒæ™¯å½“æˆè¡Œäººçš„é”™è¯¯ï¼š</p>
<p><img src="https://ww2.sinaimg.cn/large/006y8lValy1fd36adqacrj30hr0h8qe6.jpg" alt=""></p>
<p><img src="https://ww4.sinaimg.cn/large/006y8lValy1fd36apj94fj30ho0h7wpo.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006y8lValy1fd36aznxnlj30hq0h1k2b.jpg" alt=""></p>
<p><img src="https://ww3.sinaimg.cn/large/006y8lValy1fd36bnalbwj30hk0h749k.jpg" alt=""></p>
<h2 id="å‚è€ƒåšå®¢"><a href="#å‚è€ƒåšå®¢" class="headerlink" title="å‚è€ƒåšå®¢"></a>å‚è€ƒåšå®¢</h2><ol>
<li><strong><a href="http://www.itdadao.com/articles/c15a253094p0.html" target="_blank" rel="external">ä½¿ç”¨Faster-Rcnnè¿›è¡Œç›®æ ‡æ£€æµ‹(å®è·µç¯‡)</a></strong></li>
<li><a href="https://github.com/zeyuanxy/fast-rcnn/blob/master/help/train/README.md" target="_blank" rel="external"><strong>Train Fast-RCNN on Another Dataset</strong></a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;å‰è¨€&quot;&gt;&lt;a href=&quot;#å‰è¨€&quot; class=&quot;headerlink&quot; title=&quot;å‰è¨€&quot;&gt;&lt;/a&gt;å‰è¨€&lt;/h2&gt;&lt;p&gt;å‰é¢å·²ç»ä»‹ç»äº†å¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä¿®æ”¹æ•°æ®é›†è¯»å†™æ¥å£æ¥æ“ä½œæ•°æ®é›†ï¼Œæ¥ä¸‹æ¥æˆ‘æ¥è¯´æ˜ä¸€ä¸‹æ€ä¹ˆæ¥è®­ç»ƒç½‘ç»œå’Œä¹‹åçš„æ£€æµ‹è¿‡ç¨‹ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="ç»éªŒ" scheme="http://jacobkong.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ å®è·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒCaltechæ•°æ®é›†â€”â€”ä¿®æ”¹è¯»å†™æ¥å£</title>
    <link href="http://jacobkong.github.io/posts/4113466123/"/>
    <id>http://jacobkong.github.io/posts/4113466123/</id>
    <published>2017-01-16T22:32:24.000Z</published>
    <updated>2017-02-18T11:17:14.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><p>è¿™éƒ¨åˆ†ä¸»è¦è®²å¦‚ä½•ä¿®æ”¹Faster R-CNNçš„ä»£ç ï¼Œæ¥è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼Œé¦–å…ˆç¡®ä¿ä½ å·²ç»ç¼–è¯‘å®‰è£…äº†py-faster-rcnnï¼Œå¹¶ä¸”å‡†å¤‡å¥½äº†æ•°æ®é›†ï¼Œå…·ä½“å¯å‚è€ƒæˆ‘<a href="http://jacobkong.github.io/posts/2093106769/">ä¸Šä¸€ç¯‡æ–‡ç« </a>ã€‚</p>
<a id="more"></a>
<h2 id="py-faster-rcnnæ–‡ä»¶ç»“æ„"><a href="#py-faster-rcnnæ–‡ä»¶ç»“æ„" class="headerlink" title="py-faster-rcnnæ–‡ä»¶ç»“æ„"></a>py-faster-rcnnæ–‡ä»¶ç»“æ„</h2><ul>
<li>caffe-fast-rcnn<br>è¿™é‡Œæ˜¯caffeæ¡†æ¶ç›®å½•ï¼Œç”¨æ¥è¿›è¡Œcaffeç¼–è¯‘å®‰è£…</li>
<li>data<br>ç”¨æ¥å­˜æ”¾pre trainedæ¨¡å‹ï¼Œæ¯”å¦‚ImageNetä¸Šçš„ï¼Œè¦è®­ç»ƒçš„æ•°æ®é›†ä»¥åŠè¯»å–æ–‡ä»¶çš„cacheç¼“å­˜ã€‚</li>
<li>experiments<br>å­˜æ”¾é…ç½®æ–‡ä»¶ï¼Œè¿è¡Œçš„logæ–‡ä»¶ï¼Œå¦å¤–è¿™ä¸ªç›®å½•ä¸‹æœ‰scripts ç”¨æ¥è·å–imagenetçš„æ¨¡å‹ï¼Œä»¥åŠä½œè€…è®­ç»ƒå¥½çš„fast rcnnæ¨¡å‹ï¼Œä»¥åŠç›¸åº”çš„pascal-vocæ•°æ®é›†</li>
<li>lib<br>ç”¨æ¥å­˜æ”¾ä¸€äº›pythonæ¥å£æ–‡ä»¶ï¼Œå¦‚å…¶ä¸‹çš„datasetsä¸»è¦è´Ÿè´£æ•°æ®åº“è¯»å–ï¼Œconfigè´Ÿè´£cnnä¸€äº›è®­ç»ƒçš„é…ç½®é€‰é¡¹</li>
<li>matlab<br>æ”¾ç½®matlabä¸pythonçš„æ¥å£ï¼Œç”¨matlabæ¥è°ƒç”¨å®ç°detection</li>
<li>models<br>é‡Œé¢å­˜æ”¾äº†ä¸‰ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œå°å‹ç½‘ç»œçš„ZFï¼Œå¤§å‹ç½‘ç»œVGG16ï¼Œä¸­å‹ç½‘ç»œVGG_CNN_M_1024</li>
<li>output<br>è¿™é‡Œå­˜æ”¾çš„æ˜¯è®­ç»ƒå®Œæˆåçš„è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¼šåœ¨defaultæ–‡ä»¶å¤¹ä¸‹</li>
<li>tools<br>é‡Œé¢å­˜æ”¾çš„æ˜¯è®­ç»ƒå’Œæµ‹è¯•çš„Pythonæ–‡ä»¶</li>
</ul>
<h2 id="ä¿®æ”¹è®­ç»ƒä»£ç "><a href="#ä¿®æ”¹è®­ç»ƒä»£ç " class="headerlink" title="ä¿®æ”¹è®­ç»ƒä»£ç "></a>ä¿®æ”¹è®­ç»ƒä»£ç </h2><h3 id="æ‰€è¦æ“ä½œæ–‡ä»¶ç»“æ„ä»‹ç»"><a href="#æ‰€è¦æ“ä½œæ–‡ä»¶ç»“æ„ä»‹ç»" class="headerlink" title="æ‰€è¦æ“ä½œæ–‡ä»¶ç»“æ„ä»‹ç»"></a>æ‰€è¦æ“ä½œæ–‡ä»¶ç»“æ„ä»‹ç»</h3><p>æ‰€æœ‰éœ€è¦ä¿®æ”¹çš„è®­ç»ƒä»£ç éƒ½æ”¾åˆ°äº†<code>py-faster-rcnn/lib</code>æ–‡ä»¶å¤¹ä¸‹ï¼Œæˆ‘ä»¬è¿›å…¥æ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¸»è¦ç”¨åˆ°çš„æ–‡ä»¶å¤¹æœ‰ï¼š</p>
<ul>
<li>datasetsï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾è¯»å†™æ•°æ®æ¥å£ã€‚</li>
<li>fast-rcnnï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾çš„æ˜¯pythonçš„è®­ç»ƒå’Œæµ‹è¯•è„šæœ¬ï¼Œä»¥åŠè®­ç»ƒçš„é…ç½®æ–‡ä»¶ã€‚</li>
<li>roi_data_layerï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾ä¸€äº›ROIå¤„ç†æ“ä½œæ–‡ä»¶ã€‚</li>
<li>utilsï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾ä¸€äº›é€šç”¨æ“ä½œæ¯”å¦‚éæå¤§å€¼nmsï¼Œä»¥åŠè®¡ç®—bounding boxçš„é‡å ç‡ç­‰å¸¸ç”¨åŠŸèƒ½ã€‚</li>
</ul>
<p>è¯»å†™æ•°æ®æ¥å£éƒ½æ”¾åœ¨<code>datasets/</code>æ–‡ä»¶å¤¹ä¸‹ï¼Œæˆ‘ä»¬è¿›å…¥æ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¸»è¦æ–‡ä»¶æœ‰ï¼š</p>
<ul>
<li>factory.pyï¼šè¿™æ˜¯ä¸ªå·¥å‚ç±»ï¼Œç”¨ç±»ç”Ÿæˆimdbç±»å¹¶ä¸”è¿”å›æ•°æ®åº“å…±ç½‘ç»œè®­ç»ƒå’Œæµ‹è¯•ä½¿ç”¨ã€‚</li>
<li>imdb.pyï¼šè¿™æ˜¯æ•°æ®åº“è¯»å†™ç±»çš„åŸºç±»ï¼Œåˆ†è£…äº†è®¸å¤šdbçš„æ“ä½œï¼Œä½†æ˜¯å…·ä½“çš„ä¸€äº›æ–‡ä»¶è¯»å†™éœ€è¦ç»§æ‰¿ç»§ç»­è¯»å†™</li>
<li>pascal_voc.pyï¼šè¿™æ˜¯imdbçš„å­ç±»ï¼Œé‡Œé¢å®šä¹‰è®¸å¤šå‡½æ•°ç”¨æ¥è¿›è¡Œæ‰€æœ‰çš„æ•°æ®è¯»å†™æ“ä½œã€‚</li>
</ul>
<p>ä»ä¸Šé¢å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬ä¸»è¦å¯¹<code>pascal_voc.py</code>æ–‡ä»¶è¿›è¡Œä¿®æ”¹ã€‚</p>
<h3 id="pascal-voc-pyæ–‡ä»¶ä»£ç åˆ†æ"><a href="#pascal-voc-pyæ–‡ä»¶ä»£ç åˆ†æ" class="headerlink" title="pascal_voc.pyæ–‡ä»¶ä»£ç åˆ†æ"></a>pascal_voc.pyæ–‡ä»¶ä»£ç åˆ†æ</h3><p>æˆ‘ä»¬ä¸»è¦æ˜¯åŸºäº<code>pasca_voc.py</code>è¿™ä¸ªæ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œé‡Œé¢æœ‰å‡ ä¸ªé‡è¦çš„å‡½æ•°éœ€è¦ä»‹ç»ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_set, devkit_path=None)</span>:</span> <span class="comment"># è¿™ä¸ªæ˜¯åˆå§‹åŒ–å‡½æ•°ï¼Œå®ƒå¯¹åº”ç€çš„æ˜¯pascal_vocçš„æ•°æ®é›†è®¿é—®æ ¼å¼ã€‚</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_path_at</span><span class="params">(self, i)</span>:</span> <span class="comment"># æ ¹æ®ç¬¬iä¸ªå›¾åƒæ ·æœ¬è¿”å›å…¶å¯¹åº”çš„pathï¼Œå…¶è°ƒç”¨image_path_from_index(self, index):ä½œä¸ºå…¶å…·ä½“å®ç°ã€‚</span></div><div class="line">        </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_path_from_index</span><span class="params">(self, index)</span>:</span> <span class="comment"># å®ç°äº† image_pathçš„å…·ä½“åŠŸèƒ½</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_image_set_index</span><span class="params">(self)</span>:</span> <span class="comment"># åŠ è½½äº†æ ·æœ¬çš„listæ–‡ä»¶ï¼Œæ ¹æ®ImageSet/Main/æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶è¿›è¡Œimage_indexçš„åŠ è½½ã€‚</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_default_path</span><span class="params">(self)</span>:</span> <span class="comment"># è·å¾—æ•°æ®é›†åœ°å€</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gt_roidb</span><span class="params">(self)</span>:</span> <span class="comment"># è¯»å–å¹¶è¿”å›ground_truthçš„db</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rpn_roidb</span><span class="params">(self)</span>:</span> <span class="comment"># åŠ è½½rpnäº§ç”Ÿçš„roiï¼Œè°ƒç”¨_load_rpn_roidb(self, gt_roidb):å‡½æ•°ä½œä¸ºå…¶å…·ä½“å®ç°</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_rpn_roidb</span><span class="params">(self, gt_roidb)</span>:</span> <span class="comment"># åŠ è½½rpn_file</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_pascal_annotation</span><span class="params">(self, index)</span>:</span> <span class="comment"># è¿™ä¸ªå‡½æ•°æ˜¯è¯»å–gtçš„å…·ä½“å®ç°</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_write_voc_results_file</span><span class="params">(self, all_boxes)</span>:</span> <span class="comment"># å°†vocçš„æ£€æµ‹ç»“æœå†™å…¥åˆ°æ–‡ä»¶</span></div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_do_python_eval</span><span class="params">(self, output_dir = <span class="string">'output'</span>)</span>:</span> <span class="comment"># æ ¹æ®pythonçš„evluationæ¥å£æ¥åšç»“æœçš„åˆ†æ</span></div></pre></td></tr></table></figure>
<h3 id="ä¿®æ”¹pascal-voc-pyæ–‡ä»¶"><a href="#ä¿®æ”¹pascal-voc-pyæ–‡ä»¶" class="headerlink" title="ä¿®æ”¹pascal_voc.pyæ–‡ä»¶"></a>ä¿®æ”¹pascal_voc.pyæ–‡ä»¶</h3><p>è¦æƒ³å¯¹è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œè¯»å–ï¼Œæˆ‘ä»¬ä¸»è¦æ˜¯è¿›è¡Œ<code>pascal_voc.py</code>æ–‡ä»¶çš„ä¿®æ”¹ï¼Œä½†æ˜¯ä¸ºäº†ä¸ç ´åæºæ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†<code>pascal_voc.py</code>è¿›è¡Œæ‹·è´å¤åˆ¶ï¼Œä»è€Œè¿›è¡Œä¿®æ”¹ã€‚è¿™é‡Œæˆ‘å°†<code>pascal_voc.py</code>æ–‡ä»¶æ‹·è´æˆ<code>caltech.py</code>æ–‡ä»¶ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp pascal_voc.py caltech.py</div></pre></td></tr></table></figure>
<p>ä¸‹é¢æˆ‘ä»¬å¯¹<code>caltech.py</code>æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œåœ¨è¿™é‡Œæˆ‘ä¼šä¸€ä¸€åˆ—ä¸¾æ¯ä¸ªæˆ‘ä¿®æ”¹è¿‡çš„å‡½æ•°ã€‚è¿™é‡ŒæŒ‰ç…§æ–‡ä»¶ä¸­çš„é¡ºåºæ’åˆ—ã€‚ã€‚</p>
<h4 id="initå‡½æ•°ä¿®æ”¹"><a href="#initå‡½æ•°ä¿®æ”¹" class="headerlink" title="initå‡½æ•°ä¿®æ”¹"></a><strong>init</strong>å‡½æ•°ä¿®æ”¹</h4><p>è¿™é‡Œæ˜¯åŸå§‹çš„pascal_vocçš„initå‡½æ•°ï¼Œåœ¨è¿™é‡Œï¼Œç”±äºæˆ‘ä»¬è‡ªå·±çš„æ•°æ®é›†å¾€å¾€æ¯”vocçš„æ•°æ®é›†è¦æ›´ç®€å•çš„ä¸€äº›ï¼Œåœ¨ä½œè€…é¢ä»£ç é‡Œé¢ç”¨äº†å¾ˆå¤šçš„è·¯å¾„æ‹¼æ¥ï¼Œæˆ‘ä»¬ä¸ç”¨å»è¿åˆä»–çš„æ ¼å¼ï¼Œå°†è¿™äº›æ“ä½œç®€å•åŒ–å³å¯ã€‚</p>
<h5 id="åŸå§‹çš„å‡½æ•°"><a href="#åŸå§‹çš„å‡½æ•°" class="headerlink" title="åŸå§‹çš„å‡½æ•°"></a>åŸå§‹çš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_set, year, devkit_path=None)</span>:</span></div><div class="line">        imdb.__init__(self, <span class="string">'voc_'</span> + year + <span class="string">'_'</span> + image_set)</div><div class="line">        self._year = year</div><div class="line">        self._image_set = image_set</div><div class="line">        self._devkit_path = self._get_default_path() <span class="keyword">if</span> devkit_path <span class="keyword">is</span> <span class="keyword">None</span> \</div><div class="line">                            <span class="keyword">else</span> devkit_path</div><div class="line">        self._data_path = os.path.join(self._devkit_path, <span class="string">'VOC'</span> + self._year)</div><div class="line">        self._classes = (<span class="string">'__background__'</span>, <span class="comment"># always index 0</span></div><div class="line">                         <span class="string">'aeroplane'</span>, <span class="string">'bicycle'</span>, <span class="string">'bird'</span>, <span class="string">'boat'</span>,</div><div class="line">                         <span class="string">'bottle'</span>, <span class="string">'bus'</span>, <span class="string">'car'</span>, <span class="string">'cat'</span>, <span class="string">'chair'</span>,</div><div class="line">                         <span class="string">'cow'</span>, <span class="string">'diningtable'</span>, <span class="string">'dog'</span>, <span class="string">'horse'</span>,</div><div class="line">                         <span class="string">'motorbike'</span>, <span class="string">'person'</span>, <span class="string">'pottedplant'</span>,</div><div class="line">                         <span class="string">'sheep'</span>, <span class="string">'sofa'</span>, <span class="string">'train'</span>, <span class="string">'tvmonitor'</span>)</div><div class="line">        self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))</div><div class="line">        self._image_ext = <span class="string">'.jpg'</span></div><div class="line">        self._image_index = self._load_image_set_index()</div><div class="line">        <span class="comment"># Default to roidb handler</span></div><div class="line">        self._roidb_handler = self.selective_search_roidb</div><div class="line">        self._salt = str(uuid.uuid4())</div><div class="line">        self._comp_id = <span class="string">'comp4'</span></div><div class="line"></div><div class="line">        <span class="comment"># PASCAL specific config options</span></div><div class="line">        self.config = &#123;<span class="string">'cleanup'</span>     : <span class="keyword">True</span>,</div><div class="line">                       <span class="string">'use_salt'</span>    : <span class="keyword">True</span>,</div><div class="line">                       <span class="string">'use_diff'</span>    : <span class="keyword">False</span>,</div><div class="line">                       <span class="string">'matlab_eval'</span> : <span class="keyword">False</span>,</div><div class="line">                       <span class="string">'rpn_file'</span>    : <span class="keyword">None</span>,</div><div class="line">                       <span class="string">'min_size'</span>    : <span class="number">2</span>&#125;</div><div class="line"></div><div class="line">        <span class="keyword">assert</span> os.path.exists(self._devkit_path), \</div><div class="line">                <span class="string">'VOCdevkit path does not exist: &#123;&#125;'</span>.format(self._devkit_path)</div><div class="line">        <span class="keyword">assert</span> os.path.exists(self._data_path), \</div><div class="line">                <span class="string">'Path does not exist: &#123;&#125;'</span>.format(self._data_path)</div></pre></td></tr></table></figure>
<h5 id="ä¿®æ”¹åçš„å‡½æ•°"><a href="#ä¿®æ”¹åçš„å‡½æ•°" class="headerlink" title="ä¿®æ”¹åçš„å‡½æ•°"></a>ä¿®æ”¹åçš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_set, devkit_path=None)</span>:</span><span class="comment"># initial functionï¼ŒæŠŠyearåˆ é™¤</span></div><div class="line">        imdb.__init__(self, image_set) <span class="comment"># imageset is train.txt or test.txt</span></div><div class="line">        self._image_set = image_set</div><div class="line">        self._devkit_path = devkit_path <span class="comment"># devkit_path = '~/py-faster-rcnn/data/VOCdevkit'</span></div><div class="line">        self._data_path = os.path.join(self._devkit_path, <span class="string">'Caltech'</span>) <span class="comment"># _data_path = '~/py-faster-rcnn/data/VOCdevkit/Caltech'</span></div><div class="line">        self._classes = (<span class="string">'__background__'</span>, <span class="comment"># always index 0</span></div><div class="line">                         <span class="string">'person'</span>) <span class="comment"># æˆ‘åªæœ‰â€˜backgroundâ€™å’Œâ€˜personâ€™ä¸¤ç±»</span></div><div class="line">        self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))</div><div class="line">        self._image_ext = <span class="string">'.jpg'</span></div><div class="line">        self._image_index = self._load_image_set_index()</div><div class="line">        <span class="comment"># Default to roidb handler</span></div><div class="line">        self._roidb_handler = self.selective_search_roidb</div><div class="line">        self._salt = str(uuid.uuid4())</div><div class="line">        self._comp_id = <span class="string">'comp4'</span></div><div class="line"></div><div class="line">        <span class="comment"># PASCAL specific config options</span></div><div class="line">        self.config = &#123;<span class="string">'cleanup'</span>     : <span class="keyword">True</span>,</div><div class="line">                       <span class="string">'use_salt'</span>    : <span class="keyword">True</span>,</div><div class="line">                       <span class="string">'use_diff'</span>    : <span class="keyword">True</span>, <span class="comment"># æˆ‘æŠŠuse_diffæ”¹ä¸ºtrueäº†ï¼Œå› ä¸ºæˆ‘çš„æ•°æ®é›†xmlæ–‡ä»¶ä¸­æ²¡æœ‰&lt;difficult&gt;æ ‡ç­¾ï¼Œå¦åˆ™ä¹‹åè®­ç»ƒä¼šæŠ¥é”™</span></div><div class="line">                       <span class="string">'matlab_eval'</span> : <span class="keyword">False</span>,</div><div class="line">                       <span class="string">'rpn_file'</span>    : <span class="keyword">None</span>,</div><div class="line">                       <span class="string">'min_size'</span>    : <span class="number">2</span>&#125;</div><div class="line"></div><div class="line">        <span class="keyword">assert</span> os.path.exists(self._devkit_path), \</div><div class="line">                <span class="string">'VOCdevkit path does not exist: &#123;&#125;'</span>.format(self._devkit_path)</div><div class="line">        <span class="keyword">assert</span> os.path.exists(self._data_path), \</div><div class="line">                <span class="string">'Path does not exist: &#123;&#125;'</span>.format(self._data_path)</div></pre></td></tr></table></figure>
<h4 id="load-image-set-indexå‡½æ•°ä¿®æ”¹"><a href="#load-image-set-indexå‡½æ•°ä¿®æ”¹" class="headerlink" title="_load_image_set_indexå‡½æ•°ä¿®æ”¹"></a>_load_image_set_indexå‡½æ•°ä¿®æ”¹</h4><h5 id="åŸå§‹çš„å‡½æ•°-1"><a href="#åŸå§‹çš„å‡½æ•°-1" class="headerlink" title="åŸå§‹çš„å‡½æ•°"></a>åŸå§‹çš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_image_set_index</span><span class="params">(self)</span>:</span></div><div class="line">      <span class="string">"""</span></div><div class="line">          Load the indexes listed in this dataset's image set file.</div><div class="line">          """</div><div class="line">      <span class="comment"># Example path to image set file:</span></div><div class="line">      <span class="comment"># self._devkit_path + /VOCdevkit2007/VOC2007/ImageSets/Main/val.txt</span></div><div class="line">      image_set_file = os.path.join(self._data_path, <span class="string">'ImageSets'</span>, <span class="string">'Main'</span>,</div><div class="line">                                    self._image_set + <span class="string">'.txt'</span>)</div><div class="line">      <span class="keyword">assert</span> os.path.exists(image_set_file), \</div><div class="line">      <span class="string">'Path does not exist: &#123;&#125;'</span>.format(image_set_file)</div><div class="line">      <span class="keyword">with</span> open(image_set_file) <span class="keyword">as</span> f:</div><div class="line">          image_index = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</div><div class="line">          <span class="keyword">return</span> image_index</div></pre></td></tr></table></figure>
<h5 id="ä¿®æ”¹åçš„å‡½æ•°-1"><a href="#ä¿®æ”¹åçš„å‡½æ•°-1" class="headerlink" title="ä¿®æ”¹åçš„å‡½æ•°"></a>ä¿®æ”¹åçš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_image_set_index</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Load the indexes listed in this dataset's image set file.</div><div class="line">        """</div><div class="line">        <span class="comment"># Example path to image set file:</span></div><div class="line">        <span class="comment"># self._devkit_path + /VOCdevkit2007/VOC2007/ImageSets/Main/val.txt</span></div><div class="line">        <span class="comment"># /home/jk/py-faster-rcnn/data/VOCdevkit/Caltech/ImageSets/Main/train.txt</span></div><div class="line">        image_set_file = os.path.join(self._data_path, <span class="string">'ImageSets'</span>, <span class="string">'Main'</span>,</div><div class="line">                                      self._image_set + <span class="string">'.txt'</span>)</div><div class="line">        <span class="keyword">assert</span> os.path.exists(image_set_file), \</div><div class="line">                <span class="string">'Path does not exist: &#123;&#125;'</span>.format(image_set_file)</div><div class="line">        <span class="keyword">with</span> open(image_set_file) <span class="keyword">as</span> f:</div><div class="line">            image_index = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> f.readlines()]</div><div class="line">        <span class="keyword">return</span> image_index</div></pre></td></tr></table></figure>
<p>å…¶å®æ²¡æ”¹ï¼Œåªæ˜¯åŠ äº†ä¸€è¡Œæ³¨é‡Šï¼Œä»è€Œæ›´å¥½ç†è§£è·¯å¾„é—®é¢˜ã€‚</p>
<h4 id="get-default-pathå‡½æ•°ä¿®æ”¹"><a href="#get-default-pathå‡½æ•°ä¿®æ”¹" class="headerlink" title="_get_default_pathå‡½æ•°ä¿®æ”¹"></a>_get_default_pathå‡½æ•°ä¿®æ”¹</h4><p>ç›´æ¥æ³¨é‡Šå³å¯</p>
<h4 id="load-pascal-annotationå‡½æ•°ä¿®æ”¹"><a href="#load-pascal-annotationå‡½æ•°ä¿®æ”¹" class="headerlink" title="_load_pascal_annotationå‡½æ•°ä¿®æ”¹"></a>_load_pascal_annotationå‡½æ•°ä¿®æ”¹</h4><h5 id="åŸå§‹çš„å‡½æ•°-2"><a href="#åŸå§‹çš„å‡½æ•°-2" class="headerlink" title="åŸå§‹çš„å‡½æ•°"></a>åŸå§‹çš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_pascal_annotation</span><span class="params">(self, index)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Load image and bounding boxes info from XML file in the PASCAL VOC</div><div class="line">        format.</div><div class="line">        """</div><div class="line">        filename = os.path.join(self._data_path, <span class="string">'Annotations'</span>, index + <span class="string">'.xml'</span>)</div><div class="line">        tree = ET.parse(filename)</div><div class="line">        objs = tree.findall(<span class="string">'object'</span>)</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.config[<span class="string">'use_diff'</span>]:</div><div class="line">            <span class="comment"># Exclude the samples labeled as difficult</span></div><div class="line">            non_diff_objs = [</div><div class="line">                obj <span class="keyword">for</span> obj <span class="keyword">in</span> objs <span class="keyword">if</span> int(obj.find(<span class="string">'difficult'</span>).text) == <span class="number">0</span>]</div><div class="line">            <span class="comment"># if len(non_diff_objs) != len(objs):</span></div><div class="line">            <span class="comment">#     print 'Removed &#123;&#125; difficult objects'.format(</span></div><div class="line">            <span class="comment">#         len(objs) - len(non_diff_objs))</span></div><div class="line">            objs = non_diff_objs</div><div class="line">        num_objs = len(objs)</div><div class="line"></div><div class="line">        boxes = np.zeros((num_objs, <span class="number">4</span>), dtype=np.uint16)</div><div class="line">        gt_classes = np.zeros((num_objs), dtype=np.int32)</div><div class="line">        overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32)</div><div class="line">        <span class="comment"># "Seg" area for pascal is just the box area</span></div><div class="line">        seg_areas = np.zeros((num_objs), dtype=np.float32)</div><div class="line"></div><div class="line">        <span class="comment"># Load object bounding boxes into a data frame.</span></div><div class="line">        <span class="keyword">for</span> ix, obj <span class="keyword">in</span> enumerate(objs):</div><div class="line">            bbox = obj.find(<span class="string">'bndbox'</span>)</div><div class="line">            <span class="comment"># Make pixel indexes 0-based</span></div><div class="line">            x1 = float(bbox.find(<span class="string">'xmin'</span>).text) - <span class="number">1</span></div><div class="line">            y1 = float(bbox.find(<span class="string">'ymin'</span>).text) - <span class="number">1</span></div><div class="line">            x2 = float(bbox.find(<span class="string">'xmax'</span>).text) - <span class="number">1</span></div><div class="line">            y2 = float(bbox.find(<span class="string">'ymax'</span>).text) - <span class="number">1</span></div><div class="line">            cls = self._class_to_ind[obj.find(<span class="string">'name'</span>).text.lower().strip()]</div><div class="line">            boxes[ix, :] = [x1, y1, x2, y2]</div><div class="line">            gt_classes[ix] = cls</div><div class="line">            overlaps[ix, cls] = <span class="number">1.0</span></div><div class="line">            seg_areas[ix] = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</div><div class="line"></div><div class="line">        overlaps = scipy.sparse.csr_matrix(overlaps)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> &#123;<span class="string">'boxes'</span> : boxes,</div><div class="line">                <span class="string">'gt_classes'</span>: gt_classes,</div><div class="line">                <span class="string">'gt_overlaps'</span> : overlaps,</div><div class="line">                <span class="string">'flipped'</span> : <span class="keyword">False</span>,</div><div class="line">                <span class="string">'seg_areas'</span> : seg_areas&#125;</div></pre></td></tr></table></figure>
<h5 id="ä¿®æ”¹åçš„å‡½æ•°-2"><a href="#ä¿®æ”¹åçš„å‡½æ•°-2" class="headerlink" title="ä¿®æ”¹åçš„å‡½æ•°"></a>ä¿®æ”¹åçš„å‡½æ•°</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_load_pascal_annotation</span><span class="params">(self, index)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Load image and bounding boxes info from XML file in the PASCAL VOC</div><div class="line">        format.</div><div class="line">        """</div><div class="line">        filename = os.path.join(self._data_path, <span class="string">'Annotations'</span>, index + <span class="string">'.xml'</span>)</div><div class="line">        tree = ET.parse(filename)</div><div class="line">        objs = tree.findall(<span class="string">'object'</span>)</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.config[<span class="string">'use_diff'</span>]:</div><div class="line">            <span class="comment"># Exclude the samples labeled as difficult</span></div><div class="line">            non_diff_objs = [</div><div class="line">                obj <span class="keyword">for</span> obj <span class="keyword">in</span> objs <span class="keyword">if</span> int(obj.find(<span class="string">'difficult'</span>).text) == <span class="number">0</span>]</div><div class="line">            <span class="comment"># if len(non_diff_objs) != len(objs):</span></div><div class="line">            <span class="comment">#     print 'Removed &#123;&#125; difficult objects'.format(</span></div><div class="line">            <span class="comment">#         len(objs) - len(non_diff_objs))</span></div><div class="line">            objs = non_diff_objs</div><div class="line">        num_objs = len(objs)</div><div class="line"></div><div class="line">        boxes = np.zeros((num_objs, <span class="number">4</span>), dtype=np.uint16)</div><div class="line">        gt_classes = np.zeros((num_objs), dtype=np.int32)</div><div class="line">        overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32)</div><div class="line">        <span class="comment"># "Seg" area for pascal is just the box area</span></div><div class="line">        seg_areas = np.zeros((num_objs), dtype=np.float32)</div><div class="line"></div><div class="line">        <span class="comment"># Load object bounding boxes into a data frame.</span></div><div class="line">        <span class="keyword">for</span> ix, obj <span class="keyword">in</span> enumerate(objs):</div><div class="line">            bbox = obj.find(<span class="string">'bndbox'</span>)</div><div class="line">            <span class="comment"># Make pixel indexes 0-based</span></div><div class="line">            <span class="comment"># è¿™é‡Œæˆ‘æŠŠâ€˜-1â€™å…¨éƒ¨åˆ é™¤æ‰äº†ï¼Œé˜²æ­¢æœ‰çš„æ•°æ®æ˜¯0å¼€å§‹ï¼Œç„¶åâ€˜-1â€™å¯¼è‡´å˜ä¸ºè´Ÿæ•°ï¼Œäº§ç”ŸAssertErroré”™è¯¯</span></div><div class="line">            x1 = float(bbox.find(<span class="string">'xmin'</span>).text)</div><div class="line">            y1 = float(bbox.find(<span class="string">'ymin'</span>).text)</div><div class="line">            x2 = float(bbox.find(<span class="string">'xmax'</span>).text)</div><div class="line">            y2 = float(bbox.find(<span class="string">'ymax'</span>).text)</div><div class="line">            cls = self._class_to_ind[obj.find(<span class="string">'name'</span>).text.lower().strip()]</div><div class="line">            boxes[ix, :] = [x1, y1, x2, y2]</div><div class="line">            gt_classes[ix] = cls</div><div class="line">            overlaps[ix, cls] = <span class="number">1.0</span></div><div class="line">            seg_areas[ix] = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</div><div class="line"></div><div class="line">        overlaps = scipy.sparse.csr_matrix(overlaps)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> &#123;<span class="string">'boxes'</span> : boxes,</div><div class="line">                <span class="string">'gt_classes'</span>: gt_classes,</div><div class="line">                <span class="string">'gt_overlaps'</span> : overlaps,</div><div class="line">                <span class="string">'flipped'</span> : <span class="keyword">False</span>,</div><div class="line">                <span class="string">'seg_areas'</span> : seg_areas&#125;</div></pre></td></tr></table></figure>
<h4 id="mainå‡½æ•°ä¿®æ”¹"><a href="#mainå‡½æ•°ä¿®æ”¹" class="headerlink" title="mainå‡½æ•°ä¿®æ”¹"></a>mainå‡½æ•°ä¿®æ”¹</h4><p>åŸå§‹çš„å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">from</span> datasets.pascal_voc <span class="keyword">import</span> pascal_voc</div><div class="line">    d = pascal_voc(<span class="string">'trainval'</span>, <span class="string">'2007'</span>)</div><div class="line">    res = d.roidb</div><div class="line">    <span class="keyword">from</span> IPython <span class="keyword">import</span> embed; embed()</div></pre></td></tr></table></figure>
<p>ä¿®æ”¹åçš„å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">from</span> datasets.caltech <span class="keyword">import</span> caltech <span class="comment"># å¯¼å…¥caltechåŒ…</span></div><div class="line">    d = caltech(<span class="string">'train'</span>, <span class="string">'/home/jk/py-faster-rcnn/data/VOCdevkit'</span>)<span class="comment">#è°ƒç”¨æ„é€ å‡½æ•°ï¼Œä¼ å…¥imagesetå’Œè·¯å¾„</span></div><div class="line">    res = d.roidb</div><div class="line">    <span class="keyword">from</span> IPython <span class="keyword">import</span> embed; embed()</div></pre></td></tr></table></figure>
<p>è‡³æ­¤è¯»å–æ¥å£ä¿®æ”¹å®Œæ¯•ï¼Œè¯¥æ–‡ä»¶ä¸­çš„å…¶ä»–å‡½æ•°å¹¶æœªä¿®æ”¹ã€‚</p>
<h3 id="ä¿®æ”¹factory-pyæ–‡ä»¶"><a href="#ä¿®æ”¹factory-pyæ–‡ä»¶" class="headerlink" title="ä¿®æ”¹factory.pyæ–‡ä»¶"></a>ä¿®æ”¹factory.pyæ–‡ä»¶</h3><p>å½“ç½‘ç»œè®­ç»ƒæ—¶ä¼šè°ƒç”¨factoryé‡Œé¢çš„getæ–¹æ³•è·å¾—ç›¸åº”çš„imdbï¼Œé¦–å…ˆåœ¨æ–‡ä»¶å¤´import æŠŠpascal_vocæ”¹æˆcaltech</p>
<p>åœ¨è¿™ä¸ªæ–‡ä»¶ä½œè€…ç”Ÿæˆäº†å¤šä¸ªæ•°æ®åº“çš„è·¯å¾„ï¼Œæˆ‘ä»¬è‡ªå·±æ•°æ®åº“åªè¦ç»™å®šæ ¹è·¯å¾„å³å¯ï¼Œä¿®æ”¹ä¸»è¦æœ‰ä»¥ä¸‹4ä¸ª</p>
<ul>
<li>å‡½æ•°ä¹‹åæœ‰ä¸¤ä¸ªå¤šçº§çš„forå¾ªç¯ï¼Œä¹Ÿå°†å…¶æ³¨é‡Š</li>
<li>ç›´æ¥å®šä¹‰<code>devkit</code>ã€‚</li>
<li>åˆ©ç”¨åˆ›å»ºè‡ªå·±çš„è®­ç»ƒå’Œæµ‹è¯•çš„imdb setï¼Œè¿™é‡Œçš„nameçš„æ ¼å¼ä¸º<code>caltech_{}</code>ã€‚</li>
</ul>
<h4 id="åŸå§‹çš„ä»£ç "><a href="#åŸå§‹çš„ä»£ç " class="headerlink" title="åŸå§‹çš„ä»£ç "></a>åŸå§‹çš„ä»£ç </h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"><span class="comment"># Fast R-CNN</span></div><div class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></div><div class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></div><div class="line"><span class="comment"># Written by Ross Girshick</span></div><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="string">"""Factory method for easily getting imdbs by name."""</span></div><div class="line"></div><div class="line">__sets = &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">from</span> datasets.pascal_voc <span class="keyword">import</span> pascal_voc</div><div class="line"><span class="keyword">from</span> datasets.coco <span class="keyword">import</span> coco</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Set up voc_&lt;year&gt;_&lt;split&gt; using selective search "fast" mode</span></div><div class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2007'</span>, <span class="string">'2012'</span>]:</div><div class="line">    <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>, <span class="string">'trainval'</span>, <span class="string">'test'</span>]:</div><div class="line">        name = <span class="string">'voc_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</div><div class="line">        __sets[name] = (<span class="keyword">lambda</span> split=split, year=year: pascal_voc(split, year))</div><div class="line"></div><div class="line"><span class="comment"># Set up coco_2014_&lt;split&gt;</span></div><div class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2014'</span>]:</div><div class="line">    <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>, <span class="string">'minival'</span>, <span class="string">'valminusminival'</span>]:</div><div class="line">        name = <span class="string">'coco_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</div><div class="line">        __sets[name] = (<span class="keyword">lambda</span> split=split, year=year: coco(split, year))</div><div class="line"></div><div class="line"><span class="comment"># Set up coco_2015_&lt;split&gt;</span></div><div class="line"><span class="keyword">for</span> year <span class="keyword">in</span> [<span class="string">'2015'</span>]:</div><div class="line">    <span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'test'</span>, <span class="string">'test-dev'</span>]:</div><div class="line">        name = <span class="string">'coco_&#123;&#125;_&#123;&#125;'</span>.format(year, split)</div><div class="line">        __sets[name] = (<span class="keyword">lambda</span> split=split, year=year: coco(split, year))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_imdb</span><span class="params">(name)</span>:</span></div><div class="line">    <span class="string">"""Get an imdb (image database) by name."""</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> __sets.has_key(name):</div><div class="line">        <span class="keyword">raise</span> KeyError(<span class="string">'Unknown dataset: &#123;&#125;'</span>.format(name))</div><div class="line">    <span class="keyword">return</span> __sets[name]()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">list_imdbs</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""List all registered imdbs."""</span></div><div class="line">    <span class="keyword">return</span> __sets.keys()</div></pre></td></tr></table></figure>
<h4 id="ä¿®æ”¹åçš„æ–‡ä»¶"><a href="#ä¿®æ”¹åçš„æ–‡ä»¶" class="headerlink" title="ä¿®æ”¹åçš„æ–‡ä»¶"></a>ä¿®æ”¹åçš„æ–‡ä»¶</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"><span class="comment"># Fast R-CNN</span></div><div class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></div><div class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></div><div class="line"><span class="comment"># Written by Ross Girshick</span></div><div class="line"><span class="comment"># --------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="string">"""Factory method for easily getting imdbs by name."""</span></div><div class="line"></div><div class="line">__sets = &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">from</span> datasets.caltech <span class="keyword">import</span> caltech <span class="comment"># å¯¼å…¥caltechåŒ…</span></div><div class="line"><span class="comment">#from datasets.coco import coco</span></div><div class="line"><span class="comment">#import numpy as np</span></div><div class="line"></div><div class="line">devkit = <span class="string">'/home/jk/py-faster-rcnn/data/VOCdevkit'</span></div><div class="line"><span class="comment"># Set up voc_&lt;year&gt;_&lt;split&gt; using selective search "fast" mode</span></div><div class="line"><span class="comment">#for year in ['2007', '2012']:</span></div><div class="line"><span class="comment">#    for split in ['train', 'val', 'trainval', 'test']:</span></div><div class="line"><span class="comment">#        name = 'voc_&#123;&#125;_&#123;&#125;'.format(year, split)</span></div><div class="line"><span class="comment">#        __sets[name] = (lambda split=split, year=year: pascal_voc(split, year))</span></div><div class="line"></div><div class="line"><span class="comment"># Set up coco_2014_&lt;split&gt;</span></div><div class="line"><span class="comment">#for year in ['2014']:</span></div><div class="line"><span class="comment">#    for split in ['train', 'val', 'minival', 'valminusminival']:</span></div><div class="line"><span class="comment">#        name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split)</span></div><div class="line"><span class="comment">#        __sets[name] = (lambda split=split, year=year: coco(split, year))</span></div><div class="line"></div><div class="line"><span class="comment"># Set up coco_2015_&lt;split&gt;</span></div><div class="line"><span class="comment">#for year in ['2015']:</span></div><div class="line"><span class="comment">#    for split in ['test', 'test-dev']:</span></div><div class="line"><span class="comment">#        name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split)</span></div><div class="line"><span class="comment">#        __sets[name] = (lambda split=split, year=year: coco(split, year))</span></div><div class="line"></div><div class="line"><span class="comment"># Set up caltech_&lt;split&gt;</span></div><div class="line"><span class="keyword">for</span> split <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'test'</span>]:</div><div class="line">    name = <span class="string">'caltech_&#123;&#125;'</span>.format(split)</div><div class="line">    __sets[name] = (<span class="keyword">lambda</span> imageset=split, devkit=devkit: caltech(imageset, devkit))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_imdb</span><span class="params">(name)</span>:</span></div><div class="line">    <span class="string">"""Get an imdb (image database) by name."""</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> __sets.has_key(name):</div><div class="line">        <span class="keyword">raise</span> KeyError(<span class="string">'Unknown dataset: &#123;&#125;'</span>.format(name))</div><div class="line">    <span class="keyword">return</span> __sets[name]()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">list_imdbs</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""List all registered imdbs."""</span></div><div class="line">    <span class="keyword">return</span> __sets.keys()</div></pre></td></tr></table></figure>
<h3 id="ä¿®æ”¹init-pyæ–‡ä»¶"><a href="#ä¿®æ”¹init-pyæ–‡ä»¶" class="headerlink" title="ä¿®æ”¹init.pyæ–‡ä»¶"></a>ä¿®æ”¹<strong>init</strong>.pyæ–‡ä»¶</h3><p>åœ¨è¡Œé¦–æ·»åŠ ä¸Š <code>from .caltech import caltech</code></p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><ul>
<li>åæ ‡çš„é¡ºåºæˆ‘å†è¯´ä¸€æ¬¡ï¼Œè¦å·¦ä¸Šå³ä¸‹ï¼Œå¹¶ä¸”x1å¿…é¡»è¦å°äºx2ï¼Œè¿™ä¸ªæ˜¯åŸºæœ¬ï¼Œåäº†ä¼šåœ¨åæ ‡æ°´å¹³å˜æ¢çš„æ—¶å€™ä¼šå‡ºé”™ï¼Œåæ ‡ä»0å¼€å§‹ï¼Œå¦‚æœå·²ç»æ˜¯0ï¼Œåˆ™ä¸éœ€è¦å†-1ã€‚</li>
<li>è®­ç»ƒå›¾åƒçš„å¤§å°ä¸è¦å¤ªå¤§ï¼Œå¦åˆ™ç”Ÿæˆçš„OPä¹Ÿä¼šå¤ªå¤šï¼Œé€Ÿåº¦å¤ªæ…¢ï¼Œå›¾åƒæ ·æœ¬å¤§å°æœ€å¥½è°ƒæ•´åˆ°500ï¼Œ600å·¦å³ï¼Œç„¶åå†æå–OP</li>
<li>å¦‚æœè¯»å–å¹¶ç”Ÿæˆpklæ–‡ä»¶ä¹‹åï¼Œå®é™…æ•°æ®å†…å®¹æˆ–è€…é¡ºåºè¿˜æœ‰é—®é¢˜ï¼Œè®°å¾—è¦æŠŠdata/cache/ä¸‹é¢çš„pklæ–‡ä»¶ç»™åˆ æ‰ã€‚</li>
</ul>
<h2 id="å‚è€ƒåšå®¢"><a href="#å‚è€ƒåšå®¢" class="headerlink" title="å‚è€ƒåšå®¢"></a>å‚è€ƒåšå®¢</h2><ol>
<li><a href="http://www.cnblogs.com/louyihang-loves-baiyan/p/4903231.html" target="_blank" rel="external"><strong>Fast RCNNè®­ç»ƒè‡ªå·±çš„æ•°æ®é›† ï¼ˆ2ä¿®æ”¹è¯»å†™æ¥å£ï¼‰</strong></a></li>
<li><a href="http://www.cnblogs.com/CarryPotMan/p/5390336.html" target="_blank" rel="external"><strong>Faster R-CNNæ•™ç¨‹</strong></a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;å‰è¨€&quot;&gt;&lt;a href=&quot;#å‰è¨€&quot; class=&quot;headerlink&quot; title=&quot;å‰è¨€&quot;&gt;&lt;/a&gt;å‰è¨€&lt;/h2&gt;&lt;p&gt;è¿™éƒ¨åˆ†ä¸»è¦è®²å¦‚ä½•ä¿®æ”¹Faster R-CNNçš„ä»£ç ï¼Œæ¥è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼Œé¦–å…ˆç¡®ä¿ä½ å·²ç»ç¼–è¯‘å®‰è£…äº†py-faster-rcnnï¼Œå¹¶ä¸”å‡†å¤‡å¥½äº†æ•°æ®é›†ï¼Œå…·ä½“å¯å‚è€ƒæˆ‘&lt;a href=&quot;http://jacobkong.github.io/posts/2093106769/&quot;&gt;ä¸Šä¸€ç¯‡æ–‡ç« &lt;/a&gt;ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="ç»éªŒ" scheme="http://jacobkong.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ å®è·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒè¡Œäººæ£€æµ‹æ•°æ®é›†Caltechâ€”â€”å‡†å¤‡å·¥ä½œ</title>
    <link href="http://jacobkong.github.io/posts/2093106769/"/>
    <id>http://jacobkong.github.io/posts/2093106769/</id>
    <published>2017-01-15T22:32:24.000Z</published>
    <updated>2017-02-28T06:55:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><p>Faster R-CNNæ˜¯Ross Girshickå¤§ç¥åœ¨Fast R-CNNåŸºç¡€ä¸Šæå‡ºçš„åˆä¸€ä¸ªæ›´åŠ å¿«é€Ÿã€æ›´é«˜mAPçš„ç”¨äºç›®æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå¯¹Fast R-CNNè¿›è¡Œçš„æœ€ä¸»è¦çš„ä¼˜åŒ–å°±æ˜¯åœ¨Region Proposalé˜¶æ®µï¼Œå¼•å…¥äº†Region Proposal Network (RPN)æ¥è¿›è¡ŒRegion Proposalï¼ŒåŒæ—¶å¯ä»¥è¾¾åˆ°å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾çš„ç›®æ ‡ï¼Œä½¿å¾—region proposalå‡ ä¹æ˜¯<strong>cost free</strong>çš„ã€‚</p>
<p>å…³äºFaster R-CNNçš„è¯¦ç»†ä»‹ç»ï¼Œå¯ä»¥å‚è€ƒæˆ‘<a href="http://jacobkong.github.io/posts/3802700508/">ä¸Šä¸€ç¯‡åšå®¢</a>ã€‚</p>
<p>Faster R-CNNçš„ä»£ç æ˜¯å¼€æºçš„ï¼Œæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š<a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external">MATLABç‰ˆæœ¬(<strong>faster_rcnn</strong>)</a>ï¼Œ<a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">Pythonç‰ˆæœ¬(<strong>py-faster-rcnn</strong>)</a>ã€‚</p>
<p>è¿™é‡Œæˆ‘ä¸»è¦ä½¿ç”¨çš„æ˜¯Pythonç‰ˆæœ¬ï¼ŒPythonç‰ˆæœ¬åœ¨æµ‹è¯•æœŸé—´ä¼šæ¯”MATLABç‰ˆæœ¬æ…¢10%ï¼Œå› ä¸ºPython layersä¸­çš„ä¸€äº›æ“ä½œæ˜¯åœ¨CPUä¸­æ‰§è¡Œçš„ï¼Œä½†æ˜¯å‡†ç¡®ç‡åº”è¯¥æ˜¯å·®ä¸å¤šçš„ã€‚</p>
<a id="more"></a>
<h2 id="å‡†å¤‡å·¥ä½œ1â€”â€”py-faster-rcnnçš„ç¼–è¯‘å®‰è£…æµ‹è¯•"><a href="#å‡†å¤‡å·¥ä½œ1â€”â€”py-faster-rcnnçš„ç¼–è¯‘å®‰è£…æµ‹è¯•" class="headerlink" title="å‡†å¤‡å·¥ä½œ1â€”â€”py-faster-rcnnçš„ç¼–è¯‘å®‰è£…æµ‹è¯•"></a>å‡†å¤‡å·¥ä½œ1â€”â€”py-faster-rcnnçš„ç¼–è¯‘å®‰è£…æµ‹è¯•</h2><h3 id="py-faster-rcnnçš„ç¼–è¯‘å®‰è£…"><a href="#py-faster-rcnnçš„ç¼–è¯‘å®‰è£…" class="headerlink" title="py-faster-rcnnçš„ç¼–è¯‘å®‰è£…"></a>py-faster-rcnnçš„ç¼–è¯‘å®‰è£…</h3><ol>
<li><p>å…‹éš†Faster R-CNNä»“åº“ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/rbgirshick/py-faster-rcnn.git</div></pre></td></tr></table></figure>
<p>ä¸€å®šè¦åŠ ä¸Š<code>--recursive</code>æ ‡å¿—ï¼Œå‡è®¾å…‹éš†åçš„æ–‡ä»¶å¤¹åå­—å«<code>py-faster-rcnn</code></p>
</li>
<li><p>ç¼–è¯‘Cythonæ¨¡å—ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn/lib</div><div class="line">make</div></pre></td></tr></table></figure>
</li>
<li><p>ç¼–è¯‘é‡Œé¢çš„Caffeå’Œpycaffeï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn/caffe-fast-rcnn</div><div class="line"><span class="comment"># æŒ‰ç…§ç¼–è¯‘Caffeçš„æ–¹æ³•ï¼Œè¿›è¡Œç¼–è¯‘</span></div><div class="line"><span class="comment"># æ³¨æ„Makefile.configçš„ä¿®æ”¹ï¼Œè¿™é‡Œä¸å†èµ˜è¿°Caffeçš„å®‰è£…</span></div><div class="line"><span class="comment"># ç¼–è¯‘</span></div><div class="line">make -j8 &amp;&amp; make pycaffe</div></pre></td></tr></table></figure>
</li>
<li><p>è¿™é‡Œè´´ä¸Šæˆ‘çš„<code>Makefile.config</code>æ–‡ä»¶ä»£ç ï¼Œæ ¹æ®ä½ çš„æƒ…å†µè¿›è¡Œç›¸åº”ä¿®æ”¹</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## Refer to http://caffe.berkeleyvision.org/installation.html</span></div><div class="line"><span class="comment"># Contributions simplifying and improving our build system are welcome!</span></div><div class="line"></div><div class="line"><span class="comment"># cuDNN acceleration switch (uncomment to build with cuDNN).</span></div><div class="line">USE_CUDNN := 1</div><div class="line"></div><div class="line"><span class="comment"># CPU-only switch (uncomment to build without GPU support).</span></div><div class="line"><span class="comment"># CPU_ONLY := 1</span></div><div class="line"></div><div class="line"><span class="comment"># uncomment to disable IO dependencies and corresponding data layers</span></div><div class="line"><span class="comment"># USE_OPENCV := 0</span></div><div class="line"><span class="comment"># USE_LEVELDB := 0</span></div><div class="line"><span class="comment"># USE_LMDB := 0</span></div><div class="line"></div><div class="line"><span class="comment"># uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)</span></div><div class="line"><span class="comment"># You should not set this flag if you will be reading LMDBs with any</span></div><div class="line"><span class="comment"># possibility of simultaneous read and write</span></div><div class="line"><span class="comment"># ALLOW_LMDB_NOLOCK := 1</span></div><div class="line"></div><div class="line"><span class="comment"># Uncomment if you're using OpenCV 3</span></div><div class="line">OPENCV_VERSION := 3</div><div class="line"></div><div class="line"><span class="comment"># To customize your choice of compiler, uncomment and set the following.</span></div><div class="line"><span class="comment"># N.B. the default for Linux is g++ and the default for OSX is clang++</span></div><div class="line"><span class="comment"># CUSTOM_CXX := g++</span></div><div class="line"></div><div class="line"><span class="comment"># CUDA directory contains bin/ and lib/ directories that we need.</span></div><div class="line">CUDA_DIR := /usr/<span class="built_in">local</span>/cuda</div><div class="line"><span class="comment"># On Ubuntu 14.04, if cuda tools are installed via</span></div><div class="line"><span class="comment"># "sudo apt-get install nvidia-cuda-toolkit" then use this instead:</span></div><div class="line"><span class="comment"># CUDA_DIR := /usr</span></div><div class="line"></div><div class="line"><span class="comment"># CUDA architecture setting: going with all of them.</span></div><div class="line"><span class="comment"># For CUDA &lt; 6.0, comment the *_50 lines for compatibility.</span></div><div class="line">CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \</div><div class="line">-gencode arch=compute_20,code=sm_21 \</div><div class="line">-gencode arch=compute_30,code=sm_30 \</div><div class="line">-gencode arch=compute_35,code=sm_35 \</div><div class="line">-gencode arch=compute_50,code=sm_50 \</div><div class="line">-gencode arch=compute_50,code=compute_50</div><div class="line"></div><div class="line"><span class="comment"># BLAS choice:</span></div><div class="line"><span class="comment"># atlas for ATLAS (default)</span></div><div class="line"><span class="comment"># mkl for MKL</span></div><div class="line"><span class="comment"># open for OpenBlas</span></div><div class="line">BLAS :=mkl</div><div class="line"><span class="comment"># Custom (MKL/ATLAS/OpenBLAS) include and lib directories.</span></div><div class="line"><span class="comment"># Leave commented to accept the defaults for your choice of BLAS</span></div><div class="line"><span class="comment"># (which should work)!</span></div><div class="line"><span class="comment"># BLAS_INCLUDE := /path/to/your/blas</span></div><div class="line"><span class="comment"># BLAS_LIB := /path/to/your/blas</span></div><div class="line"></div><div class="line"><span class="comment"># Homebrew puts openblas in a directory that is not on the standard search path</span></div><div class="line"><span class="comment"># BLAS_INCLUDE := $(shell brew --prefix openblas)/include</span></div><div class="line"><span class="comment"># BLAS_LIB := $(shell brew --prefix openblas)/lib</span></div><div class="line"></div><div class="line"><span class="comment"># This is required only if you will compile the matlab interface.</span></div><div class="line"><span class="comment"># MATLAB directory should contain the mex binary in /bin.</span></div><div class="line">MATLAB_DIR := /usr/<span class="built_in">local</span>/MATLAB/R2016b</div><div class="line"><span class="comment"># MATLAB_DIR := /Applications/MATLAB_R2012b.app</span></div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">NOTE:</span> this is required only if you will compile the python interface.</span></div><div class="line"><span class="comment"># We need to be able to find Python.h and numpy/arrayobject.h.</span></div><div class="line"><span class="comment"># PYTHON_INCLUDE := /usr/include/python2.7 \</span></div><div class="line">/usr/lib/python2.7/dist-packages/numpy/core/include</div><div class="line"><span class="comment"># Anaconda Python distribution is quite popular. Include path:</span></div><div class="line"><span class="comment"># Verify anaconda location, sometimes it's in root.</span></div><div class="line">ANACONDA_HOME := $(HOME)/anaconda</div><div class="line">PYTHON_INCLUDE := $(ANACONDA_HOME)/include \</div><div class="line">$(ANACONDA_HOME)/include/python2.7 \</div><div class="line">$(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \</div><div class="line">$ /usr/include/python2.7</div><div class="line"><span class="comment"># Uncomment to use Python 3 (default is Python 2)</span></div><div class="line"><span class="comment"># PYTHON_LIBRARIES := boost_python3 python3.5m</span></div><div class="line"><span class="comment"># PYTHON_INCLUDE := /usr/include/python3.5m \</span></div><div class="line"><span class="comment"># /usr/lib/python3.5/dist-packages/numpy/core/include</span></div><div class="line"></div><div class="line"><span class="comment"># We need to be able to find libpythonX.X.so or .dylib.</span></div><div class="line"><span class="comment"># PYTHON_LIB := /usr/lib</span></div><div class="line">PYTHON_LIB := $(ANACONDA_HOME)/lib</div><div class="line"></div><div class="line"><span class="comment"># Homebrew installs numpy in a non standard path (keg only)</span></div><div class="line"><span class="comment"># PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include</span></div><div class="line"><span class="comment"># PYTHON_LIB += $(shell brew --prefix numpy)/lib</span></div><div class="line"></div><div class="line"><span class="comment"># Uncomment to support layers written in Python (will link against Python libs)</span></div><div class="line">WITH_PYTHON_LAYER := 1</div><div class="line"></div><div class="line"><span class="comment"># Whatever else you find you need goes here.</span></div><div class="line"><span class="comment"># INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include</span></div><div class="line"><span class="comment"># LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib</span></div><div class="line">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class="built_in">local</span>/include /usr/include/hdf5/serial </div><div class="line">LIBRARY_DIRS := $(PYTHON_LIB) /usr/<span class="built_in">local</span>/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial</div><div class="line"></div><div class="line"><span class="comment"># If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies</span></div><div class="line"><span class="comment"># INCLUDE_DIRS += $(shell brew --prefix)/include</span></div><div class="line"><span class="comment"># LIBRARY_DIRS += $(shell brew --prefix)/lib</span></div><div class="line"></div><div class="line"><span class="comment"># Uncomment to use `pkg-config` to specify OpenCV library paths.</span></div><div class="line"><span class="comment"># (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)</span></div><div class="line"><span class="comment"># USE_PKG_CONFIG := 1</span></div><div class="line"></div><div class="line"><span class="comment"># N.B. both build and distribute dirs are cleared on `make clean`</span></div><div class="line">BUILD_DIR := build</div><div class="line">DISTRIBUTE_DIR := distribute</div><div class="line"></div><div class="line"><span class="comment"># Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171</span></div><div class="line"><span class="comment"># DEBUG := 1</span></div><div class="line"></div><div class="line"><span class="comment"># The ID of the GPU that 'make runtest' will use to run unit tests.</span></div><div class="line">TEST_GPUID := 0</div><div class="line"></div><div class="line"><span class="comment"># enable pretty build (comment to see full commands)</span></div><div class="line">Q ?= @</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Demoè¿è¡Œ"><a href="#Demoè¿è¡Œ" class="headerlink" title="Demoè¿è¡Œ"></a>Demoè¿è¡Œ</h3><p>ä¸ºäº†æ£€éªŒä½ çš„py-faster-rcnnæ˜¯å¦æˆåŠŸå®‰è£…ï¼Œä½œè€…ç»™å‡ºäº†ä¸€ä¸ªdemoï¼Œå¯ä»¥åˆ©ç”¨åœ¨PASCAL VOC2007æ•°æ®é›†ä¸Šä½“ç°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ¥è¿›è¡Œdemoçš„è¿è¡Œï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li><p>ä¸‹è½½é¢„è®­ç»ƒå¥½çš„Faster R-CNNæ£€æµ‹å™¨ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn</div><div class="line">./data/scripts/fetch_faster_rcnn_models.sh</div></pre></td></tr></table></figure>
<p>è¿™æ¡å‘½ä»¤ä¼šè‡ªåŠ¨ä¸‹è½½åä¸º<code>faster_rcnn_models.tgz</code>çš„æ–‡ä»¶ï¼Œè§£å‹åä¼šåˆ›å»º<code>data/faster_rcnn_models</code>æ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¼šæœ‰ä¸¤ä¸ªæ¨¡å‹ï¼š</p>
<ul>
<li>ZF_faster_rcnn_final.caffemodelï¼šåœ¨ZFç½‘ç»œæ¨¡å‹ä¸‹è®­ç»ƒæ‰€å¾—</li>
<li>VGG16_faster_rcnn_final.caffemodelï¼šåœ¨VGG16ç½‘ç»œæ¨¡å‹ä¸‹è®­ç»ƒæ‰€å¾—ã€‚</li>
</ul>
</li>
<li><p>è¿è¡Œdemoï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn</div><div class="line">./tools/demo.py</div></pre></td></tr></table></figure>
</li>
<li><p>demoä¼šæ£€æµ‹5å¼ å›¾ç‰‡ï¼Œè¿™5å¼ å›¾ç‰‡æ”¾åœ¨<code>data/demo/</code>æ–‡ä»¶å¤¹ä¸‹ï¼Œå…¶ä¸­ä¸€å¼ çš„æ£€æµ‹ç»“æœå¦‚ä¸‹ï¼š</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNbRwgy1fcthbwzgobj30gv0e0wh9.jpg" alt=""></p>
</li>
<li><p>è‡³æ­¤å¦‚æœä¸Šè¿°è¿‡ç¨‹æ²¡æœ‰å‡ºé”™ï¼Œé‚£ä¹ˆpy-faster-rcnnç®—æ˜¯æˆåŠŸç¼–è¯‘å®‰è£…ã€‚</p>
</li>
<li><p>è‹¥å‡ºç°æŠ¥é”™å¦‚ä¸‹ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ImportError: /xx/xx/xx/py-faster-rcnn/tools/../lib/nms/cpu_nms.so: undefined symbol: PyFPE_jbuf</div></pre></td></tr></table></figure>
<p>éœ€è¦å°†<code>lib/fast_rcnn/nms_wrapper.py</code>æ–‡ä»¶ä¸­çš„<code>from nms.cpu_nms import cpu_nms</code>æ³¨é‡Šæ‰å³å¯ã€‚</p>
</li>
</ol>
<h2 id="å‡†å¤‡å·¥ä½œ2â€”â€”Caltechæ•°æ®é›†"><a href="#å‡†å¤‡å·¥ä½œ2â€”â€”Caltechæ•°æ®é›†" class="headerlink" title="å‡†å¤‡å·¥ä½œ2â€”â€”Caltechæ•°æ®é›†"></a>å‡†å¤‡å·¥ä½œ2â€”â€”Caltechæ•°æ®é›†</h2><p>ç”±äºFaster R-CNNçš„ä¸€éƒ¨åˆ†å®éªŒæ˜¯åœ¨PASCAL VOC2007æ•°æ®é›†ä¸Šè¿›è¡Œçš„ï¼Œæ‰€ä»¥è¦æƒ³ç”¨Faster R-CNNè®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ•°æ®é›†ï¼Œé¦–å…ˆåº”è¯¥ææ¸…æ¥šPASCAL VOC2007æ•°æ®é›†ä¸­çš„ç›®å½•ã€å›¾ç‰‡ã€æ ‡æ³¨æ ¼å¼ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½ç”¨è‡ªå·±çš„æ•°æ®é›†åˆ¶ä½œå‡ºç±»ä¼¼äºPASCAL VOC2007ç±»ä¼¼çš„æ•°æ®é›†ï¼Œä¾›Faster R-CNNæ¥è¿›è¡Œè®­ç»ƒåŠæµ‹è¯•ã€‚</p>
<h3 id="è·å–PASCAL-VOC2007æ•°æ®é›†"><a href="#è·å–PASCAL-VOC2007æ•°æ®é›†" class="headerlink" title="è·å–PASCAL VOC2007æ•°æ®é›†"></a>è·å–PASCAL VOC2007æ•°æ®é›†</h3><p>è¿™ä¸€éƒ¨åˆ†ä¸æ˜¯å¿…é¡»çš„ï¼Œå¦‚æœä½ éœ€è¦PASCAL VOC2007æ•°æ®é›†ï¼Œå¯ä»¥åˆ©ç”¨ä»¥ä¸‹å‘½ä»¤è·å–æ•°æ®é›†ï¼Œä½†<strong>æˆ‘ä»¬ä¸‹è½½VOCæ•°æ®é›†çš„ç›®çš„ä¸»è¦æ˜¯è§‚å¯Ÿä»–çš„æ–‡ä»¶ç»“æ„å’Œæ–‡ä»¶å†…å®¹ï¼Œä»¥ä¾¿äºæˆ‘ä»¬æ„å»ºç¬¦åˆè¦æ±‚çš„è‡ªå·±çš„æ•°æ®é›†ã€‚</strong></p>
<ol>
<li><p>åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨æ¥å­˜æ•°æ®é›†çš„åœ°æ–¹ï¼Œå‡è®¾æ˜¯<code>$HOME/data</code>æ–‡ä»¶å¤¹ã€‚</p>
</li>
<li><p>ä¸‹è½½PASCAL VOC2007çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> <span class="variable">$HOME</span>/data</div><div class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar</div><div class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar</div></pre></td></tr></table></figure>
</li>
<li><p>ä¸‹è½½å®Œåç”¨ä»¥ä¸‹å‘½ä»¤è§£å‹ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar xvf VOCtrainval_06-Nov-2007.tar</div><div class="line">tar xvf VOCtest_06-Nov-2007.tar</div></pre></td></tr></table></figure>
</li>
<li><p>ä¼šå¾—åˆ°å¦‚ä¸‹æ–‡ä»¶ç»“æ„ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$HOME</span>/data/VOCdevkit/                        <span class="comment"># æ ¹æ–‡ä»¶å¤¹</span></div><div class="line"><span class="variable">$HOME</span>/data/VOCdevkit/VOC2007                 <span class="comment"># VOC2007æ–‡ä»¶å¤¹</span></div><div class="line"><span class="variable">$HOME</span>/data/VOCdevkit/VOC2007/Annotations     <span class="comment"># æ ‡è®°æ–‡ä»¶å¤¹</span></div><div class="line"><span class="variable">$HOME</span>/data/VOCdevkit/VOC2007/ImageSets       <span class="comment"># ä¾›train.txtã€test.txtã€val.txtç­‰æ–‡ä»¶å­˜æ”¾çš„æ–‡ä»¶å¤¹</span></div><div class="line"><span class="variable">$HOME</span>/data/VOCdevkit/VOC2007/JPEGImages      <span class="comment"># å­˜æ”¾å›¾ç‰‡æ–‡ä»¶å¤¹</span></div><div class="line"><span class="comment"># ... ä»¥åŠå…¶ä»–çš„æ–‡ä»¶å¤¹åŠå­æ–‡ä»¶å¤¹ ...</span></div></pre></td></tr></table></figure>
</li>
<li><p>åˆ›å»ºå¿«æ·æ–¹å¼symlinksæ¥è¿æ¥åˆ°VOCæ•°æ®é›†å­˜æ”¾çš„åœ°æ–¹ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> py-faster-rcnn/data</div><div class="line">ln <span class="_">-s</span> <span class="variable">$HOME</span>/data/VOCdevkit/ VOCdevkit</div></pre></td></tr></table></figure>
<p>è¿™é‡Œéœ€è¦æŠŠ<code>$HOME/data/VOCdevkit/</code>æ”¹ä¸ºä½ å­˜æ”¾<code>VOCdevkit</code>æ–‡ä»¶å¤¹çš„è·¯å¾„</p>
<p><strong>æœ€å¥½ä½¿ç”¨symlinksæ¥åœ¨å…±äº«åŒä¸€ä»½æ•°æ®é›†ï¼Œé˜²æ­¢æ•°æ®é›†å¤šå¤„æ‹·è´ï¼Œå ç”¨ç©ºé—´ã€‚</strong></p>
</li>
<li><p>è‡³æ­¤VOCæ•°æ®é›†åˆ›å»ºå®Œæ¯•ã€‚</p>
</li>
</ol>
<h3 id="PASCAL-VOCæ•°æ®é›†çš„åˆ†æ"><a href="#PASCAL-VOCæ•°æ®é›†çš„åˆ†æ" class="headerlink" title="PASCAL VOCæ•°æ®é›†çš„åˆ†æ"></a>PASCAL VOCæ•°æ®é›†çš„åˆ†æ</h3><p>PASCAL VOCæ•°æ®é›†çš„æ–‡ä»¶ç»“æ„ï¼Œå¦‚ä¸‹ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">â””â”€â”€ VOCdevkit</div><div class="line">    â””â”€â”€ VOC2007ã€€</div><div class="line">        â”œâ”€â”€ Annotationsã€€ã€€</div><div class="line">        â”œâ”€â”€ ImageSetsã€€ã€€</div><div class="line">        â”‚   â”œâ”€â”€ Layoutã€€ã€€</div><div class="line">        â”‚   â”œâ”€â”€ Mainã€€ã€€</div><div class="line">        â”‚   â””â”€â”€ Segmentationã€€ã€€</div><div class="line">        â”œâ”€â”€ JPEGImagesã€€ã€€</div><div class="line">        â”œâ”€â”€ SegmentationClassã€€ã€€</div><div class="line">        â””â”€â”€ SegmentationObject</div></pre></td></tr></table></figure>
<h4 id="Annotations"><a href="#Annotations" class="headerlink" title="Annotations"></a>Annotations</h4><p>è¯¥æ–‡ä»¶å¤¹ä¸»è¦ç”¨æ¥å­˜æ”¾å›¾ç‰‡æ ‡æ³¨ï¼ˆå³ä¸ºground truthï¼‰ï¼Œæ–‡ä»¶æ˜¯.xmlæ ¼å¼ï¼Œæ¯å¼ å›¾ç‰‡éƒ½æœ‰ä¸€ä¸ª.xmlæ–‡ä»¶ä¸ä¹‹å¯¹åº”ã€‚é€‰å–å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œå¦‚ä¸‹åˆ†æï¼š</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">folder</span>&gt;</span>VOC2007<span class="tag">&lt;/<span class="name">folder</span>&gt;</span> # å¿…é¡»æœ‰ï¼Œçˆ¶æ–‡ä»¶å¤¹çš„åç§°</div><div class="line">	<span class="tag">&lt;<span class="name">filename</span>&gt;</span>000005.jpg<span class="tag">&lt;/<span class="name">filename</span>&gt;</span>ã€€#ã€€å¿…é¡»æœ‰</div><div class="line">	<span class="tag">&lt;<span class="name">source</span>&gt;</span>ã€€# å¯æœ‰å¯æ— </div><div class="line">		<span class="tag">&lt;<span class="name">database</span>&gt;</span>The VOC2007 Database<span class="tag">&lt;/<span class="name">database</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">annotation</span>&gt;</span>PASCAL VOC2007<span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">image</span>&gt;</span>flickr<span class="tag">&lt;/<span class="name">image</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">flickrid</span>&gt;</span>325991873<span class="tag">&lt;/<span class="name">flickrid</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">source</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">owner</span>&gt;</span>ã€€# å¯æœ‰å¯æ— </div><div class="line">		<span class="tag">&lt;<span class="name">flickrid</span>&gt;</span>archintent louisville<span class="tag">&lt;/<span class="name">flickrid</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>?<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">owner</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">size</span>&gt;</span>ã€€# è¡¨ç¤ºå›¾åƒå¤§å°</div><div class="line">		<span class="tag">&lt;<span class="name">width</span>&gt;</span>500<span class="tag">&lt;/<span class="name">width</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">height</span>&gt;</span>375<span class="tag">&lt;/<span class="name">height</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">size</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">segmented</span>&gt;</span>0<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span>ã€€# ç”¨äºåˆ†å‰²</div><div class="line">	<span class="tag">&lt;<span class="name">object</span>&gt;</span>ã€€# ç›®æ ‡ä¿¡æ¯ï¼Œç±»åˆ«ï¼Œbboxä¿¡æ¯ï¼Œå›¾ç‰‡ä¸­æ¯ä¸ªç›®æ ‡å¯¹åº”ä¸€ä¸ª<span class="tag">&lt;<span class="name">object</span>&gt;</span>æ ‡ç­¾</div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>chair<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">pose</span>&gt;</span>Rear<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">truncated</span>&gt;</span>0<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">xmin</span>&gt;</span>263<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">ymin</span>&gt;</span>211<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">xmax</span>&gt;</span>324<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">ymax</span>&gt;</span>339<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">object</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">object</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>chair<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">pose</span>&gt;</span>Unspecified<span class="tag">&lt;/<span class="name">pose</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">truncated</span>&gt;</span>1<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">difficult</span>&gt;</span>1<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">bndbox</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">xmin</span>&gt;</span>5<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">ymin</span>&gt;</span>244<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">xmax</span>&gt;</span>67<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></div><div class="line">			<span class="tag">&lt;<span class="name">ymax</span>&gt;</span>374<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></div><div class="line">		<span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">object</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></div></pre></td></tr></table></figure>
<p><strong>éœ€è¦æ³¨æ„çš„</strong>ï¼Œå¯¹äºæˆ‘ä»¬è‡ªå·±å‡†å¤‡çš„xmlæ ‡è®°æ–‡ä»¶ä¸­ï¼Œæ¯ä¸ª<code>&lt;object&gt;</code>æ ‡ç­¾ä¸­çš„<code>&lt;xmin&gt;</code>å’Œ<code>&lt;ymin&gt;</code>æ ‡ç­¾ä¸­æ‰€å¯¹åº”çš„åæ ‡å€¼æœ€å¥½å¤§äº0ï¼Œåƒä¸‡ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œå¦åˆ™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæŠ¥é”™ï¼š<code>AssertionError: assert (boxes[:, 2]) &gt;= boxes[:, 0]).all()</code>ï¼Œå¦‚ä¸‹ï¼š</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNbRwly1fctnwv48gzj30h701waa0.jpg" alt=""></p>
<p>æ‰€ä»¥ä¸ºäº†èƒ½å¤Ÿé¡ºåˆ©è®­ç»ƒï¼Œä¸€å®šè¦ä»”ç»†æ£€æŸ¥è‡ªå·±çš„xmlæ–‡ä»¶ä¸­çš„å·¦ä¸Šè§’çš„åæ ‡æ˜¯å¦éƒ½ä¸ºæ­£ã€‚æˆ‘è¢«è¿™ä¸ªbugå¡äº†ä¸€ä¸¤å¤©ï¼Œæœ€ç»ˆæŠŠè‡ªå·±æ ‡è®°ä¸­æ‰€æœ‰çš„é”™è¯¯åæ ‡æ‰¾å‡ºæ¥ï¼Œæ‰å¾—ä»¥é¡ºåˆ©è®­ç»ƒã€‚</p>
<h4 id="ImageSets"><a href="#ImageSets" class="headerlink" title="ImageSets"></a>ImageSets</h4><p>ImageSetsæ–‡ä»¶å¤¹ä¸‹æœ‰ä¸‰ä¸ªå­æ–‡ä»¶å¤¹ï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€å…³æ³¨Mainæ–‡ä»¶å¤¹å³å¯ã€‚Mainæ–‡ä»¶å¤¹ä¸‹ä¸»è¦ç”¨åˆ°çš„æ˜¯train.txtã€val.txtã€test.txtã€trainval.txtæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä¸­å†™ç€ä¾›è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ‰€ç”¨çš„æ–‡ä»¶åçš„é›†åˆï¼Œå¦‚ä¸‹ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNbRwly1fctobmg8rkj302f03vjrc.jpg" alt=""></p>
<h4 id="JPEGImages"><a href="#JPEGImages" class="headerlink" title="JPEGImages"></a>JPEGImages</h4><p>JPEGImagesæ–‡ä»¶å¤¹ä¸‹ä¸»è¦å­˜æ”¾ç€æ‰€æœ‰çš„.jpgæ–‡ä»¶æ ¼å¼çš„è¾“å…¥å›¾ç‰‡ï¼Œä¸åœ¨èµ˜è¿°ã€‚</p>
<h3 id="åˆ¶ä½œVOCç±»ä¼¼çš„Caltechæ•°æ®é›†"><a href="#åˆ¶ä½œVOCç±»ä¼¼çš„Caltechæ•°æ®é›†" class="headerlink" title="åˆ¶ä½œVOCç±»ä¼¼çš„Caltechæ•°æ®é›†"></a>åˆ¶ä½œVOCç±»ä¼¼çš„Caltechæ•°æ®é›†</h3><p>ç»è¿‡ä»¥ä¸Šå¯¹PASCAL VOCæ•°æ®é›†æ–‡ä»¶ç»“æ„çš„åˆ†æï¼Œæˆ‘ä»¬ä»¿ç…§å…¶ï¼Œåˆ›å»ºé¦–å…ˆåˆ›å»ºç±»ä¼¼çš„æ–‡ä»¶ç»“æ„å³å¯ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">â””â”€â”€ VOCdevkit</div><div class="line">    â””â”€â”€ VOC2007ã€€</div><div class="line">    â””â”€â”€ Caltechã€€</div><div class="line">        â”œâ”€â”€ Annotationsã€€ã€€</div><div class="line">        â”œâ”€â”€ ImageSetsã€€ã€€ã€€</div><div class="line">        â”‚   â””â”€â”€ Mainã€€ã€€</div><div class="line">        â””â”€â”€ JPEGImages</div></pre></td></tr></table></figure>
<p>æˆ‘å»ºè®®å°†Caltechæ–‡ä»¶åˆ›å»ºä¸€ä¸ªsymlinksé“¾æ¥åˆ°VOCdevkitæ–‡ä»¶å¤¹ä¹‹ä¸‹ï¼Œå› ä¸ºè¿™æ ·ä¼šæ–¹ä¾¿ä¹‹åè®­ç»ƒä»£ç çš„ä¿®æ”¹ã€‚</p>
<ul>
<li>è‡³äº<a href="https://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" target="_blank" rel="external">Caltechæ•°æ®é›†</a>å¦‚ä½•ä».seqæ–‡ä»¶è½¬åŒ–ä¸ºä¸€å¼ å¼ .jpgå›¾ç‰‡ï¼Œè¿™é‡Œå¯ä»¥<a href="https://github.com/mitmul/caltech-pedestrian-dataset-converter" target="_blank" rel="external">å‚è€ƒè¿™é‡Œ</a>ã€‚</li>
<li>è‡³äºAnnotationsä¸­ä¸€ä¸ªä¸ª.xmlæ ‡è®°æ–‡ä»¶æ˜¯å®éªŒå®¤å¸ˆå…„ç»™æˆ‘çš„ï¼Œ<a href="https://github.com/mitmul/caltech-pedestrian-dataset-converter" target="_blank" rel="external">ä¸Šé¢æåˆ°çš„æ–¹æ³•</a>ä¹Ÿå¯ä»¥è½¬åŒ–ï¼Œä½†æ˜¯å¹¶ä¸ç¬¦åˆè¦æ±‚ã€‚</li>
<li>è‡³äºImageSetsä¸­çš„train.txtæ˜¯æ ¹æ®.xmlæ–‡ä»¶å¾—æ¥çš„ï¼Œtest.txtæ˜¯æ¯ä¸ªseqä¸­æ¯éš”30å¸§å–ä¸€å¸§å›¾ç‰‡å¾—æ¥çš„ã€‚</li>
</ul>
<p>ä»¥ä¸Šæ‰€æœ‰å’Œ<a href="https://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/" target="_blank" rel="external">Caltechæ•°æ®é›†</a>æœ‰å…³çš„æ–‡ä»¶ï¼Œéƒ½å¯ä»¥ç›´æ¥é‚®ä»¶ä¸æˆ‘è”ç³»ï¼Œæˆ‘ç›´æ¥å‘ç»™ä½ ï¼Œå¯ä»¥çœä¸‹ä¸å°‘åˆ¶ä½œæ•°æ®é›†çš„æ—¶é—´ã€‚</p>
<h2 id="å‚è€ƒåšå®¢"><a href="#å‚è€ƒåšå®¢" class="headerlink" title="å‚è€ƒåšå®¢"></a>å‚è€ƒåšå®¢</h2><ol>
<li><a href="http://www.cnblogs.com/louyihang-loves-baiyan/p/4885659.html?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="external"><strong>FastRCNN è®­ç»ƒè‡ªå·±æ•°æ®é›† (1ç¼–è¯‘é…ç½®)</strong></a></li>
<li><a href="https://saicoco.github.io/object-detection-4/" target="_blank" rel="external"><strong>ç›®æ ‡æ£€æµ‹â€”Faster RCNN2</strong></a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;å‰è¨€&quot;&gt;&lt;a href=&quot;#å‰è¨€&quot; class=&quot;headerlink&quot; title=&quot;å‰è¨€&quot;&gt;&lt;/a&gt;å‰è¨€&lt;/h2&gt;&lt;p&gt;Faster R-CNNæ˜¯Ross Girshickå¤§ç¥åœ¨Fast R-CNNåŸºç¡€ä¸Šæå‡ºçš„åˆä¸€ä¸ªæ›´åŠ å¿«é€Ÿã€æ›´é«˜mAPçš„ç”¨äºç›®æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå¯¹Fast R-CNNè¿›è¡Œçš„æœ€ä¸»è¦çš„ä¼˜åŒ–å°±æ˜¯åœ¨Region Proposalé˜¶æ®µï¼Œå¼•å…¥äº†Region Proposal Network (RPN)æ¥è¿›è¡ŒRegion Proposalï¼ŒåŒæ—¶å¯ä»¥è¾¾åˆ°å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾çš„ç›®æ ‡ï¼Œä½¿å¾—region proposalå‡ ä¹æ˜¯&lt;strong&gt;cost free&lt;/strong&gt;çš„ã€‚&lt;/p&gt;
&lt;p&gt;å…³äºFaster R-CNNçš„è¯¦ç»†ä»‹ç»ï¼Œå¯ä»¥å‚è€ƒæˆ‘&lt;a href=&quot;http://jacobkong.github.io/posts/3802700508/&quot;&gt;ä¸Šä¸€ç¯‡åšå®¢&lt;/a&gt;ã€‚&lt;/p&gt;
&lt;p&gt;Faster R-CNNçš„ä»£ç æ˜¯å¼€æºçš„ï¼Œæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼š&lt;a href=&quot;https://github.com/ShaoqingRen/faster_rcnn&quot;&gt;MATLABç‰ˆæœ¬(&lt;strong&gt;faster_rcnn&lt;/strong&gt;)&lt;/a&gt;ï¼Œ&lt;a href=&quot;https://github.com/rbgirshick/py-faster-rcnn&quot;&gt;Pythonç‰ˆæœ¬(&lt;strong&gt;py-faster-rcnn&lt;/strong&gt;)&lt;/a&gt;ã€‚&lt;/p&gt;
&lt;p&gt;è¿™é‡Œæˆ‘ä¸»è¦ä½¿ç”¨çš„æ˜¯Pythonç‰ˆæœ¬ï¼ŒPythonç‰ˆæœ¬åœ¨æµ‹è¯•æœŸé—´ä¼šæ¯”MATLABç‰ˆæœ¬æ…¢10%ï¼Œå› ä¸ºPython layersä¸­çš„ä¸€äº›æ“ä½œæ˜¯åœ¨CPUä¸­æ‰§è¡Œçš„ï¼Œä½†æ˜¯å‡†ç¡®ç‡åº”è¯¥æ˜¯å·®ä¸å¤šçš„ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="ç»éªŒ" scheme="http://jacobkong.github.io/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šFaster R-CNN</title>
    <link href="http://jacobkong.github.io/posts/3802700508/"/>
    <id>http://jacobkong.github.io/posts/3802700508/</id>
    <published>2016-12-16T22:32:24.000Z</published>
    <updated>2017-03-09T06:32:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Region Proposalçš„è®¡ç®—</strong>æ˜¯åŸºäºRegion Proposalç®—æ³•æ¥å‡è®¾ç‰©ä½“ä½ç½®çš„ç‰©ä½“æ£€æµ‹ç½‘ç»œæ¯”å¦‚ï¼š<strong>SPPnet, Fast R-CNN</strong>è¿è¡Œæ—¶é—´çš„ç“¶é¢ˆã€‚</li>
<li>Faster R-CNNå¼•å…¥äº†<strong>Region Proposal Networkï¼ˆRPNï¼‰</strong>æ¥å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾ï¼Œå› æ­¤ä½¿å¾—region proposalå‡ ä¹æ˜¯<strong>cost free</strong>çš„ã€‚</li>
<li>RPN-&gt;é¢„æµ‹ç‰©ä½“è¾¹ç•Œï¼ˆobject boundsï¼‰å’Œåœ¨æ¯ä¸€ä½ç½®çš„åˆ†æ•°ï¼ˆobjectness scoreï¼‰</li>
<li>é€šè¿‡åœ¨ä¸€ä¸ªç½‘ç»œä¸­å…±äº«RPNå’ŒFast R-CNNçš„å·ç§¯ç‰¹å¾æ¥èåˆä¸¤è€…â€”â€”<strong>ä½¿ç”¨â€œattentionâ€æœºåˆ¶ã€‚</strong></li>
<li>300 proposals pre image.</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>RPæ˜¯å½“å‰è®¸å¤šå…ˆè¿›æ£€æµ‹ç³»ç»Ÿçš„ç“¶é¢ˆã€‚</li>
<li>Region proposal methods:<ul>
<li>Selective Search: one of the most popular method </li>
<li>EdgeBoxes: trade off between proposal quality and speed.</li>
<li>region proposalè¿™ä¸€æ­¥ä¾æ—§å’Œæ£€æµ‹ç½‘ç»œèŠ±è´¹åŒæ ·å¤šçš„æ—¶é—´ã€‚</li>
</ul>
</li>
<li>Fast R-CNNç”Ÿæˆçš„feature map ä¹Ÿèƒ½ç”¨æ¥ç”ŸæˆRPã€‚åœ¨è¿™äº›å·ç§¯ç‰¹å¾ä¹‹ä¸Šæˆ‘ä»¬é€šè¿‡è¿™æ ·çš„æ–¹å¼æ„å»ºRPNï¼šé€šè¿‡æ·»åŠ å‡ ä¸ªé¢å¤–çš„å·ç§¯å±‚æ¥æ¨¡æ‹Ÿä¸€ä¸ªregular gridä¸Šæ¯ä¸€ä¸ªä½ç½®çš„regress region boundså’Œobjectness scoresã€‚<strong>æ‰€ä»¥RPNä¹Ÿæ˜¯ä¸€ç§fully convolutional network(FCN)</strong>ï¼Œä»è€Œå¯ä»¥ç«¯åˆ°ç«¯è®­ç»ƒæ¥äº§ç”Ÿdetection proposalsã€‚</li>
<li><strong>anchor boxes</strong>ï¼šreferences at multiple scales and aspect ratios. æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥çœ‹æˆpyramid of regression referenceï¼Œä»è€Œé¿å…æšä¸¾å¤šå°ºå¯¸ã€å¤šæ¨ªçºµæ¯”çš„imagesæˆ–è€…filters</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>R-CNNä¸»è¦æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œä»–ä¸èƒ½é¢„æµ‹object boundsï¼Œä»–çš„å‡†ç¡®æ€§ä¾èµ–äºRegion proposalæ¨¡å—çš„è¡¨ç°</li>
</ul>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><ul>
<li>ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼š<ul>
<li>ç¬¬ä¸€ä¸ªæ¨¡å—ï¼šA deep fuuly convolutional network that proposes regionsï¼Œ<strong>ç”¨æ¥proposes regions</strong>.</li>
<li>ç¬¬äºŒä¸ªæ¨¡å—ï¼šFast R-CNNæ£€æµ‹å™¨ï¼Œä½¿ç”¨ç¬¬ä¸€æ¨¡å—æå‡ºçš„regionsã€‚</li>
</ul>
</li>
<li><strong>Attention mechanisms</strong>ï¼šRPN moduleå‘Šè¯‰Fast R-CNN module å¾€å“ªé‡Œçœ‹ï¼ˆwhere to lookï¼‰</li>
</ul>
<h3 id="Region-Proposal-Networks"><a href="#Region-Proposal-Networks" class="headerlink" title="Region Proposal Networks"></a>Region Proposal Networks</h3><ul>
<li><p>è¾“å…¥ï¼šä¸€å¼ <strong>ä»»æ„å°ºå¯¸</strong>çš„å›¾ç‰‡ã€‚</p>
</li>
<li><p>è¾“å‡ºï¼šä¸€ç»„çŸ©å½¢object proposalï¼Œæ¯ä¸ªproposaléƒ½æœ‰ä¸€ä¸ªscoreã€‚</p>
</li>
<li><p>æ˜¯ä¸€ä¸ªfully convolutional networkï¼ˆ<strong>FCN</strong>ï¼‰ï¼Œç”±äºæˆ‘ä»¬éœ€è¦åœ¨RPNå’ŒFast RCNNä¹‹é—´å…±äº«æƒå€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å‡è®¾ä¸¤ä¸ªç½‘ç»œ<strong>å…±äº«ä¸€ç»„å…±åŒçš„å·ç§¯å±‚</strong>ã€‚</p>
</li>
<li><p>ä¸ºäº†ç”Ÿæˆregion proposalsï¼Œæˆ‘ä»¬åœ¨<strong>æœ€åä¸€å±‚å…±äº«å·ç§¯å±‚</strong>è¾“å‡ºçš„feature mapä¸Šæ»‘åŠ¨ä¸€ä¸ªå¾®å‹ç½‘ç»œã€‚è¿™ä¸ªå¾®å‹ç½‘ç»œå°†è¾“å…¥çš„feature mapä¸Šçš„nxnçš„ç©ºé—´çª—å£ä½œä¸ºè¾“å…¥ã€‚æ¯ä¸€ä¸ªæ»‘åŠ¨çª—å£è¢«æ˜ å°„ä¸ºä¸€ä¸ªä½ç»´ç‰¹å¾(ZF: 256-d, VGG: 512-d, ä¹‹åè·Ÿç€ReLUå±‚)ã€‚è¿™äº›ç‰¹å¾ç„¶åè¢«é€åˆ°ä¸¤ä¸ªsiblingå…¨è¿æ¥å±‚ä¸­â€”â€”<strong>ä¸€ä¸ªbox-regression(reg)å±‚</strong>å’Œ<strong>ä¸€ä¸ªbox-classification(cls)å±‚ã€‚</strong></p>
</li>
<li><p>æ³¨æ„ï¼šå› ä¸ºå¾®å‹ç½‘ç»œä»¥æ»‘åŠ¨çª—å£æ–¹å¼æ“ä½œï¼Œ<strong>æ‰€ä»¥å®Œå…¨è¿æ¥å±‚åœ¨æ‰€æœ‰ç©ºé—´ä½ç½®ä¸Šå…±äº«ã€‚</strong> è¿™ç§ç»“æ„è‡ªç„¶åœ°é€šè¿‡ä¸€ä¸ªnÃ—nå·ç§¯å±‚ï¼Œåé¢æ˜¯ä¸¤ä¸ªåŒçº§<strong>1Ã—1</strong>å·ç§¯å±‚ï¼ˆåˆ†åˆ«ç”¨äºrpn_regå’Œrpn_clsï¼‰æ¥å®ç°ã€‚</p>
</li>
<li><p>ç”Ÿæˆregion proposalçš„æ€è·¯ï¼š<br><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fcb3fr2k40j30cq07tt9a.jpg" alt=""></p>
</li>
<li><p>rpnç½‘ç»œç»“æ„å®šä¹‰å¦‚ä¸‹ï¼š</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdgik44luaj30pf0di40j.jpg" alt=""></p>
<p>â€‹</p>
<p>â€‹</p>
</li>
</ul>
<h4 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h4><ul>
<li>å‡è®¾æ¯ä¸ªä½ç½®æœ€å¤§å¯èƒ½çš„proposalçš„æ•°é‡ä¸ºkï¼Œåœ¨æ¯ä¸ªsliding-windowä½ç½®ï¼ŒåŒæ—¶é¢„æµ‹å‡ ä¸ªRPï¼š<ul>
<li><em>reg layer</em>ï¼šæœ‰4kä¸ªè¾“å‡º</li>
<li><em>cls layer</em>ï¼šæœ‰2kä¸ªè¾“å‡ºï¼ŒæŒ‡å‡ºè¯¥æ¯ä¸€ä¸ªproposalæ˜¯å¦æ˜¯objectï¼Œ<strong>estimate probability of object or not object for each proposal</strong>ã€‚</li>
</ul>
</li>
<li>kä¸ªproposalç›¸å¯¹äºkä¸ªå‚è€ƒæ¡†ï¼ˆreference boxesï¼‰è€Œå‚æ•°åŒ–ï¼Œæˆ‘ä»¬å°†å‚è€ƒæ¡†ç§°ä¸º<strong>anchor</strong>ã€‚</li>
<li>ä¸€ä¸ªanchorä½äºsliding windowçš„ä¸­é—´ï¼ŒåŒæ—¶å…³è”ç€ä¸€ä¸ªscaleå’Œaspect rationã€‚</li>
</ul>
<h5 id="Translation-Invariant-Anchors-å¹³ç§»ä¸å˜æ€§"><a href="#Translation-Invariant-Anchors-å¹³ç§»ä¸å˜æ€§" class="headerlink" title="Translation-Invariant Anchors(å¹³ç§»ä¸å˜æ€§)"></a>Translation-Invariant Anchors(å¹³ç§»ä¸å˜æ€§)</h5><ul>
<li>å¦‚æœç§»åŠ¨äº†ä¸€å¼ å›¾åƒä¸­çš„ä¸€ä¸ªç‰©ä½“ï¼Œè¿™proposalåº”è¯¥ä¹Ÿç§»åŠ¨äº†ï¼Œè€Œä¸”ç›¸åŒçš„å‡½æ•°å¯ä»¥é¢„æµ‹å‡ºçƒ­è®®æœªçŸ¥çš„proposalã€‚MultiBoxä¸å…·å¤‡å¦‚æ­¤åŠŸèƒ½</li>
<li>å¹³ç§»ä¸å˜æ€§å¯ä»¥å‡å°‘æ¨¡å‹å¤§å°ã€‚</li>
</ul>
<h5 id="Multi-Scale-Anchor-as-Regression-References"><a href="#Multi-Scale-Anchor-as-Regression-References" class="headerlink" title="Multi-Scale Anchor as Regression References"></a>Multi-Scale Anchor as Regression References</h5><ul>
<li>Two popular ways for multi-scale predictions:<ul>
<li>ç¬¬ä¸€ç§ï¼šbased on image/feature pyramids, å¦‚ï¼šDPM and CNN-based methodsã€‚å›¾åƒè¢«resizedæˆä¸åŒå°ºå¯¸ï¼Œç„¶åä¸ºæ¯ä¸€ç§å°ºå¯¸è®¡ç®—feature maps(HOGæˆ–è€…deep convolutional features)ã€‚è¿™ç§æ–¹æ³•æ¯”è¾ƒ<strong>è´¹æ—¶</strong>ã€‚</li>
<li>ç¬¬äºŒç§ï¼šuse sliding windows of multiple scales (and/or aspect ratios) on the feature maps.â€”â€”<strong>filtersé‡‘å­—å¡”</strong>ã€‚ç¬¬äºŒç§æ–¹æ³•ç»å¸¸å’Œç¬¬ä¸€ç§æ–¹æ³•è”åˆä½¿ç”¨</li>
</ul>
</li>
<li>æœ¬è®ºæ–‡çš„æ–¹æ³•ï¼š<strong>anchoré‡‘å­—å¡”</strong>â€”â€”more cost-efficientï¼Œåªä¾é å•å°ºå¯¸çš„å›¾åƒå’Œfeature mapã€‚</li>
<li>The design of multiscale anchors is a <strong>key </strong>component for <strong>sharing features</strong> without extra cost for addressing scales.</li>
</ul>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><ul>
<li><p>ä¸ºäº†è®­ç»ƒRPNï¼Œæˆ‘ä»¬ç»™æ¯ä¸ªanchorè®¾ç½®äº†ä¸€ä¸ªäºŒå…ƒæ ‡ç­¾ï¼ˆæ˜¯ç‰©ä½“æˆ–è€…ä¸æ˜¯ç‰©ä½“ï¼‰</p>
</li>
<li><p>ä¸¤ç±»anchoræ˜¯æœ‰<strong>æ­£æ ‡ç­¾</strong>ï¼ˆis objectï¼‰çš„ï¼š</p>
<ul>
<li>anchor/anchors with highest IoU overlap with a ground-truth boxã€‚</li>
<li>an anchor that has IoU overlap higher than 0.7 with any ground-truth box.</li>
<li>ç¬¬äºŒç§æ–¹æ³•æ›´å¥½æ£€æµ‹æ­£æ ·æœ¬ï¼Œåœ¨ç¬¬äºŒç§æƒ…å†µä¸‹å¦‚æœæ‰¾ä¸åˆ°æ­£æ ·æœ¬ï¼Œé‚£ä¹ˆä½¿ç”¨ç¬¬ä¸€ç§ã€‚</li>
</ul>
</li>
<li><p>å¦‚æœä¸€ä¸ªanchorå’Œä»»ä½•ground-truth boxesçš„IoUå€¼å°äº0.3ï¼Œé‚£ä¹ˆè¯¥anchorä¸º<strong>è´Ÿæ ‡ç­¾</strong></p>
</li>
<li><p>éæ­£éè´Ÿæ ·æœ¬å¯¹training objectiveæ²¡æœ‰ç”¨ã€‚</p>
</li>
<li><p>Loss Functionï¼š</p>
<p>â€‹</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcjw1fcbwo1ut3hj309q02hjrj.jpg" alt=""></p>
<p>$N<em>{cls}=256,N</em>{reg}=256*9=2304,\lambda=10$ï¼Œè¿™æ ·ä¸¤ä¸ªlosså°±å¯ä»¥æƒé‡åŸºæœ¬ç›¸å½“äº†ã€‚</p>
</li>
<li><p>Bounding box regression</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcjw1fcbyiywha8j308k0300sy.jpg" alt=""></p>
<p>è¿™ä¸ªå¯ä»¥è€ƒè™‘ä¸ºä»anchor boxå›å½’åˆ°é™„è¿‘çš„ground truth boxã€‚</p>
</li>
<li><p>å’ŒR-CNNå’ŒFast R-CNNçš„bounding box regressionæ–¹æ³•ä¸åŒçš„æ˜¯ï¼š</p>
<ul>
<li>å‰ä¸¤ç§çš„å›å½’æ˜¯åœ¨ä»ä»»æ„å¤§å°RoIä¸­æå–çš„ç‰¹å¾è¿›è¡Œå›å½’çš„ï¼Œæ‰€ä»¥regression weightsåœ¨<strong>æ‰€æœ‰å°ºå¯¸ä¸­å…±äº«</strong>ã€‚</li>
<li>åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œç”¨äºå›å½’çš„ç‰¹å¾éƒ½æ˜¯åŒä¸€ä¸ª3x3çš„ç©ºé—´ç‰¹å¾ã€‚è€ƒè™‘åˆ°å˜åŒ–çš„å°ºå¯¸ï¼Œæœ‰kä¸ªä¸åŒçš„bounding boxeå›å½’å™¨å»å­¦ä¹ ï¼Œæ¯ä¸€ä¸ªå›å½’å™¨è´Ÿè´£å»å­¦ä¹ ä¸€ä¸ªå°ºå¯¸ä¸€ä¸ªè¡¡é‡æ¯”çš„anchorã€‚æ‰€ä»¥kä¸ªå›å½’å™¨æ˜¯<strong>ä¸å…±äº«æƒå€¼çš„</strong>ã€‚æ‰€ä»¥<strong>å¾—ç›Šäºanchorçš„è®¾è®¡ï¼Œå³ä½¿ç‰¹å¾è§„å®šï¼Œæˆ‘ä»¬ä¾æ—§å¯ä»¥å»é¢„æµ‹ä¸åŒå°ºå¯¸çš„boxã€‚</strong></li>
</ul>
</li>
</ul>
<h4 id="Training-RPNs"><a href="#Training-RPNs" class="headerlink" title="Training RPNs"></a>Training RPNs</h4><ul>
<li><strong>image-centric</strong> sampling strategy</li>
<li>mini-batch: arises from a single image that contains many positive and negative example anchors.</li>
<li>éšæœºåœ¨ä¸€å¼ å›¾ç‰‡ä¸­é‡‡æ ·256ä¸ªanchorsæ¥è®¡ç®—ä¸€ä¸ªmini-batchçš„loss functionã€‚æ­£è´Ÿanchors = 1:1.</li>
<li>all new layersçš„<strong>æƒå€¼åˆå§‹åŒ–</strong>ï¼šé«˜æ–¯åˆ†å¸ƒ$(\mu = 0, \sigma = 0.01)$ï¼Œall other layersï¼ˆæ¯”å¦‚å…±äº«å·ç§¯å±‚ï¼‰ç”¨ImageNetæ¥<strong>æƒå€¼åˆå§‹åŒ–</strong>ã€‚ç”¨ZF netæ¥è¿›è¡Œè¿›è¡Œ<strong>å¾®è°ƒ</strong>ã€‚</li>
<li><strong>å­¦ä¹ ç‡</strong>ï¼š0.001(60k)-&gt;0.0001(20k)</li>
<li><strong>åŠ¨é‡</strong>ï¼š0.9</li>
<li><strong>weight decay</strong>: 0.0005</li>
</ul>
<h3 id="Sharing-Feature-for-RPN-and-Fast-R-CNN"><a href="#Sharing-Feature-for-RPN-and-Fast-R-CNN" class="headerlink" title="Sharing Feature for RPN and Fast R-CNN"></a>Sharing Feature for RPN and Fast R-CNN</h3><ul>
<li><p><strong>sharing convolutional layers between the two networks, rather than learning two separate networks</strong></p>
</li>
<li><p>ä¸‰ç§ç‰¹å¾å…±äº«çš„æ–¹æ³•ï¼š</p>
<ul>
<li><p>Alternating trainingï¼šè¿­ä»£ï¼Œå…ˆè®­ç»ƒPRNï¼Œç„¶åç”¨proposalå»è®­ç»ƒFast R-CNNã€‚è¢«Fast R-CNNå¾®è°ƒçš„ç½‘ç»œç„¶åç”¨æ¥åˆå§‹åŒ–PRNï¼Œä»¥æ­¤è¿­ä»£ã€‚æœ¬è®ºæ–‡æ‰€æœ‰çš„å®ç°éƒ½æ˜¯ä½¿ç”¨è¯¥æ–¹æ³•ã€‚</p>
</li>
<li><p>Approximate joint trainingï¼š</p>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcjw1fccbdrnzhij30bd0b1gml.jpg" alt=""></p>
<p>RPNå’ŒFast R-CNNèåˆåˆ°ä¸€ä¸ªç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¯æ¬¡SGDè¿­ä»£è¿‡ç¨‹ä¸­ï¼š</p>
<ul>
<li>å‰å‘ä¼ é€’ï¼šRPNäº§ç”Ÿregion proposalsï¼Œè¿™äº›proposalsè¢«å½“åšå›ºå®šçš„ã€æå‰è®¡ç®—å¥½çš„proposalæ¥è®­ç»ƒFast R-CNNæ£€æµ‹å™¨ã€‚</li>
<li>åå‘ä¼ é€’ï¼šå¯¹äºå…±äº«å±‚æ¥è¯´ï¼Œæ¥è‡ªRPNçš„losså’ŒFast R-CNNçš„lossç»“åˆ.</li>
<li>ä½†æ˜¯è¿™ç§æ–¹æ³•ä¸è€ƒè™‘Bounding Boxesï¼Œå¿½ç•¥äº†proposal boxesçš„åæ ‡ä¹Ÿæ˜¯ç½‘ç»œçš„è¾“å‡ºã€‚æ‰€ä»¥è¿™ç§æ–¹æ³•å«åšapproximate</li>
</ul>
</li>
<li><p>Non-approximate joint training: è€ƒè™‘Bounding Boxesã€‚</p>
</li>
</ul>
</li>
<li><p>4-step Alternating Training:</p>
<ul>
<li>Step 1: train the RPN, initialized with an ImageNet-pre-trained model and <strong>ï¬ne-tuned</strong> end-to-end for the region proposal task.</li>
<li>Step 2: train a separate detection network by Fast R-CNN using the proposals generated by the step-1 RPN. åŒæ ·ä½¿ç”¨ImageNet-pre-trained modelæ¥åˆå§‹åŒ–ã€‚<strong>æ­¤æ—¶ä¸¤ä¸ªç½‘ç»œå¹¶æ²¡æœ‰å…±äº«å·ç§¯å±‚ã€‚</strong></li>
<li>Step 3: use the detector network to initialize RPN training but we ï¬x the shared convolutional layers and only ï¬ne-tune the layers unique to RPN. <strong>ç°åœ¨ä¸¤ä¸ªç½‘ç»œå…±äº«å·ç§¯å±‚</strong></li>
<li>Step 4: keeping the shared convolutional layers ï¬xed, we ï¬ne-tune the unique layers of Fast R-CNN.</li>
</ul>
</li>
</ul>
<h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul>
<li>Multi-scaleä¸speed-accuracyä¹‹é—´çš„trade-off</li>
<li>To reduce redundancy, we adopt <strong>non-maximum suppression (NMS)</strong> on the proposal regions based on their cls scores.</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Region Proposalçš„è®¡ç®—&lt;/strong&gt;æ˜¯åŸºäºRegion Proposalç®—æ³•æ¥å‡è®¾ç‰©ä½“ä½ç½®çš„ç‰©ä½“æ£€æµ‹ç½‘ç»œæ¯”å¦‚ï¼š&lt;strong&gt;SPPnet, Fast R-CNN&lt;/strong&gt;è¿è¡Œæ—¶é—´çš„ç“¶é¢ˆã€‚&lt;/li&gt;
&lt;li&gt;Faster R-CNNå¼•å…¥äº†&lt;strong&gt;Region Proposal Networkï¼ˆRPNï¼‰&lt;/strong&gt;æ¥å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾ï¼Œå› æ­¤ä½¿å¾—region proposalå‡ ä¹æ˜¯&lt;strong&gt;cost free&lt;/strong&gt;çš„ã€‚&lt;/li&gt;
&lt;li&gt;RPN-&amp;gt;é¢„æµ‹ç‰©ä½“è¾¹ç•Œï¼ˆobject boundsï¼‰å’Œåœ¨æ¯ä¸€ä½ç½®çš„åˆ†æ•°ï¼ˆobjectness scoreï¼‰&lt;/li&gt;
&lt;li&gt;é€šè¿‡åœ¨ä¸€ä¸ªç½‘ç»œä¸­å…±äº«RPNå’ŒFast R-CNNçš„å·ç§¯ç‰¹å¾æ¥èåˆä¸¤è€…â€”â€”&lt;strong&gt;ä½¿ç”¨â€œattentionâ€æœºåˆ¶ã€‚&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;300 proposals pre image.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šFast R-CNN</title>
    <link href="http://jacobkong.github.io/posts/1679631826/"/>
    <id>http://jacobkong.github.io/posts/1679631826/</id>
    <published>2016-12-07T22:32:24.000Z</published>
    <updated>2017-03-09T04:27:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="çŸ¥è¯†ç‚¹"><a href="#çŸ¥è¯†ç‚¹" class="headerlink" title="çŸ¥è¯†ç‚¹"></a>çŸ¥è¯†ç‚¹</h2><ul>
<li>mAPï¼šdetection quality.</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¿«é€ŸåŒºåŸŸçš„å·ç§¯ç½‘ç»œæ–¹æ³•ï¼ˆå¿«é€ŸR-CNNï¼‰ç”¨äºå¯¹è±¡æ£€æµ‹ã€‚</li>
<li>å¿«é€ŸR-CNNé‡‡ç”¨å¤šé¡¹åˆ›æ–°æŠ€æœ¯æ¥æé«˜è®­ç»ƒå’Œæµ‹è¯•é€Ÿåº¦ï¼ŒåŒæ—¶æé«˜æ£€æµ‹ç²¾åº¦ã€‚</li>
<li>é‡‡ç”¨VGG16çš„ç½‘ç»œï¼šVGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connected layers</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>ç‰©ä½“æ£€æµ‹ç›¸å¯¹äºå›¾åƒåˆ†ç±»æ˜¯æ›´å¤æ‚çš„ï¼Œåº”ä¸ºéœ€è¦ç‰©ä½“å‡†ç¡®çš„ä½ç½®ã€‚<ul>
<li>é¦–å…ˆï¼Œå¿…é¡»å¤„ç†è®¸å¤šå€™é€‰å¯¹è±¡ä½ç½®ï¼ˆé€šå¸¸ç§°ä¸ºâ€œproposalâ€ï¼‰ã€‚</li>
<li>å…¶æ¬¡ï¼Œè¿™äº›å€™é€‰è€…åªæä¾›ç²—ç•¥çš„å®šä½ï¼Œå¿…é¡»è¿›è¡Œç²¾ç¡®å®šä½æ‰èƒ½å®ç°ç²¾ç¡®å®šä½ã€‚</li>
<li>è¿™äº›é—®é¢˜çš„è§£å†³æ–¹æ¡ˆç»å¸¸æŸå®³ <strong>é€Ÿåº¦</strong> ï¼Œ <strong>å‡†ç¡®æ€§</strong> æˆ– <strong>ç®€å•æ€§</strong> ã€‚</li>
</ul>
</li>
</ul>
<h3 id="R-CNN-and-SPPnet"><a href="#R-CNN-and-SPPnet" class="headerlink" title="R-CNN and SPPnet"></a>R-CNN and SPPnet</h3><ul>
<li>R-CNN(Region-based Convolution Network)å…·æœ‰å‡ ä¸ªæ˜¾è‘—çš„ç¼ºç‚¹ï¼š<ul>
<li>è®­ç»ƒæ˜¯ä¸€ä¸ªå¤šçº§ç®¡é“ã€‚</li>
<li>è®­ç»ƒåœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šæ˜¯æ˜‚è´µçš„ã€‚</li>
<li>ç‰©ä½“æ£€æµ‹é€Ÿåº¦å¾ˆæ…¢ã€‚</li>
</ul>
</li>
<li>R-CNNæ˜¯æ…¢çš„ï¼Œå› ä¸ºå®ƒå¯¹æ¯ä¸ªå¯¹è±¡proposalæ‰§è¡ŒConvNetæ­£å‘ä¼ é€’ï¼Œè€Œä¸å…±äº«è®¡ç®—ï¼ˆsharing computationï¼‰ã€‚</li>
<li>Spatial pyramid pooling networksï¼ˆSPPnetsï¼‰ï¼Œåˆ©ç”¨sharing computationå¯¹R-CNNè¿›è¡Œäº†åŠ é€Ÿï¼Œä½†æ˜¯SPPnetsä¹Ÿå…·æœ‰æ˜æ˜¾çš„ç¼ºç‚¹ï¼ŒåƒR-CNNä¸€æ ·ï¼ŒSPPnetsä¹Ÿéœ€è¦ï¼š<ul>
<li>è®­ç»ƒæ˜¯ä¸€ä¸ªå¤šé˜¶æ®µæµç¨‹ï¼Œ</li>
<li>æ¶‰åŠæå–ç‰¹å¾ï¼Œ</li>
<li>ç”¨å¯¹æ•°æŸå¤±ç²¾ç®€ç½‘ç»œ</li>
<li>è®­ç»ƒSVM</li>
<li>èµ‹äºˆè¾¹ç•Œæ¡†å›å½’ã€‚</li>
<li>ç‰¹å¾ä¹Ÿéœ€è¦ä¹Ÿå†™å…¥ç£ç›˜ã€‚</li>
</ul>
</li>
<li>ä½†ä¸R-CNN <strong>ä¸åŒ</strong> ï¼Œåœ¨[11]ä¸­æå‡ºçš„fine-tuningç®—æ³•ä¸èƒ½æ›´æ–°åœ¨ç©ºé—´é‡‘å­—å¡”æ± ä¹‹å‰çš„å·ç§¯å±‚ã€‚ ä¸å‡ºæ‰€æ–™ï¼Œè¿™ç§é™åˆ¶ï¼ˆå›ºå®šçš„å·ç§¯å±‚ï¼‰é™åˆ¶äº†éå¸¸æ·±çš„ç½‘ç»œçš„ç²¾åº¦ã€‚</li>
</ul>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ul>
<li>Fast R-CNNä¼˜ç‚¹ï¼š</li>
</ul>
<ol>
<li>æ¯”R-CNNï¼ŒSPPnetæ›´é«˜çš„æ£€æµ‹è´¨é‡ï¼ˆmAPï¼‰</li>
<li>è®­ç»ƒæ˜¯å•é˜¶æ®µçš„ï¼Œä½¿ç”¨å¤šä»»åŠ¡æŸå¤±ï¼ˆmulti-task lossï¼‰</li>
<li>è®­ç»ƒå¯ä»¥æ›´æ–°æ‰€æœ‰ç½‘ç»œå±‚</li>
<li>ç‰¹å¾ç¼“å­˜ä¸éœ€è¦ç£ç›˜å­˜å‚¨</li>
</ol>
<h2 id="Fast-R-CNN-architecture-and-training"><a href="#Fast-R-CNN-architecture-and-training" class="headerlink" title="Fast R-CNN architecture and training"></a>Fast R-CNN architecture and training</h2><ul>
<li><p>æ•´ä½“æ¡†æ¶<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7na6fij30jk0efdju.jpg" alt=""></p>
</li>
<li><p>å¿«é€ŸR-CNNç½‘ç»œå°†<strong>æ•´ä¸ªå›¾åƒ</strong>å’Œ<strong>ä¸€ç»„object proposals</strong>ä½œä¸ºè¾“å…¥ã€‚</p>
<ul>
<li>ç½‘ç»œé¦–å…ˆä½¿ç”¨å‡ ä¸ªå·ç§¯ï¼ˆconvï¼‰å’Œæœ€å¤§æ± å±‚æ¥å¤„ç†æ•´ä¸ªå›¾åƒï¼Œä»¥äº§ç”Ÿconv feature mapã€‚</li>
<li>ç„¶åï¼Œå¯¹äºæ¯ä¸ªå¯¹è±¡proposalï¼Œ <strong>æ„Ÿå…´è¶£åŒºåŸŸï¼ˆRoIï¼‰æ± å±‚</strong> ä»ç‰¹å¾å›¾ä¸­æŠ½å–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚</li>
<li>æ¯ä¸ªç‰¹å¾å‘é‡è¢«é¦ˆé€åˆ°å®Œå…¨è¿æ¥ï¼ˆfcï¼‰å±‚åºåˆ—ï¼Œå…¶æœ€ç»ˆåˆ†æ”¯æˆä¸¤ä¸ªåŒçº§è¾“å‡ºå±‚ï¼š<ul>
<li>ä¸€ä¸ªäº§ç”Ÿå¯¹Kä¸ªå¯¹è±¡ç±»åŠ ä¸Šå…¨éƒ¨æ•è·çš„â€œèƒŒæ™¯â€ç±»çš„softmaxæ¦‚ç‡ä¼°è®¡(one that produces softmax probability estimates over K object classes plus a catch-all â€œbackgroundâ€ class)</li>
<li>å¦ä¸€ä¸ªå¯¹æ¯ä¸ªKå¯¹è±¡ç±»è¾“å‡ºå››ä¸ªå®æ•°ï¼Œæ¯ç»„4ä¸ªå€¼ç¼–ç æç‚¼å®šä¹‰Kä¸ªç±»ä¸­çš„ä¸€ä¸ªçš„çš„è¾¹ç•Œæ¡†ä½ç½®ã€‚(another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes reï¬ned bounding-box positions for one of the K classes.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="The-RoI-pooling-layer"><a href="#The-RoI-pooling-layer" class="headerlink" title="The RoI pooling layer"></a>The RoI pooling layer</h3><ul>
<li>Rol pooling layerçš„ä½œç”¨ä¸»è¦æœ‰ä¸¤ä¸ªï¼š<ul>
<li>ä¸€ä¸ªæ˜¯å°†imageä¸­çš„RoIå®šä½åˆ°feature mapä¸­å¯¹åº”patch</li>
<li>å¦ä¸€ä¸ªæ˜¯ç”¨ä¸€ä¸ªå•å±‚çš„SPP layerå°†è¿™ä¸ªfeature map patchä¸‹é‡‡æ ·ä¸ºå¤§å°å›ºå®šçš„featureå†ä¼ å…¥å…¨è¿æ¥å±‚ã€‚</li>
</ul>
</li>
<li>RoIæ± å±‚ä½¿ç”¨æœ€å¤§æ± åŒ–å°†ä»»ä½•æœ‰æ•ˆçš„RoIåŒºåŸŸå†…çš„ç‰¹å¾è½¬æ¢æˆå…·æœ‰HÃ—Wï¼ˆä¾‹å¦‚ï¼Œ7Ã—7ï¼‰çš„å›ºå®šç©ºé—´èŒƒå›´çš„å°feature mapï¼Œå…¶ä¸­Hå’ŒWæ˜¯å±‚<strong>è¶…å‚æ•°</strong> å®ƒä»¬ç‹¬ç«‹äºä»»ä½•ç‰¹å®šçš„RoIã€‚</li>
<li>åœ¨æœ¬æ–‡ä¸­ï¼ŒRoIæ˜¯conv feature mapä¸­çš„ä¸€ä¸ªçŸ©å½¢çª—å£ã€‚</li>
<li>æ¯ä¸ªRoIç”±å®šä¹‰å…¶å·¦ä¸Šè§’ï¼ˆrï¼Œcï¼‰åŠå…¶é«˜åº¦å’Œå®½åº¦ï¼ˆhï¼Œwï¼‰çš„å››å…ƒç»„ï¼ˆrï¼Œcï¼Œhï¼Œwï¼‰å®šä¹‰ã€‚</li>
<li>RoIå±‚ä»…ä»…æ˜¯Sppnetsä¸­çš„spatial pyramid pooling layerçš„ç‰¹æ®Šå½¢å¼ï¼Œå…¶ä¸­<strong>åªæœ‰ä¸€ä¸ªé‡‘å­—å¡”å±‚</strong>.</li>
</ul>
<h3 id="Initializing-from-pre-trained-networks"><a href="#Initializing-from-pre-trained-networks" class="headerlink" title="Initializing from pre-trained networks"></a>Initializing from pre-trained networks</h3><ul>
<li>ç”¨äº†3ä¸ªé¢„è®­ç»ƒçš„ImageNetç½‘ç»œï¼ˆCaffeNet/ VGG_CNN_M_1024 /VGG16ï¼‰ã€‚é¢„è®­ç»ƒçš„ç½‘ç»œåˆå§‹åŒ–Fast RCNNè¦ç»è¿‡ä¸‰æ¬¡å˜å½¢ï¼š</li>
</ul>
<ol>
<li>æœ€åä¸€ä¸ªmax poolingå±‚æ›¿æ¢ä¸ºRoI poolingå±‚ï¼Œè®¾ç½®Hâ€™å’ŒWâ€™ä¸ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚å…¼å®¹ã€‚</li>
<li>æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚å’Œsoftmaxï¼ˆåŸæœ¬æ˜¯1000ä¸ªç±»ï¼‰æ›¿æ¢ä¸ºsoftmaxçš„å¯¹K+1ä¸ªç±»åˆ«çš„åˆ†ç±»å±‚ï¼Œå’Œbounding box å›å½’å±‚ã€‚</li>
<li>è¾“å…¥ä¿®æ”¹ä¸ºä¸¤ç§æ•°æ®ï¼šä¸€ç»„Nä¸ªå›¾å½¢ï¼ŒRä¸ªRoIï¼Œbatch sizeå’ŒROIæ•°ã€å›¾åƒåˆ†è¾¨ç‡éƒ½æ˜¯å¯å˜çš„ã€‚</li>
</ol>
<h3 id="Fine-tuning-for-detection"><a href="#Fine-tuning-for-detection" class="headerlink" title="Fine-tuning for detection"></a>Fine-tuning for detection</h3><ul>
<li><p>åˆ©ç”¨åå‘ä¼ æ’­ç®—æ³•è¿›è¡Œè®­ç»ƒæ‰€æœ‰ç½‘ç»œçš„æƒé‡æ˜¯Fast R-CNNå¾ˆé‡è¦çš„ä¸€ä¸ªèƒ½åŠ›ã€‚</p>
</li>
<li><p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›´æœ‰æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨åœ¨è®­ç»ƒæœŸé—´çš„ç‰¹å¾å…±äº«ï¼ˆfeature sharing during trainingï¼‰ã€‚</p>
</li>
<li><p>åœ¨Fast R-CNNè®­ç»ƒä¸­ï¼Œ <strong>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰å°æ‰¹é‡åˆ†å±‚é‡‡æ ·</strong> ï¼Œé¦–å…ˆé€šè¿‡é‡‡æ ·Nä¸ªå›¾åƒï¼Œç„¶åé€šè¿‡ä»æ¯ä¸ªå›¾åƒé‡‡æ · <strong>R/Nä¸ª</strong> RoIsã€‚</p>
</li>
<li><p><strong>å…³é”®çš„æ˜¯ï¼Œæ¥è‡ªåŒä¸€å›¾åƒçš„RoIåœ¨å‘å‰å’Œå‘åä¼ é€’ä¸­ å…±äº«è®¡ç®— å’Œå­˜å‚¨ã€‚</strong></p>
</li>
<li><p>æ­¤å¤–ä¸ºäº†åˆ†å±‚é‡‡æ ·ï¼ŒFast R-CNNä½¿ç”¨äº†ä¸€ä¸ª<strong>æµæ°´çº¿è®­ç»ƒè¿‡ç¨‹</strong>ï¼Œåˆ©ç”¨ä¸€ä¸ªfine-tuningé˜¶æ®µæ¥è”åˆä¼˜åŒ–ä¸€ä¸ªsoftmaxåˆ†ç±»å™¨å’Œbounding boxå›å½’ï¼Œè€Œéè®­ç»ƒä¸€ä¸ªsoftmaxåˆ†ç±»å™¨ï¼ŒSVMsï¼Œå’Œregressionåœ¨ä¸‰ä¸ªç‹¬ç«‹çš„é˜¶æ®µã€‚</p>
</li>
<li><p>Multi-task lossï¼š</p>
<ul>
<li>ä¸¤ä¸ªsiblingè¾“å‡ºå±‚ï¼š<ul>
<li>ç¬¬ä¸€å±‚ï¼šè¾“å‡ºç¦»æ•£æ¦‚ç‡åˆ†å¸ƒï¼ˆé’ˆå¯¹æ¯ä¸ªRoIsï¼‰ï¼Œ$p=(p_0,â€¦,p_K)$ï¼Œåˆ†åˆ«å¯¹åº”$K+1$ä¸ªç±»ã€‚pæ˜¯åœ¨ä¸€ä¸ªå…¨è¿æ¥å±‚çš„$K+1$ä¸ªè¾“å‡ºä¸Šçš„softmaxã€‚</li>
<li>ç¬¬äºŒå±‚ï¼šè¾“å‡ºbounding-boxçš„å›å½’åç§»(bounding-box regression offsets)ï¼Œé’ˆå¯¹K object classesä¸­çš„æ¯ä¸€ä¸ªç±»ï¼Œè®¡ç®—$t^k=(t^k_x,t^k_y,t^k_w,t^k_h)$ï¼Œ<strong>å…·ä½“è§R-CNNå¾—è¡¥å……ææ–™ï¼Œé‡Œé¢æœ‰å¾ˆè¯¦ç»†çš„ä»‹ç»bounding box regression</strong>ã€‚</li>
</ul>
</li>
<li>æ¯ä¸€ä¸ªè®­ç»ƒRoIsè¢«æ ‡æ³¨ä¸€ä¸ªground truthç±»$u$ï¼Œå’Œä¸€ä¸ªground truth bounding box å›å½’ç›®æ ‡$v$ã€‚</li>
</ul>
<ul>
<li>ä¸¤ä¸ªlossï¼Œä»¥ä¸‹åˆ†åˆ«ä»‹ç»ï¼š<ul>
<li>å¯¹äºåˆ†ç±»lossï¼Œæ˜¯ä¸€ä¸ªN+1è·¯çš„softmaxè¾“å‡ºï¼Œå…¶ä¸­çš„Næ˜¯ç±»åˆ«ä¸ªæ•°ï¼Œ1æ˜¯èƒŒæ™¯ã€‚</li>
<li>å¯¹äºå›å½’lossï¼Œæ˜¯ä¸€ä¸ª4xNè·¯è¾“å‡ºçš„regressorï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹äºæ¯ä¸ªç±»åˆ«éƒ½ä¼šè®­ç»ƒä¸€ä¸ªå•ç‹¬çš„regressorçš„æ„æ€ï¼Œæ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯ï¼Œè¿™é‡Œregressorçš„lossä¸æ˜¯L2çš„ï¼Œè€Œæ˜¯ä¸€ä¸ªå¹³æ»‘çš„L1ï¼Œå½¢å¼å¦‚ä¸‹ï¼š</li>
</ul>
</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfo7oia0ij30bg05n74f.jpg" alt=""></p>
</li>
<li><p>æˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªmulti-task loss L åœ¨æ¯ä¸ªè¢«æ ‡æ³¨çš„RoIä¸Šæ¥è”åˆè®­ç»ƒåˆ†ç±»å™¨å’Œbounding box regression</p>
</li>
<li><p>Mini-batch samplingï¼šåœ¨å¾®è°ƒæ—¶ï¼Œæ¯ä¸ªSGDçš„mini-batchæ˜¯éšæœºæ‰¾ä¸¤ä¸ªå›¾ç‰‡ï¼ŒRä¸º128ï¼Œå› æ­¤æ¯ä¸ªå›¾ä¸Šå–æ ·64ä¸ªRoIã€‚ä»object proposalä¸­é€‰25%çš„RoIï¼Œå°±æ˜¯å’Œground-truthäº¤å è‡³å°‘ä¸º0.5çš„ã€‚å‰©ä¸‹çš„ä½œä¸ºèƒŒæ™¯ã€‚</p>
</li>
<li><p>Back-propagation through RoI pooling layersï¼š</p>
<ul>
<li><p>RoI poolingå±‚è®¡ç®—æŸå¤±å‡½æ•°å¯¹æ¯ä¸ªè¾“å…¥å˜é‡xçš„åå¯¼æ•°ï¼Œå¦‚ä¸‹ï¼š</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7owdcpj306q01mwee.jpg" alt=""></p>
<p>yæ˜¯poolingåçš„è¾“å‡ºå•å…ƒï¼Œxæ˜¯poolingå‰çš„è¾“å…¥å•å…ƒï¼Œå¦‚æœyç”±x poolingè€Œæ¥ï¼Œåˆ™å°†æŸå¤±Lå¯¹yçš„åå¯¼è®¡å…¥ç´¯åŠ å€¼ï¼Œæœ€åç´¯åŠ å®ŒRä¸ªRoIä¸­çš„æ‰€æœ‰è¾“å‡ºå•å…ƒã€‚ä¸‹é¢æ˜¯æˆ‘ç†è§£çš„xã€yã€rçš„å…³ç³»ï¼š</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfoo7cuv7j30qf0ardgq.jpg" alt="20151208163114338"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Scale-invariance"><a href="#Scale-invariance" class="headerlink" title="Scale invariance"></a>Scale invariance</h3><ul>
<li>è¿™é‡Œè®¨è®ºobjectçš„scaleé—®é¢˜ï¼Œå°±æ˜¯ç½‘ç»œå¯¹äºobjectçš„scaleåº”è¯¥æ˜¯è¦ä¸æ•æ„Ÿçš„ã€‚è¿™é‡Œè¿˜æ˜¯å¼•ç”¨äº†SPPçš„æ–¹æ³•ï¼Œæœ‰ä¸¤ç§:<ul>
<li>brute force ï¼ˆsingle scaleï¼‰ï¼Œä¹Ÿå°±æ˜¯ç®€å•è®¤ä¸ºobjectä¸éœ€è¦é¢„å…ˆresizeåˆ°ç±»ä¼¼çš„scaleå†ä¼ å…¥ç½‘ç»œï¼Œç›´æ¥å°†imageå®šæ­»ä¸ºæŸç§scaleï¼Œç›´æ¥è¾“å…¥ç½‘ç»œæ¥è®­ç»ƒå°±å¥½äº†ï¼Œç„¶åæœŸæœ›ç½‘ç»œè‡ªå·±èƒ½å¤Ÿå­¦ä¹ åˆ°scale-invarianceçš„è¡¨è¾¾ã€‚</li>
<li>image pyramids ï¼ˆmulti scaleï¼‰ï¼Œä¹Ÿå°±æ˜¯è¦ç”Ÿæˆä¸€ä¸ªé‡‘å­—å¡”ï¼Œç„¶åå¯¹äºobjectï¼Œåœ¨é‡‘å­—å¡”ä¸Šæ‰¾åˆ°ä¸€ä¸ªå¤§å°æ¯”è¾ƒæ¥è¿‘227x227çš„æŠ•å½±ç‰ˆæœ¬ï¼Œç„¶åç”¨è¿™ä¸ªç‰ˆæœ¬å»è®­ç»ƒç½‘ç»œã€‚</li>
</ul>
</li>
<li>å¯ä»¥çœ‹å‡ºï¼Œ2åº”è¯¥æ¯”1æ›´åŠ å¥½ï¼Œä½œè€…ä¹Ÿåœ¨5.2è®¨è®ºäº†ï¼Œ2çš„è¡¨ç°ç¡®å®æ¯”1å¥½ï¼Œä½†æ˜¯å¥½çš„ä¸ç®—å¤ªå¤šï¼Œå¤§æ¦‚æ˜¯1ä¸ªmAPå·¦å³ï¼Œä½†æ˜¯æ—¶é—´è¦æ…¢ä¸å°‘ï¼Œæ‰€ä»¥ä½œè€…å®é™…é‡‡ç”¨çš„æ˜¯ç¬¬ä¸€ä¸ªç­–ç•¥ï¼Œä¹Ÿå°±æ˜¯single scaleã€‚</li>
<li>è¿™é‡Œï¼ŒFRCNæµ‹è¯•ä¹‹æ‰€ä»¥æ¯”SPPå¿«ï¼Œå¾ˆå¤§åŸå› æ˜¯å› ä¸ºè¿™é‡Œï¼Œå› ä¸ºSPPç”¨äº†2ï¼Œè€ŒFRCNç”¨äº†1ã€‚</li>
</ul>
<h2 id="Fast-R-CNN-detection"><a href="#Fast-R-CNN-detection" class="headerlink" title="Fast R-CNN detection"></a>Fast R-CNN detection</h2><ul>
<li>å¤§å‹å…¨è¿æ¥å±‚å¾ˆå®¹æ˜“çš„å¯ä»¥é€šè¿‡å°†ä»–ä»¬ä¸ <strong>truncated SVD(å¥‡å¼‚å€¼åˆ†è§£)</strong> å‹ç¼©æ¥åŠ é€Ÿè®¡ç®—ã€‚</li>
</ul>
<h2 id="Main-results"><a href="#Main-results" class="headerlink" title="Main results"></a>Main results</h2><ul>
<li>All Fast R-CNN results in this paper using VGG16 ï¬ne-tune layers conv3 1 and up; all experments with models S and M ï¬ne-tune layers conv2 and up.</li>
</ul>
<h2 id="Design-evaluation"><a href="#Design-evaluation" class="headerlink" title="Design evaluation"></a>Design evaluation</h2><h3 id="Do-we-need-more-training-data"><a href="#Do-we-need-more-training-data" class="headerlink" title="Do we need more training data?"></a>Do we need more training data?</h3><ul>
<li>åœ¨è®­ç»ƒæœŸé—´ï¼Œä½œè€…åšè¿‡çš„å”¯ä¸€ä¸€ä¸ªæ•°æ®å¢é‡çš„æ–¹å¼æ˜¯æ°´å¹³ç¿»è½¬ã€‚ ä½œè€…ä¹Ÿè¯•è¿‡å°†VOC12çš„æ•°æ®ä¹Ÿä½œä¸ºæ‹“å±•æ•°æ®åŠ å…¥åˆ°finetuneçš„æ•°æ®ä¸­ï¼Œç»“æœVOC07çš„mAPä»66.9åˆ°äº†70.0ï¼Œè¯´æ˜å¯¹äºç½‘ç»œæ¥è¯´ï¼Œ <strong>æ•°æ®è¶Šå¤šå°±æ˜¯è¶Šå¥½çš„ã€‚</strong></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;a href=&quot;#çŸ¥è¯†ç‚¹&quot; class=&quot;headerlink&quot; title=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;/a&gt;çŸ¥è¯†ç‚¹&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;mAPï¼šdetection quality.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¿«é€ŸåŒºåŸŸçš„å·ç§¯ç½‘ç»œæ–¹æ³•ï¼ˆå¿«é€ŸR-CNNï¼‰ç”¨äºå¯¹è±¡æ£€æµ‹ã€‚&lt;/li&gt;
&lt;li&gt;å¿«é€ŸR-CNNé‡‡ç”¨å¤šé¡¹åˆ›æ–°æŠ€æœ¯æ¥æé«˜è®­ç»ƒå’Œæµ‹è¯•é€Ÿåº¦ï¼ŒåŒæ—¶æé«˜æ£€æµ‹ç²¾åº¦ã€‚&lt;/li&gt;
&lt;li&gt;é‡‡ç”¨VGG16çš„ç½‘ç»œï¼šVGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connected layers&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šSpatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</title>
    <link href="http://jacobkong.github.io/posts/3054155989/"/>
    <id>http://jacobkong.github.io/posts/3054155989/</id>
    <published>2016-12-06T22:32:24.000Z</published>
    <updated>2017-01-28T09:00:55.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>ç°æœ‰çš„æ·±å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰éœ€è¦å›ºå®šå°ºå¯¸ï¼ˆä¾‹å¦‚ï¼Œ224Ã—224ï¼‰çš„è¾“å…¥å›¾åƒã€‚</li>
<li>æ–°çš„ç½‘ç»œç»“æ„ï¼Œç§°ä¸ºSPP-netï¼Œå¯ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œè€Œä¸ç®¡å›¾åƒå¤§å°/è§„æ¨¡ã€‚</li>
<li>ä½¿ç”¨SPP-netï¼Œæˆ‘ä»¬ä»æ•´ä¸ªå›¾åƒåªè®¡ç®—ä¸€æ¬¡ç‰¹å¾å›¾ï¼Œç„¶ååœ¨ä»»æ„åŒºåŸŸï¼ˆå­å›¾åƒï¼‰ä¸­æ± ç‰¹å¾ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºä»¥è®­ç»ƒæ£€æµ‹å™¨ã€‚</li>
</ul>
<a id="more"></a>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><ul>
<li>åœ¨CNNçš„è®­ç»ƒå’Œæµ‹è¯•ä¸­å­˜åœ¨æŠ€æœ¯é—®é¢˜ï¼šæ™®éçš„CNNéœ€è¦å›ºå®šçš„è¾“å…¥å›¾åƒå¤§å°ï¼ˆä¾‹å¦‚ï¼Œ224Ã—224ï¼‰ï¼Œå…¶é™åˆ¶äº†è¾“å…¥å›¾åƒçš„å®½é«˜æ¯”å’Œæ¯”ä¾‹ã€‚</li>
<li>Cropping</li>
<li>Warping-&gt;unwanted geometric distortion(ä¸éœ€è¦çš„å‡ ä½•å¤±çœŸ)</li>
<li><p>é‚£ä¹ˆä¸ºä»€ä¹ˆCNNéœ€è¦å›ºå®šè¾“å…¥å¤§å°ï¼Ÿ</p>
<ul>
<li>CNNä¸»è¦ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šå·ç§¯å±‚å’Œè·Ÿéšçš„å®Œå…¨è¿æ¥çš„å±‚ã€‚</li>
<li>äº‹å®ä¸Šï¼Œå·ç§¯å±‚ä¸éœ€è¦å›ºå®šçš„å›¾åƒå¤§å°ï¼Œå¹¶ä¸”å¯ä»¥ç”Ÿæˆä»»ä½•å¤§å°çš„ç‰¹å¾å›¾</li>
<li>å¦ä¸€æ–¹é¢ï¼Œæ ¹æ®å®šä¹‰ï¼šå®Œå…¨è¿æ¥çš„å±‚éœ€è¦å…·æœ‰å›ºå®šå°ºå¯¸/é•¿åº¦è¾“å…¥ã€‚æ‰€ä»¥å›ºå®šå°ºå¯¸å®Œå…¨æ¥è‡ªäº <strong>å…¨è¿æ¥å±‚</strong></li>
</ul>
</li>
<li><p>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªspatial pyramid poolingï¼ˆç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚ï¼‰æ¥å»æ‰é¢æ˜‚ç½—å›ºå®šè¾“å…¥çš„çº¦æŸã€‚</p>
</li>
<li><p>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚çš„é¡¶éƒ¨æ·»åŠ ä¸€ä¸ªSPPå±‚ã€‚ SPPå±‚æ±‡é›†ç‰¹å¾å¹¶äº§ç”Ÿå›ºå®šé•¿åº¦çš„è¾“å‡ºï¼Œç„¶åé¦ˆé€åˆ°å®Œå…¨è¿æ¥çš„å±‚ï¼ˆæˆ–å…¶ä»–åˆ†ç±»å™¨ï¼‰ã€‚</p>
</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfnxkqg21j30jl03hwf2.jpg" alt=""></p>
<ul>
<li><p>SPPå¯¹äºæ·±åº¦CNNæœ‰ç€ä¸€äº›æ˜¾è‘—çš„ç‰¹æ€§ï¼š</p>
<ul>
<li>1ï¼‰SPPèƒ½å¤Ÿç”Ÿæˆå›ºå®šé•¿åº¦çš„è¾“å‡ºï¼Œè€Œä¸ç®¡è¾“å…¥å¤§å°ï¼Œè€Œåœ¨ä»¥å‰çš„æ·±åº¦ç½‘ç»œ[3]ä¸­ä½¿ç”¨çš„æ»‘åŠ¨çª—å£æ± ä¸èƒ½;</li>
<li>2ï¼‰SPPä½¿ç”¨å¤šçº§ç©ºé—´ä»“ï¼Œè€Œæ»‘åŠ¨çª—å£æ± ä»…ä½¿ç”¨å•ä¸ªçª—å£å¤§å°ã€‚ å¤šå±‚æ± åŒ–å·²è¢«è¯æ˜å¯¹äºå¯¹è±¡å˜å½¢æ˜¯é²æ£’çš„[15];</li>
<li>3ï¼‰ç”±äºè¾“å…¥å°ºåº¦çš„çµæ´»æ€§ï¼ŒSPPå¯ä»¥åœ¨å¯å˜å°ºåº¦ä¸Šæå–çš„ç‰¹å¾ã€‚</li>
</ul>
</li>
<li><p>å®éªŒè¡¨æ˜ï¼Œè¿™ç§å¤šå°ºå¯¸è®­ç»ƒä¸ä¼ ç»Ÿçš„å•å°ºå¯¸è®­ç»ƒä¸€æ ·æ”¶æ•›ï¼Œå¹¶å¯¼è‡´æ›´å¥½çš„æµ‹è¯•ç²¾åº¦ã€‚</p>
</li>
<li><p>SPPçš„ä¼˜ç‚¹æ˜¯ä¸ç‰¹å®šçš„CNNè®¾è®¡æ˜¯æ­£äº¤çš„ã€‚</p>
</li>
<li><p>Caltech101: L. Fei-Fei, R. Fergus, and P. Perona, â€œLearning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories,â€ CVIU, 2007.</p>
</li>
<li><p>VOC 2007: M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman, â€œThe PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results,â€ 2007.</p>
</li>
<li><p>ä½†æ˜¯R-CNNä¸­çš„ç‰¹å¾è®¡ç®—æ˜¯è€—æ—¶çš„ï¼Œå› ä¸ºå®ƒå¯¹æ¯ä¸ªå›¾åƒçš„æ•°åƒä¸ªwrapedåŒºåŸŸçš„åŸå§‹åƒç´ é‡å¤åº”ç”¨æ·±å·ç§¯ç½‘ç»œã€‚è€Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥åœ¨ä¸€æ•´å¼ å›¾åƒä¸Šåªè·‘ä¸€æ¬¡å·ç§¯å±‚</p>
</li>
</ul>
<h2 id="DEEP-NETWORKS-WITH-SPATIAL-PYRAMID-POOLING"><a href="#DEEP-NETWORKS-WITH-SPATIAL-PYRAMID-POOLING" class="headerlink" title="DEEP NETWORKS WITH SPATIAL PYRAMID POOLING"></a>DEEP NETWORKS WITH SPATIAL PYRAMID POOLING</h2><ul>
<li>è¾“å…¥å›¾åƒä¸­çš„è¿™äº›å½¢çŠ¶æ¿€æ´»åœ¨ç›¸åº”ä½ç½®çš„feature map</li>
</ul>
<h3 id="The-Spatial-Pyramid-Pooling-Layer"><a href="#The-Spatial-Pyramid-Pooling-Layer" class="headerlink" title="The Spatial Pyramid Pooling Layer"></a>The Spatial Pyramid Pooling Layer</h3><ul>
<li>Bag-of-Words (BoW) approach-&gt;ç”¨æ¥å°†ç”Ÿæˆçš„ç‰¹å¾è¿›è¡Œpoolä»è€Œäº§ç”Ÿå›ºå®šé•¿åº¦çš„å‘é‡ã€‚</li>
<li>ç©ºé—´é‡‘å­—å¡”æ± æé«˜BoWï¼Œå› ä¸ºå®ƒå¯ä»¥é€šè¿‡åœ¨å±€éƒ¨ç©ºé—´ä»“ä¸­æ±‡é›†æ¥ <strong>ç»´æŠ¤ç©ºé—´ä¿¡æ¯</strong> ã€‚</li>
<li><p>â€œglobal poolingâ€ operation</p>
<ul>
<li>a global average pooling</li>
<li>a global average pooling</li>
</ul>
</li>
</ul>
<h3 id="Training-the-Network"><a href="#Training-the-Network" class="headerlink" title="Training the Network"></a>Training the Network</h3><ul>
<li>Single-size training</li>
<li>Multi-size training</li>
</ul>
<h2 id="SPP-NET-FOR-IMAGE-CLASSIFICATION"><a href="#SPP-NET-FOR-IMAGE-CLASSIFICATION" class="headerlink" title="SPP-NET FOR IMAGE CLASSIFICATION"></a>SPP-NET FOR IMAGE CLASSIFICATION</h2><h2 id="SPP-NET-FOR-OBJECT-DETECTION"><a href="#SPP-NET-FOR-OBJECT-DETECTION" class="headerlink" title="SPP-NET FOR OBJECT DETECTION"></a>SPP-NET FOR OBJECT DETECTION</h2><ul>
<li>å¯¹äºR-CNNæ¥è¯´ï¼ŒFeature extraction is the major timing bottleneck in testing.</li>
<li>å¯¹äºæˆ‘ä»¬çš„SPP-netæ¥è¯´ï¼Œæˆ‘ä»¬ä»ä¸€æ•´å¼ å›¾ç‰‡ä¸­å€¼æå–ä¸€æ¬¡ç‰¹å¾ã€‚</li>
<li>On the contrary, our method enables feature extraction in <strong>arbitrary windows</strong> from the deep convolutional feature maps.</li>
</ul>
<h3 id="Detection-Algorithm"><a href="#Detection-Algorithm" class="headerlink" title="Detection Algorithm"></a>Detection Algorithm</h3><p><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfnxjqg0ej30h50lfai3.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;ç°æœ‰çš„æ·±å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰éœ€è¦å›ºå®šå°ºå¯¸ï¼ˆä¾‹å¦‚ï¼Œ224Ã—224ï¼‰çš„è¾“å…¥å›¾åƒã€‚&lt;/li&gt;
&lt;li&gt;æ–°çš„ç½‘ç»œç»“æ„ï¼Œç§°ä¸ºSPP-netï¼Œå¯ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œè€Œä¸ç®¡å›¾åƒå¤§å°/è§„æ¨¡ã€‚&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨SPP-netï¼Œæˆ‘ä»¬ä»æ•´ä¸ªå›¾åƒåªè®¡ç®—ä¸€æ¬¡ç‰¹å¾å›¾ï¼Œç„¶ååœ¨ä»»æ„åŒºåŸŸï¼ˆå­å›¾åƒï¼‰ä¸­æ± ç‰¹å¾ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºä»¥è®­ç»ƒæ£€æµ‹å™¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šRich feature hierarchies for accurate object detection and semantic segmentation</title>
    <link href="http://jacobkong.github.io/posts/4241353321/"/>
    <id>http://jacobkong.github.io/posts/4241353321/</id>
    <published>2016-12-05T22:32:24.000Z</published>
    <updated>2017-01-28T09:00:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>mAP: mean average precisionï¼Œå¹³å‡å‡†ç¡®åº¦</li>
<li><p>æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆä¸¤ä¸ªå…³é”®çš„è§è§£ï¼š</p>
<ul>
<li>ç¬¬ä¸€ï¼šé‡‡ç”¨é«˜å®¹é‡çš„å·ç§¯ç¥ç»ç½‘ç»œæ¥ä»ä¸Šåˆ°ä¸‹çš„è¿›è¡Œregion proposalï¼Œä»è€Œå®ç°å®šä½å’Œåˆ†å‰²ç‰©ä½“ã€‚</li>
<li>å½“æ ‡è®°çš„è®­ç»ƒæ•°æ®ç¨€ç¼ºæ—¶ï¼Œå¯ä»¥å…ˆå¯¹è¾…åŠ©æ•°æ®é›†ï¼ˆä»»åŠ¡ï¼‰è¿›è¡Œå—ç›‘ç£çš„é¢„è®­ç»ƒï¼Œ éšåæ˜¯åŸºäºåŸŸè¿›è¡Œç‰¹å®šè°ƒæ•´ï¼Œäº§ç”Ÿæ˜¾ç€çš„æ€§èƒ½æå‡ã€‚</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>å…³äºå„ç§è§†è§‰è¯†åˆ«ä»»åŠ¡çš„ä¸Šä¸€ä¸ªåå¹´çš„è¿›å±•ä¸»è¦åŸºäºSIFTå’ŒHOGçš„ä½¿ç”¨</li>
<li><p>å®ç°è¿™ä¸ªç»“æœéœ€è¦è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼š</p>
<ul>
<li>åˆ©ç”¨æ·±åº¦ç½‘ç»œå°†å¯¹è±¡å®šä½</li>
<li>ä»…åˆ©ç”¨å°‘é‡çš„æ³¨é‡Šæ£€æµ‹æ•°æ®æ¥è®­ç»ƒè®­ç»ƒé«˜å®¹é‡æ¨¡å‹ã€‚</li>
</ul>
</li>
<li>æˆ‘ä»¬é€šè¿‡åœ¨â€œä½¿ç”¨åŒºåŸŸè¯†åˆ«â€èŒƒä¾‹å†…æ“ä½œï¼Œæ¥è§£å†³CNNå®šä½é—®é¢˜</li>
<li>åœ¨æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºè¾“å…¥å›¾åƒç”Ÿæˆå¤§çº¦2000ä¸ªç±»åˆ«æ— å…³åŒºåŸŸææ¡ˆï¼Œä½¿ç”¨CNNä»æ¯ä¸ªproposalä¸­æå–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œç„¶åä½¿ç”¨ç±»åˆ«ç‰¹å®šçš„çº¿æ€§SVMå¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œåˆ†ç±»ã€‚</li>
<li>æ£€æµ‹ä¸­é¢ä¸´çš„ç¬¬äºŒä¸ªæŒ‘æˆ˜æ˜¯æ ‡è®°çš„æ•°æ®ä¸è¶³ï¼Œç›®å‰å¯ç”¨çš„æ•°æ®æ•°é‡ä¸è¶³ä»¥è®­ç»ƒå¤§å‹CNNã€‚è¿™ä¸ªé—®é¢˜çš„å¸¸è§„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ— ç›‘ç£é¢„è®­ç»ƒï¼Œç„¶åæ˜¯ç›‘ç£ fine-tuningã€‚</li>
<li>æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºCNNï¼Œæœ‰å¾ˆå¤§æ¯”ä¾‹çš„å‚æ•°ï¼ˆ94%ï¼‰å¯ä»¥åœ¨æ£€æµ‹ç²¾åº¦çš„é€‚åº¦é™ä½çš„æƒ…å†µä¸‹è¢«å»é™¤ã€‚</li>
<li>æˆ‘ä»¬è¯æ˜ä¸€ä¸ªç®€å•çš„ <strong>è¾¹ç•Œæ¡†å›å½’æ–¹æ³•ï¼ˆbounding box regressionï¼‰</strong> æ˜¾ç€å‡å°‘è¯¯å®šä½ï¼Œè¿™æ˜¯ä¸»è¦çš„è¯¯å·®æ¨¡å¼(error mode)ã€‚</li>
<li>åœ¨å¼€å‘æŠ€æœ¯ç»†èŠ‚ä¹‹å‰ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°ï¼Œå› ä¸ºR-CNNåœ¨æ˜¯åŒºåŸŸä¸Šæ“ä½œï¼Œæ‰€ä»¥å¾ˆè‡ªç„¶å°†å…¶æ‰©å±•åˆ°è¯­ä¹‰åˆ†å‰²ï¼ˆsemantic segmentationï¼‰çš„ä»»åŠ¡ã€‚</li>
</ul>
<h2 id="Object-detection-with-R-CNN"><a href="#Object-detection-with-R-CNN" class="headerlink" title="Object detection with R-CNN"></a>Object detection with R-CNN</h2><ul>
<li><p>æˆ‘ä»¬çš„å¯¹è±¡æ£€æµ‹ç³»ç»Ÿç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆ:</p>
<ul>
<li>é¦–å…ˆç”Ÿæˆç±»åˆ«ç‹¬ç«‹(category-independent)åŒºåŸŸproposalã€‚ è¿™äº›proposalå®šä¹‰äº†å¯ç”¨äºæ£€æµ‹å™¨çš„å€™é€‰æ£€æµ‹é›†åˆã€‚</li>
<li>ç¬¬äºŒä¸ªæ¨¡å—æ˜¯å¤§å·ç§¯ç¥ç»ç½‘ç»œï¼Œä»æ¯ä¸ªåŒºåŸŸæå–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚</li>
<li>ç¬¬ä¸‰ä¸ªæ¨¡å—æ˜¯ä¸€ç±»ç‰¹å®šç±»å‹çš„çº¿æ€§SVMã€‚</li>
</ul>
</li>
</ul>
<h3 id="Module-design"><a href="#Module-design" class="headerlink" title="Module design"></a>Module design</h3><ul>
<li><p>Region proposals: ç›®å‰æœ‰å¾ˆå¤šç”¨æ¥ç”Ÿæˆcategory-independentçš„region proposalçš„æ–¹æ³•ï¼š</p>
<ul>
<li>Objectness</li>
<li>selective search</li>
<li>category-independent object proposals</li>
<li>constrained parametric min-cuts (CPMC)</li>
<li>multi-scale combinatorial grouping</li>
<li>detect mitotic cells by applying a CNN to regularly-spaced square crops, which are a special case of region proposals.(é€šè¿‡å°†CNNåº”ç”¨äºè§„åˆ™é—´éš”çš„æ–¹å½¢ä½œç‰©æ¥æ£€æµ‹æœ‰ä¸åˆ†è£‚ç»†èƒï¼Œè¿™æ˜¯åŒºåŸŸææ¡ˆçš„ç‰¹æ®Šæƒ…å†µã€‚)</li>
</ul>
</li>
<li><p>è™½ç„¶R-CNNä¸ç‰¹å®šåŒºåŸŸå»ºè®®æ–¹æ³•æ— å…³ï¼Œä½†æˆ‘ä»¬ä½¿ç”¨é€‰æ‹©æ€§æœç´¢(selective search)æ¥å®ç°ä¸å…ˆå‰æ£€æµ‹å·¥ä½œçš„å—æ§æ¯”è¾ƒ</p>
</li>
<li><p>Feature extraction:æˆ‘ä»¬ä»æ¯ä¸ªåŒºåŸŸææ¡ˆä¸­æå–ä¸€ä¸ª4096ç»´ç‰¹å¾å‘é‡ï¼Œç‰¹å¾é€šè¿‡å‰å‘ä¼ æ’­å¯¹227Ã—227 RGBå›¾åƒé€šè¿‡ <strong>äº”ä¸ªå·ç§¯å±‚å’Œä¸¤ä¸ªå®Œå…¨è¿æ¥çš„å±‚</strong> è®¡ç®—ã€‚</p>
</li>
<li>æ— è®ºå€™é€‰åŒºåŸŸçš„å¤§å°æˆ–å®½é«˜æ¯”å¦‚ä½•ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†å…¶å‘¨å›´çš„ç´§å¯†è¾¹ç•Œæ¡†ä¸­çš„æ‰€æœ‰åƒç´ è£…åˆ°æ‰€éœ€çš„å¤§å°(227x227åƒç´ å°ºå¯¸)ã€‚</li>
</ul>
<h3 id="Test-time-detection"><a href="#Test-time-detection" class="headerlink" title="Test-time detection"></a>Test-time detection</h3><ul>
<li>åœ¨æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬å¯¹æµ‹è¯•å›¾åƒè¿è¡Œé€‰æ‹©æ€§æœç´¢ä»¥æå–å¤§çº¦2000ä¸ªåŒºåŸŸå»ºè®®ï¼ˆæˆ‘ä»¬åœ¨æ‰€æœ‰å®éªŒä¸­ä½¿ç”¨é€‰æ‹©æ€§æœç´¢çš„â€œå¿«é€Ÿæ¨¡å¼ï¼ˆfast modeï¼‰â€ï¼‰ã€‚</li>
<li>ç»™å®šå›¾åƒä¸­çš„æ‰€æœ‰å¾—åˆ†åŒºåŸŸï¼Œæˆ‘ä»¬åº”ç”¨è´ªå¿ƒéæœ€å¤§æŠ‘åˆ¶(greedy non-maximum suppression)ï¼ˆå¯¹äºæ¯ä¸ªç±»ç‹¬ç«‹åœ°ï¼‰ï¼Œå¦‚æœä¸çš„é¥­è¾ƒé«˜çš„åŒºåŸŸæœ‰é‡å ï¼Œä¸”IoUå¤§äºå­¦ä¹ åˆ°çš„é˜ˆå€¼ï¼Œåˆ™è¯¥æ‹’ç»åŒºåŸŸã€‚</li>
<li><p>Run-time analysis.ä¸¤ä¸ªå±æ€§ä½¿æ£€æµ‹æ›´é«˜æ ¡ã€‚</p>
<ul>
<li>é¦–å…ˆï¼Œæ‰€æœ‰CNNå‚æ•°åœ¨æ‰€æœ‰ç±»åˆ«ä¸­å…±äº«ã€‚</li>
<li>ç¬¬äºŒï¼ŒCNNè®¡ç®—çš„ç‰¹å¾å‘é‡ä¸å…¶ä»–å¸¸è§æ–¹æ³•ï¼ˆä¾‹å¦‚å…·æœ‰è§†è§‰è¯è¢‹ç¼–ç çš„ç©ºé—´æ£±é‡‘å­—å¡”ï¼‰ç›¸æ¯”æ˜¯ <strong>ä½ç»´çš„</strong> ã€‚</li>
<li>å”¯ä¸€çš„ç±»ç‰¹å®š(class-specific)è®¡ç®—æ˜¯ç‰¹å¾å’ŒSVMæƒé‡ä¹‹é—´çš„ç‚¹ç§¯å’Œéæœ€å¤§æŠ‘åˆ¶ã€‚</li>
</ul>
</li>
</ul>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ul>
<li>é™¤äº†ç”¨éšæœºåˆå§‹åŒ–çš„21è·¯åˆ†ç±»å±‚ï¼ˆå¯¹äº20ä¸ªVOCç±»åŠ ä¸ŠèƒŒæ™¯ï¼‰æ›¿æ¢CNNçš„ImageNetç‰¹å®šçš„1000è·¯åˆ†ç±»å±‚ä¹‹å¤–ï¼ŒCNNæ¶æ„æ˜¯ä¸å˜çš„ã€‚</li>
<li>æˆ‘ä»¬å°†æ‰€æœ‰region proposalä¸ä¸€ä¸ªground-truthé‡å ä¸ºIoU&gt;0.5ï¼Œä½œä¸ºè¯¥æ¡†ç±»çš„é˜³æ€§ï¼Œå…¶ä½™ä½œä¸ºé˜´æ€§ã€‚</li>
<li>æˆ‘ä»¬ä»¥0.001çš„å­¦ä¹ é€Ÿç‡ï¼ˆåˆå§‹é¢„è®­ç»ƒé€Ÿç‡çš„1/10ï¼‰å¼€å§‹SGDï¼Œè¿™å…è®¸ç²¾ç»†è°ƒæ•´è¿›è¡Œï¼Œè€Œä¸æ˜¯ç ´ååˆå§‹åŒ–ã€‚</li>
<li>ä¸€æ—¦æå–ç‰¹å¾å¹¶åº”ç”¨è®­ç»ƒæ ‡ç­¾ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªç±»ä¼˜åŒ–ä¸€ä¸ªçº¿æ€§SVMã€‚</li>
<li>ç”±äºè®­ç»ƒæ•°æ®å¤ªå¤§ï¼Œæ— æ³•è®°å¿†ï¼Œæˆ‘ä»¬é‡‡ç”¨æ ‡å‡† <strong>hard negative mining method</strong> ã€‚</li>
</ul>
<h3 id="Results-on-PASCAL-VOC-2010-12"><a href="#Results-on-PASCAL-VOC-2010-12" class="headerlink" title="Results on PASCAL VOC 2010-12"></a>Results on PASCAL VOC 2010-12</h3><h2 id="Visualization-ablation-and-modes-of-error"><a href="#Visualization-ablation-and-modes-of-error" class="headerlink" title="Visualization, ablation, and modes of error"></a>Visualization, ablation, and modes of error</h2><h3 id="Visualizing-learned-features"><a href="#Visualizing-learned-features" class="headerlink" title="Visualizing learned features"></a>Visualizing learned features</h3><ul>
<li>pool-5ï¼Œæ˜¯ç½‘ç»œç¬¬äº”ä¸ªä¹Ÿæ˜¯æœ€åä¸€ä¸ªå·åŸºå±‚çš„max-poolå±‚çš„è¾“å‡ºã€‚ï¼ˆæ˜¯ä¸€ä¸ªmax-poolingå±‚ï¼‰</li>
<li>The pool-5 feature map is 6 Ã— 6 Ã— 256 = 9216ç»´ã€‚</li>
<li>å¿½ç•¥è¾¹ç•Œæ•ˆåº”ï¼Œæ¯ä¸ªpool-5å•å…ƒåœ¨åŸå§‹227Ã—227åƒç´ è¾“å…¥ä¸­å…·æœ‰195Ã—195åƒç´ çš„æ¥æ”¶åœºã€‚</li>
</ul>
<h3 id="Ablation-studies"><a href="#Ablation-studies" class="headerlink" title="Ablation studies"></a>Ablation studies</h3><ul>
<li>Fc6ä¸pool-5å…¨è¿æ¥ï¼Œä¸ºäº†è®¡ç®—ç‰¹å¾ï¼Œä»–å®ƒå°† <strong>4096Ã—9216çš„æƒé‡çŸ©é˜µä¹˜ä»¥pool-5çš„feature map</strong> ï¼ˆé‡æ–°å½¢æˆä¸º9216ç»´çŸ¢é‡ï¼‰ï¼Œç„¶åæ·»åŠ åå·®çŸ¢é‡ã€‚</li>
<li>Fc7æ˜¯ç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œé€šè¿‡å°†ç”±fc 6è®¡ç®—çš„ç‰¹å¾ä¹˜ä»¥ <strong>4096Ã—4096</strong> æƒé‡çŸ©é˜µï¼Œå¹¶ç±»ä¼¼åœ°æ·»åŠ åç½®çŸ¢é‡å’Œåº”ç”¨åŠæ³¢æ•´æµæ¥å®ç°ã€‚</li>
<li>å¤§å¤šæ•°CNNçš„è¡¨ç¤ºèƒ½åŠ›æ¥è‡ªå®ƒçš„å·ç§¯å±‚ï¼Œè€Œä¸æ˜¯æ¥è‡ªå¤§å¾—å¤šçš„å¯†é›†è¿æ¥çš„å±‚ã€‚</li>
<li>All R-CNN variants strongly outperform the three DPM baselines</li>
</ul>
<h3 id="Detection-error-analysis"><a href="#Detection-error-analysis" class="headerlink" title="Detection error analysis"></a>Detection error analysis</h3><h3 id="Bounding-box-regression"><a href="#Bounding-box-regression" class="headerlink" title="Bounding box regression"></a>Bounding box regression</h3><h2 id="Semantic-segmentation"><a href="#Semantic-segmentation" class="headerlink" title="Semantic segmentation"></a>Semantic segmentation</h2><ul>
<li>full</li>
<li>fg</li>
<li>full+fg</li>
<li>The fg strategy slightly outperforms full, indicating that the masked region shape provides a stronger signal, matching our intuition.</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul>
<li>ä¹‹å‰æœ€å¥½çš„æ€§èƒ½ç³»ç»Ÿæ˜¯å°†å¤šä¸ªä½çº§å›¾åƒç‰¹å¾ä¸æ¥è‡ªå¯¹è±¡æ£€æµ‹å™¨å’Œåœºæ™¯åˆ†ç±»å™¨çš„é«˜çº§ä¸Šä¸‹æ–‡ç»„åˆåœ¨ä¸€èµ·çš„å¤æ‚é›†åˆã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç®€å•å’Œå¯æ‰©å±•çš„å¯¹è±¡æ£€æµ‹ç®—æ³•ï¼Œä¸PASCAL VOC 2012ä¸Šçš„æœ€ä½³ä»¥å‰çš„ç»“æœç›¸æ¯”æä¾›30ï¼…çš„ç›¸å¯¹æ”¹è¿›ã€‚</li>
<li>æˆ‘ä»¬æ¨æµ‹â€œsupervised pre-training/domain-speciï¬c ï¬ne-tuningâ€èŒƒä¾‹å°†å¯¹å„ç§æ•°æ®ç¼ºä¹çš„è§†è§‰é—®é¢˜é«˜åº¦æœ‰æ•ˆã€‚</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;mAP: mean average precisionï¼Œå¹³å‡å‡†ç¡®åº¦&lt;/li&gt;
&lt;li&gt;&lt;p&gt;æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆä¸¤ä¸ªå…³é”®çš„è§è§£ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¬¬ä¸€ï¼šé‡‡ç”¨é«˜å®¹é‡çš„å·ç§¯ç¥ç»ç½‘ç»œæ¥ä»ä¸Šåˆ°ä¸‹çš„è¿›è¡Œregion proposalï¼Œä»è€Œå®ç°å®šä½å’Œåˆ†å‰²ç‰©ä½“ã€‚&lt;/li&gt;
&lt;li&gt;å½“æ ‡è®°çš„è®­ç»ƒæ•°æ®ç¨€ç¼ºæ—¶ï¼Œå¯ä»¥å…ˆå¯¹è¾…åŠ©æ•°æ®é›†ï¼ˆä»»åŠ¡ï¼‰è¿›è¡Œå—ç›‘ç£çš„é¢„è®­ç»ƒï¼Œ éšåæ˜¯åŸºäºåŸŸè¿›è¡Œç‰¹å®šè°ƒæ•´ï¼Œäº§ç”Ÿæ˜¾ç€çš„æ€§èƒ½æå‡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šFused DNN - A deep neural network fusion approach to fast and robust pedestrian detection</title>
    <link href="http://jacobkong.github.io/posts/2553947436/"/>
    <id>http://jacobkong.github.io/posts/2553947436/</id>
    <published>2016-12-04T22:32:24.000Z</published>
    <updated>2017-01-28T09:00:31.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ç›¸å…³çŸ¥è¯†ç‚¹"><a href="#ç›¸å…³çŸ¥è¯†ç‚¹" class="headerlink" title="ç›¸å…³çŸ¥è¯†ç‚¹"></a>ç›¸å…³çŸ¥è¯†ç‚¹</h2><ul>
<li><strong>L1èŒƒæ•°</strong> ä¹Ÿç§°ä¸ºæœ€å°ç»å¯¹åå·®ï¼ˆLADï¼‰ï¼Œæœ€å°ç»å¯¹è¯¯å·®ï¼ˆLAEï¼‰ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„ç»å¯¹å·®(S)çš„å’Œ</li>
</ul>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqk8unvtj306d0273ye.jpg" alt=""></p>
<ul>
<li>L2èŒƒæ•°ä¹Ÿç§°ä¸ºæœ€å°äºŒä¹˜ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„å·®(S)çš„å¹³æ–¹çš„å’Œ</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk9chp0j305w01wjra.jpg" alt=""></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>æ‰€æå‡ºçš„ç½‘ç»œèåˆæ¶æ„å…è®¸å¤šä¸ªç½‘ç»œçš„å¹¶è¡Œå¤„ç†æ¥æé«˜é€Ÿåº¦ã€‚</li>
<li>é¦–å…ˆæ˜¯ä¸€ä¸ªæ·±åº¦å·ç§¯ç½‘ç»œè¢«è®­ç»ƒä¸ºä¸€ä¸ªç‰©ä½“æ£€æµ‹å™¨æ¥ç”Ÿæˆæ‰€æœ‰æœ‰å¯èƒ½çš„ä¸åŒå°ºå¯¸å’Œé®æŒ¡çš„è¡Œäººå€™é€‰é›†ã€‚</li>
<li>ç„¶åï¼Œå¤šä¸ªæ·±åº¦ç¥ç»ç½‘ç»œè¢«å¹¶è¡Œä½¿ç”¨æ¥ä¹‹åæç‚¼è¿™äº›è¡Œäººå€™é€‰é›†ã€‚</li>
<li>æˆ‘ä»¬å¼•å…¥åŸºäºè½¯æ‹’ç»çš„ç½‘ç»œèåˆæ–¹æ³•å°†æ¥è‡ªæ‰€æœ‰ç½‘ç»œçš„è½¯åº¦é‡èåˆåœ¨ä¸€èµ·ï¼Œä»¥äº§ç”Ÿæœ€ç»ˆç½®ä¿¡åˆ†æ•°ã€‚</li>
<li>æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå°†é€åƒç´ è¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼ˆ pixel-wise semantic segmentation networkï¼‰é›†æˆåˆ°ç½‘ç»œèåˆæ¶æ„ä¸­ä½œä¸ºè¡Œäººæ£€æµ‹å™¨çš„åŠ å¼ºçš„æ–¹æ³•ã€‚</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Tradeoff between accuracy and speed.</li>
<li>å…¶ä»–å› ç´ ï¼Œå¦‚æ‹¥æŒ¤çš„åœºæ™¯ï¼Œéäººå µå¡ç‰©ä½“(non-person occluding objects)æˆ–ä¸åŒçš„è¡Œäººå¤–è§‚ï¼ˆä¸åŒçš„å§¿åŠ¿æˆ–æœè£…é£æ ¼ï¼‰ä¹Ÿä½¿è¿™ä¸ªReal-timeè¡Œäººæ£€æµ‹é—®é¢˜å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>è¡Œäººæ£€æµ‹çš„ä¸€èˆ¬æ¡†æ¶å¯ä»¥åˆ†è§£ä¸ºï¼š</li>
<li>region proposal generation,</li>
<li>feature extraction,</li>
<li><p>pedestrian verification</p>
</li>
<li><p>Fused Deep Neural Network(F-DNN)</p>
</li>
<li>è¯¥æ¶æ„åŒ…æ‹¬è¡Œäººpedestrian candidiate generatorï¼Œå…¶é€šè¿‡è®­ç»ƒæ·±å·ç§¯ç¥ç»ç½‘ç»œè·å¾—ä»¥ï¼Œä»è€Œå…·æœ‰é«˜æ£€æµ‹ç‡ï¼Œè™½ç„¶æœ‰å¤§çš„å‡é˜³æ€§ç‡ã€‚</li>
<li>ä½¿ç”¨æ·±åº¦æ‰©å±•å·ç§¯å’Œä¸Šä¸‹æ–‡èšåˆçš„å¹¶è¡Œè¯­ä¹‰åˆ†å‰²ç½‘ç»œ[30]ä¸ºå€™é€‰è¡Œäººæä¾›äº†å¦ä¸€ä¸ªè½¯çš„ä¿¡ä»»æŠ•ç¥¨ï¼Œå®ƒè¿›ä¸€æ­¥ä¸å€™é€‰ç”Ÿæˆå™¨å’Œåˆ†ç±»ç½‘ç»œèåˆã€‚</li>
</ul>
<h2 id="The-Fused-Deep-Neural-Network"><a href="#The-Fused-Deep-Neural-Network" class="headerlink" title="The Fused Deep Neural Network"></a>The Fused Deep Neural Network</h2><ul>
<li>æå‡ºçš„ç½‘ç»œæ¶æ„åŒ…æ‹¬è¡Œäººå€™é€‰ç”Ÿæˆå™¨ï¼Œåˆ†ç±»ç½‘ç»œå’Œåƒç´ çº§è¯­ä¹‰åˆ†å‰²ç½‘ç»œã€‚</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk6f5o3j30q00iumyv.jpg" alt=""></p>
<ul>
<li><p>SSD: a single shot multi-box detector(å•é•œå¤´å¤šç®±æ£€æµ‹å™¨)ï¼Œè¡Œäººå€™é€‰ç”Ÿæˆå™¨æ˜¯ä¸€ä¸ªsingle shot multi-box detectorï¼ˆSSDï¼‰</p>
</li>
<li><p>æ¯ä¸ªè¡Œäººå€™é€‰è€…ä¸å…¶å®šä½BBåæ ‡å’Œç½®ä¿¡åº¦å¾—åˆ†ç›¸å…³è”ã€‚</p>
</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç½‘ç»œèåˆæ–¹æ³•â€”â€”ç§°ä¸ºåŸºäºè½¯æ‹’ç»çš„ç½‘ç»œèåˆï¼ˆSNFï¼‰ã€‚å¹¶éæ˜¯æ‰§è¡Œæ¥å—æˆ–æ‹’ç»å€™é€‰è€…çš„ç¡¬äºŒè¿›åˆ¶åˆ†ç±»ï¼Œè€Œæ˜¯åŸºäºæ¥è‡ªåˆ†ç±»å™¨çš„å€™é€‰è€…çš„ <strong>èšåˆåº¦</strong> æ¥æå‡æˆ–æŠ˜æ‰£è¡Œäººå€™é€‰è€…çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚</li>
<li>æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åˆ©ç”¨å…·æœ‰è¯­ä¹‰åˆ†å‰²ï¼ˆSSï¼‰çš„ä¸Šä¸‹æ–‡èšé›†æ‰©å±•å·ç§¯ç½‘ç»œï¼ˆcontext aggregation dilated convolutional network with semantic segmentationï¼‰ä½œä¸ºå¦ä¸€ä¸ªåˆ†ç±»å™¨å¹¶å°†å…¶é›†æˆåˆ°æˆ‘ä»¬çš„ç½‘ç»œèåˆæ¶æ„ä¸­çš„æ–¹æ³•ã€‚ä½†æ˜¯åœ¨é€Ÿåº¦ä¸Šä¼šå˜å¾—ç‰¹åˆ«æ…¢ã€‚</li>
</ul>
<h3 id="Pedestrian-Candidate-Generator"><a href="#Pedestrian-Candidate-Generator" class="headerlink" title="Pedestrian Candidate Generator"></a>Pedestrian Candidate Generator</h3><ul>
<li>SSDæ˜¯å…·æœ‰æˆªæ–­VGG16(truncated VGG16)ä½œä¸ºåŸºç¡€ç½‘ç»œçš„å‰é¦ˆå·ç§¯ç½‘ç»œã€‚</li>
<li>SSDçš„ç»“æ„ï¼š</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqk7e7e6j30pe07rgmh.jpg" alt=""></p>
<ul>
<li><p>L2å½’ä¸€åŒ–æŠ€æœ¯ç”¨äºç¼©å°ç‰¹å¾é‡</p>
</li>
<li><p>å¯¹äºå¤§å°ä¸ºmÃ—nÃ—pçš„æ¯ä¸ªè¾“å‡ºå±‚ï¼Œåœ¨æ¯ä¸ªä½ç½®å¤„è®¾ç½®ä¸åŒå°ºåº¦å’Œçºµæ¨ªæ¯”çš„ä¸€ç»„é»˜è®¤BBã€‚ å°†3Ã—3Ã—pä¸ªå·ç§¯å†…æ ¸åº”ç”¨äºæ¯ä¸ªä½ç½®ä»¥äº§ç”Ÿå…³äºé»˜è®¤BBä½ç½®çš„åˆ†ç±»åˆ†æ•°å’ŒBBä½ç½®åç§»ã€‚</p>
</li>
<li>è®­ç»ƒçš„ç›®æ ‡å‡½æ•°æ˜¯ï¼š</li>
</ul>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqka1k2nj306u01nq2u.jpg" alt=""></p>
<h3 id="Classiï¬cation-Network-and-Soft-rejection-based-DNN-Fusion"><a href="#Classiï¬cation-Network-and-Soft-rejection-based-DNN-Fusion" class="headerlink" title="Classiï¬cation Network and Soft-rejection based DNN Fusion"></a>Classiï¬cation Network and Soft-rejection based DNN Fusion</h3><ul>
<li>åˆ†ç±»ç½‘ç»œç”±å¤šä¸ªäºŒå…ƒåˆ†ç±»æ·±å±‚ç¥ç»ç½‘ç»œç»„æˆï¼Œè¿™äº›ç½‘ç»œåœ¨ç¬¬ä¸€é˜¶æ®µçš„ç”Ÿæˆçš„è¡Œäººå€™é€‰é›†ä¸­è®­ç»ƒã€‚</li>
<li>SNFï¼šè€ƒè™‘ä¸€ä¸ªè¡Œäººå€™é€‰äººå’Œä¸€ä¸ªåˆ†ç±»å™¨ã€‚å¦‚æœåˆ†ç±»å™¨å¯¹å€™é€‰äººæœ‰é«˜çš„ä¿¡ä»»åº¦ï¼Œæˆ‘ä»¬é€šè¿‡ä¹˜ä»¥å¤§äº1çš„ç½®ä¿¡å› å­ä¹˜ä»¥å€™é€‰å‘ç”Ÿå™¨æ¥æé«˜å…¶åŸå§‹åˆ†æ•°ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬ä»¥å°äº1çš„ç¼©æ”¾å› å­å‡å°å…¶å¾—åˆ†ã€‚æˆ‘ä»¬å°†â€œç½®ä¿¡â€å®šä¹‰ä¸ºè‡³å°‘ä¸ºacçš„åˆ†ç±»æ¦‚ç‡ã€‚ä¸ºäº†èåˆæ‰€æœ‰Mä¸ªåˆ†ç±»å™¨ï¼Œæˆ‘ä»¬å°†å€™é€‰è€…çš„åŸå§‹ä¿¡ä»»å¾—åˆ†ä¸åˆ†ç±»ç½‘ç»œä¸­æ‰€æœ‰åˆ†ç±»å™¨çš„ä¿¡ä»»ç¼©æ”¾å› å­çš„ä¹˜ç§¯ç›¸ä¹˜ã€‚</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqkaszbpj30q202qt9i.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfqkaaiiij3086024t8n.jpg" alt=""></p>
<ul>
<li>SNFèƒŒåçš„å…³é”®æ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬ä¸ç›´æ¥æ¥å—æˆ–æ‹’ç»ä»»ä½•å€™é€‰è¡Œäººï¼Œè€Œæ˜¯åŸºäºåˆ†ç±»æ¦‚ç‡çš„å› ç´ æ¥æ‰©å±•å®ƒä»¬ã€‚</li>
</ul>
<h3 id="Pixel-wise-semantic-segmentation-for-object-detection-reinforcement"><a href="#Pixel-wise-semantic-segmentation-for-object-detection-reinforcement" class="headerlink" title="Pixel-wise semantic segmentation for object detection reinforcement"></a>Pixel-wise semantic segmentation for object detection reinforcement</h3><ul>
<li>ä¸ºäº†æ‰§è¡Œå¯†é›†é¢„æµ‹ï¼ŒSSç½‘ç»œç”±å®Œå…¨å·ç§¯çš„VGG16ç½‘ç»œç»„æˆï¼Œå…¶é€‚åº”äºä½œä¸ºå‰ç«¯é¢„æµ‹æ¨¡å—çš„æ‰©å±•å·ç§¯ï¼Œå…¶è¾“å‡ºè¢«é¦ˆé€åˆ°å¤šå°ºåº¦ä¸Šä¸‹æ–‡èšåˆæ¨¡å—ï¼Œè¯¥å¤šå°ºåº¦ä¸Šä¸‹æ–‡èšåˆæ¨¡å—ç”±å®Œå…¨å·ç§¯ç½‘ç»œç»„æˆï¼Œå…¶å·ç§¯å±‚å…·æœ‰å¢åŠ æ‰©å¼ å› å­ã€‚</li>
<li>è¾“å…¥å›¾åƒè¢«ç¼©æ”¾å¹¶ç”±SSç½‘ç»œç›´æ¥å¤„ç†ï¼ŒSSç½‘ç»œäº§ç”Ÿå…·æœ‰æ˜¾ç¤ºå‡ºè¡Œäººç±»æ¿€æ´»åƒç´ çš„ä¸€ç§é¢œè‰²å’Œæ˜¾ç¤ºå‡ºèƒŒæ™¯çš„å…¶ä»–é¢œè‰²çš„äºŒè¿›é®ç½©ã€‚</li>
<li>æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ç­–ç•¥æ¥èåˆç»“æœï¼šå¦‚æœè¡Œäººåƒç´ å æ®å€™é€‰BBåŒºåŸŸçš„è‡³å°‘20ï¼…ï¼Œæˆ‘ä»¬æ¥å—å€™é€‰è€…å¹¶ä¿æŒå…¶å¾—åˆ†ä¸å˜; å¦åˆ™ï¼Œæˆ‘ä»¬åº”ç”¨SNFæ¥ç¼©æ”¾åŸå§‹çš„ä¿¡ä»»åˆ†æ•°ã€‚</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqkbeg8wj30g002cwen.jpg" alt=""></p>
<h2 id="Experiments-and-result-analysis"><a href="#Experiments-and-result-analysis" class="headerlink" title="Experiments and result analysis"></a>Experiments and result analysis</h2><h3 id="Data-and-evaluation-settings"><a href="#Data-and-evaluation-settings" class="headerlink" title="Data and evaluation settings"></a>Data and evaluation settings</h3><h3 id="Training-details-and-results"><a href="#Training-details-and-results" class="headerlink" title="Training details and results"></a>Training details and results</h3><ul>
<li><strong>ç¡¬æ‹’ç»ï¼ˆHard Rejectionï¼‰</strong> è¢«å®šä¹‰ä¸ºæ¶ˆé™¤ç”±ä»»ä½•åˆ†ç±»å™¨åˆ†ç±»ä¸ºå‡é˜³æ€§çš„ä»»ä½•å€™é€‰è€…ã€‚</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ç›¸å…³çŸ¥è¯†ç‚¹&quot;&gt;&lt;a href=&quot;#ç›¸å…³çŸ¥è¯†ç‚¹&quot; class=&quot;headerlink&quot; title=&quot;ç›¸å…³çŸ¥è¯†ç‚¹&quot;&gt;&lt;/a&gt;ç›¸å…³çŸ¥è¯†ç‚¹&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;L1èŒƒæ•°&lt;/strong&gt; ä¹Ÿç§°ä¸ºæœ€å°ç»å¯¹åå·®ï¼ˆLADï¼‰ï¼Œæœ€å°ç»å¯¹è¯¯å·®ï¼ˆLAEï¼‰ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„ç»å¯¹å·®(S)çš„å’Œ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqk8unvtj306d0273ye.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2èŒƒæ•°ä¹Ÿç§°ä¸ºæœ€å°äºŒä¹˜ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„å·®(S)çš„å¹³æ–¹çš„å’Œ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk9chp0j305w01wjra.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;æ‰€æå‡ºçš„ç½‘ç»œèåˆæ¶æ„å…è®¸å¤šä¸ªç½‘ç»œçš„å¹¶è¡Œå¤„ç†æ¥æé«˜é€Ÿåº¦ã€‚&lt;/li&gt;
&lt;li&gt;é¦–å…ˆæ˜¯ä¸€ä¸ªæ·±åº¦å·ç§¯ç½‘ç»œè¢«è®­ç»ƒä¸ºä¸€ä¸ªç‰©ä½“æ£€æµ‹å™¨æ¥ç”Ÿæˆæ‰€æœ‰æœ‰å¯èƒ½çš„ä¸åŒå°ºå¯¸å’Œé®æŒ¡çš„è¡Œäººå€™é€‰é›†ã€‚&lt;/li&gt;
&lt;li&gt;ç„¶åï¼Œå¤šä¸ªæ·±åº¦ç¥ç»ç½‘ç»œè¢«å¹¶è¡Œä½¿ç”¨æ¥ä¹‹åæç‚¼è¿™äº›è¡Œäººå€™é€‰é›†ã€‚&lt;/li&gt;
&lt;li&gt;æˆ‘ä»¬å¼•å…¥åŸºäºè½¯æ‹’ç»çš„ç½‘ç»œèåˆæ–¹æ³•å°†æ¥è‡ªæ‰€æœ‰ç½‘ç»œçš„è½¯åº¦é‡èåˆåœ¨ä¸€èµ·ï¼Œä»¥äº§ç”Ÿæœ€ç»ˆç½®ä¿¡åˆ†æ•°ã€‚&lt;/li&gt;
&lt;li&gt;æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå°†é€åƒç´ è¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼ˆ pixel-wise semantic segmentation networkï¼‰é›†æˆåˆ°ç½‘ç»œèåˆæ¶æ„ä¸­ä½œä¸ºè¡Œäººæ£€æµ‹å™¨çš„åŠ å¼ºçš„æ–¹æ³•ã€‚&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="Deep Learning" scheme="http://jacobkong.github.io/tags/Deep-Learning/"/>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://jacobkong.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šRobust Real-Time Face Detection</title>
    <link href="http://jacobkong.github.io/posts/2903903730/"/>
    <id>http://jacobkong.github.io/posts/2903903730/</id>
    <published>2016-12-03T22:32:24.000Z</published>
    <updated>2017-01-28T07:37:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="çŸ¥è¯†ç‚¹"><a href="#çŸ¥è¯†ç‚¹" class="headerlink" title="çŸ¥è¯†ç‚¹"></a>çŸ¥è¯†ç‚¹</h2><ul>
<li>å‚…é‡Œå¶å˜æ¢çš„ä¸€ä¸ªæ¨è®ºï¼š<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrudkda8j308h01d3yg.jpg" alt=""></li>
</ul>
<p>ä¸€ä¸ªæ—¶åŸŸä¸‹çš„å¤æ‚ä¿¡å·å‡½æ•°å¯ä»¥åˆ†è§£æˆå¤šä¸ªç®€å•ä¿¡å·å‡½æ•°çš„å’Œï¼Œç„¶åå¯¹å„ä¸ªå­ä¿¡å·å‡½æ•°åšå‚…é‡Œå¶å˜æ¢å¹¶å†æ¬¡æ±‚å’Œï¼Œå°±æ±‚å‡ºäº†åŸä¿¡å·çš„å‚…é‡Œå¶å˜æ¢ã€‚</p>
<ul>
<li><p>å·ç§¯å®šç†(Convolution Theorem)ï¼šä¿¡å·få’Œä¿¡å·gçš„å·ç§¯çš„å‚…é‡Œå¶å˜æ¢ï¼Œç­‰äºfã€gå„è‡ªçš„å‚…é‡Œå¶å˜æ¢çš„ç§¯<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfrue2zlyj304n01gdfp.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrufxyw0j306z0263yf.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfru90t5uj30jt09j75c.jpg" alt=""><br>æ•´ä¸ªè¿‡ç¨‹çš„æ ¸å¿ƒå°±æ˜¯â€œï¼ˆåè½¬ï¼‰ï¼Œç§»åŠ¨ï¼Œä¹˜ç§¯ï¼Œæ±‚å’Œâ€</p>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>äºŒç»´å·ç§¯</p>
<ul>
<li><p>æ•°å­¦å®šä¹‰<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfru5ml16j30f901kdfv.jpg" alt=""></p>
<p>äºŒç»´å·ç§¯åœ¨å›¾åƒå¤„ç†ä¸­ä¼šç»å¸¸é‡åˆ°ï¼Œå›¾åƒå¤„ç†ä¸­ç”¨åˆ°çš„å¤§å¤šæ˜¯äºŒç»´å·ç§¯çš„ç¦»æ•£å½¢å¼ï¼š<br><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfrum5q4ej30cv01o74a.jpg" alt=""></p>
</li>
<li>å›¾åƒå¤„ç†ä¸­çš„äºŒç»´å·ç§¯ï¼ŒäºŒç»´å·ç§¯å°±æ˜¯ä¸€ç»´å·ç§¯çš„æ‰©å±•ï¼ŒåŸç†å·®ä¸å¤šã€‚æ ¸å¿ƒè¿˜æ˜¯ï¼ˆåè½¬ï¼‰ï¼Œç§»åŠ¨ï¼Œä¹˜ç§¯ï¼Œæ±‚å’Œã€‚è¿™é‡ŒäºŒç»´çš„åè½¬å°±æ˜¯å°†å·ç§¯æ ¸æ²¿åå¯¹è§’çº¿ç¿»è½¬ï¼Œæ¯”å¦‚ï¼š<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfru4uj25j307m02wjrd.jpg" alt=""><br>ä¹‹åï¼Œå·ç§¯æ ¸åœ¨äºŒç»´å¹³é¢ä¸Šå¹³ç§»ï¼Œå¹¶ä¸”å·ç§¯æ ¸çš„æ¯ä¸ªå…ƒç´ ä¸è¢«å·ç§¯å›¾åƒå¯¹åº”ä½ç½®ç›¸ä¹˜ï¼Œå†æ±‚å’Œã€‚é€šè¿‡å·ç§¯æ ¸çš„ä¸æ–­ç§»åŠ¨ï¼Œæˆ‘ä»¬å°±æœ‰äº†ä¸€ä¸ªæ–°çš„å›¾åƒï¼Œ <strong>è¿™ä¸ªå›¾åƒå®Œå…¨ç”±å·ç§¯æ ¸åœ¨å„ä¸ªä½ç½®æ—¶çš„ä¹˜ç§¯æ±‚å’Œçš„ç»“æœç»„æˆã€‚</strong></li>
</ul>
</li>
<li><p>å·´æ‹¿èµ«ç©ºé—´ï¼šæ›´ç²¾ç¡®åœ°è¯´ï¼Œå·´æ‹¿èµ«ç©ºé—´æ˜¯ä¸€ä¸ªå…·æœ‰èŒƒæ•°å¹¶å¯¹æ­¤èŒƒæ•°å®Œå¤‡çš„å‘é‡ç©ºé—´ã€‚</p>
</li>
<li><p>è®¸å¤šåœ¨æ•°å­¦åˆ†æä¸­å­¦åˆ°çš„æ— é™ç»´å‡½æ•°ç©ºé—´éƒ½æ˜¯å·´æ‹¿èµ«ç©ºé—´ã€‚</p>
</li>
<li><p>å·´æ‹¿èµ«ç©ºé—´æœ‰ä¸¤ç§å¸¸è§çš„ç±»å‹ï¼šâ€œå®å·´æ‹¿èµ«ç©ºé—´â€åŠâ€œå¤å·´æ‹¿èµ«ç©ºé—´â€ï¼Œåˆ†åˆ«æ˜¯æŒ‡å°†å·´æ‹¿èµ«ç©ºé—´çš„å‘é‡ç©ºé—´å®šä¹‰äºç”±å®æ•°æˆ–å¤æ•°ç»„æˆçš„åŸŸä¹‹ä¸Šã€‚</p>
</li>
<li><p>Overcompleteï¼š</p>
<ul>
<li>å¯¹äºBanach space Xä¸­çš„ä¸€ä¸ªå­é›†ï¼Œå¦‚æœXä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½å¯ä»¥åˆ©ç”¨å­é›†ä¸­çš„å…ƒç´ åœ¨èŒƒæ•°å†…è¿›è¡Œæœ‰é™çº¿æ€§ç»„åˆæ¥è‰¯å¥½è¿‘ä¼¼ï¼Œåˆ™è¯¥ç³»ç»ŸXæ˜¯å®Œå¤‡Completeçš„ã€‚</li>
<li>è¯¥å®Œå¤‡ç³»ç»Ÿæ˜¯è¿‡å®Œå¤‡ï¼ˆOvercompleteï¼‰çš„ï¼Œå¦‚æœä»å­é›†ä¸­ç§»å»ä¸€ä¸ªå…ƒç´ ï¼Œè¯¥ç³»ç»Ÿä¾æ—§æ˜¯å®Œå¤‡çš„ï¼Œåˆ™è¯¥ç³»ç»Ÿç§°ä¸ºè¿‡å®Œå¤‡çš„ã€‚</li>
<li>åœ¨ä¸åŒçš„ç ”ç©¶ä¸­ï¼Œæ¯”å¦‚ä¿¡å·å¤„ç†å’ŒåŠŸèƒ½è¿‘ä¼¼ï¼Œè¿‡å®Œå¤‡å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜è¾¾åˆ°ä¸€ä¸ªæ›´ç¨³å®šã€æ›´å¥å£®ï¼Œæˆ–è€…ç›¸æ¯”äºä½¿ç”¨åŸºå‘é‡æ›´ç´§å‡‘çš„åˆ†è§£ã€‚</li>
<li>å¦‚æœ # (basis vectoråŸºå‘é‡)&gt;è¾“å…¥çš„ç»´åº¦ï¼Œåˆ™æˆ‘ä»¬æœ‰ä¸€ä¸ªovercomplete representation.</li>
</ul>
</li>
<li><p>ROCæ›²çº¿ï¼šåœ¨ä¿¡å·æ£€æµ‹ç†è®ºä¸­ï¼Œæ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼ˆreceiver operating characteristic curveï¼Œæˆ–è€…å«ROCæ›²çº¿ï¼‰æ˜¯ä¸€ç§åæ ‡å›¾å¼çš„åˆ†æå·¥å…·ï¼Œç”¨äº</p>
<ul>
<li>(1) é€‰æ‹©æœ€ä½³çš„ä¿¡å·ä¾¦æµ‹æ¨¡å‹ã€èˆå¼ƒæ¬¡ä½³çš„æ¨¡å‹ã€‚</li>
<li>(2) åœ¨åŒä¸€æ¨¡å‹ä¸­è®¾å®šæœ€ä½³é˜ˆå€¼ã€‚</li>
<li>ä» (0, 0) åˆ° (1,1) çš„å¯¹è§’çº¿å°†ROCç©ºé—´åˆ’åˆ†ä¸ºå·¦ä¸Šï¼å³ä¸‹ä¸¤ä¸ªåŒºåŸŸï¼Œåœ¨è¿™æ¡çº¿çš„ <strong>ä»¥ä¸Šçš„ç‚¹</strong> ä»£è¡¨äº†ä¸€ä¸ª <strong>å¥½</strong> çš„åˆ†ç±»ç»“æœï¼ˆèƒœè¿‡éšæœºåˆ†ç±»ï¼‰ï¼Œè€Œåœ¨è¿™æ¡çº¿ <strong>ä»¥ä¸‹çš„ç‚¹</strong> ä»£è¡¨äº† <strong>å·®</strong> çš„åˆ†ç±»ç»“æœï¼ˆåŠ£äºéšæœºåˆ†ç±»ï¼‰ã€‚</li>
<li>å®Œç¾çš„é¢„æµ‹æ˜¯ä¸€ä¸ªåœ¨å·¦ä¸Šè§’çš„ç‚¹.</li>
<li>æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰ï¼šROCæ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ï¼Œè‹¥éšæœºæŠ½å–ä¸€ä¸ªé˜³æ€§æ ·æœ¬å’Œä¸€ä¸ªé˜´æ€§æ ·æœ¬ï¼Œåˆ†ç±»å™¨æ­£ç¡®åˆ¤æ–­é˜³æ€§æ ·æœ¬çš„å€¼é«˜äºé˜´æ€§æ ·æœ¬ä¹‹æœºç‡=AUCã€‚ç®€å•è¯´ï¼šAUCå€¼è¶Šå¤§çš„åˆ†ç±»å™¨ï¼Œæ­£ç¡®ç‡è¶Šé«˜ã€‚</li>
</ul>
</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>ä»‹ç»ä¸€ä¸ªè„¸éƒ¨æ£€æµ‹æ¡†æ¶ã€‚</li>
<li>ä¸‰ä¸ªè´¡çŒ®ï¼š</li>
<li>å¼•å…¥æ–°å›¾åƒè¡¨ç¤ºâ€”â€”ç§°ä¸ºâ€œç§¯åˆ†å›¾åƒâ€ï¼Œå…¶å…è®¸æˆ‘ä»¬çš„æ£€æµ‹å™¨éå¸¸å¿«é€Ÿåœ°è®¡ç®—æ‰€ä½¿ç”¨çš„ç‰¹å¾ã€‚</li>
<li>æå‡ºä¸€ä¸ªåˆ©ç”¨AdaBostå­¦ä¹ ç®—æ³•æ„å»ºçš„ç®€å•æœ‰æ•ˆçš„åˆ†ç±»å™¨ï¼Œæ¥ä»æå¤§æ½œåœ¨ç‰¹å¾é›†ä¸­é€‰å‡ºå¾ˆå°‘çš„å…³é”®è§†è§‰ç‰¹å¾ã€‚</li>
<li>åœ¨çº§è”ä¸­ç»„åˆåˆ†ç±»å™¨ï¼Œä»è€Œå¿«é€Ÿä¸¢å¼ƒå›¾åƒçš„èƒŒæ™¯åŒºåŸŸï¼ŒåŒæ—¶åœ¨æœ‰å¯èƒ½çš„é¢éƒ¨åŒºåŸŸä¸ŠèŠ±è´¹æ›´å¤šçš„è®¡ç®—ã€‚</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>Haar Basis å‡½æ•°ï¼š<br><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfru9jaxij308q05st8t.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrucbw2pj30fn07kaaj.jpg" alt=""></p>
</li>
<li><p>Integral image: ç±»ä¼¼äºè®¡ç®—æœºå›¾å½¢å­¦ä¸­åˆ©ç”¨æ±‚å’ŒåŒºåŸŸè¡¨æ¥è¿›è¡Œçº¹ç†æ˜ å°„ã€‚</p>
</li>
<li><p>Haar-like featuresï¼šå°±æ˜¯mountä¸¤ä¸ªæˆ–å¤šä¸ªåŒºåŸŸçš„åƒç´ å€¼ä¹‹å’Œçš„å·®å€¼ã€‚</p>
</li>
<li>AdaBoostï¼šè‡ªé€‚åº”å¢å¼ºï¼Œ å…·ä½“è¯´æ¥ï¼Œæ•´ä¸ªAdaboost è¿­ä»£ç®—æ³•å°±3æ­¥ï¼š</li>
<li>åˆå§‹åŒ–è®­ç»ƒæ•°æ®çš„æƒå€¼åˆ†å¸ƒã€‚å¦‚æœæœ‰Nä¸ªæ ·æœ¬ï¼Œåˆ™æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬æœ€å¼€å§‹æ—¶éƒ½è¢«èµ‹äºˆç›¸åŒçš„æƒå€¼ï¼š1/Nã€‚</li>
<li>è®­ç»ƒå¼±åˆ†ç±»å™¨ã€‚å…·ä½“è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æœæŸä¸ªæ ·æœ¬ç‚¹å·²ç»è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆåœ¨æ„é€ ä¸‹ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œå®ƒçš„æƒå€¼å°±è¢«é™ä½ï¼›ç›¸åï¼Œå¦‚æœæŸä¸ªæ ·æœ¬ç‚¹æ²¡æœ‰è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆå®ƒçš„æƒå€¼å°±å¾—åˆ°æé«˜ã€‚ç„¶åï¼Œæƒå€¼æ›´æ–°è¿‡çš„æ ·æœ¬é›†è¢«ç”¨äºè®­ç»ƒä¸‹ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å¦‚æ­¤è¿­ä»£åœ°è¿›è¡Œä¸‹å»ã€‚</li>
<li>å°†å„ä¸ªè®­ç»ƒå¾—åˆ°çš„å¼±åˆ†ç±»å™¨ç»„åˆæˆå¼ºåˆ†ç±»å™¨ã€‚å„ä¸ªå¼±åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹ç»“æŸåï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå¤§çš„å†³å®šä½œç”¨ï¼Œè€Œé™ä½åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå°çš„å†³å®šä½œç”¨ã€‚æ¢è¨€ä¹‹ï¼Œè¯¯å·®ç‡ä½çš„å¼±åˆ†ç±»å™¨åœ¨æœ€ç»ˆåˆ†ç±»å™¨ä¸­å çš„æƒé‡è¾ƒå¤§ï¼Œå¦åˆ™è¾ƒå°ã€‚</li>
<li>çº§è”æ£€æµ‹è¿‡ç¨‹çš„ç»“æ„åŸºæœ¬ä¸Šæ˜¯ç®€å¹¶å†³ç­–æ ‘çš„ç»“æ„</li>
</ul>
<h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><ul>
<li>åŸºäºç‰¹å¾çš„ç³»ç»Ÿæ“ä½œè‚¯å®šæ¯”ä¸€ä¸ªåŸºäºåƒç´ çš„ç³»ç»Ÿæ›´æ›´å¿«</li>
<li>ï¼ˆTwo-rectangle featureï¼‰ä¸¤çŸ©å½¢ç‰¹å¾çš„å€¼æ˜¯ä¸¤ä¸ªçŸ©å½¢åŒºåŸŸå†…çš„åƒç´ ä¹‹å’Œçš„å·®</li>
<li>(Three-rectangle feature)ä¸‰çŸ©å½¢ç‰¹å¾è®¡ç®—ä»ä¸­å¿ƒçŸ©å½¢ä¸­çš„å’Œå‡å»çš„ä¸¤ä¸ªå¤–éƒ¨çŸ©å½¢çš„å’Œã€‚</li>
<li>(Four-rectangle feature)å››çŸ©å½¢ç‰¹å¾è®¡ç®—çŸ©å½¢å¯¹è§’çº¿å¯¹ä¹‹é—´çš„å·®å¼‚ã€‚<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrul9r26j30aw09ydg6.jpg" alt=""></li>
</ul>
<p>çŸ©é˜µç‰¹å¾=ä»ç°è‰²çŸ©å½¢ä¸­çš„åƒç´ çš„å’Œä¸­å‡å»ä½äºç™½è‰²çŸ©å½¢å†…çš„åƒç´ çš„å’Œã€‚</p>
<h3 id="Integral-Image"><a href="#Integral-Image" class="headerlink" title="Integral Image"></a>Integral Image</h3><ul>
<li><p>çŸ©é˜µç‰¹å¾å¯ä»¥é€šè¿‡å›¾åƒçš„ä¸­é—´è¡¨ç¤ºæ¥å¿«é€Ÿè®¡ç®—ï¼Œä»è€Œæˆä¸ºIntegral Image.</p>
</li>
<li><p>ç§¯åˆ†å›¾çš„æ¯ä¸€ç‚¹ï¼ˆx, yï¼‰çš„å€¼æ˜¯åŸå›¾ä¸­å¯¹åº”ä½ç½®çš„å·¦ä¸Šè§’åŒºåŸŸçš„æ‰€æœ‰å€¼å¾—å’Œã€‚</p>
</li>
<li><p>ç§¯åˆ†å›¾æ¯ä¸€ç‚¹çš„ï¼ˆx, yï¼‰å€¼æ˜¯ï¼š<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrujq2ygj30f601g749.jpg" alt=""></p>
</li>
<li><p>ä½ç½®xï¼Œyå¤„çš„ç§¯åˆ†å›¾åƒåŒ…å«xï¼Œyï¼ˆåŒ…æ‹¬ç«¯ç‚¹ï¼‰ä¸Šæ–¹å’Œå·¦ä¾§çš„åƒç´ çš„å’Œ:<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfruhirv4j309d021t8p.jpg" alt=""></p>
</li>
</ul>
<p>ii(x, y) is the integral image</p>
<p>i(x, y) is the original image<br><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfru76drdj30au02gwem.jpg" alt=""></p>
<p>sï¼ˆxï¼Œyï¼‰æ˜¯ç´¯ç§¯è¡Œå’Œ</p>
<p>s(x, âˆ’1) = 0, ii(âˆ’1, y) = 0)</p>
<p>ç§¯åˆ†å›¾å¯ä»¥åªéå†ä¸€æ¬¡å›¾åƒå³å¯æœ‰æ•ˆçš„è®¡ç®—å‡ºæ¥</p>
<ul>
<li><p>ä½¿ç”¨ç§¯åˆ†å›¾åƒï¼Œå¯ä»¥åœ¨å››ä¸ªé˜µåˆ—å‚è€ƒä¸­è®¡ç®—ä»»ä½•çŸ©å½¢å’Œã€‚<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfru8nyo9j30c8096jrh.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfruav2urj30d602jwej.jpg" alt=""></p>
</li>
<li><p>Two-rectangle featureï¼šéœ€è¦6ä¸ªé˜µåˆ—å‚è€ƒ<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrughx0aj30ga0gr408.jpg" alt=""></p>
</li>
<li><p>Three-rectangle featureï¼šéœ€è¦8ä¸ªé˜µåˆ—å‚è€ƒ</p>
</li>
<li><p>Four-rectangle featureï¼šéœ€è¦9ä¸ªé˜µåˆ—å‚è€ƒ</p>
</li>
<li><p>åœ¨çº¿æ€§è¿ç®—ï¼ˆä¾‹å¦‚f.gï¼‰çš„æƒ…å†µä¸‹ï¼Œå¦‚æœå…¶é€†è¢«åº”ç”¨äºç»“æœï¼Œåˆ™ä»»ä½•å¯é€†çº¿æ€§ç®—å­å¯ä»¥åº”ç”¨äºfæˆ–gã€‚</p>
</li>
<li><p>ä¾‹å¦‚åœ¨å·ç§¯çš„æƒ…å†µä¸‹ï¼Œå¦‚æœå¯¼æ•°è¿ç®—ç¬¦è¢«åº”ç”¨äºå›¾åƒå’Œå·ç§¯æ ¸ï¼Œåˆ™ç»“æœå¿…é¡»è¢«åŒé‡ç§¯åˆ†.<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfru56d7dj307g01ra9z.jpg" alt=""></p>
</li>
<li><p>å¦‚æœfå’Œgçš„å¯¼æ•°ç¨€ç–ï¼ˆæˆ–å¯ä»¥è¿™æ ·åšï¼‰ï¼Œå·ç§¯å¯ä»¥æ˜¾ç€åŠ é€Ÿã€‚</p>
</li>
<li><p>ç±»ä¼¼çš„ä¸€ä¸ªè®¤è¯†æ˜¯ï¼šå¦‚æœå…¶é€†è¢«åº”ç”¨äºgï¼Œåˆ™ä¸€ä¸ªå¯é€†çº¿æ€§ç®—å­å¯ä»¥åº”ç”¨äºfã€‚<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfru68n1lj307x01tdfs.jpg" alt=""></p>
</li>
<li><p>åœ¨è¯¥æ¡†æ¶ä¸­è§‚å¯Ÿï¼ŒçŸ©å½¢å’Œçš„è®¡ç®—å¯ä»¥è¡¨ç¤ºä¸ºç‚¹ç§¯iÂ·rï¼Œå…¶ä¸­iæ˜¯å›¾åƒï¼Œræ˜¯box carå›¾åƒï¼ˆåœ¨æ„Ÿå…´è¶£çš„çŸ©å½¢å†…çš„å€¼ä¸º1ï¼Œå¤–é¢æ˜¯0ï¼‰ã€‚ æ­¤æ“ä½œå¯ä»¥é‡å†™ï¼š<br><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfrufk96vj306c02gwee.jpg" alt=""></p>
</li>
</ul>
<p>ç§¯åˆ†å›¾åƒå®é™…ä¸Šæ˜¯å›¾åƒçš„äºŒé‡ç§¯åˆ†ï¼ˆé¦–å…ˆæ²¿è¡Œï¼Œç„¶åæ²¿åˆ—ï¼‰ã€‚</p>
<ul>
<li>çŸ©å½¢çš„äºŒé˜¶å¯¼æ•°ï¼ˆç¬¬ä¸€è¡Œåœ¨è¡Œä¸­ï¼Œç„¶ååœ¨åˆ—ä¸­ï¼‰åœ¨çŸ©å½¢çš„è§’å¤„äº§ç”Ÿå››ä¸ªdeltaå‡½æ•°ã€‚ ç¬¬äºŒç‚¹ç§¯çš„è¯„ä¼°é€šè¿‡å››ä¸ªé˜µåˆ—è®¿é—®æ¥å®Œæˆã€‚</li>
</ul>
<h3 id="Feature-Discussion"><a href="#Feature-Discussion" class="headerlink" title="Feature Discussion"></a>Feature Discussion</h3><ul>
<li>ä¸å¯æ“çºµæ»¤æ³¢å™¨ï¼ˆSteerable filtersï¼‰ç­‰æ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ï¼ŒçŸ©å½¢ç‰¹æ€§æœ‰ç‚¹åŸå§‹ã€‚</li>
<li>å¯æ§æ»¤æ³¢å™¨å¯¹è¾¹ç•Œçš„è¯¦ç»†åˆ†æï¼Œå›¾åƒå‹ç¼©å’Œçº¹ç†åˆ†æçš„éå¸¸æœ‰ç”¨ã€‚</li>
<li>ç”±äºæ­£äº¤æ€§ä¸æ˜¯è¿™ä¸ªç‰¹å¾é›†çš„ä¸­å¿ƒï¼Œæˆ‘ä»¬é€‰æ‹©ç”Ÿæˆä¸€ä¸ªéå¸¸å¤§è€Œä¸”å„ç§å„æ ·çš„çŸ©å½¢ç‰¹å¾é›†ã€‚</li>
<li>ä»ç»éªŒä¸Šçœ‹ï¼Œä¼¼ä¹çŸ©å½¢ç‰¹å¾é›†æä¾›äº†ä¸°å¯Œçš„å›¾åƒè¡¨ç¤ºï¼Œèƒ½æ”¯æŒæœ‰æ•ˆçš„å­¦ä¹ ã€‚</li>
<li>ä¸ºäº†åˆ©ç”¨ç§¯åˆ†å›¾åƒæŠ€æœ¯çš„è®¡ç®—æœ‰äº‹ï¼Œè€ƒè™‘ç”¨æ›´å¸¸è§„çš„æ–¹æ³•å»è®¡ç®—å›¾åƒé‡‘å­—å¡”ã€‚</li>
<li>åƒå¤§å¤šæ•°é¢éƒ¨æ£€æµ‹ç³»ç»Ÿä¸€æ ·ï¼Œæˆ‘ä»¬çš„æ£€æµ‹å™¨åœ¨è®¸å¤šå°ºåº¦æ‰«æè¾“å…¥; ä»ä»¥å°ºå¯¸ä¸º24Ã—24åƒç´ æ£€æµ‹é¢éƒ¨çš„åŸºæœ¬åˆ»åº¦å¼€å§‹ï¼Œåœ¨12ä¸ªåˆ»åº¦ä»¥å¤§äºä¸Šä¸€ä¸ªçš„1.25å€çš„å› å­æ‰«æ384Ã—288åƒç´ çš„å›¾åƒã€‚</li>
</ul>
<h2 id="Learning-Classification-Functions"><a href="#Learning-Classification-Functions" class="headerlink" title="Learning Classification Functions"></a>Learning Classification Functions</h2><ul>
<li>ç»™å®šæ£€æµ‹å™¨çš„åŸºæœ¬åˆ†è¾¨ç‡æ˜¯24Ã—24ï¼ŒçŸ©å½¢ç‰¹å¾çš„ç©·å°½é›†æ˜¯ç›¸å½“å¤§çš„ï¼Œ160000.</li>
<li>æˆ‘ä»¬çš„å‡è®¾æ˜¯ï¼Œç”±å®éªŒè¯æ˜ï¼Œéå¸¸å°‘æ•°çš„çŸ©å½¢ç‰¹å¾å¯ä»¥ç»„åˆå½¢æˆä¸€ä¸ªæœ‰æ•ˆçš„åˆ†ç±»å™¨ã€‚ <strong>ä¸»è¦çš„æŒ‘æˆ˜æ˜¯æ‰¾åˆ°è¿™äº›åŠŸèƒ½ã€‚</strong></li>
<li>Adaboostï¼šå°†å¤šä¸ªå¼±åˆ†ç±»å™¨ç»„åˆæˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ã€‚ï¼ˆä¸€ä¸ªç®€å•å­¦ä¹ ç®—æ³•å«åšweak learnerï¼‰ã€‚</li>
<li>ä¼ ç»Ÿçš„çš„AdaBoostè¿‡ç¨‹å¯ä»¥å®¹æ˜“åœ°è§£é‡Šä¸ºè´ªå¿ƒç‰¹å¾é€‰æ‹©è¿‡ç¨‹ã€‚</li>
<li>ä¸€ä¸ª <strong>æŒ‘æˆ˜</strong> æ˜¯å°†å¤§çš„æƒé‡ä¸æ¯ä¸ªè‰¯å¥½çš„åˆ†ç±»å‡½æ•°ç›¸å…³è”ï¼Œå¹¶å°†è¾ƒå°çš„æƒé‡ä¸è¾ƒå·®çš„å‡½æ•°ç›¸å…³è”ã€‚</li>
<li>AdaBoostæ˜¯ä¸€ä¸ªç”¨äºæœç´¢å°‘æ•°å…·æœ‰æ˜¾ç€å“ç§çš„è‰¯å¥½â€œç‰¹å¾â€çš„æœ‰æ•ˆç¨‹åºã€‚</li>
<li>å°†ä¸€ä¸ªweak learné™åˆ¶åˆ°åˆ†ç±»å‡½æ•°å‡ ä½•ä¸­ï¼Œæ¯ä¸€ä¸ªå‡½æ•°éƒ½åªä¾èµ–äºä¸€ä¸ªå•ä¸€çš„ç‰¹å¾ã€‚</li>
<li>è‹¥å­¦ä¹ å®£å‘é€‰æ‹©å•ä¸€çš„èƒ½å¤Ÿæœ€å¥½åˆ†å¼€æ­£å’Œè´Ÿæ ·æœ¬çš„çŸ©å½¢ç‰¹å¾ã€‚</li>
<li>å¯¹äºæ¯ä¸€ä¸ªç‰¹å¾ï¼Œweak learnerå†³å®šæœ€ä¼˜åˆ†ç±»å‡½æ•°é˜ˆå€¼ï¼Œä»è€Œå¯ä»¥ä½¿å¾—æœ€å°‘æ•°ç›®çš„æ ·æœ¬è¢«é”™åˆ†ã€‚</li>
<li>ä¸€ä¸ªå¼±åˆ†ç±»å™¨h(x, f, p, Î¸)å› æ­¤åŒ…å«ä¸€ä¸ªç‰¹å¾fï¼Œä¸€ä¸ªé˜ˆå€¼Î¸ï¼Œä¸€ä¸ªæ˜¾ç¤ºä¸ç­‰å¼æ–¹å‘çš„ææ€§pï¼š<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfruf310ij30ai01odfv.jpg" alt=""></li>
</ul>
<p>è¿™é‡Œxæ˜¯ä¸€ä¸ªå›¾ç‰‡24*24åƒç´ çš„å­çª—å£ã€‚</p>
<ul>
<li>æˆ‘ä»¬ä½¿ç”¨çš„å¼±åˆ†ç±»å™¨ï¼ˆé˜ˆå€¼å•ä¸€ç‰¹å¾ï¼‰å¯ä»¥è¢«è§†ä¸ºå•èŠ‚ç‚¹å†³ç­–æ ‘ã€‚</li>
<li><strong>Boosting ç®—æ³•</strong> ï¼šTæ˜¯åˆ©ç”¨æ¯ä¸ªå•ä¸ªç‰¹å¾æ„é€ çš„å‡è®¾ï¼Œæœ€ç»ˆå‡è®¾æ˜¯Tä¸ªå‡è®¾çš„åŠ æƒçº¿æ€§ç»„åˆï¼Œå…¶ä¸­æƒé‡ä¸è®­ç»ƒè¯¯å·®æˆåæ¯”ã€‚</li>
</ul>
<ol>
<li>ç»™å®šæ ·æœ¬å›¾ç‰‡(x1, y1), (x2, y2), â€¦, (xn, yn)ã€‚å…¶ä¸­yi=0, 1åˆ†åˆ«ä¸ºè´Ÿæ ·æœ¬å’Œæ­£æ ·æœ¬ã€‚</li>
<li>åˆå§‹åŒ–æƒå€¼w1, i=1/(2m), 1/(2l)åˆ†åˆ«å½“yi=0, 1ã€‚å…¶ä¸­må’Œlåˆ†åˆ«æ˜¯è´Ÿæ ·æœ¬å’Œæ­£æ ·æœ¬çš„æ•°é‡ã€‚</li>
<li><p>For t=1, â€¦, T:</p>
</li>
<li><p>å½’ä¸€åŒ–æƒé‡,<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrucsnrpj305e01bgli.jpg" alt=""></p>
</li>
<li><p>æ ¹æ®åŠ æƒé”™è¯¯é€‰æ‹©æœ€ä½³å¼±åˆ†ç±»å™¨ï¼š<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfruidyr6j30cx01zgln.jpg" alt=""></p>
</li>
<li><p>å®šä¹‰ ht(x) = h(x, ft, pt,Î¸t) å…¶ä¸­ft, pt, å’Œ Î¸t æ˜¯Îµtçš„æœ€å°å€¼.</p>
</li>
<li><p>æ›´æ–°æƒå€¼ï¼š<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfruadstnj306101c0sm.jpg" alt=""><br>å…¶ä¸­ei=0å½“æ ·ä¾‹xiè¢«æ­£ç¡®çš„åˆ†ç±»ï¼Œå¦åˆ™ei=1ï¼Œå¹¶ä¸”<br><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfruklba8j303c017mx0.jpg" alt=""></p>
</li>
<li><p>æœ€åçš„å¼ºåˆ†ç±»å™¨æ˜¯ï¼š</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfru83b9xj30c104xjrk.jpg" alt=""><br>å…¶ä¸­<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfru6hdsij303t0160sl.jpg" alt=""></p>
<h3 id="Learning-Discussion"><a href="#Learning-Discussion" class="headerlink" title="Learning Discussion"></a>Learning Discussion</h3></li>
</ol>
<ul>
<li><p>å¼±åˆ†ç±»å™¨é€‰æ‹©ç®—æ³•è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¯¹äºæ¯ä¸ªç‰¹å¾ï¼Œæ ¹æ®ç‰¹å¾å€¼å¯¹æ ·ä¾‹è¿›è¡Œæ’åºã€‚</li>
<li>è¯¥ç‰¹å¾çš„AdaBoostæœ€ä½³é˜ˆå€¼å¯ä»¥åœ¨è¯¥æ’åºåˆ—è¡¨ä¸Šçš„å•æ¬¡é€šè¿‡ä¸­è®¡ç®—ã€‚</li>
<li>å¯¹äºæ’åºåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œå››ä¸ªå’Œè¢«ç»´æŠ¤å’Œè¯„ä¼°ï¼š</li>
<li>æ­£å®ä¾‹æƒé‡T+çš„æ€»å’Œã€‚</li>
<li>è´Ÿå®ä¾‹æƒé‡T-çš„æ€»å’Œã€‚</li>
<li>å½“å‰ç¤ºä¾‹S+ä¹‹ä¸‹çš„æ­£æƒé‡çš„å’Œã€‚</li>
<li>å½“å‰ç¤ºä¾‹S-ä¹‹ä¸‹çš„è´Ÿæƒé‡çš„å’Œã€‚</li>
</ul>
</li>
<li><p>åœ¨æ’åºä¸€ä¸ªåˆ’åˆ†å½“å‰å’Œä¸Šä¸€ç¤ºä¾‹ä¹‹é—´çš„èŒƒå›´çš„é˜ˆå€¼çš„é”™è¯¯æ˜¯ï¼š<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrud40xsj30dk01gjrd.jpg" alt=""></p>
</li>
</ul>
<h3 id="Learning-Results"><a href="#Learning-Results" class="headerlink" title="Learning Results"></a>Learning Results</h3><ul>
<li>åœ¨ç°å®åº”ç”¨ä¸­ï¼Œå‡æ­£ä¾‹ç‡å¿…é¡»æ¥è¿‘1/1000000ã€‚</li>
<li>æ‰€é€‰æ‹©çš„ <strong>ç¬¬ä¸€ç‰¹å¾</strong> ä¼¼ä¹é›†ä¸­äºå±æ€§å³çœ¼ç›çš„åŒºåŸŸé€šå¸¸æ¯”é¼»å­å’Œè„¸é¢Šçš„åŒºåŸŸæ›´æš—ã€‚</li>
<li>æ‰€é€‰æ‹©çš„ <strong>ç¬¬äºŒç‰¹å¾</strong> ä¾èµ–äºçœ¼ç›æ¯”é¼»æ¢æ›´æš—çš„ç‰¹æ€§ã€‚</li>
<li>æé«˜æ€§èƒ½æœ€ç›´æ¥æŠ€æœ¯æ˜¯æ·»åŠ æ›´å¤šçš„ç‰¹å¾ï¼Œä½†è¿™æ ·ç›´æ¥å¯¼è‡´è®¡ç®—æ—¶é—´çš„å¢åŠ ã€‚</li>
<li>Receiver operating characteristic (ROC)æ›²çº¿ï¼š<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfruhvzrpj30e30ao3yq.jpg" alt=""></li>
</ul>
<h2 id="The-Attentional-Cascade"><a href="#The-Attentional-Cascade" class="headerlink" title="The Attentional Cascade"></a>The Attentional Cascade</h2><ul>
<li>æœ¬èŠ‚æè¿°äº†ç”¨äºæ„é€ çº§è”çš„åˆ†ç±»å™¨çš„ç®—æ³•ï¼Œå…¶å®ç°äº†æé«˜çš„æ£€æµ‹æ€§èƒ½ï¼ŒåŒæ—¶ä»æ ¹æœ¬ä¸Šå‡å°‘äº†è®¡ç®—æ—¶é—´ã€‚</li>
<li>é˜ˆå€¼è¶Šä½ï¼Œæ£€æµ‹ç‡è¶Šé«˜ï¼Œå‡æ­£ä¾‹ç‡è¶Šé«˜ã€‚</li>
<li>ä»åŒç‰¹å¾å¼ºåˆ†ç±»å™¨å¼€å§‹ï¼Œå¯ä»¥é€šè¿‡ <strong>è°ƒæ•´å¼ºåˆ†ç±»å™¨é˜ˆå€¼</strong> ä»¥æœ€å°åŒ–å‡é˜´æ€§æ¥è·å¾—æœ‰æ•ˆçš„é¢éƒ¨æ»¤æ³¢å™¨ã€‚</li>
<li>å¯ä»¥è°ƒæ•´åŒç‰¹å¾åˆ†ç±»å™¨ä»¥50ï¼…çš„å‡é˜³æ€§ç‡æ¥æ£€æµ‹100ï¼…çš„é¢éƒ¨ã€‚</li>
<li>æ•´ä½“çš„æ£€æµ‹è¿‡ç¨‹å½¢å¼æ˜¯ç®€å¹¶å†³ç­–æ ‘çš„å½¢å¼ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œçº§è”â€ã€‚</li>
<li>åœ¨ä»»ä½•ç‚¹ä¸Šçš„å¦å®šç»“æœç«‹å³å¯¼è‡´å¯¹è¯¥å­çª—å£çš„æ‹’ç»ã€‚</li>
<li>æ›´æ·±çš„åˆ†ç±»å™¨é¢ä¸´çš„æ›´å›°éš¾çš„ä¾‹å­,å°†æ•´ä¸ªROCæ›²çº¿å‘ä¸‹æ¨ã€‚ åœ¨ç»™å®šçš„æ£€æµ‹ç‡ä¸‹ï¼Œè¾ƒæ·±çš„åˆ†ç±»å™¨å…·æœ‰ç›¸åº”è¾ƒé«˜çš„å‡é˜³æ€§ç‡ã€‚</li>
</ul>
<h3 id="Training-a-Cascade-of-Classifiers"><a href="#Training-a-Cascade-of-Classifiers" class="headerlink" title="Training a Cascade of Classifiers"></a>Training a Cascade of Classifiers</h3><ul>
<li><p>Given a trained cascade of classifiers, the false positive rate of the cascade isï¼š<br><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfru7u7f1j303g02bjr9.jpg" alt=""></p>
</li>
<li><p>The detection rate is:</p>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrumlwqej303p02idfp.jpg" alt=""></p>
</li>
<li><p>The expected number of features which are evaluated is:</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrubq3n2j307s02c0sq.jpg" alt=""></p>
</li>
<li><p>ç”¨äºè®­ç»ƒåç»­å±‚çš„è´Ÿæ ·ä¾‹é›†åˆæ˜¯é€šè¿‡è¿è¡Œæ£€æµ‹å™¨æ”¶é›†é€šè¿‡åœ¨ä¸åŒ…å«ä»»ä½•é¢éƒ¨å®ä¾‹çš„ä¸€ç»„å›¾åƒä¸Šè€Œæ‰¾åˆ°çš„æ‰€æœ‰é”™è¯¯æ£€æµ‹æ¥è·å¾—ã€‚</p>
</li>
<li><p>æ„å»ºä¸€ä¸ªç»ƒçº§æ£€æµ‹å™¨çš„è®­ç»ƒç®—æ³•ï¼š</p>
</li>
</ul>
<h3 id="Simple-Experiment"><a href="#Simple-Experiment" class="headerlink" title="Simple Experiment"></a>Simple Experiment</h3><h3 id="Detector-Cascade-Discussion"><a href="#Detector-Cascade-Discussion" class="headerlink" title="Detector Cascade Discussion"></a>Detector Cascade Discussion</h3><ul>
<li>å°†æ£€æµ‹å™¨è®­ç»ƒä¸ºåˆ†ç±»å™¨åºåˆ—çš„éšè—å¥½å¤„æ˜¯:æœ€ç»ˆæ£€æµ‹å™¨çœ‹åˆ°çš„æœ‰æ•ˆæ•°ç›®çš„è´Ÿæ ·ä¾‹æ•°ç›®å¯èƒ½éå¸¸å¤§ã€‚</li>
<li>åœ¨å®è·µä¸­ï¼Œç”±äºæˆ‘ä»¬çš„æ£€æµ‹å™¨çš„å½¢å¼å’Œå®ƒä½¿ç”¨çš„ç‰¹æ€§æ˜¯éå¸¸é«˜æ•ˆçš„ï¼Œæ‰€ä»¥åœ¨æ¯ä¸ªå°ºåº¦å’Œä½ç½®è¯„ä¼°æˆ‘ä»¬çš„æ£€æµ‹å™¨çš„ <strong>æ‘Šé”€æˆæœ¬</strong> æ¯”åœ¨æ•´ä¸ªå›¾åƒä¸­æ‰¾åˆ°å¹¶åˆ†ç»„è¾¹ç¼˜æ›´å¿«ã€‚</li>
</ul>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Training-Dataset"><a href="#Training-Dataset" class="headerlink" title="Training Dataset"></a>Training Dataset</h3><ul>
<li>äº‹å®ä¸Šï¼ŒåŒ…å«åœ¨è¾ƒå¤§å­çª—å£ä¸­çš„é™„åŠ ä¿¡æ¯å¯ä»¥ç”¨äºåœ¨æ£€æµ‹çº§è”ä¸­è¾ƒæ—©åœ°æ‹’ç»non-faceã€‚</li>
</ul>
<h3 id="Structure-of-the-Detector-Cascade"><a href="#Structure-of-the-Detector-Cascade" class="headerlink" title="Structure of the Detector Cascade"></a>Structure of the Detector Cascade</h3><ul>
<li>æœ€ç»ˆçš„æ£€æµ‹å™¨æ˜¯38å±‚åˆ†çº§å™¨ï¼ŒåŒ…æ‹¬æ€»å…±6060ä¸ªç‰¹å¾ã€‚</li>
<li>çº§è”ä¸­çš„ç¬¬ä¸€ä¸ªåˆ†ç±»å™¨æ˜¯ä½¿ç”¨ä¸¤ä¸ªç‰¹å¾æ„é€ çš„ï¼Œåœ¨æ£€æµ‹100%çš„é¢éƒ¨æ—¶å¯ä»¥æ‹’ç»50%çš„non-faces.</li>
<li>ä¸‹ä¸€ä¸ªåˆ†ç±»å™¨å…·æœ‰åä¸ªç‰¹å¾ï¼Œå¹¶ä¸”åœ¨æ£€æµ‹å‡ ä¹100ï¼…çš„é¢éƒ¨æ—¶æ‹’ç»80ï¼…çš„éé¢éƒ¨ã€‚</li>
<li>æ¥ä¸‹æ¥çš„ä¸¤å±‚æ˜¯25ä¸ªç‰¹å¾åˆ†ç±»å™¨ï¼Œå…¶åæ˜¯ä¸‰ä¸ª50ç‰¹å¾åˆ†ç±»å™¨ï¼Œå†ä¹‹åæ˜¯å…·æœ‰æ ¹æ®è¡¨2ä¸­çš„ç®—æ³•é€‰æ‹©çš„å„ç§ä¸åŒæ•°ç›®çš„ç‰¹å¾çš„åˆ†ç±»å™¨ã€‚</li>
<li>æ·»åŠ æ›´å¤šå±‚ï¼Œç›´åˆ°éªŒè¯é›†ä¸Šçš„å‡é˜³æ€§ç‡æ¥è¿‘é›¶ï¼ŒåŒæ—¶ä»ä¿æŒé«˜çš„æ­£ç¡®æ£€æµ‹ç‡ã€‚</li>
</ul>
<h3 id="Speed-of-the-Final-Detector"><a href="#Speed-of-the-Final-Detector" class="headerlink" title="Speed of the Final Detector"></a>Speed of the Final Detector</h3><ul>
<li>çº§è”æ£€æµ‹å™¨çš„é€Ÿåº¦ç›´æ¥ä¸æ¯ä¸ªè¢«æ‰«æçš„å­çª—å£çš„ç‰¹å¾æ•°é‡ç›¸å…³ã€‚</li>
</ul>
<h3 id="Image-Processing"><a href="#Image-Processing" class="headerlink" title="Image Processing"></a>Image Processing</h3><ul>
<li>ç”¨äºè®­ç»ƒçš„æ‰€æœ‰ç¤ºä¾‹å­çª—å£è¢« <strong>æ–¹å·®å½’ä¸€</strong> åŒ–ä»¥ä½¿ä¸åŒç…§æ˜æ¡ä»¶çš„å½±å“æœ€å°åŒ–ã€‚</li>
<li>å¯ä»¥ä½¿ç”¨ <strong>ä¸€å¯¹ç§¯åˆ†å›¾åƒ</strong> æ¥å¿«é€Ÿè®¡ç®—å›¾åƒå­çª—å£çš„æ–¹å·®ã€‚</li>
<li>åœ¨æ‰«ææœŸé—´ï¼Œå¯ä»¥é€šè¿‡å¯¹ç‰¹å¾å€¼è¿›è¡Œåä¹˜ï¼Œè€Œä¸æ˜¯å¯¹åƒç´ è¿›è¡Œæ“ä½œæ¥å®ç°å›¾åƒå½’ä¸€åŒ–çš„æ•ˆæœã€‚</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;a href=&quot;#çŸ¥è¯†ç‚¹&quot; class=&quot;headerlink&quot; title=&quot;çŸ¥è¯†ç‚¹&quot;&gt;&lt;/a&gt;çŸ¥è¯†ç‚¹&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;å‚…é‡Œå¶å˜æ¢çš„ä¸€ä¸ªæ¨è®ºï¼š&lt;br&gt;&lt;img src=&quot;https://ww4.sinaimg.cn/large/006tKfTcgw1fbfrudkda8j308h01d3yg.jpg&quot; alt=&quot;&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸€ä¸ªæ—¶åŸŸä¸‹çš„å¤æ‚ä¿¡å·å‡½æ•°å¯ä»¥åˆ†è§£æˆå¤šä¸ªç®€å•ä¿¡å·å‡½æ•°çš„å’Œï¼Œç„¶åå¯¹å„ä¸ªå­ä¿¡å·å‡½æ•°åšå‚…é‡Œå¶å˜æ¢å¹¶å†æ¬¡æ±‚å’Œï¼Œå°±æ±‚å‡ºäº†åŸä¿¡å·çš„å‚…é‡Œå¶å˜æ¢ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;å·ç§¯å®šç†(Convolution Theorem)ï¼šä¿¡å·få’Œä¿¡å·gçš„å·ç§¯çš„å‚…é‡Œå¶å˜æ¢ï¼Œç­‰äºfã€gå„è‡ªçš„å‚…é‡Œå¶å˜æ¢çš„ç§¯&lt;br&gt;&lt;img src=&quot;https://ww3.sinaimg.cn/large/006tKfTcgw1fbfrue2zlyj304n01gdfp.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ww1.sinaimg.cn/large/006tKfTcgw1fbfrufxyw0j306z0263yf.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ww1.sinaimg.cn/large/006tKfTcgw1fbfru90t5uj30jt09j75c.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;æ•´ä¸ªè¿‡ç¨‹çš„æ ¸å¿ƒå°±æ˜¯â€œï¼ˆåè½¬ï¼‰ï¼Œç§»åŠ¨ï¼Œä¹˜ç§¯ï¼Œæ±‚å’Œâ€&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="è®ºæ–‡ç¬”è®°" scheme="http://jacobkong.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Object Detection" scheme="http://jacobkong.github.io/tags/Object-Detection/"/>
    
      <category term="ç›®æ ‡æ£€æµ‹" scheme="http://jacobkong.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
</feed>
