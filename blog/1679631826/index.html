<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>深度学习论文笔记：Fast R-CNN | Weijie Kong&#39;s Homepage</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <meta name="description" content="知识点
mAP：detection quality.

Abstract
本文提出一种基于快速区域的卷积网络方法（快速R-CNN）用于对象检测。
快速R-CNN采用多项创新技术来提高训练和测试速度，同时提高检测精度。
采用VGG16的网络：VGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connect">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习论文笔记：Fast R-CNN">
<meta property="og:url" content="http://jacobkong.github.io/blog/1679631826/index.html">
<meta property="og:site_name" content="Weijie Kong's Homepage">
<meta property="og:description" content="知识点
mAP：detection quality.

Abstract
本文提出一种基于快速区域的卷积网络方法（快速R-CNN）用于对象检测。
快速R-CNN采用多项创新技术来提高训练和测试速度，同时提高检测精度。
采用VGG16的网络：VGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connect">
<meta property="og:image" content="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7na6fij30jk0efdju.jpg">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfo7oia0ij30bg05n74f.jpg">
<meta property="og:image" content="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7owdcpj306q01mwee.jpg">
<meta property="og:image" content="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfoo7cuv7j30qf0ardgq.jpg">
<meta property="og:updated_time" content="2017-03-09T04:27:47.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习论文笔记：Fast R-CNN">
<meta name="twitter:description" content="知识点
mAP：detection quality.

Abstract
本文提出一种基于快速区域的卷积网络方法（快速R-CNN）用于对象检测。
快速R-CNN采用多项创新技术来提高训练和测试速度，同时提高检测精度。
采用VGG16的网络：VGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connect">
<meta name="twitter:image" content="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7na6fij30jk0efdju.jpg">

  
    <link rel="alternate" href="/atom.xml" title="Weijie Kong&#39;s Homepage" type="application/atom+xml" />
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/favicon2.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/favicon2.png">

  <meta name="msapplication-TileImage" content="/favicon2.png"/>
  <meta name="msapplication-TileColor" content="#000000"/>

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png" />

  <link rel="icon" sizes="256x256" href="/favicon2.png" />
  <!--<![endif]-->
  

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css" />

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/academicons.min.css"/>
  <link rel="stylesheet" href="/css/vendors.css">
  <link rel="stylesheet" href="/css/style.css">
  
  <!-- Google Analytics -->
  <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89889116-1', 'auto');
  ga('send', 'pageview');

  </script>
  <!-- End Google Analytics -->



  <script src="/js/vendors.js"></script>

  <script>
    define('jquery', function () {
      return window.jQuery;
    });
  </script>


</head>
<body>

  <div class="navbar-fixed">
  <nav id="main-navbar" class="blue z-depth-1" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span class="white-text">Weijie Kong&#39;s Homepage</span>
        
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/"><span class="white-text">Home</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog"><span class="white-text">Blog</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv/resume-zh.pdf"><span class="white-text">CV/中</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv"><span class="white-text">CV/En</sapn></a>
          </li>
        
      </ul>

      <a href="#" data-activates="nav-mobile" class="button-collapse">
        <i class="material-icons white-text">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="side-nav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv/resume-zh.pdf">CV/中</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv">CV/En</a>
  </li>
  
</ul>


  <div id="main-container">
    
<div class="container">
  <div class="row">
    <div class="col s12">


      <article id="post-深度学习论文笔记：Fast R-CNN" class="article article-type-post" itemscope itemprop="blogPost">

        <div class="article-inner">
          

          <header class="article-header">
          
              
  
    <h1 class="article-title header" itemprop="name">
      深度学习论文笔记：Fast R-CNN
    </h1>
  


          

            <div class="article-meta">
              <i class="fa fa-calendar"></i>
              <time datetime="2016-12-07T22:32:24.000Z" itemprop="datePublished">Dec 07, 2016</time>
            </div>
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><ul>
<li>mAP：detection quality.</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>本文提出一种基于快速区域的卷积网络方法（快速R-CNN）用于对象检测。</li>
<li>快速R-CNN采用多项创新技术来提高训练和测试速度，同时提高检测精度。</li>
<li>采用VGG16的网络：VGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connected layers</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>物体检测相对于图像分类是更复杂的，应为需要物体准确的位置。<ul>
<li>首先，必须处理许多候选对象位置（通常称为“proposal”）。</li>
<li>其次，这些候选者只提供粗略的定位，必须进行精确定位才能实现精确定位。</li>
<li>这些问题的解决方案经常损害 <strong>速度</strong> ， <strong>准确性</strong> 或 <strong>简单性</strong> 。</li>
</ul>
</li>
</ul>
<h3 id="R-CNN-and-SPPnet"><a href="#R-CNN-and-SPPnet" class="headerlink" title="R-CNN and SPPnet"></a>R-CNN and SPPnet</h3><ul>
<li>R-CNN(Region-based Convolution Network)具有几个显著的缺点：<ul>
<li>训练是一个多级管道。</li>
<li>训练在空间和时间上是昂贵的。</li>
<li>物体检测速度很慢。</li>
</ul>
</li>
<li>R-CNN是慢的，因为它对每个对象proposal执行ConvNet正向传递，而不共享计算（sharing computation）。</li>
<li>Spatial pyramid pooling networks（SPPnets），利用sharing computation对R-CNN进行了加速，但是SPPnets也具有明显的缺点，像R-CNN一样，SPPnets也需要：<ul>
<li>训练是一个多阶段流程，</li>
<li>涉及提取特征，</li>
<li>用对数损失精简网络</li>
<li>训练SVM</li>
<li>赋予边界框回归。</li>
<li>特征也需要也写入磁盘。</li>
</ul>
</li>
<li>但与R-CNN <strong>不同</strong> ，在[11]中提出的fine-tuning算法不能更新在空间金字塔池之前的卷积层。 不出所料，这种限制（固定的卷积层）限制了非常深的网络的精度。</li>
</ul>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ul>
<li>Fast R-CNN优点：</li>
</ul>
<ol>
<li>比R-CNN，SPPnet更高的检测质量（mAP）</li>
<li>训练是单阶段的，使用多任务损失（multi-task loss）</li>
<li>训练可以更新所有网络层</li>
<li>特征缓存不需要磁盘存储</li>
</ol>
<h2 id="Fast-R-CNN-architecture-and-training"><a href="#Fast-R-CNN-architecture-and-training" class="headerlink" title="Fast R-CNN architecture and training"></a>Fast R-CNN architecture and training</h2><ul>
<li><p>整体框架<br><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7na6fij30jk0efdju.jpg" alt=""></p>
</li>
<li><p>快速R-CNN网络将<strong>整个图像</strong>和<strong>一组object proposals</strong>作为输入。</p>
<ul>
<li>网络首先使用几个卷积（conv）和最大池层来处理整个图像，以产生conv feature map。</li>
<li>然后，对于每个对象proposal， <strong>感兴趣区域（RoI）池层</strong> 从特征图中抽取固定长度的特征向量。</li>
<li>每个特征向量被馈送到完全连接（fc）层序列，其最终分支成两个同级输出层：<ul>
<li>一个产生对K个对象类加上全部捕获的“背景”类的softmax概率估计(one that produces softmax probability estimates over K object classes plus a catch-all “background” class)</li>
<li>另一个对每个K对象类输出四个实数，每组4个值编码提炼定义K个类中的一个的的边界框位置。(another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes reﬁned bounding-box positions for one of the K classes.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="The-RoI-pooling-layer"><a href="#The-RoI-pooling-layer" class="headerlink" title="The RoI pooling layer"></a>The RoI pooling layer</h3><ul>
<li>Rol pooling layer的作用主要有两个：<ul>
<li>一个是将image中的RoI定位到feature map中对应patch</li>
<li>另一个是用一个单层的SPP layer将这个feature map patch下采样为大小固定的feature再传入全连接层。</li>
</ul>
</li>
<li>RoI池层使用最大池化将任何有效的RoI区域内的特征转换成具有H×W（例如，7×7）的固定空间范围的小feature map，其中H和W是层<strong>超参数</strong> 它们独立于任何特定的RoI。</li>
<li>在本文中，RoI是conv feature map中的一个矩形窗口。</li>
<li>每个RoI由定义其左上角（r，c）及其高度和宽度（h，w）的四元组（r，c，h，w）定义。</li>
<li>RoI层仅仅是Sppnets中的spatial pyramid pooling layer的特殊形式，其中<strong>只有一个金字塔层</strong>.</li>
</ul>
<h3 id="Initializing-from-pre-trained-networks"><a href="#Initializing-from-pre-trained-networks" class="headerlink" title="Initializing from pre-trained networks"></a>Initializing from pre-trained networks</h3><ul>
<li>用了3个预训练的ImageNet网络（CaffeNet/ VGG_CNN_M_1024 /VGG16）。预训练的网络初始化Fast RCNN要经过三次变形：</li>
</ul>
<ol>
<li>最后一个max pooling层替换为RoI pooling层，设置H’和W’与第一个全连接层兼容。</li>
<li>最后一个全连接层和softmax（原本是1000个类）替换为softmax的对K+1个类别的分类层，和bounding box 回归层。</li>
<li>输入修改为两种数据：一组N个图形，R个RoI，batch size和ROI数、图像分辨率都是可变的。</li>
</ol>
<h3 id="Fine-tuning-for-detection"><a href="#Fine-tuning-for-detection" class="headerlink" title="Fine-tuning for detection"></a>Fine-tuning for detection</h3><ul>
<li><p>利用反向传播算法进行训练所有网络的权重是Fast R-CNN很重要的一个能力。</p>
</li>
<li><p>我们提出了一种更有效的训练方法，利用在训练期间的特征共享（feature sharing during training）。</p>
</li>
<li><p>在Fast R-CNN训练中， <strong>随机梯度下降（SGD）小批量分层采样</strong> ，首先通过采样N个图像，然后通过从每个图像采样 <strong>R/N个</strong> RoIs。</p>
</li>
<li><p><strong>关键的是，来自同一图像的RoI在向前和向后传递中 共享计算 和存储。</strong></p>
</li>
<li><p>此外为了分层采样，Fast R-CNN使用了一个<strong>流水线训练过程</strong>，利用一个fine-tuning阶段来联合优化一个softmax分类器和bounding box回归，而非训练一个softmax分类器，SVMs，和regression在三个独立的阶段。</p>
</li>
<li><p>Multi-task loss：</p>
<ul>
<li>两个sibling输出层：<ul>
<li>第一层：输出离散概率分布（针对每个RoIs），$p=(p_0,…,p_K)$，分别对应$K+1$个类。p是在一个全连接层的$K+1$个输出上的softmax。</li>
<li>第二层：输出bounding-box的回归偏移(bounding-box regression offsets)，针对K object classes中的每一个类，计算$t^k=(t^k_x,t^k_y,t^k_w,t^k_h)$，<strong>具体见R-CNN得补充材料，里面有很详细的介绍bounding box regression</strong>。</li>
</ul>
</li>
<li>每一个训练RoIs被标注一个ground truth类$u$，和一个ground truth bounding box 回归目标$v$。</li>
</ul>
<ul>
<li>两个loss，以下分别介绍：<ul>
<li>对于分类loss，是一个N+1路的softmax输出，其中的N是类别个数，1是背景。</li>
<li>对于回归loss，是一个4xN路输出的regressor，也就是说对于每个类别都会训练一个单独的regressor的意思，比较有意思的是，这里regressor的loss不是L2的，而是一个平滑的L1，形式如下：</li>
</ul>
</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfo7oia0ij30bg05n74f.jpg" alt=""></p>
</li>
<li><p>我们利用一个multi-task loss L 在每个被标注的RoI上来联合训练分类器和bounding box regression</p>
</li>
<li><p>Mini-batch sampling：在微调时，每个SGD的mini-batch是随机找两个图片，R为128，因此每个图上取样64个RoI。从object proposal中选25%的RoI，就是和ground-truth交叠至少为0.5的。剩下的作为背景。</p>
</li>
<li><p>Back-propagation through RoI pooling layers：</p>
<ul>
<li><p>RoI pooling层计算损失函数对每个输入变量x的偏导数，如下：</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfo7owdcpj306q01mwee.jpg" alt=""></p>
<p>y是pooling后的输出单元，x是pooling前的输入单元，如果y由x pooling而来，则将损失L对y的偏导计入累加值，最后累加完R个RoI中的所有输出单元。下面是我理解的x、y、r的关系：</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfoo7cuv7j30qf0ardgq.jpg" alt="20151208163114338"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Scale-invariance"><a href="#Scale-invariance" class="headerlink" title="Scale invariance"></a>Scale invariance</h3><ul>
<li>这里讨论object的scale问题，就是网络对于object的scale应该是要不敏感的。这里还是引用了SPP的方法，有两种:<ul>
<li>brute force （single scale），也就是简单认为object不需要预先resize到类似的scale再传入网络，直接将image定死为某种scale，直接输入网络来训练就好了，然后期望网络自己能够学习到scale-invariance的表达。</li>
<li>image pyramids （multi scale），也就是要生成一个金字塔，然后对于object，在金字塔上找到一个大小比较接近227x227的投影版本，然后用这个版本去训练网络。</li>
</ul>
</li>
<li>可以看出，2应该比1更加好，作者也在5.2讨论了，2的表现确实比1好，但是好的不算太多，大概是1个mAP左右，但是时间要慢不少，所以作者实际采用的是第一个策略，也就是single scale。</li>
<li>这里，FRCN测试之所以比SPP快，很大原因是因为这里，因为SPP用了2，而FRCN用了1。</li>
</ul>
<h2 id="Fast-R-CNN-detection"><a href="#Fast-R-CNN-detection" class="headerlink" title="Fast R-CNN detection"></a>Fast R-CNN detection</h2><ul>
<li>大型全连接层很容易的可以通过将他们与 <strong>truncated SVD(奇异值分解)</strong> 压缩来加速计算。</li>
</ul>
<h2 id="Main-results"><a href="#Main-results" class="headerlink" title="Main results"></a>Main results</h2><ul>
<li>All Fast R-CNN results in this paper using VGG16 ﬁne-tune layers conv3 1 and up; all experments with models S and M ﬁne-tune layers conv2 and up.</li>
</ul>
<h2 id="Design-evaluation"><a href="#Design-evaluation" class="headerlink" title="Design evaluation"></a>Design evaluation</h2><h3 id="Do-we-need-more-training-data"><a href="#Do-we-need-more-training-data" class="headerlink" title="Do we need more training data?"></a>Do we need more training data?</h3><ul>
<li>在训练期间，作者做过的唯一一个数据增量的方式是水平翻转。 作者也试过将VOC12的数据也作为拓展数据加入到finetune的数据中，结果VOC07的mAP从66.9到了70.0，说明对于网络来说， <strong>数据越多就是越好的。</strong></li>
</ul>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="http://jacobkong.github.io/blog/1679631826/" data-id="cjrnebv2m00111k2pp71barpu" class="article-share-link">Share</a>
            
              <a href="http://jacobkong.github.io/blog/1679631826/#disqus_thread" class="article-comment-link">Comments</a>
            
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Object-Detection/">Object Detection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/目标检测/">目标检测</a></li></ul>

          </footer>

        </div>

        
          
<nav id="article-nav" class="white">
  <div class="nav-wrapper">
    <ul class="row">
    
      <li class="col s6">
        <a href="/blog/3802700508/" id="article-nav-newer" class="article-nav-link-wrap grey-text text-darken-1 truncate">
          <i class="fa fa-arrow-left"></i>
          <span class="article-nav-title">深度学习论文笔记：Faster R-CNN</span>
        </a>
      </li>
    

    
      <li class="col s6">
        <a href="/blog/3054155989/" id="article-nav-older" class="article-nav-link-wrap grey-text text-darken-1 right-align truncate">
          <span class="article-nav-title">深度学习论文笔记：Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</span>
          <i class="fa fa-arrow-right"></i>
        </a>
      </li>
    

    </ul>
  </div>
</nav>


        
      </article>


      

      <hr />

      <section id="comments">
        <div id="disqus_thread">
          <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
      </section>
      



    </div>
  </div>
</div>


  
  <script>
    var disqus_shortname = 'jacobkong';
    
    var disqus_url = 'http://jacobkong.github.io/blog/1679631826/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  



  </div>

  <footer class="page-footer blue lighten-2">
    <div class="container">
        <div class="row">
            <div class="col l6 s12">
                <h5><a href="http://media.pkusz.edu.cn" class="white-text" target="_blank">Digital Media R&D Center, PKU</a></h5>
            </div>

        </div>
    </div>
    <div class="footer-copyright">
      <div class="container">
            Created by <a class="orange-text text-lighten-3" href="http://hexo.io/">Weijie Kong</a>. Last
            update 2019/03/02.

            <!-- <div class="right">
              Powered by <a href="http://hexo.io/" rel="nofollow" class="white-text" target="_blank">Hexo</a>
            </div> -->
        </div>
    </div>
  </footer>

  <script src="/js/app.js"></script>

</body>
</html>
