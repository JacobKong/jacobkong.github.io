<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>行人检测论文笔记：Fused DNN - A deep neural network fusion approach to fast and robust pedestrian detection | Weijie Kong&#39;s Homepage</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <meta name="description" content="相关知识点
L1范数 也称为最小绝对偏差（LAD），最小绝对误差（LAE）。它基本上最小化目标值(Yi)和估计值(f(xi))之间的绝对差(S)的和



L2范数也称为最小二乘。它基本上最小化目标值(Yi)和估计值(f(xi))之间的差(S)的平方的和


Abstract
所提出的网络融合架构允许多个网络的并行处理来提高速度。
首先是一个深度卷积网络被训练为一个物体检测器来生成所有有可能的不同">
<meta property="og:type" content="article">
<meta property="og:title" content="行人检测论文笔记：Fused DNN - A deep neural network fusion approach to fast and robust pedestrian detection">
<meta property="og:url" content="http://jacobkong.github.io/blog/2553947436/index.html">
<meta property="og:site_name" content="Weijie Kong's Homepage">
<meta property="og:description" content="相关知识点
L1范数 也称为最小绝对偏差（LAD），最小绝对误差（LAE）。它基本上最小化目标值(Yi)和估计值(f(xi))之间的绝对差(S)的和



L2范数也称为最小二乘。它基本上最小化目标值(Yi)和估计值(f(xi))之间的差(S)的平方的和


Abstract
所提出的网络融合架构允许多个网络的并行处理来提高速度。
首先是一个深度卷积网络被训练为一个物体检测器来生成所有有可能的不同">
<meta property="og:image" content="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqk8unvtj306d0273ye.jpg">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk9chp0j305w01wjra.jpg">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk6f5o3j30q00iumyv.jpg">
<meta property="og:image" content="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqk7e7e6j30pe07rgmh.jpg">
<meta property="og:image" content="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqka1k2nj306u01nq2u.jpg">
<meta property="og:image" content="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqkaszbpj30q202qt9i.jpg">
<meta property="og:image" content="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfqkaaiiij3086024t8n.jpg">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqkbeg8wj30g002cwen.jpg">
<meta property="og:updated_time" content="2017-01-28T09:00:31.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="行人检测论文笔记：Fused DNN - A deep neural network fusion approach to fast and robust pedestrian detection">
<meta name="twitter:description" content="相关知识点
L1范数 也称为最小绝对偏差（LAD），最小绝对误差（LAE）。它基本上最小化目标值(Yi)和估计值(f(xi))之间的绝对差(S)的和



L2范数也称为最小二乘。它基本上最小化目标值(Yi)和估计值(f(xi))之间的差(S)的平方的和


Abstract
所提出的网络融合架构允许多个网络的并行处理来提高速度。
首先是一个深度卷积网络被训练为一个物体检测器来生成所有有可能的不同">
<meta name="twitter:image" content="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqk8unvtj306d0273ye.jpg">

  
    <link rel="alternate" href="/atom.xml" title="Weijie Kong&#39;s Homepage" type="application/atom+xml" />
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/favicon2.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/favicon2.png">

  <meta name="msapplication-TileImage" content="/favicon2.png"/>
  <meta name="msapplication-TileColor" content="#000000"/>

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png" />

  <link rel="icon" sizes="256x256" href="/favicon2.png" />
  <!--<![endif]-->
  

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css" />

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/academicons.min.css"/>
  <link rel="stylesheet" href="/css/vendors.css">
  <link rel="stylesheet" href="/css/style.css">
  
  <!-- Google Analytics -->
  <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89889116-1', 'auto');
  ga('send', 'pageview');

  </script>
  <!-- End Google Analytics -->



  <script src="/js/vendors.js"></script>

  <script>
    define('jquery', function () {
      return window.jQuery;
    });
  </script>


</head>
<body>

  <div class="navbar-fixed">
  <nav id="main-navbar" class="blue z-depth-1" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span class="white-text">Weijie Kong&#39;s Homepage</span>
        
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/"><span class="white-text">Home</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog"><span class="white-text">Blog</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv/resume-zh.pdf"><span class="white-text">CV/中</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv"><span class="white-text">CV/En</sapn></a>
          </li>
        
      </ul>

      <a href="#" data-activates="nav-mobile" class="button-collapse">
        <i class="material-icons white-text">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="side-nav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv/resume-zh.pdf">CV/中</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv">CV/En</a>
  </li>
  
</ul>


  <div id="main-container">
    
<div class="container">
  <div class="row">
    <div class="col s12">


      <article id="post-行人检测论文笔记：Fused DNN - A deep neural network fusion approach to fast and robust pedestrian detection" class="article article-type-post" itemscope itemprop="blogPost">

        <div class="article-inner">
          

          <header class="article-header">
          
              
  
    <h1 class="article-title header" itemprop="name">
      行人检测论文笔记：Fused DNN - A deep neural network fusion approach to fast and robust pedestrian detection
    </h1>
  


          

            <div class="article-meta">
              <i class="fa fa-calendar"></i>
              <time datetime="2016-12-04T22:32:24.000Z" itemprop="datePublished">Dec 04, 2016</time>
            </div>
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <h2 id="相关知识点"><a href="#相关知识点" class="headerlink" title="相关知识点"></a>相关知识点</h2><ul>
<li><strong>L1范数</strong> 也称为最小绝对偏差（LAD），最小绝对误差（LAE）。它基本上最小化目标值(Yi)和估计值(f(xi))之间的绝对差(S)的和</li>
</ul>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqk8unvtj306d0273ye.jpg" alt=""></p>
<ul>
<li>L2范数也称为最小二乘。它基本上最小化目标值(Yi)和估计值(f(xi))之间的差(S)的平方的和</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk9chp0j305w01wjra.jpg" alt=""></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>所提出的网络融合架构允许多个网络的并行处理来提高速度。</li>
<li>首先是一个深度卷积网络被训练为一个物体检测器来生成所有有可能的不同尺寸和遮挡的行人候选集。</li>
<li>然后，多个深度神经网络被并行使用来之后提炼这些行人候选集。</li>
<li>我们引入基于软拒绝的网络融合方法将来自所有网络的软度量融合在一起，以产生最终置信分数。</li>
<li>此外，我们提出了一种用于将逐像素语义分割网络（ pixel-wise semantic segmentation network）集成到网络融合架构中作为行人检测器的加强的方法。</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Tradeoff between accuracy and speed.</li>
<li>其他因素，如拥挤的场景，非人堵塞物体(non-person occluding objects)或不同的行人外观（不同的姿势或服装风格）也使这个Real-time行人检测问题具有挑战性。</li>
<li>行人检测的一般框架可以分解为：</li>
<li>region proposal generation,</li>
<li>feature extraction,</li>
<li><p>pedestrian verification</p>
</li>
<li><p>Fused Deep Neural Network(F-DNN)</p>
</li>
<li>该架构包括行人pedestrian candidiate generator，其通过训练深卷积神经网络获得以，从而具有高检测率，虽然有大的假阳性率。</li>
<li>使用深度扩展卷积和上下文聚合的并行语义分割网络[30]为候选行人提供了另一个软的信任投票，它进一步与候选生成器和分类网络融合。</li>
</ul>
<h2 id="The-Fused-Deep-Neural-Network"><a href="#The-Fused-Deep-Neural-Network" class="headerlink" title="The Fused Deep Neural Network"></a>The Fused Deep Neural Network</h2><ul>
<li>提出的网络架构包括行人候选生成器，分类网络和像素级语义分割网络。</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqk6f5o3j30q00iumyv.jpg" alt=""></p>
<ul>
<li><p>SSD: a single shot multi-box detector(单镜头多箱检测器)，行人候选生成器是一个single shot multi-box detector（SSD）</p>
</li>
<li><p>每个行人候选者与其定位BB坐标和置信度得分相关联。</p>
</li>
<li>我们提出了一种新的网络融合方法——称为基于软拒绝的网络融合（SNF）。并非是执行接受或拒绝候选者的硬二进制分类，而是基于来自分类器的候选者的 <strong>聚合度</strong> 来提升或折扣行人候选者的置信度分数。</li>
<li>我们进一步提出了一种利用具有语义分割（SS）的上下文聚集扩展卷积网络（context aggregation dilated convolutional network with semantic segmentation）作为另一个分类器并将其集成到我们的网络融合架构中的方法。但是在速度上会变得特别慢。</li>
</ul>
<h3 id="Pedestrian-Candidate-Generator"><a href="#Pedestrian-Candidate-Generator" class="headerlink" title="Pedestrian Candidate Generator"></a>Pedestrian Candidate Generator</h3><ul>
<li>SSD是具有截断VGG16(truncated VGG16)作为基础网络的前馈卷积网络。</li>
<li>SSD的结构：</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqk7e7e6j30pe07rgmh.jpg" alt=""></p>
<ul>
<li><p>L2归一化技术用于缩小特征量</p>
</li>
<li><p>对于大小为m×n×p的每个输出层，在每个位置处设置不同尺度和纵横比的一组默认BB。 将3×3×p个卷积内核应用于每个位置以产生关于默认BB位置的分类分数和BB位置偏移。</p>
</li>
<li>训练的目标函数是：</li>
</ul>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcgw1fbfqka1k2nj306u01nq2u.jpg" alt=""></p>
<h3 id="Classiﬁcation-Network-and-Soft-rejection-based-DNN-Fusion"><a href="#Classiﬁcation-Network-and-Soft-rejection-based-DNN-Fusion" class="headerlink" title="Classiﬁcation Network and Soft-rejection based DNN Fusion"></a>Classiﬁcation Network and Soft-rejection based DNN Fusion</h3><ul>
<li>分类网络由多个二元分类深层神经网络组成，这些网络在第一阶段的生成的行人候选集中训练。</li>
<li>SNF：考虑一个行人候选人和一个分类器。如果分类器对候选人有高的信任度，我们通过乘以大于1的置信因子乘以候选发生器来提高其原始分数。否则，我们以小于1的缩放因子减小其得分。我们将“置信”定义为至少为ac的分类概率。为了融合所有M个分类器，我们将候选者的原始信任得分与分类网络中所有分类器的信任缩放因子的乘积相乘。</li>
</ul>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcgw1fbfqkaszbpj30q202qt9i.jpg" alt=""></p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcgw1fbfqkaaiiij3086024t8n.jpg" alt=""></p>
<ul>
<li>SNF背后的关键思想是，我们不直接接受或拒绝任何候选行人，而是基于分类概率的因素来扩展它们。</li>
</ul>
<h3 id="Pixel-wise-semantic-segmentation-for-object-detection-reinforcement"><a href="#Pixel-wise-semantic-segmentation-for-object-detection-reinforcement" class="headerlink" title="Pixel-wise semantic segmentation for object detection reinforcement"></a>Pixel-wise semantic segmentation for object detection reinforcement</h3><ul>
<li>为了执行密集预测，SS网络由完全卷积的VGG16网络组成，其适应于作为前端预测模块的扩展卷积，其输出被馈送到多尺度上下文聚合模块，该多尺度上下文聚合模块由完全卷积网络组成，其卷积层具有增加扩张因子。</li>
<li>输入图像被缩放并由SS网络直接处理，SS网络产生具有显示出行人类激活像素的一种颜色和显示出背景的其他颜色的二进遮罩。</li>
<li>我们使用以下策略来融合结果：如果行人像素占据候选BB区域的至少20％，我们接受候选者并保持其得分不变; 否则，我们应用SNF来缩放原始的信任分数。</li>
</ul>
<p><img src="https://ww4.sinaimg.cn/large/006tKfTcgw1fbfqkbeg8wj30g002cwen.jpg" alt=""></p>
<h2 id="Experiments-and-result-analysis"><a href="#Experiments-and-result-analysis" class="headerlink" title="Experiments and result analysis"></a>Experiments and result analysis</h2><h3 id="Data-and-evaluation-settings"><a href="#Data-and-evaluation-settings" class="headerlink" title="Data and evaluation settings"></a>Data and evaluation settings</h3><h3 id="Training-details-and-results"><a href="#Training-details-and-results" class="headerlink" title="Training details and results"></a>Training details and results</h3><ul>
<li><strong>硬拒绝（Hard Rejection）</strong> 被定义为消除由任何分类器分类为假阳性的任何候选者。</li>
</ul>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="http://jacobkong.github.io/blog/2553947436/" data-id="cjrnebv1o000h1k2pusjiio1x" class="article-share-link">Share</a>
            
              <a href="http://jacobkong.github.io/blog/2553947436/#disqus_thread" class="article-comment-link">Comments</a>
            
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Object-Detection/">Object Detection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/目标检测/">目标检测</a></li></ul>

          </footer>

        </div>

        
          
<nav id="article-nav" class="white">
  <div class="nav-wrapper">
    <ul class="row">
    
      <li class="col s6">
        <a href="/blog/4241353321/" id="article-nav-newer" class="article-nav-link-wrap grey-text text-darken-1 truncate">
          <i class="fa fa-arrow-left"></i>
          <span class="article-nav-title">深度学习论文笔记：Rich feature hierarchies for accurate object detection and semantic segmentation</span>
        </a>
      </li>
    

    
      <li class="col s6">
        <a href="/blog/2397281138/" id="article-nav-older" class="article-nav-link-wrap grey-text text-darken-1 right-align truncate">
          <span class="article-nav-title">行人检测论文笔记：How Far are We from Solving Pedestrian Detection?</span>
          <i class="fa fa-arrow-right"></i>
        </a>
      </li>
    

    </ul>
  </div>
</nav>


        
      </article>


      

      <hr />

      <section id="comments">
        <div id="disqus_thread">
          <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
      </section>
      



    </div>
  </div>
</div>


  
  <script>
    var disqus_shortname = 'jacobkong';
    
    var disqus_url = 'http://jacobkong.github.io/blog/2553947436/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  



  </div>

  <footer class="page-footer blue lighten-2">
    <div class="container">
        <div class="row">
            <div class="col l6 s12">
                <h5><a href="http://media.pkusz.edu.cn" class="white-text" target="_blank">Digital Media R&D Center, PKU</a></h5>
            </div>

        </div>
    </div>
    <div class="footer-copyright">
      <div class="container">
            Created by <a class="orange-text text-lighten-3" href="http://hexo.io/">Weijie Kong</a>. Last
            update 2019/03/02.

            <!-- <div class="right">
              Powered by <a href="http://hexo.io/" rel="nofollow" class="white-text" target="_blank">Hexo</a>
            </div> -->
        </div>
    </div>
  </footer>

  <script src="/js/app.js"></script>

</body>
</html>
