<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>深度学习论文笔记：Faster R-CNN | Weijie Kong&#39;s Homepage</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <meta name="description" content="Abstract
Region Proposal的计算是基于Region Proposal算法来假设物体位置的物体检测网络比如：SPPnet, Fast R-CNN运行时间的瓶颈。
Faster R-CNN引入了Region Proposal Network（RPN）来和检测网络共享整个图片的卷积网络特征，因此使得region proposal几乎是cost free的。
RPN-&amp;gt;预测物体">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习论文笔记：Faster R-CNN">
<meta property="og:url" content="http://jacobkong.github.io/blog/3802700508/index.html">
<meta property="og:site_name" content="Weijie Kong's Homepage">
<meta property="og:description" content="Abstract
Region Proposal的计算是基于Region Proposal算法来假设物体位置的物体检测网络比如：SPPnet, Fast R-CNN运行时间的瓶颈。
Faster R-CNN引入了Region Proposal Network（RPN）来和检测网络共享整个图片的卷积网络特征，因此使得region proposal几乎是cost free的。
RPN-&amp;gt;预测物体">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tKfTcjw1fcb3fr2k40j30cq07tt9a.jpg">
<meta property="og:image" content="https://ww4.sinaimg.cn/large/006tNc79ly1fdgik44luaj30pf0di40j.jpg">
<meta property="og:image" content="https://ww3.sinaimg.cn/large/006tKfTcjw1fcbwo1ut3hj309q02hjrj.jpg">
<meta property="og:image" content="https://ww1.sinaimg.cn/large/006tKfTcjw1fcbyiywha8j308k0300sy.jpg">
<meta property="og:image" content="https://ww2.sinaimg.cn/large/006tKfTcjw1fccbdrnzhij30bd0b1gml.jpg">
<meta property="og:updated_time" content="2017-03-09T06:32:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习论文笔记：Faster R-CNN">
<meta name="twitter:description" content="Abstract
Region Proposal的计算是基于Region Proposal算法来假设物体位置的物体检测网络比如：SPPnet, Fast R-CNN运行时间的瓶颈。
Faster R-CNN引入了Region Proposal Network（RPN）来和检测网络共享整个图片的卷积网络特征，因此使得region proposal几乎是cost free的。
RPN-&amp;gt;预测物体">
<meta name="twitter:image" content="https://ww4.sinaimg.cn/large/006tKfTcjw1fcb3fr2k40j30cq07tt9a.jpg">

  
    <link rel="alternate" href="/atom.xml" title="Weijie Kong&#39;s Homepage" type="application/atom+xml" />
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/favicon2.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/favicon2.png">

  <meta name="msapplication-TileImage" content="/favicon2.png"/>
  <meta name="msapplication-TileColor" content="#000000"/>

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png" />

  <link rel="icon" sizes="256x256" href="/favicon2.png" />
  <!--<![endif]-->
  

  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css" />

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/academicons.min.css"/>
  <link rel="stylesheet" href="/css/vendors.css">
  <link rel="stylesheet" href="/css/style.css">
  
  <!-- Google Analytics -->
  <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89889116-1', 'auto');
  ga('send', 'pageview');

  </script>
  <!-- End Google Analytics -->



  <script src="/js/vendors.js"></script>

  <script>
    define('jquery', function () {
      return window.jQuery;
    });
  </script>


</head>
<body>

  <div class="navbar-fixed">
  <nav id="main-navbar" class="blue z-depth-1" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span class="white-text">Weijie Kong&#39;s Homepage</span>
        
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/"><span class="white-text">Home</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog"><span class="white-text">Blog</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv/resume-zh.pdf"><span class="white-text">CV/中</sapn></a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/cv"><span class="white-text">CV/En</sapn></a>
          </li>
        
      </ul>

      <a href="#" data-activates="nav-mobile" class="button-collapse">
        <i class="material-icons white-text">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="side-nav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv/resume-zh.pdf">CV/中</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/cv">CV/En</a>
  </li>
  
</ul>


  <div id="main-container">
    
<div class="container">
  <div class="row">
    <div class="col s12">


      <article id="post-深度学习论文笔记：Faster R-CNN" class="article article-type-post" itemscope itemprop="blogPost">

        <div class="article-inner">
          

          <header class="article-header">
          
              
  
    <h1 class="article-title header" itemprop="name">
      深度学习论文笔记：Faster R-CNN
    </h1>
  


          

            <div class="article-meta">
              <i class="fa fa-calendar"></i>
              <time datetime="2016-12-16T22:32:24.000Z" itemprop="datePublished">Dec 16, 2016</time>
            </div>
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Region Proposal的计算</strong>是基于Region Proposal算法来假设物体位置的物体检测网络比如：<strong>SPPnet, Fast R-CNN</strong>运行时间的瓶颈。</li>
<li>Faster R-CNN引入了<strong>Region Proposal Network（RPN）</strong>来和检测网络共享整个图片的卷积网络特征，因此使得region proposal几乎是<strong>cost free</strong>的。</li>
<li>RPN-&gt;预测物体边界（object bounds）和在每一位置的分数（objectness score）</li>
<li>通过在一个网络中共享RPN和Fast R-CNN的卷积特征来融合两者——<strong>使用“attention”机制。</strong></li>
<li>300 proposals pre image.</li>
</ul>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>RP是当前许多先进检测系统的瓶颈。</li>
<li>Region proposal methods:<ul>
<li>Selective Search: one of the most popular method </li>
<li>EdgeBoxes: trade off between proposal quality and speed.</li>
<li>region proposal这一步依旧和检测网络花费同样多的时间。</li>
</ul>
</li>
<li>Fast R-CNN生成的feature map 也能用来生成RP。在这些卷积特征之上我们通过这样的方式构建RPN：通过添加几个额外的卷积层来模拟一个regular grid上每一个位置的regress region bounds和objectness scores。<strong>所以RPN也是一种fully convolutional network(FCN)</strong>，从而可以端到端训练来产生detection proposals。</li>
<li><strong>anchor boxes</strong>：references at multiple scales and aspect ratios. 我们的方法可以看成pyramid of regression reference，从而避免枚举多尺寸、多横纵比的images或者filters</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>R-CNN主要是一个分类器，他不能预测object bounds，他的准确性依赖于Region proposal模块的表现</li>
</ul>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><ul>
<li>由两个模块组成：<ul>
<li>第一个模块：A deep fuuly convolutional network that proposes regions，<strong>用来proposes regions</strong>.</li>
<li>第二个模块：Fast R-CNN检测器，使用第一模块提出的regions。</li>
</ul>
</li>
<li><strong>Attention mechanisms</strong>：RPN module告诉Fast R-CNN module 往哪里看（where to look）</li>
</ul>
<h3 id="Region-Proposal-Networks"><a href="#Region-Proposal-Networks" class="headerlink" title="Region Proposal Networks"></a>Region Proposal Networks</h3><ul>
<li><p>输入：一张<strong>任意尺寸</strong>的图片。</p>
</li>
<li><p>输出：一组矩形object proposal，每个proposal都有一个score。</p>
</li>
<li><p>是一个fully convolutional network（<strong>FCN</strong>），由于我们需要在RPN和Fast RCNN之间共享权值，所以我们假设两个网络<strong>共享一组共同的卷积层</strong>。</p>
</li>
<li><p>为了生成region proposals，我们在<strong>最后一层共享卷积层</strong>输出的feature map上滑动一个微型网络。这个微型网络将输入的feature map上的nxn的空间窗口作为输入。每一个滑动窗口被映射为一个低维特征(ZF: 256-d, VGG: 512-d, 之后跟着ReLU层)。这些特征然后被送到两个sibling全连接层中——<strong>一个box-regression(reg)层</strong>和<strong>一个box-classification(cls)层。</strong></p>
</li>
<li><p>注意：因为微型网络以滑动窗口方式操作，<strong>所以完全连接层在所有空间位置上共享。</strong> 这种结构自然地通过一个n×n卷积层，后面是两个同级<strong>1×1</strong>卷积层（分别用于rpn_reg和rpn_cls）来实现。</p>
</li>
<li><p>生成region proposal的思路：<br><img src="https://ww4.sinaimg.cn/large/006tKfTcjw1fcb3fr2k40j30cq07tt9a.jpg" alt=""></p>
</li>
<li><p>rpn网络结构定义如下：</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdgik44luaj30pf0di40j.jpg" alt=""></p>
<p>​</p>
<p>​</p>
</li>
</ul>
<h4 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h4><ul>
<li>假设每个位置最大可能的proposal的数量为k，在每个sliding-window位置，同时预测几个RP：<ul>
<li><em>reg layer</em>：有4k个输出</li>
<li><em>cls layer</em>：有2k个输出，指出该每一个proposal是否是object，<strong>estimate probability of object or not object for each proposal</strong>。</li>
</ul>
</li>
<li>k个proposal相对于k个参考框（reference boxes）而参数化，我们将参考框称为<strong>anchor</strong>。</li>
<li>一个anchor位于sliding window的中间，同时关联着一个scale和aspect ration。</li>
</ul>
<h5 id="Translation-Invariant-Anchors-平移不变性"><a href="#Translation-Invariant-Anchors-平移不变性" class="headerlink" title="Translation-Invariant Anchors(平移不变性)"></a>Translation-Invariant Anchors(平移不变性)</h5><ul>
<li>如果移动了一张图像中的一个物体，这proposal应该也移动了，而且相同的函数可以预测出热议未知的proposal。MultiBox不具备如此功能</li>
<li>平移不变性可以减少模型大小。</li>
</ul>
<h5 id="Multi-Scale-Anchor-as-Regression-References"><a href="#Multi-Scale-Anchor-as-Regression-References" class="headerlink" title="Multi-Scale Anchor as Regression References"></a>Multi-Scale Anchor as Regression References</h5><ul>
<li>Two popular ways for multi-scale predictions:<ul>
<li>第一种：based on image/feature pyramids, 如：DPM and CNN-based methods。图像被resized成不同尺寸，然后为每一种尺寸计算feature maps(HOG或者deep convolutional features)。这种方法比较<strong>费时</strong>。</li>
<li>第二种：use sliding windows of multiple scales (and/or aspect ratios) on the feature maps.——<strong>filters金字塔</strong>。第二种方法经常和第一种方法联合使用</li>
</ul>
</li>
<li>本论文的方法：<strong>anchor金字塔</strong>——more cost-efficient，只依靠单尺寸的图像和feature map。</li>
<li>The design of multiscale anchors is a <strong>key </strong>component for <strong>sharing features</strong> without extra cost for addressing scales.</li>
</ul>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><ul>
<li><p>为了训练RPN，我们给每个anchor设置了一个二元标签（是物体或者不是物体）</p>
</li>
<li><p>两类anchor是有<strong>正标签</strong>（is object）的：</p>
<ul>
<li>anchor/anchors with highest IoU overlap with a ground-truth box。</li>
<li>an anchor that has IoU overlap higher than 0.7 with any ground-truth box.</li>
<li>第二种方法更好检测正样本，在第二种情况下如果找不到正样本，那么使用第一种。</li>
</ul>
</li>
<li><p>如果一个anchor和任何ground-truth boxes的IoU值小于0.3，那么该anchor为<strong>负标签</strong></p>
</li>
<li><p>非正非负样本对training objective没有用。</p>
</li>
<li><p>Loss Function：</p>
<p>​</p>
<p><img src="https://ww3.sinaimg.cn/large/006tKfTcjw1fcbwo1ut3hj309q02hjrj.jpg" alt=""></p>
<p>$N<em>{cls}=256,N</em>{reg}=256*9=2304,\lambda=10$，这样两个loss就可以权重基本相当了。</p>
</li>
<li><p>Bounding box regression</p>
<p><img src="https://ww1.sinaimg.cn/large/006tKfTcjw1fcbyiywha8j308k0300sy.jpg" alt=""></p>
<p>这个可以考虑为从anchor box回归到附近的ground truth box。</p>
</li>
<li><p>和R-CNN和Fast R-CNN的bounding box regression方法不同的是：</p>
<ul>
<li>前两种的回归是在从任意大小RoI中提取的特征进行回归的，所以regression weights在<strong>所有尺寸中共享</strong>。</li>
<li>在我们的方法中，用于回归的特征都是同一个3x3的空间特征。考虑到变化的尺寸，有k个不同的bounding boxe回归器去学习，每一个回归器负责去学习一个尺寸一个衡重比的anchor。所以k个回归器是<strong>不共享权值的</strong>。所以<strong>得益于anchor的设计，即使特征规定，我们依旧可以去预测不同尺寸的box。</strong></li>
</ul>
</li>
</ul>
<h4 id="Training-RPNs"><a href="#Training-RPNs" class="headerlink" title="Training RPNs"></a>Training RPNs</h4><ul>
<li><strong>image-centric</strong> sampling strategy</li>
<li>mini-batch: arises from a single image that contains many positive and negative example anchors.</li>
<li>随机在一张图片中采样256个anchors来计算一个mini-batch的loss function。正负anchors = 1:1.</li>
<li>all new layers的<strong>权值初始化</strong>：高斯分布$(\mu = 0, \sigma = 0.01)$，all other layers（比如共享卷积层）用ImageNet来<strong>权值初始化</strong>。用ZF net来进行进行<strong>微调</strong>。</li>
<li><strong>学习率</strong>：0.001(60k)-&gt;0.0001(20k)</li>
<li><strong>动量</strong>：0.9</li>
<li><strong>weight decay</strong>: 0.0005</li>
</ul>
<h3 id="Sharing-Feature-for-RPN-and-Fast-R-CNN"><a href="#Sharing-Feature-for-RPN-and-Fast-R-CNN" class="headerlink" title="Sharing Feature for RPN and Fast R-CNN"></a>Sharing Feature for RPN and Fast R-CNN</h3><ul>
<li><p><strong>sharing convolutional layers between the two networks, rather than learning two separate networks</strong></p>
</li>
<li><p>三种特征共享的方法：</p>
<ul>
<li><p>Alternating training：迭代，先训练PRN，然后用proposal去训练Fast R-CNN。被Fast R-CNN微调的网络然后用来初始化PRN，以此迭代。本论文所有的实现都是使用该方法。</p>
</li>
<li><p>Approximate joint training：</p>
<p><img src="https://ww2.sinaimg.cn/large/006tKfTcjw1fccbdrnzhij30bd0b1gml.jpg" alt=""></p>
<p>RPN和Fast R-CNN融合到一个网络中进行训练。在每次SGD迭代过程中：</p>
<ul>
<li>前向传递：RPN产生region proposals，这些proposals被当做固定的、提前计算好的proposal来训练Fast R-CNN检测器。</li>
<li>反向传递：对于共享层来说，来自RPN的loss和Fast R-CNN的loss结合.</li>
<li>但是这种方法不考虑Bounding Boxes，忽略了proposal boxes的坐标也是网络的输出。所以这种方法叫做approximate</li>
</ul>
</li>
<li><p>Non-approximate joint training: 考虑Bounding Boxes。</p>
</li>
</ul>
</li>
<li><p>4-step Alternating Training:</p>
<ul>
<li>Step 1: train the RPN, initialized with an ImageNet-pre-trained model and <strong>ﬁne-tuned</strong> end-to-end for the region proposal task.</li>
<li>Step 2: train a separate detection network by Fast R-CNN using the proposals generated by the step-1 RPN. 同样使用ImageNet-pre-trained model来初始化。<strong>此时两个网络并没有共享卷积层。</strong></li>
<li>Step 3: use the detector network to initialize RPN training but we ﬁx the shared convolutional layers and only ﬁne-tune the layers unique to RPN. <strong>现在两个网络共享卷积层</strong></li>
<li>Step 4: keeping the shared convolutional layers ﬁxed, we ﬁne-tune the unique layers of Fast R-CNN.</li>
</ul>
</li>
</ul>
<h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul>
<li>Multi-scale与speed-accuracy之间的trade-off</li>
<li>To reduce redundancy, we adopt <strong>non-maximum suppression (NMS)</strong> on the proposal regions based on their cls scores.</li>
</ul>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="http://jacobkong.github.io/blog/3802700508/" data-id="cjrnebv2c000t1k2p3dt33vy3" class="article-share-link">Share</a>
            
              <a href="http://jacobkong.github.io/blog/3802700508/#disqus_thread" class="article-comment-link">Comments</a>
            
            
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Object-Detection/">Object Detection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/目标检测/">目标检测</a></li></ul>

          </footer>

        </div>

        
          
<nav id="article-nav" class="white">
  <div class="nav-wrapper">
    <ul class="row">
    
      <li class="col s6">
        <a href="/blog/2093106769/" id="article-nav-newer" class="article-nav-link-wrap grey-text text-darken-1 truncate">
          <i class="fa fa-arrow-left"></i>
          <span class="article-nav-title">深度学习实践经验：用Faster R-CNN训练行人检测数据集Caltech——准备工作</span>
        </a>
      </li>
    

    
      <li class="col s6">
        <a href="/blog/1679631826/" id="article-nav-older" class="article-nav-link-wrap grey-text text-darken-1 right-align truncate">
          <span class="article-nav-title">深度学习论文笔记：Fast R-CNN</span>
          <i class="fa fa-arrow-right"></i>
        </a>
      </li>
    

    </ul>
  </div>
</nav>


        
      </article>


      

      <hr />

      <section id="comments">
        <div id="disqus_thread">
          <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
      </section>
      



    </div>
  </div>
</div>


  
  <script>
    var disqus_shortname = 'jacobkong';
    
    var disqus_url = 'http://jacobkong.github.io/blog/3802700508/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  



  </div>

  <footer class="page-footer blue lighten-2">
    <div class="container">
        <div class="row">
            <div class="col l6 s12">
                <h5><a href="http://media.pkusz.edu.cn" class="white-text" target="_blank">Digital Media R&D Center, PKU</a></h5>
            </div>

        </div>
    </div>
    <div class="footer-copyright">
      <div class="container">
            Created by <a class="orange-text text-lighten-3" href="http://hexo.io/">Weijie Kong</a>. Last
            update 2019/03/02.

            <!-- <div class="right">
              Powered by <a href="http://hexo.io/" rel="nofollow" class="white-text" target="_blank">Hexo</a>
            </div> -->
        </div>
    </div>
  </footer>

  <script src="/js/app.js"></script>

</body>
</html>
