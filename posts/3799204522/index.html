<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Action Recognition,行为识别,CVPR 2018," />





  <link rel="alternate" href="/atom.xml" title="JacobKong's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition这是今年CVPR 2018中做行为识别的一篇文章，提出了一个叫做光流引导的特征（Optical Flow guided Feature，OFF）。时间信息是视频行为识别的关键，二光流可以很好的表征时">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记：CVPR 2018 关于行为识别论文略读笔记">
<meta property="og:url" content="http://jacobkong.github.io/posts/3799204522/index.html">
<meta property="og:site_name" content="JacobKong's Blog">
<meta property="og:description" content="论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition这是今年CVPR 2018中做行为识别的一篇文章，提出了一个叫做光流引导的特征（Optical Flow guided Feature，OFF）。时间信息是视频行为识别的关键，二光流可以很好的表征时">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fs2q4e9o1wj30yy0nf7cz.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fsea15nqunj315o0m3ah8.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79ly1fs44dyxu0aj30kl0migsy.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tKfTcgy1fs8h8br7cvj30l10qitfh.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8h7m3emnj30nb0o7gzt.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8hm9zxzsj313e09gwjz.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tKfTcgy1fs8ps5lpmpj30nk0cv0xn.jpg">
<meta property="og:updated_time" content="2018-06-17T09:05:57.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文笔记：CVPR 2018 关于行为识别论文略读笔记">
<meta name="twitter:description" content="论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition这是今年CVPR 2018中做行为识别的一篇文章，提出了一个叫做光流引导的特征（Optical Flow guided Feature，OFF）。时间信息是视频行为识别的关键，二光流可以很好的表征时">
<meta name="twitter:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fs2q4e9o1wj30yy0nf7cz.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://jacobkong.github.io/posts/3799204522/"/>




<script src="https://neveryu.github.io/js/src/pace.min.js"></script>

  <title> 论文笔记：CVPR 2018 关于行为识别论文略读笔记 | JacobKong's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89889116-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?62f2b754cef72ea357bef905cd2ce0b4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">JacobKong's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle">路漫漫其修远兮......</p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'NFszD9eySBJRbQZ_cJLt','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://jacobkong.github.io/posts/3799204522/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Jacob Kong">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="JacobKong's Blog">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="JacobKong's Blog" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                论文笔记：CVPR 2018 关于行为识别论文略读笔记
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-02T15:51:24+08:00">
                2018-06-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文笔记/" itemprop="url" rel="index">
                    <span itemprop="name">论文笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/posts/3799204522/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="posts/3799204522/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/posts/3799204522/" class="leancloud_visitors" data-flag-title="论文笔记：CVPR 2018 关于行为识别论文略读笔记">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="论文一：Optical-Flow-Guided-Feature-A-Fast-and-Robust-Motion-Representation-for-Video-Action-Recognition"><a href="#论文一：Optical-Flow-Guided-Feature-A-Fast-and-Robust-Motion-Representation-for-Video-Action-Recognition" class="headerlink" title="论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition"></a>论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition</h2><p>这是今年CVPR 2018中做行为识别的一篇文章，提出了一个叫做光流引导的特征（Optical Flow guided Feature，OFF）。时间信息是视频行为识别的关键，二光流可以很好的表征时间信息，其在视频分析领域已经被很多工作证明是一个很有用的特征。但是目前的双流网络Two-Stream在训练时其实还是比较麻烦的，因为需要单独对视频提取光流图，然后送到网络的另一至进行训练；而且如果数据集很大的话，光流图和RGB图像合起来得有原视频数据大小的好几倍，也十分消耗硬盘空间。因此思考如何利用单流网络同时利用RGB特征以及类似光流的特征去进行训练是一个值得思考的问题。本文从光流本身的定义出发，给了我们一个关于该问题很好的启发。该方法也在UCF-101逮到了96%的分类准确率，超过了不用Kinetics数据集预训练的I3D模型，可见该方法的有效性。</p>
<a id="more"></a>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fs2q4e9o1wj30yy0nf7cz.jpg" alt="image-20180607170447318"></p>
<p>本文提出的光流引导特征（OFF），它使网络能够通过快速和稳健的方法提取时间信息。 OFF由光流的定义导出，并与光流正交。该特征由水平和垂直方向上的特征图的空间梯度以及从不同帧的特征图之间的差异获得的时间梯度组成，OFF操作是CNN特征上的像素级运算，而且所有操作都是可导的，因此整个过程是可以端到端训练的，而且可以应用到仅有RGB输入的网络中去同时有效提取空间和时间特征。</p>
<h2 id="论文二：Recognize-Actions-by-Disentangling-Components-of-Dynamics"><a href="#论文二：Recognize-Actions-by-Disentangling-Components-of-Dynamics" class="headerlink" title="论文二：Recognize Actions by Disentangling Components of Dynamics"></a>论文二：Recognize Actions by Disentangling Components of Dynamics</h2><p>这是今年CVPR 2018中做行为识别的另一篇文章。<strong>本文和第一篇论文的中心思想相似：都是想通过原始的RGB图像直接在网络中间接获得类似光流的特征，从而减少目前双流网络中计算光流模块导致的额外开销。</strong>因此本文提出了一个新的用于视频表征学习的ConvNet框架，其可以完全从原始视频帧中推导出动态信息，而不需进行额外的光流估计。具体网络框架如下：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fsea15nqunj315o0m3ah8.jpg" alt=""></p>
<p>大致流程为：给定一个连续的帧序列，该模型首先产生一些低级特征映射，然后将其馈入三个分支，分别是静态外观（Static Appearance，上），外观动态（Apparent Motion，中）和外观变化（Appearance Change，下）。 这些分支分别计算其对应的高级特征并进行预测。 最后，这些预测被合并为最终的预测。最后，3个组件预测出的结果将通过求平均的方式融合到一起生成最终的预测。</p>
<p>其中在静态外观分支，通过迭代地应用2D卷积，空间2D池化和时间1D池化来逐渐提取外观特征；在外观动态分支，主要提取视频帧中特征点的空间位移，主要第一次引入了Cost Volume来进行外观动态的估计；在外观变化分支中，由于不是所有的变化都能够通过外观动态表解释，诸如物体外观的固有变化或照明变化的其他因素也可能导致视频帧的变化，不同于以前使用RGB-diff的方法，本文提出了一个叫做warped differences的方法来表征外观变化。</p>
<p>通过在UCF101和Kinetics两个数据集上进行验证，本文的方法在仅使用RGB图像帧的前提下也能取得很有竞争力的结果，而且具有很高的效率，证明了方法的优越性和有效性。</p>
<h2 id="论文三：2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning"><a href="#论文三：2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning" class="headerlink" title="论文三：2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning"></a>论文三：2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning</h2><p>这是今年CVPR 2018中做行为识别的一篇文章，主要突出了一个多任务网络来同时做2D和3D的姿态估计以及2D和3D的行为识别，同时利用姿态估计的结果来促进行为识别任务的性能。<strong>这也是解决问题的一个很好的出发点，就是利用两个任务来互相促进</strong>。</p>
<p>下图是网络的整体框架图，输入静态的RGB图像，同时进行姿态估计和行为识别。其中的姿态估计模型是利用基于回归的方法，其中利用了一个可微分的Softargmax来联合2D和3D的姿态估计。其中的动作识别方法分为两部分，一部分基于身体关节坐标序列，我们称之为<strong>基于姿态的识别</strong>，另一部分基于一系列视觉特征，我们称其为<strong>基于外观的识别</strong>。 将每个部分的结果组合起来估计最终的动作标签。</p>
<p>作者在MPII, Human3.6M, Penn Action 和 NTU四个数据集上进行了实验，验证了模型在两个任务上的有效性。</p>
<p>本文值得借鉴的一个思想就是：利用多任务之间的互相促进，来提升各自任务的有效性。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fs44dyxu0aj30kl0migsy.jpg" alt=""></p>
<h2 id="论文四：Deep-Progressive-Reinforcement-Learning-for-Skeleton-based-Action-Recognition"><a href="#论文四：Deep-Progressive-Reinforcement-Learning-for-Skeleton-based-Action-Recognition" class="headerlink" title="论文四：Deep Progressive Reinforcement Learning for Skeleton-based Action Recognition"></a>论文四：Deep Progressive Reinforcement Learning for Skeleton-based Action Recognition</h2><p>这是今年CVPR 2018中基于骨架（Skeleton-based）来做行为识别的一篇文章，但是一个重要的创新点是利用增强学习首先找到一段视频帧中最具动作代表性的帧，丢弃掉序列中的不明确帧，然后利用基于图的神经网络来捕捉关节连接点之间的依赖关系，从而达到行为识别的目的。框架图如下：</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fs8h8br7cvj30l10qitfh.jpg" alt=""></p>
<p><strong>方法大致流程为：</strong>给定一个人体关节的视频，我们首先选择框架提取网络（FDNet）来提取视频中的关键帧，这是由提出的深度渐进式强化学习方法进行训练所得到。 我们根据两个重要因素逐步调整每个状态下的选定帧。 一个是所选帧用于动作识别的所具备的判别能力。 另一个是所选帧与整个动作序列的关系。然后，我们采用<strong>基于图的卷积神经网络（GCNN）</strong>，它保留了人体关节之间的依赖关系，以处理所选关键帧以进行动作识别。 本文的方法在三个广泛使用的数据集上实现了非常有竞争力的性能。</p>
<h2 id="论文五：Im2Flow-Motion-Hallucination-from-Static-Images-for-Action-Recognition"><a href="#论文五：Im2Flow-Motion-Hallucination-from-Static-Images-for-Action-Recognition" class="headerlink" title="论文五：Im2Flow: Motion Hallucination from Static Images for Action Recognition"></a>论文五：Im2Flow: Motion Hallucination from Static Images for Action Recognition</h2><p>这是今年CVPR 2018中在<strong>静态图像</strong>中做行为识别的一篇文章。静态图像动作识别需要系统识别发生在单张照片中的行为。 该问题对于基于人类行为和事件组织照片集合（例如，在网络，社交媒体上的照片）具有实际意义。现有的一些方法都仅仅依据图像的表象特征——物体、场景和肢体姿势来区分单张静态图像中的动作，但是这样的方法会忽略图像中所包含的丰富的动态结构和动作。为了挖掘单张图片所包含的motion信息，本文提出了一种为单张图片产生类似光流的图像，表示图像中所蕴含的未来的可能的motion。 其中一个<strong>关键的想法是</strong>：从数千个未标记的视频中学习一个先验的短期动态，一次来在新的静态图像上推断的预期光流，然后训练利用RGB流和光流来进行的动作的识别。框架图如下：</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8h7m3emnj30nb0o7gzt.jpg" alt=""></p>
<p><strong>方法大致流程为：</strong>首先通过观察上千个包含各种动作的未标注的视频中学习一个动作的先验知识（motion prior）；然后利用下图中的Image-to-image translation模型，去将一个RGB图像转化为上图右边类似的光流图，改光流图是3通道的，前两个通道是motion angle $\theta\in[0,2\pi]$，第三个通道是幅度M。最后通过RGB图像和得到的光流图像去共同进行行为识别。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fs8hm9zxzsj313e09gwjz.jpg" alt=""></p>
<p>本方法很重要的一个创新点：结合了GAN中的Image-to-image translation模型来仅仅为静态图像即可生成相应的光流图，所预测出的光流是十分准确的，同时也提升了行为识别的准确性，思想值得借鉴。</p>
<h2 id="论文六：Compressed-Video-Action-Recognition"><a href="#论文六：Compressed-Video-Action-Recognition" class="headerlink" title="论文六：Compressed Video Action Recognition"></a>论文六：Compressed Video Action Recognition</h2><p>这是今年CVPR 2018中做行为识别的另一篇文章。本文很重要的一个创新点是：利用压缩视频作为输入来进行视频中的行为识别。原始的视频帧数据往往具有巨大的尺寸而且高时间冗余，关于动作的有用信息很容易淹没在许多不相关的背景数据中。利用压缩后的视频具有许多好处：首先由于视频压缩（使用H.264，HEVC等）可将原始视频信息量降低两个数量级；其次视频中压缩中的motion vector提供了额外的motion信息，这是RGB图像所不具备的；而且压缩视频排除了空间可变性，这样提高了模型的泛化性；最后压缩视频模型会更快更简单更准确；因此本文建议直接在压缩视频上训练深层网络。</p>
<p>大多数现代编解码器将视频分成I帧（内编码帧），P帧（预测帧）和零个或多个B帧（双向帧）。I帧是常规图像并且被压缩。P帧引用前面的帧并仅编码相对前一帧所需要的‘变化’。B帧可以被视为特殊的P帧，其中运动向量是双向计算的，并且只要在参考中没有循环就可以引用未来帧。</p>
<p>本文工作将视频压缩后得到的用于描述两帧之间变化的motion vector、residual帧图像（如下图所示）作为各种SOTA网络中输入进行行为识别，都得到了很明显的提升，而且更快速、更简单、更准确。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fs8ps5lpmpj30nk0cv0xn.jpg" alt=""></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Action-Recognition/" rel="tag"># Action Recognition</a>
          
            <a href="/tags/行为识别/" rel="tag"># 行为识别</a>
          
            <a href="/tags/CVPR-2018/" rel="tag"># CVPR 2018</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/posts/3531717168/" rel="next" title="行为检测论文笔记：One-shot Action Localization by Learning Sequence Matching Network">
                <i class="fa fa-chevron-left"></i> 行为检测论文笔记：One-shot Action Localization by Learning Sequence Matching Network
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/posts/3309988052/" rel="prev" title="行为识别论文笔记：Something about Temporal Reasoning">
                行为识别论文笔记：Something about Temporal Reasoning <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Jacob Kong" />
          <p class="site-author-name" itemprop="name">Jacob Kong</p>
          <p class="site-description motion-element" itemprop="description">欢迎来到孔伟杰（@JacobKong_Dev）的博客。 本人本科毕业于东北大学软件学院，目前在北大信工攻读硕士。 研究兴趣：计算机视觉|视频分析|行人检测。</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="mailto:weijie.kong@pku.edu.cn" target="_blank" title="Email">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                  Email
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/JacobKong" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2232756824" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#论文一：Optical-Flow-Guided-Feature-A-Fast-and-Robust-Motion-Representation-for-Video-Action-Recognition"><span class="nav-number">1.</span> <span class="nav-text">论文一：Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文二：Recognize-Actions-by-Disentangling-Components-of-Dynamics"><span class="nav-number">2.</span> <span class="nav-text">论文二：Recognize Actions by Disentangling Components of Dynamics</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文三：2D-3D-Pose-Estimation-and-Action-Recognition-using-Multitask-Deep-Learning"><span class="nav-number">3.</span> <span class="nav-text">论文三：2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文四：Deep-Progressive-Reinforcement-Learning-for-Skeleton-based-Action-Recognition"><span class="nav-number">4.</span> <span class="nav-text">论文四：Deep Progressive Reinforcement Learning for Skeleton-based Action Recognition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文五：Im2Flow-Motion-Hallucination-from-Static-Images-for-Action-Recognition"><span class="nav-number">5.</span> <span class="nav-text">论文五：Im2Flow: Motion Hallucination from Static Images for Action Recognition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#论文六：Compressed-Video-Action-Recognition"><span class="nav-number">6.</span> <span class="nav-text">论文六：Compressed Video Action Recognition</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jacob Kong</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'jacobkong';
      var disqus_identifier = 'posts/3799204522/';

      var disqus_title = "论文笔记：CVPR 2018 关于行为识别论文略读笔记";


      function run_disqus_script(disqus_script) {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');

      
        var disqus_config = function () {
            this.page.url = disqus_url;
            this.page.identifier = disqus_identifier;
            this.page.title = disqus_title;
        };
        run_disqus_script('embed.js');
      

    </script>
  









  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("YzdOPGD6UVitIPREYUH017Yt-gzGzoHsz", "W0g9MHOvC23K6PV4r2loD7d0");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  


</body>
</html>
