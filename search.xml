<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ã€CleanMyMac 3 æœ€æ–°ç‰ˆ å®˜æ–¹æ­£ç‰ˆåºåˆ—å· å…¨ç½‘æœ€ä½Ž 85å…ƒã€‘ã€é€Office 365 è®¢é˜… æ°¸ä¹…å‡çº§ç‰ˆè´¦å· ä»…éœ€25å…ƒã€‘]]></title>
    <url>%2Fposts%2F2173074278%2F</url>
    <content type="text"><![CDATA[ä½œä¸ºä¸€ä¸ªç»å¸¸æ½œæ°´äºŽè®ºå›çš„èŒæ–°ï¼Œä¹Ÿæ›¾ç»ä»Žè®ºå›æ”¶é›†åˆ°å„ç§ä¼˜ç§€çš„è½¯ä»¶ï¼Œæ”¶ç›Šé¢‡å¤šã€‚ CleanMyMac 3ä¸­æ–‡ç‰ˆä»…éœ€ï¿¥85å…¶ä¸­CleanMyMac 3å¯ä»¥è¯´æ˜¯Macä¸Šæœ€å—æ¬¢è¿Žçš„ç³»ç»Ÿæ¸…ç†è½¯ä»¶ï¼Œä¹Ÿæ˜¯è®ºå›ä¸­æœç´¢å…³é”®è¯æœ€å¤šçš„è½¯ä»¶ï¼Œä¸‹è½½ä¹Ÿæ˜¯æœ€å¤šçš„ã€‚ ç„¶è€Œè¿™æ¬¾è½¯ä»¶å¯ä»¥è¯´æœ‰ä¸ªå¾ˆè›‹ç–¼çš„åœ°æ–¹ï¼Œå°±æ˜¯åªè¦macç³»ç»Ÿå‡çº§åˆ°æ–°ä¸€ç‰ˆçš„ç³»ç»Ÿï¼Œç ´jieç‰ˆçš„è½¯ä»¶å°±å¤±æ•ˆæ— æ³•ä½¿ç”¨ï¼Œè€Œç›®å‰CleanMyMac 3å®˜æ–¹æ­£ç‰ˆï¿¥99çš„ä»·é’±ï¼Œå…¶å®žä½œä¸ºä¸€æ¬¾åžƒåœ¾æ¸…ç†è½¯ä»¶ï¼Œè¿˜æ˜¯æœ‰ç‚¹å°è´µã€‚ ä»Šå¤©ï¼Œã€ä¹”å¸ƒæ•°ç ã€‘æ­£å¼å¼€ä¸šï¼Œä¸ºäº†å›žé¦ˆå¹¿å¤§è®ºå›å¥½å‹ä¹‹å‰åˆ†äº«çš„å„ç§ä¼˜ç§€è½¯ä»¶ï¼Œä¸è¿½æ±‚åˆ©æ¶¦ï¼Œåªè¿½æ±‚å£ç¢‘ï¼ŒCleanMyMac 3ä¸­æ–‡ç‰ˆç›®å‰ä»…éœ€ï¿¥85ï¼Œå¯ä»¥è¯´æ˜¯å…¨ç½‘æœ€ä½Žä»·äº†ï¼ä¿è¯æ˜¯å®˜æ–¹æ­£ç‰ˆï¼Œä¸€æœºä¸€å·ï¼ŒåŒç‰ˆæœ¬æ°¸ä¹…å‡çº§ï¼Œå†ä¹Ÿä¸ç”¨æ€•ç³»ç»Ÿå‡çº§å¯¼è‡´è½¯ä»¶æ— æ³•ä½¿ç”¨äº†ï¼ ä¹‹å‰çŠ¹è±«å«Œè´µçš„æœ‹å‹æŠ“ç´§è¿™æ¬¡å¯ä»¥èº²ä¸€æ¬¡æ‰‹äº†ï¼Œå¾ˆå¿«å°†æ¢å¤åŽŸä»·ï¼ ç›®å‰è´­ä¹°è¯¥è½¯ä»¶å¯ä»¥é€Office 365æ­£ç‰ˆæ°¸ä¹…å‡çº§è´¦å·ä¸€ä¸ªï¼Œç¦åˆ©å¤šå¤šï¼ è”ç³»å®¢æœï¼Œå‘é€æš—å·â€œè®ºå›â€æ”¹ä»·ï¼ ç”µè„‘ç‰ˆè®¿é—®ï¼š https://item.taobao.com/item.htm?spm=a1z38n.10677092.0.0.4ca41debljWxbC&amp;id=570190131412 æ‰‹æœºç‰ˆç²˜è´´ä»¥ä¸‹å†…å®¹ï¼Œåœ¨æ‰‹æ·˜ä¸­æ‰“å¼€å³å¯ï¼š ã€CleanMyMac 3æ¿€æ´»ç åºåˆ—å· clean my macä½Žä»·æ³¨å†Œç é‡è£…æ›´æ–°ã€‘http://m.tb.cn/h.3ZaAKWb ç‚¹å‡»é“¾æŽ¥ï¼Œå†é€‰æ‹©æµè§ˆå™¨å’‘é–žï¼›æˆ–å¾©Â·åˆ¶è¿™æ®µæè¿°â‚¬kr7z0wvz2ooâ‚¬åŽåˆ°ðŸ‘‰æ·˜â™‚å¯³â™€ðŸ‘ˆ ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Office 365 ä»…éœ€25å…ƒæ›´æœ‰æ­£ç‰ˆOffice 365è´¦å·ï¼Œä¸€äººä¸€å·ï¼Œæ°¸ä¹…å‡çº§ï¼Œæ¯ä¸ªè´¦å·å¯ä»¥æ¿€æ´»5å°PC+Macä»¥åŠ5å°ç§»åŠ¨è®¾å¤‡ï¼Œç›®å‰ä»…éœ€ï¿¥25ï¼š ç”µè„‘ç‰ˆè®¿é—®ï¼š https://item.taobao.com/item.htm?spm=a1z38n.10677092.0.0.4ca41debljWxbC&amp;id=570292742115 æ‰‹æœºç‰ˆç²˜è´´ä»¥ä¸‹å†…å®¹ï¼Œåœ¨æ‰‹æ·˜ä¸­æ‰“å¼€å³å¯ï¼š ã€Office365 2016 è®¢é˜… win mac ipad å®¶åº­ä¸ªäºº word excel pptã€‘http://m.tb.cn/h.3ZdsIlS ç‚¹å‡»é“¾æŽ¥ï¼Œå†é€‰æ‹©æµè§ˆå™¨å’‘é–žï¼›æˆ–å¾©Â·åˆ¶è¿™æ®µæè¿°â‚¬MOaA0wvy9ySâ‚¬åŽåˆ°ðŸ‘‰æ·˜â™‚å¯³â™€ðŸ‘ˆ]]></content>
      <categories>
        <category>è½¯ä»¶åˆ†äº«</category>
      </categories>
      <tags>
        <tag>è½¯ä»¶åˆ†äº«</tag>
        <tag>CleanMyMac</tag>
        <tag>Office</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è®ºæ–‡ç¬”è®°ï¼šCVPR 2018 å…³äºŽè¡Œä¸ºè¯†åˆ«è®ºæ–‡ç•¥è¯»ç¬”è®°ï¼ˆäºŒï¼‰]]></title>
    <url>%2Fposts%2F3799204522%2F</url>
    <content type="text"><![CDATA[è®ºæ–‡äº”ï¼šPoTion: Pose MoTion Representation for Action Recognitionå’Œä¸Šé¢ä¸¤ç¯‡è®ºæ–‡ç±»ä¼¼ï¼Œè¿™ç¯‡æ–‡ç« ä¸»è¦æ˜¯åˆ©ç”¨äººä½“å…³é”®ç‚¹ï¼ˆKeypointï¼‰æ¥åšè¡Œä¸ºè¯†åˆ«ã€‚ç›®å‰çš„è®¸å¤šæ–¹æ³•ä¸»è¦æ˜¯åŒæµç½‘ç»œæ¥åˆ†åˆ«å¤„ç†å¤–è§‚ï¼ˆappearanceï¼‰å’ŒåŠ¨æ€ï¼ˆmotionï¼‰ã€‚åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œä½œè€…å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„è¡¨ç¤ºæ–¹å¼ï¼Œå¯ä»¥ä¼˜é›…åœ°ç¼–ç æŸäº›è¯­ä¹‰å…³é”®ç‚¹çš„ç§»åŠ¨ã€‚æˆ‘ä»¬ä½¿ç”¨äººä½“å…³èŠ‚ä½œä¸ºè¿™äº›å…³é”®ç‚¹ï¼Œç¼–ç åŽçš„ç»´åº¦å›ºå®šçš„ç‰¹å¾ç§°ä¸ºï¼šPoTionï¼Œå°†è¯¥ç‰¹å¾å›¾è¾“é€åˆ°ç®€å•çš„CNNä¸­å³å¯ç”¨ç”¨æ¥è¡Œä¸ºè¯†åˆ«åˆ†ç±»ã€‚æ–¹æ³•æ¡†æž¶å›¾å¦‚ä¸‹ï¼š æ–¹æ³•å¤§è‡´æµç¨‹ä¸ºï¼šé¦–å…ˆåœ¨æ¯ä¸ªå¸§ä¸­è¿è¡Œç›®å‰æœ€å…ˆè¿›çš„äººä½“å§¿æ€ä¼°è®¡å™¨ï¼Œå¹¶ä¸ºæ¯ä¸ªäººä½“å…³èŠ‚èŽ·å–çƒ­å›¾ã€‚è¿™äº›çƒ­å›¾å¯¹æ¯ä¸ªåƒç´ çš„æ¦‚çŽ‡è¿›è¡Œç¼–ç ä»¥åŒ…å«ç‰¹å®šçš„å…³èŠ‚ã€‚æˆ‘ä»¬ä½¿ç”¨å–å†³äºŽè§†é¢‘ç‰‡æ®µå¸§çš„ç›¸å¯¹æ—¶é—´çš„é¢œè‰²å¯¹è¿™äº›çƒ­åº¦å›¾è¿›è¡Œç€è‰²ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ä¸ºä¸åŒé€šé“ä¸‹çš„éšæ—¶é—´çš„ä¸Šè‰²æœºåˆ¶ï¼š å¯¹äºŽæ¯ä¸ªå…³èŠ‚ï¼Œæˆ‘ä»¬å¯¹æ‰€æœ‰å¸§ä¸Šçš„å½©è‰²çƒ­å›¾è¿›è¡Œæ±‚å’Œï¼Œä»¥èŽ·å¾—æ•´ä¸ªè§†é¢‘ç‰‡æ®µçš„PoTionè¡¨ç¤ºã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºä¸ºæŸä¸€å…³èŠ‚ç‚¹èšåˆä¹‹åŽçš„è‰²å½©å›¾ï¼Œä½¿ç”¨äº†ä¸åŒçš„èšåˆæ–¹å¼ï¼š ç»™å®šè¿™ç§è¡¨ç¤ºå½¢å¼ï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæµ…å±‚CNNæž¶æž„ï¼ŒåŒ…å«6ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªå®Œå…¨è¿žæŽ¥çš„å±‚æ¥æ‰§è¡ŒåŠ¨ä½œåˆ†ç±»ï¼ŒCNNç»“æž„å¦‚ä¸‹ï¼š æ•´ä¸ªè¿™ä¸ªç½‘ç»œå¯ä»¥ä»Žå¤´å¼€å§‹è®­ç»ƒï¼Œå¹¶èƒœè¿‡å…¶ä»–å§¿åŠ¿è¡¨ç¤ºå•†æ³•ã€‚è€Œä¸”ï¼Œç”±äºŽç½‘ç»œå¾ˆæµ…å¹¶ä¸”ä»¥æ•´ä¸ªè§†é¢‘clipçš„ç´§å‡‘è¡¨ç¤ºä¸ºè¾“å…¥ï¼Œå› æ­¤è®­ç»ƒä¾‹å¦‚éžå¸¸å¿«é€Ÿã€‚åœ¨ä¸€å°ç”¨äºŽHMDBçš„GPUä¸Šåªéœ€è¦4ä¸ªå°æ—¶ï¼Œè€Œæ ‡å‡†çš„åŒæµæ–¹æ³•åˆ™éœ€è¦å‡ å¤©çš„åŸ¹è®­å’Œä»”ç»†çš„åˆå§‹åŒ–[5,43]ã€‚å¦å¤–ï¼ŒPoTionå¯ä»¥çœ‹åšæ˜¯æ ‡å‡†å¤–è§‚å’Œè¿åŠ¨æµçš„è¡¥å……ã€‚ä¸ŽRGBå’Œå…‰å­¦æµç¨‹çš„I3D [5]ç»“åˆä½¿ç”¨æ—¶ï¼Œæˆ‘ä»¬åœ¨JHMDBï¼ŒHMDBï¼ŒUCF101ä¸ŠèŽ·å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ è®ºæ–‡å…­ï¼šIm2Flow: Motion Hallucination from Static Images for Action Recognitionè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åœ¨é™æ€å›¾åƒä¸­åšè¡Œä¸ºè¯†åˆ«çš„ä¸€ç¯‡æ–‡ç« ã€‚é™æ€å›¾åƒåŠ¨ä½œè¯†åˆ«éœ€è¦ç³»ç»Ÿè¯†åˆ«å‘ç”Ÿåœ¨å•å¼ ç…§ç‰‡ä¸­çš„è¡Œä¸ºã€‚ è¯¥é—®é¢˜å¯¹äºŽåŸºäºŽäººç±»è¡Œä¸ºå’Œäº‹ä»¶ç»„ç»‡ç…§ç‰‡é›†åˆï¼ˆä¾‹å¦‚ï¼Œåœ¨ç½‘ç»œï¼Œç¤¾äº¤åª’ä½“ä¸Šçš„ç…§ç‰‡ï¼‰å…·æœ‰å®žé™…æ„ä¹‰ã€‚çŽ°æœ‰çš„ä¸€äº›æ–¹æ³•éƒ½ä»…ä»…ä¾æ®å›¾åƒçš„è¡¨è±¡ç‰¹å¾â€”â€”ç‰©ä½“ã€åœºæ™¯å’Œè‚¢ä½“å§¿åŠ¿æ¥åŒºåˆ†å•å¼ é™æ€å›¾åƒä¸­çš„åŠ¨ä½œï¼Œä½†æ˜¯è¿™æ ·çš„æ–¹æ³•ä¼šå¿½ç•¥å›¾åƒä¸­æ‰€åŒ…å«çš„ä¸°å¯Œçš„åŠ¨æ€ç»“æž„å’ŒåŠ¨ä½œã€‚ä¸ºäº†æŒ–æŽ˜å•å¼ å›¾ç‰‡æ‰€åŒ…å«çš„motionä¿¡æ¯ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸ºå•å¼ å›¾ç‰‡äº§ç”Ÿç±»ä¼¼å…‰æµçš„å›¾åƒï¼Œè¡¨ç¤ºå›¾åƒä¸­æ‰€è•´å«çš„æœªæ¥çš„å¯èƒ½çš„motionã€‚ å…¶ä¸­ä¸€ä¸ªå…³é”®çš„æƒ³æ³•æ˜¯ï¼šä»Žæ•°åƒä¸ªæœªæ ‡è®°çš„è§†é¢‘ä¸­å­¦ä¹ ä¸€ä¸ªå…ˆéªŒçš„çŸ­æœŸåŠ¨æ€ï¼Œä¸€æ¬¡æ¥åœ¨æ–°çš„é™æ€å›¾åƒä¸ŠæŽ¨æ–­çš„é¢„æœŸå…‰æµï¼Œç„¶åŽè®­ç»ƒåˆ©ç”¨RGBæµå’Œå…‰æµæ¥è¿›è¡Œçš„åŠ¨ä½œçš„è¯†åˆ«ã€‚æ¡†æž¶å›¾å¦‚ä¸‹ï¼š æ–¹æ³•å¤§è‡´æµç¨‹ä¸ºï¼šé¦–å…ˆé€šè¿‡è§‚å¯Ÿä¸Šåƒä¸ªåŒ…å«å„ç§åŠ¨ä½œçš„æœªæ ‡æ³¨çš„è§†é¢‘ä¸­å­¦ä¹ ä¸€ä¸ªåŠ¨ä½œçš„å…ˆéªŒçŸ¥è¯†ï¼ˆmotion priorï¼‰ï¼›ç„¶åŽåˆ©ç”¨ä¸‹å›¾ä¸­çš„Image-to-image translationæ¨¡åž‹ï¼ŒåŽ»å°†ä¸€ä¸ªRGBå›¾åƒè½¬åŒ–ä¸ºä¸Šå›¾å³è¾¹ç±»ä¼¼çš„å…‰æµå›¾ï¼Œæ”¹å…‰æµå›¾æ˜¯3é€šé“çš„ï¼Œå‰ä¸¤ä¸ªé€šé“æ˜¯motion angle $\theta\in[0,2\pi]$ï¼Œç¬¬ä¸‰ä¸ªé€šé“æ˜¯å¹…åº¦Mã€‚æœ€åŽé€šè¿‡RGBå›¾åƒå’Œå¾—åˆ°çš„å…‰æµå›¾åƒåŽ»å…±åŒè¿›è¡Œè¡Œä¸ºè¯†åˆ«ã€‚ æœ¬æ–¹æ³•å¾ˆé‡è¦çš„ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼šç»“åˆäº†GANä¸­çš„Image-to-image translationæ¨¡åž‹æ¥ä»…ä»…ä¸ºé™æ€å›¾åƒå³å¯ç”Ÿæˆç›¸åº”çš„å…‰æµå›¾ï¼Œæ‰€é¢„æµ‹å‡ºçš„å…‰æµæ˜¯ååˆ†å‡†ç¡®çš„ï¼ŒåŒæ—¶ä¹Ÿæå‡äº†è¡Œä¸ºè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œæ€æƒ³å€¼å¾—å€Ÿé‰´ã€‚ è®ºæ–‡ä¸ƒï¼šCompressed Video Action Recognitionè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åšè¡Œä¸ºè¯†åˆ«çš„å¦ä¸€ç¯‡æ–‡ç« ã€‚æœ¬æ–‡å¾ˆé‡è¦çš„ä¸€ä¸ªåˆ›æ–°ç‚¹æ˜¯ï¼šåˆ©ç”¨åŽ‹ç¼©è§†é¢‘ä½œä¸ºè¾“å…¥æ¥è¿›è¡Œè§†é¢‘ä¸­çš„è¡Œä¸ºè¯†åˆ«ã€‚åŽŸå§‹çš„è§†é¢‘å¸§æ•°æ®å¾€å¾€å…·æœ‰å·¨å¤§çš„å°ºå¯¸è€Œä¸”é«˜æ—¶é—´å†—ä½™ï¼Œå…³äºŽåŠ¨ä½œçš„æœ‰ç”¨ä¿¡æ¯å¾ˆå®¹æ˜“æ·¹æ²¡åœ¨è®¸å¤šä¸ç›¸å…³çš„èƒŒæ™¯æ•°æ®ä¸­ã€‚åˆ©ç”¨åŽ‹ç¼©åŽçš„è§†é¢‘å…·æœ‰è®¸å¤šå¥½å¤„ï¼šé¦–å…ˆç”±äºŽè§†é¢‘åŽ‹ç¼©ï¼ˆä½¿ç”¨H.264ï¼ŒHEVCç­‰ï¼‰å¯å°†åŽŸå§‹è§†é¢‘ä¿¡æ¯é‡é™ä½Žä¸¤ä¸ªæ•°é‡çº§ï¼›å…¶æ¬¡è§†é¢‘ä¸­åŽ‹ç¼©ä¸­çš„motion vectoræä¾›äº†é¢å¤–çš„motionä¿¡æ¯ï¼Œè¿™æ˜¯RGBå›¾åƒæ‰€ä¸å…·å¤‡çš„ï¼›è€Œä¸”åŽ‹ç¼©è§†é¢‘æŽ’é™¤äº†ç©ºé—´å¯å˜æ€§ï¼Œè¿™æ ·æé«˜äº†æ¨¡åž‹çš„æ³›åŒ–æ€§ï¼›æœ€åŽåŽ‹ç¼©è§†é¢‘æ¨¡åž‹ä¼šæ›´å¿«æ›´ç®€å•æ›´å‡†ç¡®ï¼›å› æ­¤æœ¬æ–‡å»ºè®®ç›´æŽ¥åœ¨åŽ‹ç¼©è§†é¢‘ä¸Šè®­ç»ƒæ·±å±‚ç½‘ç»œã€‚ å¤§å¤šæ•°çŽ°ä»£ç¼–è§£ç å™¨å°†è§†é¢‘åˆ†æˆIå¸§ï¼ˆå†…ç¼–ç å¸§ï¼‰ï¼ŒPå¸§ï¼ˆé¢„æµ‹å¸§ï¼‰å’Œé›¶ä¸ªæˆ–å¤šä¸ªBå¸§ï¼ˆåŒå‘å¸§ï¼‰ã€‚Iå¸§æ˜¯å¸¸è§„å›¾åƒå¹¶ä¸”è¢«åŽ‹ç¼©ã€‚På¸§å¼•ç”¨å‰é¢çš„å¸§å¹¶ä»…ç¼–ç ç›¸å¯¹å‰ä¸€å¸§æ‰€éœ€è¦çš„â€˜å˜åŒ–â€™ã€‚Bå¸§å¯ä»¥è¢«è§†ä¸ºç‰¹æ®Šçš„På¸§ï¼Œå…¶ä¸­è¿åŠ¨å‘é‡æ˜¯åŒå‘è®¡ç®—çš„ï¼Œå¹¶ä¸”åªè¦åœ¨å‚è€ƒä¸­æ²¡æœ‰å¾ªçŽ¯å°±å¯ä»¥å¼•ç”¨æœªæ¥å¸§ã€‚ æœ¬æ–‡å·¥ä½œå°†è§†é¢‘åŽ‹ç¼©åŽå¾—åˆ°çš„ç”¨äºŽæè¿°ä¸¤å¸§ä¹‹é—´å˜åŒ–çš„motion vectorã€residualå¸§å›¾åƒï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ä½œä¸ºå„ç§SOTAç½‘ç»œä¸­è¾“å…¥è¿›è¡Œè¡Œä¸ºè¯†åˆ«ï¼Œéƒ½å¾—åˆ°äº†å¾ˆæ˜Žæ˜¾çš„æå‡ï¼Œè€Œä¸”æ›´å¿«é€Ÿã€æ›´ç®€å•ã€æ›´å‡†ç¡®ã€‚ è®ºæ–‡å…«ï¼šWhat have we learned from deep representations for action recognition?è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­å¯¹è¡Œä¸ºè¯†åˆ«ä»»åŠ¡æ—¶ç©ºç‰¹å¾ç ”ç©¶çš„ä¸€ç¯‡æŽ¢ç©¶æ€§æ–‡ç« ã€‚è¿™ç¯‡æ–‡ç« é€šè¿‡å¯è§†åŒ–åŒæµç½‘ç»œå…·ä½“æ‰€å­¦ä¹ åˆ°çš„æ—¶ç©ºç‰¹å¾æ¥æŽ¢ç©¶è§†é¢‘ä¸­è¡Œä¸ºè¯†åˆ«è¿™ä¸€ä»»åŠ¡ã€‚æˆ‘ä»¬å±•ç¤ºäº†ç”¨äºŽå¤–è§‚å’Œè¿åŠ¨ç‰©ä½“çš„å±€éƒ¨æ£€æµ‹å™¨ï¼Œä»¥å½¢æˆç”¨äºŽè¯†åˆ«äººç±»è¡Œä¸ºçš„åˆ†å¸ƒå¼è¡¨ç¤ºã€‚ ç›®å‰çš„å¯è§†åŒ–æ–¹æ³•æœ‰ä¸‰ç±»ï¼š Visualization for given inputs. Activation maximization. Generative Adversarial Networks (GANs). æœ¬æ–‡çš„å¯è§†åŒ–æ–¹æ³•æ˜¯åŸºäºŽactivation maximizationå¹¶å°†å®ƒä»¬æ‰©å±•åˆ°æ—¶ç©ºåŸŸï¼Œä»¥ä¾¿åœ¨åŒæµèžåˆæ¨¡åž‹ä¸­æ‰¾åˆ°å„ä¸ªå•å…ƒçš„é¦–é€‰æ—¶ç©ºè¾“å…¥ï¼Œæˆ‘ä»¬å°†é—®é¢˜è¡¨è¿°ä¸ºåœ¨è¾“å…¥ç©ºé—´ä¸­æœç´¢çš„ï¼ˆæ­£åˆ™åŒ–çš„ï¼‰åŸºäºŽæ¢¯åº¦çš„ä¼˜åŒ–é—®é¢˜ï¼Œæ–¹æ³•æ¡†æž¶å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ æ–¹æ³•æµç¨‹ä¸ºï¼šéšæœºåˆå§‹åŒ–çš„è¾“å…¥å‘ˆçŽ°ç»™æˆ‘ä»¬æ¨¡åž‹çš„å…‰æµå’Œå¤–è§‚è·¯å¾„ã€‚ æˆ‘ä»¬è®¡ç®—ç‰¹å¾å›¾ä¸€ç›´åˆ°æˆ‘ä»¬æƒ³è¦å¯è§†åŒ–çš„ç‰¹å®šå›¾å±‚ã€‚ é€‰æ‹©å•ä¸ªç›®æ ‡ç‰¹å¾é€šé“cï¼Œå¹¶ä¸”æ‰§è¡Œæ¿€æ´»æœ€å¤§åŒ–ï¼ˆactivation maximizationï¼‰ä»¥åˆ†ä¸¤æ­¥äº§ç”Ÿä¼˜é€‰è¾“å…¥ï¼ˆpreferred inputï¼‰ã€‚ é¦–å…ˆï¼Œå½±å“cçš„è¾“å…¥ä¸Šçš„å¯¼æ•°æ˜¯é€šè¿‡å°†ç›®æ ‡æŸè€—ï¼ˆåœ¨æ‰€æœ‰ä½ç½®ä¸Šæ±‚å’Œï¼‰åå‘è®¡ç®—åˆ°è¾“å…¥å±‚æ¥è®¡ç®—çš„ã€‚ å…¶æ¬¡ï¼Œé€šè¿‡å­¦ä¹ é€ŸçŽ‡ç¼©æ”¾ä¼ æ’­çš„æ¢¯åº¦å¹¶å°†å…¶æ·»åŠ åˆ°å½“å‰è¾“å…¥ã€‚ è¿™äº›æ“ä½œç”±å›¾2ä¸­çš„è™šçº¿çº¢çº¿è¯´æ˜Žã€‚åŸºäºŽæ¢¯åº¦çš„ä¼˜åŒ–ä»¥è‡ªé€‚åº”é™ä½Žçš„å­¦ä¹ é€ŸçŽ‡è¿­ä»£åœ°æ‰§è¡Œè¿™äº›æ­¥éª¤ï¼Œç›´åˆ°è¾“å…¥æ”¶æ•›ä¸ºæ­¢ã€‚ é‡è¦çš„æ˜¯ï¼Œåœ¨æ­¤ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œç½‘ç»œæƒé‡ä¸ä¼šæ”¹å˜ï¼Œåªæœ‰è¾“å…¥æŽ¥æ”¶æ›´æ”¹ã€‚ ä¸»è¦çš„ç»“è®ºæœ‰å¦‚ä¸‹å››ç‚¹ï¼š ç¬¬ä¸€ï¼šç›¸æ¯”äºŽåˆ†å¼€å•ç‹¬å­¦ä¹ å¤–è§‚ä»¥åŠè¿åŠ¨ç‰¹å¾ï¼Œcross-streamå¯ä»¥å­¦ä¹ åˆ°çœŸæ­£çš„æ—¶ç©ºç‰¹å¾ ç¬¬äºŒï¼šç½‘ç»œå¯ä»¥å­¦ä¹ é«˜åº¦ç±»åˆ«å·²çŸ¥çš„æœ¬åœ°è¡¨ç¤ºï¼Œä¹Ÿå¯ä»¥å­¦ä¹ é€‚ç”¨äºŽä¸€ç³»åˆ—ç±»çš„é€šç”¨è¡¨ç¤ºã€‚ ç¬¬ä¸‰ï¼šé€šè¿‡ç½‘ç»œç»“æž„ï¼Œç‰¹å¾å˜å¾—æ›´åŠ æŠ½è±¡å¹¶ä¸”å¯¹äºŽå¯¹èŽ·å¾—æœŸæœ›çš„åˆ†å¸ƒä¸é‡è¦çš„æ•°æ®ï¼ˆæ¯”å¦‚ä¸åŒé€Ÿåº¦é—´çš„motionæ¨¡å¼ï¼‰æ˜¾ç¤ºå‡ºé€æ¸å¢žåŠ çš„ä¸å˜æ€§ã€‚ ç¬¬å››ï¼šå¯è§†åŒ–ä¸ä»…å¯ç”¨äºŽæ­ç¤ºå­¦ä¹ çš„è¡¨ç¤ºï¼Œè¿˜å¯ç”¨äºŽæ­ç¤ºè®­ç»ƒæ•°æ®çš„ç‰¹æ€§å¹¶è§£é‡Šç³»ç»Ÿçš„å¤±è´¥æƒ…å†µã€‚ è®ºæ–‡å…«ï¼šNon-local Neural Networksè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åšåˆ©ç”¨Non-localæ–¹æ³•åŽ»åšè¡Œä¸ºè¯†åˆ«çš„ä¸€ç¯‡æ–‡ç« ã€‚long-rangeçš„ä¾èµ–æ•æ‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒé—®é¢˜ï¼Œå¯¹äºŽåºåˆ—æ•°æ®ï¼Œrecurrentæ“ä½œæ˜¯ä¸»è¦çš„æ–¹æ³•ï¼Œå¯¹äºŽå›¾åƒæ•°æ®ï¼Œlong-rangeä¾èµ–é€šè¿‡å¤šå±‚çš„å·ç§¯å½¢æˆçš„æ„Ÿå—é‡Žæ¥æ•æ‰ã€‚ä½†å·ç§¯å’Œrecurrentæ“ä½œéƒ½æ˜¯localçš„æ“ä½œï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œå—å¯å‘äºŽè®¡ç®—æœºè§†è§‰çš„ç»å…¸non-localå‡å€¼æ³•ï¼Œä½œè€…æå‡ºäº†è¿›è¡Œnon-localæ“ä½œçš„é€šç”¨æž„å»ºå—ç³»åˆ—ï¼Œæ¥æ•èŽ·long-rangeä¾èµ–æ€§çš„ã€‚æœ¬æ–‡ä¸­çš„non-localæ“ä½œå°†æ‰€æœ‰ä½ç½®å¤„çš„ç‰¹å¾çš„åŠ æƒå’Œä½œä¸ºæŸä¸€ä½ç½®çš„å“åº”ã€‚ç›´è§‚ä¸€ç‚¹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä½¿ç”¨éžæœ¬åœ°æ“ä½œæœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š ï¼ˆaï¼‰ä¸Žå¾ªçŽ¯å’Œå·ç§¯æ“ä½œçš„æ¸è¿›è¡Œä¸ºç›¸åï¼Œéžæœ¬åœ°æ“ä½œé€šè¿‡è®¡ç®—ä»»æ„ä¸¤ä¸ªä½ç½®ä¹‹é—´çš„ç›¸äº’ä½œç”¨ç›´æŽ¥æ•èŽ·é•¿ç¨‹ä¾èµ–æ€§ï¼Œè€Œä¸ç®¡å®ƒä»¬çš„ä½ç½®è·ç¦»å¦‚ä½•; ï¼ˆbï¼‰æ­£å¦‚æˆ‘ä»¬åœ¨å®žéªŒä¸­æ‰€è¡¨æ˜Žçš„é‚£æ ·ï¼Œéžå±€éƒ¨æ“ä½œæ˜¯æœ‰æ•ˆçš„ï¼Œå³ä½¿åªæœ‰å‡ å±‚ï¼ˆä¾‹å¦‚5ï¼‰ä¹Ÿèƒ½è¾¾åˆ°æœ€ä½³æ•ˆæžœ; ï¼ˆcï¼‰æœ€åŽï¼Œæˆ‘ä»¬çš„éžæœ¬åœ°æ“ä½œä¿æŒå¯å˜è¾“å…¥å¤§å°ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°ä¸Žå…¶ä»–æ“ä½œç»„åˆï¼ˆä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨çš„å·ç§¯ï¼‰ã€‚ è¯¥non-localæž„å»ºå—å¯ä»¥é›†æˆåˆ°ç›®å‰è®¸å¤šè®¡ç®—æœºè§†è§‰æ¡†æž¶ä¸­ã€‚é€šè¿‡åœ¨è§†é¢‘åˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡ŒéªŒè¯ï¼Œæˆ‘ä»¬çš„non-localæ¨¡åž‹ä¹Ÿå¯ä»¥åœ¨Kineticså’ŒCharadesæ•°æ®é›†ä¸Šå–å¾—å¾ˆæœ‰ç«žäº‰åŠ›çš„ç»“æžœï¼›åœ¨é™æ€å›¾åƒè¯†åˆ«ä¸­ï¼Œæˆ‘ä»¬çš„non-localæ¨¡åž‹æé«˜äº†åœ¨COCOæ•°æ®é›†ä¸Šçš„å¯¹è±¡æ£€æµ‹/åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ï¼Œè¯æ˜Žäº†æ¨¡åž‹çš„æœ‰æ•ˆæ€§ã€‚ â€‹]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Action Recognition</tag>
        <tag>è¡Œä¸ºè¯†åˆ«</tag>
        <tag>CVPR 2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œä¸ºè¯†åˆ«è®ºæ–‡ç¬”è®°ï¼šSomething about Temporal Reasoning]]></title>
    <url>%2Fposts%2F3309988052%2F</url>
    <content type="text"><![CDATA[åœ¨è§†é¢‘çš„è¡Œä¸ºè¯†åˆ«ä¸­ï¼Œå½±å“æ€§èƒ½å¾ˆé‡è¦çš„ä¸€ç‚¹ï¼šå°±æ˜¯æ¨¡åž‹èƒ½å¦æå–å‡ºå¼ºæœ‰åŠ›çš„æ—¶é—´ä¿¡æ¯ã€‚è™½ç„¶æœ‰çš„è¡Œä¸ºå…‰ä»Žå•å¼ å›¾åƒçš„ç©ºé—´ç‰¹å¾å°±èƒ½å¤§æ¦‚åˆ¤æ–­å‡ºå…¶ä¸­æ‰€åŒ…å«çš„åŠ¨ä½œæ˜¯ä»€ä¹ˆï¼Œä½†æ˜¯è¿˜æ˜¯æœ‰å¾ˆå¤šåŠ¨ä½œéœ€è¦ä»Žå…¶éšæ—¶é—´çš„å˜åŒ–æ‰èƒ½å‡†ç¡®åˆ¤æ–­å‡ºæ¥ã€‚æœ€è¿‘çœ‹äº†å‡ ç¯‡å…³äºŽè§†é¢‘ä¸­æ—¶é—´æŽ¨ç†ï¼ˆTemproal Reasioningï¼‰çš„æ–‡ç« ï¼Œè¿™é‡Œé¡ºä¾¿æ•´ç†ä¸€ä¸‹ã€‚ è®ºæ–‡ä¸€ï¼šTemporal Relational Reasoning in Videosæ—¶é—´å…³ç³»æŽ¨ç†æ˜¯æŒ‡è¿žæŽ¥ç‰©ä½“æˆ–å®žä½“éšæ—¶é—´æœ‰æ„ä¹‰å˜åŒ–çš„èƒ½åŠ›ã€‚å—å¯å‘äºŽRelation Networkï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ—¶é—´å…³ç³»ç½‘ç»œï¼ˆTemporal Relation Network ï¼ŒTRNï¼‰ï¼Œç”¨æ¥åœ¨å¤šæ—¶é—´å°ºåº¦ä¸Šå­¦ä¹ å¹¶æŽ¨ç†è§†é¢‘å¸§ä¹‹é—´çš„æ—¶é—´ä¾èµ–å…³ç³»ï¼Œè¯¥ç½‘ç»œå¯ä»¥æ€æƒ³å¾ˆç®€å•ï¼Œå¯ä»¥å¾ˆå®¹æ˜“çš„é›†æˆåˆ°çŽ°æœ‰çš„å·ç§¯ç¥žç»ç½‘ç»œä¸­ã€‚ é¦–å…ˆæœ¬æ–‡å®šä¹‰äº†æ—¶é—´å…³ç³»ï¼ˆTemporal Relationsï¼‰ã€‚ç»™å®šä¸€æ®µè§†é¢‘Vï¼Œé€‰å–nä¸ªæœ‰åºçš„è§†é¢‘å¸§åºåˆ—${f_1,f_2,â€¦,f_n}$ï¼Œåˆ™ç¬¬$f_i$å’Œ$f_j$å¸§çš„å…³ç³»å®šä¹‰å¦‚ä¸‹ï¼š T_2(V)=h_\delta(\sum_{i]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Action Recognition</tag>
        <tag>è¡Œä¸ºè¯†åˆ«</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è®ºæ–‡ç¬”è®°ï¼šCVPR 2018 å…³äºŽè¡Œä¸ºè¯†åˆ«è®ºæ–‡ç•¥è¯»ç¬”è®°ï¼ˆä¸€ï¼‰]]></title>
    <url>%2Fposts%2F3799204522%2F</url>
    <content type="text"><![CDATA[è®ºæ–‡ä¸€ï¼šOptical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognitionè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åšè¡Œä¸ºè¯†åˆ«çš„ä¸€ç¯‡æ–‡ç« ï¼Œæå‡ºäº†ä¸€ä¸ªå«åšå…‰æµå¼•å¯¼çš„ç‰¹å¾ï¼ˆOptical Flow guided Featureï¼ŒOFFï¼‰ã€‚æ—¶é—´ä¿¡æ¯æ˜¯è§†é¢‘è¡Œä¸ºè¯†åˆ«çš„å…³é”®ï¼ŒäºŒå…‰æµå¯ä»¥å¾ˆå¥½çš„è¡¨å¾æ—¶é—´ä¿¡æ¯ï¼Œå…¶åœ¨è§†é¢‘åˆ†æžé¢†åŸŸå·²ç»è¢«å¾ˆå¤šå·¥ä½œè¯æ˜Žæ˜¯ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„ç‰¹å¾ã€‚ä½†æ˜¯ç›®å‰çš„åŒæµç½‘ç»œTwo-Streamåœ¨è®­ç»ƒæ—¶å…¶å®žè¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦çš„ï¼Œå› ä¸ºéœ€è¦å•ç‹¬å¯¹è§†é¢‘æå–å…‰æµå›¾ï¼Œç„¶åŽé€åˆ°ç½‘ç»œçš„å¦ä¸€è‡³è¿›è¡Œè®­ç»ƒï¼›è€Œä¸”å¦‚æžœæ•°æ®é›†å¾ˆå¤§çš„è¯ï¼Œå…‰æµå›¾å’ŒRGBå›¾åƒåˆèµ·æ¥å¾—æœ‰åŽŸè§†é¢‘æ•°æ®å¤§å°çš„å¥½å‡ å€ï¼Œä¹Ÿååˆ†æ¶ˆè€—ç¡¬ç›˜ç©ºé—´ã€‚å› æ­¤æ€è€ƒå¦‚ä½•åˆ©ç”¨å•æµç½‘ç»œåŒæ—¶åˆ©ç”¨RGBç‰¹å¾ä»¥åŠç±»ä¼¼å…‰æµçš„ç‰¹å¾åŽ»è¿›è¡Œè®­ç»ƒæ˜¯ä¸€ä¸ªå€¼å¾—æ€è€ƒçš„é—®é¢˜ã€‚æœ¬æ–‡ä»Žå…‰æµæœ¬èº«çš„å®šä¹‰å‡ºå‘ï¼Œç»™äº†æˆ‘ä»¬ä¸€ä¸ªå…³äºŽè¯¥é—®é¢˜å¾ˆå¥½çš„å¯å‘ã€‚è¯¥æ–¹æ³•ä¹Ÿåœ¨UCF-101é€®åˆ°äº†96%çš„åˆ†ç±»å‡†ç¡®çŽ‡ï¼Œè¶…è¿‡äº†ä¸ç”¨Kineticsæ•°æ®é›†é¢„è®­ç»ƒçš„I3Dæ¨¡åž‹ï¼Œå¯è§è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ æœ¬æ–‡æå‡ºçš„å…‰æµå¼•å¯¼ç‰¹å¾ï¼ˆOFFï¼‰ï¼Œå®ƒä½¿ç½‘ç»œèƒ½å¤Ÿé€šè¿‡å¿«é€Ÿå’Œç¨³å¥çš„æ–¹æ³•æå–æ—¶é—´ä¿¡æ¯ã€‚ OFFç”±å…‰æµçš„å®šä¹‰å¯¼å‡ºï¼Œå¹¶ä¸Žå…‰æµæ­£äº¤ã€‚è¯¥ç‰¹å¾ç”±æ°´å¹³å’Œåž‚ç›´æ–¹å‘ä¸Šçš„ç‰¹å¾å›¾çš„ç©ºé—´æ¢¯åº¦ä»¥åŠä»Žä¸åŒå¸§çš„ç‰¹å¾å›¾ä¹‹é—´çš„å·®å¼‚èŽ·å¾—çš„æ—¶é—´æ¢¯åº¦ç»„æˆï¼ŒOFFæ“ä½œæ˜¯CNNç‰¹å¾ä¸Šçš„åƒç´ çº§è¿ç®—ï¼Œè€Œä¸”æ‰€æœ‰æ“ä½œéƒ½æ˜¯å¯å¯¼çš„ï¼Œå› æ­¤æ•´ä¸ªè¿‡ç¨‹æ˜¯å¯ä»¥ç«¯åˆ°ç«¯è®­ç»ƒçš„ï¼Œè€Œä¸”å¯ä»¥åº”ç”¨åˆ°ä»…æœ‰RGBè¾“å…¥çš„ç½‘ç»œä¸­åŽ»åŒæ—¶æœ‰æ•ˆæå–ç©ºé—´å’Œæ—¶é—´ç‰¹å¾ã€‚ è®ºæ–‡äºŒï¼šRecognize Actions by Disentangling Components of Dynamicsè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åšè¡Œä¸ºè¯†åˆ«çš„å¦ä¸€ç¯‡æ–‡ç« ã€‚æœ¬æ–‡å’Œç¬¬ä¸€ç¯‡è®ºæ–‡çš„ä¸­å¿ƒæ€æƒ³ç›¸ä¼¼ï¼šéƒ½æ˜¯æƒ³é€šè¿‡åŽŸå§‹çš„RGBå›¾åƒç›´æŽ¥åœ¨ç½‘ç»œä¸­é—´æŽ¥èŽ·å¾—ç±»ä¼¼å…‰æµçš„ç‰¹å¾ï¼Œä»Žè€Œå‡å°‘ç›®å‰åŒæµç½‘ç»œä¸­è®¡ç®—å…‰æµæ¨¡å—å¯¼è‡´çš„é¢å¤–å¼€é”€ã€‚å› æ­¤æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”¨äºŽè§†é¢‘è¡¨å¾å­¦ä¹ çš„ConvNetæ¡†æž¶ï¼Œå…¶å¯ä»¥å®Œå…¨ä»ŽåŽŸå§‹è§†é¢‘å¸§ä¸­æŽ¨å¯¼å‡ºåŠ¨æ€ä¿¡æ¯ï¼Œè€Œä¸éœ€è¿›è¡Œé¢å¤–çš„å…‰æµä¼°è®¡ã€‚å…·ä½“ç½‘ç»œæ¡†æž¶å¦‚ä¸‹ï¼š å¤§è‡´æµç¨‹ä¸ºï¼šç»™å®šä¸€ä¸ªè¿žç»­çš„å¸§åºåˆ—ï¼Œè¯¥æ¨¡åž‹é¦–å…ˆäº§ç”Ÿä¸€äº›ä½Žçº§ç‰¹å¾æ˜ å°„ï¼Œç„¶åŽå°†å…¶é¦ˆå…¥ä¸‰ä¸ªåˆ†æ”¯ï¼Œåˆ†åˆ«æ˜¯é™æ€å¤–è§‚ï¼ˆStatic Appearanceï¼Œä¸Šï¼‰ï¼Œå¤–è§‚åŠ¨æ€ï¼ˆApparent Motionï¼Œä¸­ï¼‰å’Œå¤–è§‚å˜åŒ–ï¼ˆAppearance Changeï¼Œä¸‹ï¼‰ã€‚ è¿™äº›åˆ†æ”¯åˆ†åˆ«è®¡ç®—å…¶å¯¹åº”çš„é«˜çº§ç‰¹å¾å¹¶è¿›è¡Œé¢„æµ‹ã€‚ æœ€åŽï¼Œè¿™äº›é¢„æµ‹è¢«åˆå¹¶ä¸ºæœ€ç»ˆçš„é¢„æµ‹ã€‚æœ€åŽï¼Œ3ä¸ªç»„ä»¶é¢„æµ‹å‡ºçš„ç»“æžœå°†é€šè¿‡æ±‚å¹³å‡çš„æ–¹å¼èžåˆåˆ°ä¸€èµ·ç”Ÿæˆæœ€ç»ˆçš„é¢„æµ‹ã€‚ å…¶ä¸­åœ¨é™æ€å¤–è§‚åˆ†æ”¯ï¼Œé€šè¿‡è¿­ä»£åœ°åº”ç”¨2Då·ç§¯ï¼Œç©ºé—´2Dæ± åŒ–å’Œæ—¶é—´1Dæ± åŒ–æ¥é€æ¸æå–å¤–è§‚ç‰¹å¾ï¼›åœ¨å¤–è§‚åŠ¨æ€åˆ†æ”¯ï¼Œä¸»è¦æå–è§†é¢‘å¸§ä¸­ç‰¹å¾ç‚¹çš„ç©ºé—´ä½ç§»ï¼Œä¸»è¦ç¬¬ä¸€æ¬¡å¼•å…¥äº†Cost Volumeæ¥è¿›è¡Œå¤–è§‚åŠ¨æ€çš„ä¼°è®¡ï¼›åœ¨å¤–è§‚å˜åŒ–åˆ†æ”¯ä¸­ï¼Œç”±äºŽä¸æ˜¯æ‰€æœ‰çš„å˜åŒ–éƒ½èƒ½å¤Ÿé€šè¿‡å¤–è§‚åŠ¨æ€è¡¨è§£é‡Šï¼Œè¯¸å¦‚ç‰©ä½“å¤–è§‚çš„å›ºæœ‰å˜åŒ–æˆ–ç…§æ˜Žå˜åŒ–çš„å…¶ä»–å› ç´ ä¹Ÿå¯èƒ½å¯¼è‡´è§†é¢‘å¸§çš„å˜åŒ–ï¼Œä¸åŒäºŽä»¥å‰ä½¿ç”¨RGB-diffçš„æ–¹æ³•ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå«åšwarped differencesçš„æ–¹æ³•æ¥è¡¨å¾å¤–è§‚å˜åŒ–ã€‚ é€šè¿‡åœ¨UCF101å’ŒKineticsä¸¤ä¸ªæ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨ä»…ä½¿ç”¨RGBå›¾åƒå¸§çš„å‰æä¸‹ä¹Ÿèƒ½å–å¾—å¾ˆæœ‰ç«žäº‰åŠ›çš„ç»“æžœï¼Œè€Œä¸”å…·æœ‰å¾ˆé«˜çš„æ•ˆçŽ‡ï¼Œè¯æ˜Žäº†æ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œæœ‰æ•ˆæ€§ã€‚ è®ºæ–‡ä¸‰ï¼š2D/3D Pose Estimation and Action Recognition using Multitask Deep Learningè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åˆ©ç”¨å§¿æ€åšè¡Œä¸ºè¯†åˆ«çš„ä¸€ç¯‡æ–‡ç« ï¼Œä¸»è¦çªå‡ºäº†ä¸€ä¸ªå¤šä»»åŠ¡ç½‘ç»œæ¥åŒæ—¶åš2Då’Œ3Dçš„å§¿æ€ä¼°è®¡ä»¥åŠ2Då’Œ3Dçš„è¡Œä¸ºè¯†åˆ«ï¼ŒåŒæ—¶åˆ©ç”¨å§¿æ€ä¼°è®¡çš„ç»“æžœæ¥ä¿ƒè¿›è¡Œä¸ºè¯†åˆ«ä»»åŠ¡çš„æ€§èƒ½ã€‚è¿™ä¹Ÿæ˜¯è§£å†³é—®é¢˜çš„ä¸€ä¸ªå¾ˆå¥½çš„å‡ºå‘ç‚¹ï¼Œå°±æ˜¯åˆ©ç”¨ä¸¤ä¸ªä»»åŠ¡æ¥äº’ç›¸ä¿ƒè¿›ã€‚ ä¸‹å›¾æ˜¯ç½‘ç»œçš„æ•´ä½“æ¡†æž¶å›¾ï¼Œè¾“å…¥é™æ€çš„RGBå›¾åƒï¼ŒåŒæ—¶è¿›è¡Œå§¿æ€ä¼°è®¡å’Œè¡Œä¸ºè¯†åˆ«ã€‚å…¶ä¸­çš„å§¿æ€ä¼°è®¡æ¨¡åž‹æ˜¯åˆ©ç”¨åŸºäºŽå›žå½’çš„æ–¹æ³•ï¼Œå…¶ä¸­åˆ©ç”¨äº†ä¸€ä¸ªå¯å¾®åˆ†çš„Softargmaxæ¥è”åˆ2Då’Œ3Dçš„å§¿æ€ä¼°è®¡ã€‚å…¶ä¸­çš„åŠ¨ä½œè¯†åˆ«æ–¹æ³•åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†åŸºäºŽèº«ä½“å…³èŠ‚åæ ‡åºåˆ—ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºåŸºäºŽå§¿æ€çš„è¯†åˆ«ï¼Œå¦ä¸€éƒ¨åˆ†åŸºäºŽä¸€ç³»åˆ—è§†è§‰ç‰¹å¾ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºåŸºäºŽå¤–è§‚çš„è¯†åˆ«ã€‚ å°†æ¯ä¸ªéƒ¨åˆ†çš„ç»“æžœç»„åˆèµ·æ¥ä¼°è®¡æœ€ç»ˆçš„åŠ¨ä½œæ ‡ç­¾ã€‚ ä½œè€…åœ¨MPII, Human3.6M, Penn Action å’Œ NTUå››ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®žéªŒï¼ŒéªŒè¯äº†æ¨¡åž‹åœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ æœ¬æ–‡å€¼å¾—å€Ÿé‰´çš„ä¸€ä¸ªæ€æƒ³å°±æ˜¯ï¼šåˆ©ç”¨å¤šä»»åŠ¡ä¹‹é—´çš„äº’ç›¸ä¿ƒè¿›ï¼Œæ¥æå‡å„è‡ªä»»åŠ¡çš„æœ‰æ•ˆæ€§ã€‚ è®ºæ–‡å››ï¼šDeep Progressive Reinforcement Learning for Skeleton-based Action Recognitionè¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­åŸºäºŽéª¨æž¶ï¼ˆSkeleton-basedï¼‰æ¥åšè¡Œä¸ºè¯†åˆ«çš„ä¸€ç¯‡æ–‡ç« ï¼Œä½†æ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹æ˜¯åˆ©ç”¨å¢žå¼ºå­¦ä¹ é¦–å…ˆæ‰¾åˆ°ä¸€æ®µè§†é¢‘å¸§ä¸­æœ€å…·åŠ¨ä½œä»£è¡¨æ€§çš„å¸§ï¼Œä¸¢å¼ƒæŽ‰åºåˆ—ä¸­çš„ä¸æ˜Žç¡®å¸§ï¼Œç„¶åŽåˆ©ç”¨åŸºäºŽå›¾çš„ç¥žç»ç½‘ç»œæ¥æ•æ‰å…³èŠ‚è¿žæŽ¥ç‚¹ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä»Žè€Œè¾¾åˆ°è¡Œä¸ºè¯†åˆ«çš„ç›®çš„ã€‚æ¡†æž¶å›¾å¦‚ä¸‹ï¼š æ–¹æ³•å¤§è‡´æµç¨‹ä¸ºï¼šç»™å®šä¸€ä¸ªäººä½“å…³èŠ‚çš„è§†é¢‘ï¼Œæˆ‘ä»¬é¦–å…ˆé€‰æ‹©æ¡†æž¶æå–ç½‘ç»œï¼ˆFDNetï¼‰æ¥æå–è§†é¢‘ä¸­çš„å…³é”®å¸§ï¼Œè¿™æ˜¯ç”±æå‡ºçš„æ·±åº¦æ¸è¿›å¼å¼ºåŒ–å­¦ä¹ æ–¹æ³•è¿›è¡Œè®­ç»ƒæ‰€å¾—åˆ°ã€‚ æˆ‘ä»¬æ ¹æ®ä¸¤ä¸ªé‡è¦å› ç´ é€æ­¥è°ƒæ•´æ¯ä¸ªçŠ¶æ€ä¸‹çš„é€‰å®šå¸§ã€‚ ä¸€ä¸ªæ˜¯æ‰€é€‰å¸§ç”¨äºŽåŠ¨ä½œè¯†åˆ«çš„æ‰€å…·å¤‡çš„åˆ¤åˆ«èƒ½åŠ›ã€‚ å¦ä¸€ä¸ªæ˜¯æ‰€é€‰å¸§ä¸Žæ•´ä¸ªåŠ¨ä½œåºåˆ—çš„å…³ç³»ã€‚ç„¶åŽï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºŽå›¾çš„å·ç§¯ç¥žç»ç½‘ç»œï¼ˆGCNNï¼‰ï¼Œå®ƒä¿ç•™äº†äººä½“å…³èŠ‚ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä»¥å¤„ç†æ‰€é€‰å…³é”®å¸§ä»¥è¿›è¡ŒåŠ¨ä½œè¯†åˆ«ã€‚ æœ¬æ–‡çš„æ–¹æ³•åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šå®žçŽ°äº†éžå¸¸æœ‰ç«žäº‰åŠ›çš„æ€§èƒ½ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Action Recognition</tag>
        <tag>è¡Œä¸ºè¯†åˆ«</tag>
        <tag>CVPR 2018</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œä¸ºæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šOne-shot Action Localization by Learning Sequence Matching Network]]></title>
    <url>%2Fposts%2F3531717168%2F</url>
    <content type="text"><![CDATA[è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æŽ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„å¦ä¸€ç¯‡ï¼ŒåŸºäºŽå­¦ä¹ çš„æ—¶é—´è½´åŠ¨ä½œå®šä½æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ã€‚ ç„¶è€Œï¼Œè¿™æ ·çš„å¤§è§„æ¨¡è§†é¢‘æ•°æ®é›†ä¸ä»…éžå¸¸éš¾ä»¥èŽ·å¾—è€Œä¸”å¯èƒ½å› ä¸ºå­˜åœ¨æ— æ•°çš„åŠ¨ä½œç±»åˆ«è€Œä¸å®žç”¨ã€‚ å½“è®­ç»ƒæ ·æœ¬å°‘ä¸”ç½•è§æ—¶ï¼Œå½“å‰æ–¹æ³•çš„å¼Šç«¯å°±æš´éœ²å‡ºæ¥äº†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨åŒ¹é…ç½‘ç»œçš„One-shotå­¦ä¹ æŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨ç›¸å…³æ€§æ¥æŒ–æŽ˜å’Œå®šä½ä»¥å‰æ²¡æœ‰çœ‹è¿‡ç±»åˆ«çš„è¡Œä¸ºã€‚ æœ¬æ–‡åœ¨THUMOS14å’ŒActivityNetæ•°æ®é›†ä¸Šè¯„ä¼°äº†æœ¬æ–‡çš„one-shotåŠ¨ä½œå®šä½æ–¹æ³•ã€‚ èƒŒæ™¯ çŽ°åœ¨æ˜¾å­˜çš„åŸºäºŽæ·±åº¦å­¦ä¹ çš„è¡Œä¸ºå®šä½çš„æ–¹æ³•éƒ½é‡‡ç”¨å¾ˆå¼ºçš„ç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œéžå¸¸è€—æ—¶åŽ»æ”¶é›†ã€‚ è™½ç„¶è½¬ç§»å­¦ä¹ æˆ–æ¨¡åž‹é¢„è®­ç»ƒå¯èƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†å¤„ç†æ–°çš„åŠ¨ä½œç±»åˆ«å’Œå°†å­¦ä¹ çš„ç½‘ç»œæ¨¡åž‹ä»¥é«˜æ•°æ®æ•ˆçŽ‡é€‚åº”åˆ°æ–°åœºæ™¯ä¸­ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œè€ƒè™‘one(few)-shotçš„åŠ¨ä½œå®šä½å­¦ä¹ åœºæ™¯ï¼šç»™å‡ºä¸€ä¸ªï¼ˆæˆ–å‡ ä¸ªï¼‰æ–°åŠ¨ä½œç±»çš„ä¾‹å­ï¼Œé€šå¸¸æ¯ä¸ªç±»ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ£€æµ‹æœªä¿®å‰ªè§†é¢‘ä¸­æ‰€æœ‰å‡ºçŽ°çš„æ¯ä¸ªç±»ã€‚ ç›®å‰å¾ˆå°‘æœ‰å·¥ä½œå°†one-shot learningåº”ç”¨åˆ°æ£€æµ‹æ—¶ç©ºç‰¹å¾ç›®æ ‡ä¸­ã€‚ ç›®çš„ä¸ºç¼“è§£ç›®å‰ç”¨æ¥è®­ç»ƒçš„åŠ¨ä½œè§†é¢‘æ•°æ®é‡ç¨€å°‘ä¸”éš¾ä»¥èŽ·å–çš„é—®é¢˜ï¼Œåˆ©ç”¨one(few)-shot learningçš„æ–¹æ³•ï¼Œé€šè¿‡å°‘é‡è®­ç»ƒæ ·æœ¬å³å¯è¾¾åˆ°æ—¶é—´è½´å®šä½ä»¥åŠæœªè§è¿‡çš„åŠ¨ä½œçš„é¢„æµ‹ï¼Œæé«˜æ¨¡åž‹çš„æ³›åŒ–æ€§èƒ½ã€‚ æ–¹æ³•è®ºæ–‡æ¡†æž¶å¦‚ä¸‹ï¼š æœ¬æ–‡å¼€å‘äº†ä¸€ç§æ–°é¢–çš„å…ƒå­¦ä¹ ï¼ˆmeta-learningï¼‰ç­–ç•¥ï¼Œå°†è§†é¢‘åºåˆ—åŒ¹é…çš„ä»»åŠ¡çº§å…ˆéªŒçŸ¥è¯†é›†æˆåˆ°å­¦ä¹ åŠ¨ä½œå®šä½ä¸­ã€‚ æˆ‘ä»¬çš„ä¸€æ¬¡å­¦ä¹ ç­–ç•¥çš„å…³é”®æ€æƒ³æ˜¯åŠ¨ä½œè§†é¢‘çš„ç›´è§‚ï¼Œç»“æž„åŒ–è¡¨ç¤ºé€‚åˆäºŽç”¨æ¥åŒ¹é…ï¼ˆéƒ¨åˆ†ï¼‰åºåˆ—ï¼ˆmatching sequencesï¼‰ï¼Œä»¥åŠä¸€ç§ç›¸ä¼¼æ€§åº¦é‡ï¼Œå®ƒå…è®¸æˆ‘ä»¬å°†åŠ¨ä½œç¤ºä¾‹çš„æ ‡ç­¾è½¬æ¢ä¸ºæœªä¿®å‰ªè§†é¢‘ä¸­çš„åŠ¨ä½œæè®®ã€‚ æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„Matching Networkç»“æž„ï¼Œé¦–å…ˆç”Ÿæˆè®¸å¤šproposalï¼Œç„¶åŽè¿™äº›proposalé€å…¥åˆ°ä¸‰ä¸ªç½‘ç»œç»„ä»¶ä¸­è¿›è¡ŒåŠ¨ä½œæ ‡ç­¾é¢„æµ‹ï¼š Video Encoder Networkï¼šå®ƒä¸ºæ¯ä¸ªè¡ŒåŠ¨å»ºè®®å’Œå‚è€ƒè¡ŒåŠ¨è®¡ç®—ä¸€ä¸ªsegment-basedçš„åŠ¨ä½œè¡¨ç¤ºï¼Œå®ƒç»´æŠ¤è¡ŒåŠ¨çš„æ—¶é—´ç»“æž„å¹¶ç”¨äºŽå‡†ç¡®å®šä½ã€‚ è¯¥ç½‘ç»œçš„æ€§èƒ½ä¾èµ–äºŽå€™é€‰proposalå’Œå‚è€ƒè§†é¢‘ä¹‹é—´çš„èƒ½å¦è‰¯å¥½å¯¹åº”ï¼Œä¸ºäº†å®žçŽ°å‡†ç¡®å¯¹é½ï¼Œæˆ‘ä»¬æ‰“ç®—åœ¨è¡ŒåŠ¨è¡¨ç¤ºä¸­ä¿ç•™åŠ¨ä½œè§†é¢‘çš„æ—¶é—´ç»“æž„ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåˆ©ç”¨ranking LSTMæ¥èŽ·å¾—segment-basedçš„è§†é¢‘è¡¨ç¤ºï¼Œä»¥ä¾¿å°†æ¯ä¸ªåŠ¨ä½œå®žä¾‹ç¼–ç ä¸ºå›ºå®šé•¿åº¦åºåˆ—çš„è§†é¢‘ç‰‡æ®µç‰¹å¾ã€‚ Similarity Network: å°†è¡ŒåŠ¨å»ºè®®åˆ©ç”¨ç›¸ä¼¼æ€§ç½‘ç»œä¸Žæ¯ä¸ªå‚è€ƒè¡ŒåŠ¨ï¼ˆreference actionï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œè¯¥ç½‘ç»œåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ç”Ÿæˆä¸€ç»„ç›¸å…³åˆ†æ•°ã€‚ ç±»ä¼¼äºŽMatching Networkï¼Œç½‘ç»œé¦–å…ˆè®¡ç®—æ¯ä¸ªå•ç‹¬ç¤ºä¾‹$x_i$ç›¸å¯¹äºŽæ•´ä¸ªæ”¯æŒé›†ï¼ˆsupport setï¼‰çš„å®Œæ•´ä¸Šä¸‹æ–‡åµŒå…¥ ç„¶åŽç»™å®šä¸€ä¸ªè¡ŒåŠ¨å»ºè®®$\hat{x}$åŠå…¶ç¼–ç å‘é‡$g(x_i)$ï¼Œç›¸ä¼¼æ€§ç½‘ç»œè®¡ç®—æè®®è¡¨ç¤ºä¸Žæ‰€æœ‰ç¤ºä¾‹ä¹‹é—´çš„ä½™å¼¦è·ç¦»ï¼š æŽ¥ç€åŸºäºŽä¸Šè¿°è·ç¦»ï¼ŒåŽŸå§‹åŒ¹é…ç½‘ç»œä½¿ç”¨å…³æ³¨æœºåˆ¶å’ŒæŠ•ç¥¨ç­–ç•¥å°†æµ‹è¯•æ•°æ®åˆ†ç±»åˆ°æ”¯æŒé›†ä¸­çš„ä¸€ä¸ªç±»ä¸­ æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œç”±äºŽæ”¯æŒé›†åªç”±å‰æ™¯ç±»ç»„æˆï¼Œè¿™ç§åˆ†ç±»æ–¹æ³•ä¸é€‚ç”¨äºŽå®šä½ä»»åŠ¡ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»åŒºåˆ†å‰æ™¯å’ŒèƒŒæ™¯ã€‚ å› æ­¤ï¼Œåœ¨æœ¬æ–‡çš„ one-shot action localization æž¶æž„ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸ä¼¼æ€§ç½‘ç»œè®¡ç®—ç›¸å…³åˆ†æ•°ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªå•ç‹¬çš„æ ‡ç­¾ç½‘ç»œæ¥æŽ¨æ–­æ¯ä¸ªææ¡ˆçš„ç±»åˆ«æ ‡ç­¾ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰ã€‚ Labeling Network: è®¾ç½®ä¸åŒé•¿åº¦çš„æ—¶é—´çª—å£ï¼Œæ ¹æ®æ—¶é—´çª—å£å†…çš„encoding vectorå’Œcorrelation scoresï¼Œç¬¬ä¸‰ä¸ªç½‘ç»œä¼šåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­é¢„æµ‹ææ¡ˆçš„åŠ¨ä½œç±»åˆ«æ ‡ç­¾ï¼ˆä½œä¸ºå‰æ™¯ç±»åˆ«æˆ–èƒŒæ™¯ä¹‹ä¸€ï¼‰ã€‚ æ ‡è®°ç½‘ç»œç›´æŽ¥åº”ç”¨äºŽç›¸å…³çŸ©é˜µã€‚ ç±»ä¼¼äºŽé€šè¿‡æ¯”è¾ƒä½™å¼¦è·ç¦»è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨çŸ­æš‚çš„æ—¶é—´è·¨åº¦ä¸Šåœ¨ç›¸å…³çŸ©é˜µä¸Šåº”ç”¨å…¨è¿žæŽ¥å±‚æ¥æ¯”è¾ƒç›¸å…³çŸ©é˜µçš„ç›¸åŒåˆ—çš„ä¸åŒè¡Œï¼Œå¹¶ä¸”è¾“å‡ºåœ¨å‰æ™¯å’Œé€šè¿‡sigmoidæ¿€æ´»çš„èƒŒæ™¯ã€‚ å…¨è¿žæŽ¥ç½‘ç»œæ²¿æ—¶é—´ç»´åº¦æ»‘è¿‡ç›¸å…³çŸ©é˜µï¼Œä¸ºæ¯ä¸ªææ¡ˆç¡®å®šå‰æ™¯/èƒŒæ™¯ã€‚ åœ¨æ ‡ç­¾ç½‘ç»œç¡®å®šä¸ºå‰æ™¯çš„æè®®ä¸­ï¼Œå…¬å¼6åº”ç”¨äºŽé¢„æµ‹åŠ¨ä½œæ ‡ç­¾ï¼Œå¦‚æ¡†æž¶å›¾çš„ä¸ŠåŠéƒ¨åˆ†æ‰€ç¤ºã€‚ ç›¸å…³çŸ©é˜µåŒ…å«æœ‰å…³ç‰¹å®šç‰¹å®šç±»çš„ä¿¡æ¯ä»¥åŠææ¡ˆæ˜¯å±žäºŽèƒŒæ™¯è¿˜æ˜¯å±žäºŽå‰æ™¯ã€‚ ä¾‹å¦‚ï¼Œå¦‚æžœä¸Žä¸€ä¸ªç¤ºä¾‹çš„å…³è”æ¯”å…¶ä»–ç¤ºä¾‹çš„å…³è”é«˜å¾—å¤šï¼Œé‚£ä¹ˆè¯¥æè®®å¾ˆå¯èƒ½å±žäºŽå‰æ™¯å¹¶ä¸”ä¸Žç¤ºä¾‹å…·æœ‰ç›¸åŒçš„åŠ¨ä½œæ ‡ç­¾; å¦‚æžœä¸Žæ‰€æœ‰ä¾‹å­çš„ç›¸å…³æ€§éƒ½æ¯”è¾ƒä½Žï¼Œé‚£ä¹ˆå®ƒå¯èƒ½å±žäºŽèƒŒæ™¯ã€‚ æ ‡ç­¾ç½‘ç»œé€šè¿‡è®­ç»ƒå­¦ä¹ è¿™äº›æ ‡å‡†ã€‚ è¿˜è¦æ³¨æ„æ ‡ç­¾ç½‘ç»œåœ¨æŸç§æ„ä¹‰ä¸Šç‹¬ç«‹äºŽåŠ¨ä½œç±»åˆ«ï¼Œå› ä¸ºå®ƒåº”ç”¨äºŽç›¸å…³çŸ©é˜µè€Œä¸æ˜¯æ¯ä¸ªè§†é¢‘çš„ç‰¹å¾è¡¨ç¤ºã€‚ è¿™æ„å‘³ç€å®ƒå­¦åˆ°çš„æ ‡å‡†åº”è¯¥é€‚ç”¨äºŽè¾“å…¥æ¥è‡ªä¸åŒç±»åˆ«çš„è§†é¢‘ï¼Œè¿™ä½¿å¾—å®ƒé€‚ç”¨äºŽä¸€æ¬¡æ€§é¢„æµ‹ã€‚ åŽå¤„ç†é˜¶æ®µï¼šæˆ‘ä»¬ç»“åˆå¤šå°ºåº¦ proposal-level é¢„æµ‹æ¥èŽ·å¾—frame-levelçš„å•å¸§çº§é¢„æµ‹ï¼Œå¹¶å°†ç›¸åŒæ ‡å·çš„ç›¸é‚»å¸§åˆ†ç»„ä»¥èŽ·å¾—åŠ¨ä½œå®žä¾‹ã€‚ æœ¬æ–‡çš„å®šä½ç³»ç»Ÿæ˜¯é’ˆå¯¹ one-shot action localization è€Œè®¾è®¡çš„ï¼Œç›¸åº”çš„ Meta Learning Formulation å¯ç”¨äºŽæ¨¡åž‹çš„è®­ç»ƒã€‚ ç³»ç»Ÿçš„æ¯ä¸ªç»„æˆéƒ¨åˆ†éƒ½æ˜¯å¯å¯¼çš„ï¼Œå¹¶ä¸”å¯ä»¥å¯¹ç³»ç»Ÿè¿›è¡Œç«¯åˆ°ç«¯çš„åŸ¹è®­ã€‚ ç„¶è€Œï¼Œä¸ºäº†èŽ·å¾—æ›´å¥½çš„åˆå§‹åŒ–å’Œæ€§èƒ½ï¼Œæˆ‘ä»¬å¯¹Video Encoder Networkå’ŒSimilarity Networkè¿›è¡Œäº†é¢„è®­ç»ƒã€‚ Meta Learning Formulation åœ¨å…ƒå­¦ä¹ ä¸­ï¼Œæ¨¡åž‹åœ¨ä¸€ç»„è®­ç»ƒä»»åŠ¡çš„å…ƒé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼Œå¹¶å¯¹å¦ä¸€ç»„æµ‹è¯•ä»»åŠ¡è¿›è¡Œè¯„ä¼° å…ƒå­¦ä¹ çš„ç›®æ ‡æ˜¯åœ¨å…ƒæµ‹è¯•ä»»åŠ¡åˆ†å¸ƒä¸­æ‰¾åˆ°æœ€å°åŒ–æŸå¤±çš„æ¨¡åž‹ Optimization for the Localization System æŸå¤±å‡½æ•°ä¸ºï¼š å…¶ä¸­ï¼Œä¸¤ä¸ªæŸå¤±å‡½æ•°åˆ†åˆ«å¦‚ä¸‹ï¼š Pretraining for Video Encoder &amp; Similarity Net é¢„è®­ç»ƒä¸¤è€…çš„æŸå¤±å‡½æ•°ï¼š åˆ©ç”¨åˆ°äº†ä¸€ä¸ªRanking Lossï¼Œå…¶ç›´è§‚çš„æƒ³æ³•æ˜¯ï¼šå½“ç»™äºˆè¶Šæ¥è¶Šå¤šçš„è§†é¢‘å†…å®¹ï¼Œåˆ†ç±»å™¨ä¼šç”Ÿæˆè¶Šæ¥è¶Šç½®ä¿¡åº¦é«˜çš„é¢„æµ‹ å®žéªŒ å®žéªŒåœ¨Thumos14å’ŒActivityNet 1.2ä¸Šè¿›è¡Œè¯„ä¼° One-shoté—®é¢˜è®¾ç½®è¦æ±‚æµ‹è¯•æœŸé—´çš„ç±»åˆ«ä¸å¾—å­˜åœ¨åœ¨è®­ç»ƒæœŸé—´ï¼Œå› æ­¤åœ¨è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­éœ€è¦å¯¹ä¸¤ä¸ªæ•°æ®é›†è¿›è¡Œåˆ’åˆ†ï¼Œä»Žè€Œè¾¾åˆ°è¿™ä¸€è¦æ±‚ è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µæœ‰å¾ˆå¤šç»†èŠ‚ï¼Œå»ºè®®çœ‹è®ºæ–‡ï¼Œè¿™é‡Œä¸å†èµ˜è¿° å’Œå¼ºç›‘ç£æ–¹æ³•çš„æ¯”è¾ƒï¼Œæˆ‘ä»¬ä»Žè¡¨1å’Œè¡¨2å¯ä»¥çœ‹å‡ºï¼Œè™½ç„¶one-shotå’Œå…¨ç›‘ç£è¡Œä¸ºæ£€æµ‹ä¹‹é—´ä»ç„¶å­˜åœ¨æ€§èƒ½å·®è·ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»¥one-shotè®¾ç½®è¿›è¡Œæµ‹è¯•æ—¶ï¼Œæ˜¾ç€ä¼˜äºŽç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ æˆ‘ä»¬åœ¨Thumos14æ•°æ®é›†ä¸Šä½¿ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œæ¯ç±»15ä¸ªæ ·æœ¬è¿›ä¸€æ­¥æµ‹è¯•æˆ‘ä»¬çš„æ–¹æ³•ã€‚ æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œæ€§èƒ½å‡ºçŽ°æ˜Žæ˜¾æå‡ï¼Œè€ŒCDCåªæœ‰å¾ˆå°çš„æå‡ï¼Œè¿™è¡¨æ˜Žæˆ‘ä»¬çš„æ–¹æ³•ç›¸å¯¹äºŽæ ·æœ¬æ•°é‡å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚ è¿˜æœ‰ä¸€äº›æ¶ˆèžæŽ¢ç©¶å®žéªŒï¼Œè¿™é‡Œä¹Ÿä¸å†èµ˜è¿° ä¼˜ç‚¹ é’ˆå¯¹ç›®å‰è§†é¢‘æ•°æ®é›†æ ‡æ³¨è´¹æ—¶ã€éš¾ä»¥èŽ·å¾—ç­‰ç—›ç‚¹ï¼Œä½œè€…é¦–æ¬¡å°†one(few)-shotçš„æ–¹æ³•å¼•å…¥äº†æ—¶é—´è½´å®šä½ï¼Œå¾ˆæœ‰åˆ›æ–°ç‚¹ï¼Œå’Œå¼±ç›‘ç£å­¦ä¹ æœ‰å¼‚æ›²åŒå·¥ä¹‹å¦™ æå‡ºäº†ä¸€ç§åŸºäºŽåŒ¹é…ç½‘ç»œæ¡†æž¶çš„åŠ¨ä½œå®šä½é—®é¢˜çš„å…ƒå­¦ä¹ æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿæ•èŽ·ä»»åŠ¡çº§åˆ«ï¼ˆtask-levelï¼‰çš„å…ˆéªŒçŸ¥è¯† åŽå¤„ç†ä¸­çš„groupingç­–ç•¥å¯ä»¥è¦ç”¨åœ¨æˆ‘ä¹‹å‰çš„å·¥ä½œä¸­ ç¼ºç‚¹ æ€§èƒ½ç›®å‰çœ‹æ¥å¹¶ä¸æ˜¯ç‰¹åˆ«ç†æƒ³ï¼Œå’Œå…¨ç›‘ç£çš„æ–¹æ³•è¿˜æœ‰å·®è·ï¼Œè¿˜æœ‰å¾ˆå¤šæ”¹è¿›çš„ç©ºé—´ï¼Œè¿™å¯èƒ½éœ€è¦å¤šåŽ»äº†è§£ä¸€äº›one-shot learningæˆ–transfer learningç­‰æ–¹å‘çš„è®ºæ–‡ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Action Detection</tag>
        <tag>è¡Œä¸ºæ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œä¸ºæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šRethinking the Faster R-CNN Architecture for Temporal Action Localization]]></title>
    <url>%2Fposts%2F3697434189%2F</url>
    <content type="text"><![CDATA[è¿™æ˜¯ä»Šå¹´CVPR 2018ä¸­æŽ¥å—ä¸ºæ•°ä¸å¤šçš„åŠ¨ä½œæ—¶é—´è½´å®šä½è®ºæ–‡ä¸­çš„ä¸€ç¯‡ï¼Œè§£å†³äº†ç›®å‰çŽ°å­˜æ–¹æ³•ä¸­çš„3ä¸ªé—®é¢˜ï¼šï¼ˆ1ï¼‰Multi-scaleçš„åŠ¨ä½œç‰‡æ®µï¼›ï¼ˆ2ï¼‰Temproal contextçš„åˆ©ç”¨ï¼›ï¼ˆ3ï¼‰Multi-stream ç‰¹å¾èžåˆã€‚æ–¹æ³•åœ¨THUMOSâ€™ 14æ•°æ®é›†ä¸Šçš„æè®®å’Œæ£€æµ‹ä»»åŠ¡ä¸Šè¾¾åˆ°ç›®å‰æœ€å¥½çš„æ•ˆæžœï¼ˆmAP@tIoU=0.5è¾¾åˆ°42.8%ï¼‰ï¼Œåœ¨ActivityNetæ•°æ®åŠä¸Šå–å¾—äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•ˆæžœã€‚ èƒŒæ™¯ æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹å…¶å®žå’Œç›®æ ‡æ£€æµ‹ç›¸ç±»ä¼¼ï¼Œå› æ­¤ç›®å‰è®¸å¤šè¡Œä¸ºæ£€æµ‹çš„æ–¹æ³•éƒ½å—å¯å‘äºŽç›®æ ‡æ£€æµ‹çš„ä¸€äº›å…ˆè¿›æ–¹æ³•ï¼Œæ¯”å¦‚R-CNNç³»åˆ—ï¼Œå…ˆä»Žæ•´ä¸ªè§†é¢‘ä¸­ç”Ÿæˆsegments proposalï¼Œç„¶åŽç”¨åˆ†ç±»å™¨åŽ»å¯¹è¿™äº›proposalè¿›è¡Œåˆ†ç±»ã€‚ ç›®å‰æœ‰ä¸€äº›æ–¹æ³•å°†Faster R-CNNè¿ç§»åˆ°æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹ä¸­ï¼Œç„¶è€Œç›´æŽ¥è¿ç§»è¿‡æ¥å¼•å…¥ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚ä¸‹ï¼š å¦‚ä½•å¤„ç†è¡ŒåŠ¨æŒç»­æ—¶é—´çš„å·¨å¤§å˜åŒ–ï¼Ÿ å› ä¸ºè¡Œä¸ºä¼šæœ‰è®¸å¤šæ—¶é—´é•¿çŸ­ä¸ä¸€çš„æŒç»­æ—¶é—´ï¼Œä»Žå‡ ç§’åˆ°å‡ åˆ†é’Ÿçš„è¡Œä¸ºç‰‡æ®µéƒ½æœ‰ï¼Œè€ŒFaster R-CNNåˆ©ç”¨anchoræproposalä¼šåœ¨ç‰¹å¾çš„temporal scopeå’Œanchorçš„spanä¹‹é—´äº§ç”ŸmisalignmentçŽ°è±¡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªmulti-towerç½‘ç»œå’Œåˆ©ç”¨æ‰©å¼ æ—¶é—´å·ç§¯ï¼ˆdilated temporal convolutionsï¼‰æ¥è§£å†³alignmentçš„é—®é¢˜ã€‚ å¦‚ä½•åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Ÿ åŠ¨ä½œå®žä¾‹ä¹‹å‰å’Œä¹‹åŽçš„æ—¶åˆ»åŒ…å«å…³äºŽå®šä½å’Œåˆ†ç±»çš„å…³é”®ä¿¡æ¯ï¼ˆå¯ä»¥è¯´æ¯”å¯¹è±¡çš„ç©ºé—´ä¸Šä¸‹æ–‡æ›´é‡è¦ï¼‰ã€‚Faster R-CNNæ²¡æœ‰åˆ©ç”¨æ—¶é—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æˆ‘ä»¬å»ºè®®é€šè¿‡æ‰©å±•ææ¡ˆç”Ÿæˆå’ŒåŠ¨ä½œåˆ†ç±»ä¸­çš„æ„Ÿå—é‡Žæ¥æ˜Žç¡®åœ°ç¼–ç æ—¶é—´ä¸Šä¸‹æ–‡ã€‚ å¦‚ä½•æœ€å¥½çš„åŽ»èžåˆmulti-streamçš„ç‰¹å¾ï¼Ÿ å¯¹äºŽFaster R-CNNæŽ¢ç´¢è¿™ç§RGBå’ŒFlowç‰¹å¾èžåˆæ–¹é¢çš„å·¥ä½œæœ‰é™ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŽæœŸèžåˆæ–¹æ¡ˆï¼Œå¹¶ä¸”ç»éªŒæ€§åœ°è¯æ˜Žäº†å®ƒåœ¨ä¸€èˆ¬çš„æ—©æœŸèžåˆæ–¹æ¡ˆä¸Šçš„ä¼˜åŠ¿ã€‚ ç›®çš„è§£å†³Faster R-CNNç›´æŽ¥å¼•å…¥åˆ°æ—¶é—´è½´è¡Œä¸ºæ£€æµ‹ä¸­çš„ä¸Šè¿°3ä¸ªæŒ‘æˆ˜,å¹¶ä»¥æ­¤æ¥æå‡Faster R-CNNåœ¨è¡Œä¸ºæ£€æµ‹ä¸­çš„æ€§èƒ½. æ–¹æ³•è®ºæ–‡æ¡†æž¶å¦‚ä¸‹ï¼š æœ¬æ–‡æå‡ºäº†TAL-Netï¼Œæœ‰ä¸‰ä¸ªåˆ›æ–°çš„ç»“æž„æ”¹å˜ï¼š Receptive Field Alignment ä¼ ç»Ÿçš„anchoræœºåˆ¶æœ‰ä¸€ä¸ªç¼ºç‚¹ï¼šæ¯ä¸ªæ—¶é—´ç‚¹çš„é”šç‚¹åˆ†ç±»éƒ½æœ‰ç›¸åŒçš„å•ä¸€çš„æ„Ÿå—é‡Žã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®å°†æ¯ä¸ªé”šç‚¹çš„æ„Ÿå—é‡Žä¸Žå®ƒçš„æ—¶é—´è·¨åº¦å¯¹é½ã€‚ è¿™æ˜¯é€šè¿‡ä¸¤ä¸ªå…³é”®å› ç´ å®žçŽ°çš„ï¼šmulti-towerç½‘ç»œå’Œæ‰©å¼ æ—¶é—´å·ç§¯ï¼ˆdilated temporal convolutionsï¼‰ã€‚ ç»™å®šä¸€ä¸ªä¸€ç»´feature mapï¼Œæˆ‘ä»¬çš„Segment Proposal Network ç”±Kä¸ªtemproal ConvNets ç»„æˆï¼Œæ¯ä¸ªKç½‘ç»œè´Ÿè´£å¯¹ç‰¹å®šæ¯”ä¾‹çš„é”šæ®µè¿›è¡Œåˆ†ç±».æœ€é‡è¦çš„æ˜¯ï¼Œæ¯ä¸ªæ—¶é—´ConvNetéƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä½¿å¾—å…¶æŽ¥å—çš„å­—æ®µå¤§å°ä¸Žç›¸å…³çš„é”šç‚¹å°ºåº¦ä¸€è‡´ã€‚ åœ¨æ¯ä¸ªConvNetç»“æŸæ—¶ï¼Œæˆ‘ä»¬åˆ†åˆ«åº”ç”¨ä¸¤ä¸ªæ ¸å¿ƒå¤§å°ä¸º1çš„å¹³è¡Œå·ç§¯å±‚è¿›è¡Œé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›žå½’ã€‚ å¦ä¸€é—®é¢˜ï¼šå¦‚ä½•è®¾è®¡å…·æœ‰å¯æŽ§æ„Ÿå—é‡Žsçš„æ—¶é—´å·ç§¯ï¼Ÿ æ–¹æ³•ä¸€ï¼šå¦‚æžœs=2L+1ï¼Œåˆ™å åŠ Lå±‚å·ç§¯å±‚å¾—åˆ°ç›¸åº”çš„æ„Ÿå—é‡Žã€‚ç¼ºç‚¹æ˜¯å±‚æ•°Léšç€sçº¿æ€§å¢žåŠ ï¼Œå¾ˆå®¹æ˜“å¢žåŠ å‚æ•°æ•°é‡ä½¿ç½‘ç»œè¿‡æ‹Ÿåˆã€‚ æ–¹æ³•äºŒï¼šåœ¨æ¯ä¸€å±‚å·ç§¯å±‚åŽæ·»åŠ ä¸€ä¸ªkernel sizeä¸º2çš„poolingå±‚ï¼Œåˆ™æ„Ÿå—é‡Ž$s=2^{(L+1)}-1$ï¼Œæ­¤æ—¶å±‚æ•°éšç€sæˆlogå˜åŒ–ï¼Œä½†æ˜¯æ·»åŠ poolingå±‚ä¼šå‡å°è¾“å‡ºfeature mapçš„åˆ†è¾¨çŽ‡ï¼Œä¼šå½±å“å®šä½å‡†ç¡®çŽ‡ã€‚ æ–¹æ³•ä¸‰ï¼šä½¿ç”¨æ‰©å……æ—¶é—´å·ç§¯ï¼Œè¿™ç§å·ç§¯å¯ä»¥åœ¨æ‰©å……æ„Ÿå—é‡Žçš„åŒæ—¶ä¸æŸå¤±åˆ†è¾¨çŽ‡ã€‚åœ¨æˆ‘ä»¬çš„Segment Proposal Networkä¸­ï¼Œæ¯ä¸€ä¸ªtemporal ConvNetéƒ½åªç”±2ä¸ªdilated convolutional layersç»„æˆã€‚ä¸ºäº†èŽ·å¾—ä¸€ä¸ªç›®æ ‡æ„Ÿå—é‡Žsï¼Œåˆ™ç¬¬ä¸€å±‚çš„dilated convolutional layersçš„dilation rate $r_1=s/6, r_2=(s/6)\times2$. Context Feature Extraction æ—¶é—´è½´ä¸Šä¸‹æ–‡ä¿¡æ¯ååˆ†é‡è¦ ä¸ºäº†ç¡®ä¿ä¸Šä¸‹æ–‡ç‰¹å¾ç”¨äºŽé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›žå½’ï¼Œæ„Ÿå—é‡Žå¿…é¡»è¦†ç›–æ—¶é—´è½´ä¸Šä¸‹æ–‡ä¿¡æ¯åŒºåŸŸï¼Œå¯ä»¥é€šè¿‡å°†dilation rateåŠ å€ï¼Œå³$r_1=s/6\times2, r_2=(s/6)\times2\times2$ï¼Œå¦‚ä¸‹ï¼š åœ¨åŠ¨ä½œåˆ†ç±»é˜¶æ®µï¼Œæˆ‘ä»¬è¦åˆ©ç”¨SoI poolingæ¥ä¸ºæ¯ä¸ªproposalæå–ä¸€ä¸ªå›ºå®šå°ºå¯¸çš„feature map Late Feature Fusion ç›®å‰è®¸å¤šæ–¹æ³•éƒ½åœ¨ä½¿ç”¨RGBå’Œå…‰æµç‰¹å¾ æœ¬æ–‡ä¸ºåŒæµç‰¹å¾æå‡ºäº†ä¸€ä¸ªåŽèžåˆçš„æœºåˆ¶ ä»¬é¦–å…ˆä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„ç½‘ç»œåˆ†åˆ«ä»ŽRGBå¸§å’Œå åŠ çš„å…‰æµä¸­æå–ä¸¤ä¸ªä¸€ç»´ç‰¹å¾æ˜ å°„ã€‚ æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¸åŒçš„Segment Proposal Networkæ¥å¤„ç†æ¯ä¸ªfeature maï¼Œè¯¥ç½‘ç»œå¹¶è¡Œåœ°ç”Ÿæˆé”šå®šåˆ†ç±»å’Œè¾¹ç•Œå›žå½’çš„é€»è¾‘ã€‚ æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªä¸¤ä¸ªç½‘ç»œçš„logitsçš„å…ƒç´ å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆçš„é€»è¾‘æ¥ç”Ÿæˆæè®®ã€‚ å¯¹äºŽæ¯ä¸ªææ¡ˆï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªç‰¹å¾æ˜ å°„ä¸Šå¹¶è¡Œæ‰§è¡ŒSoIæ± ï¼Œå¹¶åœ¨æ¯ä¸ªè¾“å‡ºä¸Šåº”ç”¨ä¸åŒçš„DNNåˆ†ç±»å™¨ã€‚ å®žéªŒ åŸºäºŽTensorFlowç›®æ ‡æ£€æµ‹API 9ä¸ªanchorï¼Œscalesä¸º{1, 2, 3, 4, 5, 6, 8, 11, 16} NMSé˜ˆå€¼ä¸º0.7åŽ»ç­›é€‰proposalï¼Œä¿ç•™å‰300ä¸ªproposalç”¨äºŽåˆ†ç±» THUMOSâ€™ 14æ£€æµ‹ç»“æžœ ActivityNet v1.3åœ¨éªŒè¯é›†çš„æ£€æµ‹ç»“æžœ ä¼˜ç‚¹ç›¸æ¯”äºŽR-C3Dï¼Œæœ¬æ–‡çš„æ–¹æ³•è§£å†³äº†Multi-scaleçš„é—®é¢˜ï¼Œåˆ©ç”¨äº†ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥åŠé¢å¤–çš„å…‰æµä¿¡æ¯ï¼Œè§£å†³äº†ç›®å‰è®¸å¤šæ–¹æ³•ä¸­å­˜åœ¨çš„å¤§å¤§å°å°çš„ç¼ºé™·ï¼Œç»„åˆæˆäº†ä¸€ä¸ªè¾ƒä¸ºå®Œæ•´çš„æ¡†æž¶ï¼Œå› æ­¤åœ¨THUMOSâ€™ 14æ•°æ®é›†ä¸Šæ£€æµ‹æ•ˆæžœè¾¾åˆ°æœ€å¥½ï¼Œåœ¨ActivityNetæ•°æ®é›†ä¸Šä¹Ÿå–å¾—äº†å¾ˆæœ‰ç«žäº‰åŠ›çš„ç»“æžœï¼Œä½†æ˜¯è¿˜æ˜¯ä¸å¦‚SSNçš„ç»“æžœã€‚æ–‡ä¸­åˆ†æžï¼šTHUMOSâ€™ 14æ˜¯ä¸€ä¸ªæ›´å¥½çš„ç”¨æ¥è¯„ä¼°è¡Œä¸ºå®šä½çš„æ•°æ®é›†ï¼Œå› ä¸ºå…¶æ¯æ®µè§†é¢‘ä¸­åŒ…å«æœ‰æ›´å¤šçš„è¡Œä¸ºå®žä¾‹ï¼Œå¹¶ä¸”æ¯æ®µè§†é¢‘åŒ…å«å¤§é‡çš„èƒŒæ™¯æ´»åŠ¨ã€‚ ç¼ºç‚¹æˆ‘è®¤ä¸ºé™¤äº†ç¬¬ä¸€ç‚¹åˆ›æ–°ï¼šåˆ©ç”¨dilated temporal convlutionalç»„æˆæ„Ÿå—é‡Žå¯æŽ§çš„multi-towerç½‘ç»œæ¥è§£å†³multi-scaleé—®é¢˜æ¯”è¾ƒæœ‰åˆ›æ–°å¤–ï¼Œå¦å¤–ä¸¤ç‚¹åˆ›æ–°å…¶å®žä¸ç®—ç‰¹åˆ«æœ‰æ–°æ„ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Action Detection</tag>
        <tag>è¡Œä¸ºæ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è®ºæ–‡è°ƒç ”ï¼šICCV 2017è®ºæ–‡è°ƒç ”]]></title>
    <url>%2Fposts%2F679115822%2F</url>
    <content type="text"><![CDATA[Visual object tracking Learning Policies for Adaptive Tracking with Deep Feature Cascades Our fundamental insight is to take an adaptive approach, where easy frames are processed with cheap features (such as pixel values), while challenging frames are processed with invariant but expensive deep features. Formulate the adaptive tracking problem as a decision-making process. Learn an agent to decide whether to locate objects with high conï¬dence on an early layer, or continue processing subsequent layers of a network. Signiï¬cantly reduces the feedforward cost. Train the agent ofï¬‚ine in a reinforcement learning fashion. Obviously, the major computational burden comes from the forward pass through the entire network, and can be larger with deeper architectures. However, when the object is visually distinct or barely moves, early layers are in most scenarios sufï¬cient for precise localization - offering the potential for substantial computational savings. The agent learns to ï¬nd the target at each layer, and decides if it is conï¬dent enough to output and stop there. Tracking The Untrackable: Learning to Track Multiple Cues with Long-Term Dependencies Combine cues in a coherent end-to-end fashion over a long period of time. Present a structure of Recurrent Neural Networks (RNN) that jointly reasons on multiple cues over a temporal window. We are able to correct many data association errors and recover observations from an occluded state. Tracking as Online Decision-Making: Learning a Policy from Streaming Videos with Reinforcement Learning A tracking agent must follow an object despite ambiguous image frames and a limited computational budget. The agent must decide where to look in the upcoming frames when to reinitialize because it believes the target has been lost when to update its appearance model for the tracked object Formulating tracking as a partially observable decision-making process (POMDP). Sparse rewards allow us to quickly train on massive datasets. Challenges: First, the limited quantity of annotated video data impedes both training and evaluation. Second, as vision (re)integrates with robotics, video processing must be done in an online, streaming fashion. Face detection S3FD - Single Shot Scale-invariant Face Detector. Use a single deep neural network, especially for small faces. Contribution æå‡ºä¸€ä¸ªå°ºåº¦å…¬å¹³çš„äººè„¸æ£€æµ‹æ¡†æž¶æ¥å¤„ç†ä¸åŒå°ºåº¦çš„äººè„¸ã€‚æˆ‘ä»¬åœ¨å„ç§å„æ ·çš„å›¾å±‚ä¸Šæ‹¼è´´anchorï¼Œä»¥ç¡®ä¿æ‰€æœ‰äººè„¸çš„æ¯”ä¾‹å°ºéƒ½å…·æœ‰è¶³å¤Ÿçš„ç‰¹å¾ç”¨äºŽæ£€æµ‹ã€‚åŸºäºŽæœ‰æ•ˆæŽ¥æ”¶åŸŸï¼ˆeffective receptive ï¬eldï¼‰å’Œç­‰æ¯”ä¾‹åŒºé—´åŽŸåˆ™ï¼ˆequal proportion interval principleï¼‰è®¾è®¡anchor ç”¨å°ºåº¦è¡¥å¿anchoråŒ¹é…ç­–ç•¥ï¼ˆ a scale compensation anchor matching strategyï¼‰æé«˜å°è„¸çš„å¬å›žçŽ‡; é€šè¿‡æœ€å¤§åŒ–èƒŒæ™¯æ ‡ç­¾ï¼ˆ max-out background labelï¼‰å‡å°‘å°è„¸çš„è¯¯æŠ¥çŽ‡ã€‚ effective receptive ï¬eld: Understanding the effective receptive ï¬eld in deep convolutional neural networks. Salient Object Detection Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection How to better aggregate multi-level convolutional feature maps for salient object detection is underexplored. Our framework: First integrates multi-level feature maps into multiple resolutions, which simultaneously incorporate coarse semantics and ï¬ne details. Then it adaptively learns to combine these feature maps at each resolution and predict saliency maps with the combined features. Finally, the predicted results are efï¬ciently fused to generate the ï¬nal saliency map. In addition, edge-aware maps and high-level predictions are embedded into the framework. Learning Uncertain Convolutional Features for Accurate Saliency Detection The key contribution of this work is to learn deep uncertain convolutional features (UCF), which encourage the robustness and accuracy of saliency detection. æˆ‘ä»¬æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ··åˆä¸Šé‡‡æ ·æ–¹æ³•æ¥å‡å°‘æˆ‘ä»¬çš„è§£ç å™¨ç½‘ç»œä¸­åŽ»å·ç§¯ç®—å­çš„æ£‹ç›˜ä¼ªå½±ã€‚ We ï¬nd that the actual cause of these artifacts is the upsampling mechanism, which generally utilizes the deconvolution operation. Action Related Encouraging LSTMs to Anticipate Actions Very Early Action anticipation - identify the action from only partially available videos. To this end, we develop a multi-stage LSTM architecture that leverages context-aware and action-aware features, and introduce a novel loss function that encourages the model to predict the correct class as early as possible. Intuitive: our loss models the intuition that some actions, such as running and high jump, are highly ambiguous after seeing only the ï¬rst few frames, and false positives should therefore not be penalized too strongly in the early stages. We would like to predict a high probability for the correct class as early as possible, and thus penalize false negatives from the beginning of the sequence. Contribute a novel multi-stage Long Short Term Memory (LSTM) architecture for action anticipation. This model effectively extracts and jointly exploits context- and action-aware features. Existing method drawbacks: This is in contrast to existing methods that typically extract either global representations for the entire image or video sequence thus not focusing on the action itself, or localize the feature extraction process to the action itself via dense trajectories optical ï¬‚ow or actionness, thus failing to exploit contextual information. åˆ©ç”¨å…‰æµä¸å…è®¸è¿™äº›æ–¹æ³•åœ¨localizationè¿‡ç¨‹ä¸­æ˜Žç¡®åœ°åˆ©ç”¨å¤–è§‚ã€‚ Computing optical ï¬‚ow is typically expensive. In the future, we intend to study new ways to incorporate additional sources of information, such as dense trajectories and human skeletons in our framework. Unsupervised Action Discovery and Localization in Videos åˆ›æ–°ï¼šæ— ç›‘ç£çš„action localizationã€‚ First to address the problem of unsupervised action localization in videos. We propose a novel approach that: Discovers action class labels Spatio-temporally localizes actions in videos. Method: It begins by computing local video features to apply spectral clustering on a set of unlabeled training videos. For each cluster of videos, an undirected graph is constructed to extract a dominant set, which are known for high internal homogeneity and in-homogeneity between vertices outside it. Next, a discriminative clustering approach is applied, by training a classiï¬er for each cluster, to iteratively select videos from the non-dominant set and obtain complete video action classes. Once classes are discovered, training videos within each cluster are selected to perform automatic spatio-temporal annotations, by ï¬rst over-segmenting videos in each discovered class into supervoxelsï¼ˆè¶…ä½“ç´ ï¼‰ and constructing a directed graph ï¼ˆæœ‰å‘å›¾ï¼‰to apply a variant of knapsack problem with temporal constraints. ï¼ˆå¹¶æž„å»ºæœ‰å‘å›¾ä»¥åº”ç”¨å…·æœ‰æ—¶é—´çº¦æŸçš„èƒŒåŒ…é—®é¢˜çš„å˜ä½“ã€‚ï¼‰ èƒŒåŒ…ä¼˜åŒ–è”åˆæ”¶é›†è¶…ä½“ç´ çš„ä¸€ä¸ªå­é›†ï¼Œé€šè¿‡å¼ºåˆ¶æ³¨é‡Šçš„åŠ¨ä½œè¿›è¡Œæ—¶ç©ºè¿žæŽ¥ï¼Œå…¶ä½“ç§¯æ˜¯ä¸€ä¸ªactorçš„å¤§å°ã€‚These annotations are used to train SVM action classiï¬ers. åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæ“ä½œä½¿ç”¨ç±»ä¼¼çš„èƒŒåŒ…æ–¹æ³•æ¥è¿›è¡Œlocalizeï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­å°†è¶…ä½“ç´ åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ä½¿ç”¨æ¥è‡ªå‘çŽ°çš„åŠ¨ä½œç±»çš„è§†é¢‘å­¦ä¹ çš„SVMè¢«ç”¨äºŽè¯†åˆ«è¿™äº›åŠ¨ä½œã€‚ However, supervised algorithms have some disadvantages compared to unsupervised approaches, due to the difï¬culty of video annotation. Contributionsï¼š Automatic discovery of action class labels using a new discriminative clustering approach with dominant sets (Sec. 3). We propose a novel Knapsack approach with graph-based temporal constraints to annotate actions in training videos The annotations within each cluster of videos are jointly selected by Binary Integer Quadratic Programming (BIQP) optimization to train action classiï¬ers. Structural SVM is used to learn the pairwise relations of supervoxels within foreground action and foreground-background, which enforces that the supervoxels belonging to the action to be simultaneously selected. Lastly, we address a new problem of Unsupervised Action Localization (Sec. 5.2). Dense-Captioning Events in Videos We introduce the task of dense-captioning events, which involves both detecting and describing events in a video. Our model introduces a variant of an existing proposal module that is designed to capture both short as well as long events that span minutes. To capture the dependencies between the events in a video, our model introduces a new captioning module that uses contextual information from past and future events to jointly describe all events. While the success of these methods is encouraging, they all share one key limitation: detail. We introduce the task of dense-captioning events, which requires a model to generate a set of descriptions for multiple events occurring in the video and localize them in time. However, we observe that densecaptioning events comes with its own set of challenges distinct from the image case. One observation is that events in videos can range across multiple time scales and can even overlap. Past captioning works have circumvented this problem by encoding the entire video sequence by mean-pooling [50] or by using a recurrent neural network (RNN) [49]. To overcome this limitation, we extend recent work on generating action proposals [10] to multi-scale detection of events. Another key observation is that the events in a given video are usually related to one another. We introduce a captioning module that utilizes the context from all the events from our proposal module to generate each sentence. Learning long-term dependencies for action recognition with a biologically-inspired deep network How to efï¬ciently learn long-term dependencies from sequences still remains a pretty challenging task. As one of the key models for sequence learning, recurrent neural network (RNN) and its variants such as long short term memory (LSTM) and gated recurrent unit (GRU) are still not powerful enough in practice. One possible reason is that they have only feedforward connections, which is different from the biological neural system that is typically composed of both feedforward and feedback connections.(æ—¢æœ‰å‰ä¼ ï¼Œä¹Ÿæœ‰åé¦ˆ) Propose shuttleNet technologically. The shuttleNet consists of several processors, each of which is a GRU while associated with multiple groups of cells and states. Attention mechanism is then employed to select the best information ï¬‚ow pathway. Adaptive RNN Tree for Large-Scale Human Action Recognition We present the RNN Tree (RNN-T), an adaptive learning framework for skeleton based human action recognition. Our method categorizes action classes and uses multiple Recurrent Neural Networks (RNNs) in a treelike hierarchy. åœ¨éª¨æž¶è¡¨ç¤ºä¸­çš„è¡Œä¸ºæ˜¯é€šè¿‡åˆ†å±‚æŽ¨ç†è¿‡ç¨‹æ¥è¯†åˆ«çš„ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œå•ç‹¬çš„RNNå°†ç»†åŒ–çš„è¡Œä¸ºç±»åˆ«ä¸Žå¢žåŠ çš„ç½®ä¿¡åº¦ RNN-T effectively addresses two main challenges of large-scale action recognition: able to distinguish ï¬ne-grained action classes that are intractable using a single network adaptive to new action classes by augmenting an existing model. Ensemble Deep Learning for Skeleton-based Action Recognition using Temporal Sliding LSTM networks Traditional methods generally use relative coordinate systems dependent on some joints, and model only the long-term dependency, while excluding short-term and medium term dependencies. We transform the skeletons into another coordinate system to obtain the robustness to scale, rotation and translation and then extract salient motion features from them. We propose novel ensemble Temporal Sliding LSTM (TS-LSTM) networks for skeleton-based action recognition. The proposed network is composed of multiple parts containing short-term, medium-term and long-term TS-LSTM networks. With a rapid development of 3D data acquisition over the past few decades, lots of researches on human activity recognition from 3D data can have been actively performed. For the modeling of human actions, recent researches show that Long Short-Term Memory (LSTM) networks are superior to temporal pyramids and hidden markov models. Overall Methodï¼š Firstly, we transform the coordinates of input skeleton sequences so that the data can be robust to scale, rotation and translation. Secondly, instead of using the simple joint positions, we employ the motion features in terms of temporal differences, which help our networks to be focused on the actual skeleton movements. Thirdly, the motion features are processed with multi-term LSTMs containing short-term, medium-term and long-term LSTMs, which allow robustness to variable temporal dynamics. Finally, the multi-term LSTMs capture a variety of action dynamics through ensemble. What Actions are Needed for Understanding Human Actions in Videos? We analyze the current state of human activity understanding in videos. The goal of this paper is to examine datasets, evaluation metrics, algorithms, and potential future directions. The results demonstrate that while there is inherent ambiguity in the temporal extent of activities, current datasets still permit effective benchmarking. æˆ‘ä»¬å‘çŽ°ï¼Œå½“ä¸Žæ—¶é—´æŽ¨ç†ç›¸ç»“åˆæ—¶ï¼Œå¯¹ç‰©ä½“å’Œå§¿æ€çš„ç»†ç²’åº¦ç†è§£å¾ˆå¯èƒ½åœ¨ç®—æ³•ç²¾åº¦ä¸Šäº§ç”Ÿå®žè´¨æ€§çš„æ”¹å–„ã€‚ Some questions: What is an activity and how should we represent it? Do activities have well-deï¬ned spatial and temporal extent? What role do goals and intentions play in deï¬ning and understanding activities? What does the data show about the right categories for recognition in case of activities? Do existing approaches scale with increasing complexity of activities categories, video data, or temporal relationships between activities? Are the hypothesized new avenues of studying context, objects, or intentions worthwhile: Do these really help in understanding videos? This paper provides an in-depth analysis of the new generation of video datasets, human annotators, activity categories, recognition approaches, and above all possible new cues for video understanding. We found that people considered verbs to be relatively more ambiguous. This suggests that despite boundary ambiguity, current datasets allow us to understand, learn from, and evaluate the temporal extents of activities. That is, a perfect classiï¬er would automatically do 5 times better than current state-of-the-art [30] on activity localization. This suggests that focusing our attention on gaining more insight into activity classiï¬cation would naturally yield signiï¬cant improvements in localization accuracy as well. Having concluded that: (1) we should be reasoning about activities as (verb,object) pairs rather than just verb, (2) temporal boundaries of activities are ambiguous but nevertheless meaningful, and (3) classiï¬cation of short videos is a reasonable proxy for temporal localization This suggests that moving forward ï¬ne-grained discrimination between activities with similar objects and verbs is needed. Lattice Long Short-Term Memory for Human Action Recognition However, naively applying RNNs to video sequences in a convolutional manner implicitly assumes that motions in videos are stationary across different spatial locations. This assumption is valid for short-term motions but invalid when the duration of the motion is long. In this work, we propose Lattice-LSTM (L^2STM), which extends LSTM by learning independent hidden state transitions of memory cells for individual spatial locations. Additionally, we introduce a novel multi-modal training procedure for training our network. An accurate action recognition should: (1) have a high capacity for learning and capturing as many motion dynamics as possible (2) when an action appears in sequential images, the neurons should properly decide what kind of spatio-temporal dynamics should be encoded into the memory for distinguishing actions. Common Action Discovery and Localization in Unconstrained Videos In this work, we tackle the problem of common action discovery and localization in unconstrained videos, where we do not assume to know the types, numbers or locations of the common actions in the videos. To perform automatic discovery and localization in such challenging scenarios, we ï¬rst generate action proposals using human prior. By building an afï¬nity graph among all action proposals, we formulate the common action discovery as a subgraph density maximization problem to select the proposals containing common actions. ä¸ºäº†é¿å…åœ¨æŒ‡æ•°çº§å¤§çš„è§£ç©ºé—´ä¸­æžšä¸¾ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„å¤šé¡¹å¼æ—¶é—´ä¼˜åŒ–ç®—æ³•ã€‚ It solves the problem up to a user speciï¬ed error bound with respect to the global optimal solution. Action discoveryçš„å›°éš¾ï¼š é¦–å…ˆï¼Œç”±äºŽæˆ‘ä»¬äº‹å…ˆä¸çŸ¥é“åœ¨ç»™å®šçš„æ•°æ®é›†ä¸­å¸¸è§çš„åŠ¨ä½œç±»åž‹æˆ–ä½ç½®ï¼Œæˆ‘ä»¬å¿…é¡»åŒæ—¶è¿›è¡Œå‘çŽ°å’Œå®šä½ã€‚ ç»™å®šä¸€ç»„æœªæ ‡è®°çš„è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦è‡ªåŠ¨è¯†åˆ«ä¸€ç»„æ•èŽ·å¸¸è§æ“ä½œçš„æ—¶ç©ºè¾¹ç•Œæ¡†ã€‚ å…¶æ¬¡ï¼Œç±»ä¼¼çš„è¡Œä¸ºä¹Ÿå¯èƒ½ç”±äºŽè§†ç‚¹å˜åŒ–ï¼Œå°ºåº¦å˜åŒ–æˆ–ç›¸æœºè¿åŠ¨è€Œå‡ºçŽ°ä¸åŒã€‚ è‡ªåŠ¨å…³è”è¿™äº›å¸¸è§æ“ä½œå¹¶ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ã€‚ æœ€åŽï¼Œé™¤äº†å¸¸è§çš„åŠ¨ä½œä¹‹å¤–ï¼Œè§†é¢‘è¿˜å¯èƒ½åŒ…å«åŠ¨æ€èƒŒæ™¯æˆ–ä¸å¸¸è§çš„åŠ¨ä½œï¼Œå› æ­¤å°†è¿™ç§â€œnoisy motionsâ€ä¸Žå¸¸è§åŠ¨ä½œåŒºåˆ†å¼€æ¥æ˜¯è‡³å…³é‡è¦çš„ã€‚ Pedestrian Related HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis Learning of comprehensive features of pedestrians for ï¬ne-grained tasks remains an open problem. HydraPlus-Net: multi-directionally feeds the multi-level attention maps to different feature layers. Advantages: (1) the model is capable of capturing multiple attentions from low-level to semantic-level (2) it explores the multi-scale selectiveness of attentive features to enrich the ï¬nal feature representations for a pedestrian image. We demonstrate the effectiveness and generality of the proposed HP-net for pedestrian analysis on two tasks, i.e. pedestrian attribute recognition and person reidentiï¬cation. However, the learning of feature representation for pedestrian images, as the backbone for all those applications, still confronts critical challenges and needs profound studies. However, existing arts merely extract global features [13, 24, 30] and are hardly effective to location-aware semantic pattern extraction. Multidirectional attention (MDA) modules Reliable 3D skeleton-based action recognition (SAR) is now feasible [1]. Although much progress has been achieved, these methods are still facing two challenges. We term the ï¬rst one as the discriminative challenge. We term the second challenge as adaptability. Pose Estimation Towards 3D Human Pose Estimation in the Wild: A Weakly-Supervised Approach We propose a weakly-supervised transfer learning method that uses mixed 2D and 3D labels in a uniï¬ed deep neutral network that presents two-stage cascaded structure. Object Detection Flow-Guided Feature Aggregation for Video Object Detection Video object detection The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. We present ï¬‚ow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. å®ƒé€šè¿‡æ²¿ç€è¿åŠ¨è·¯å¾„èšé›†é™„è¿‘çš„ç‰¹å¾æ¥æ”¹è¿›æ¯å¸§ç‰¹å¾ï¼Œä»Žè€Œæé«˜äº†è§†é¢‘è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚ Fast moving objects. DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling We deï¬ne the object detection from imagery problem as estimating a very large but extremely sparse bounding box dependent probability distribution. ï¼ˆæˆ‘ä»¬å°†å›¾åƒé—®é¢˜ä¸­çš„ç›®æ ‡æ£€æµ‹å®šä¹‰ä¸ºä¼°è®¡éžå¸¸å¤§ä½†æžå…¶ç¨€ç–çš„è¾¹ç•Œæ¡†ç›¸å…³æ¦‚çŽ‡åˆ†å¸ƒã€‚ï¼‰ Two novelties: a corner based region-of-interest estimator a deconvolution based CNN model Image Recognition Multi-label Image Recognition by Recurrently Discovering Attentional Regions Current solutions for this task usually rely on an extra step of extracting hypothesis regions (i.e., region proposals), resulting in redundant computation and sub-optimal performance. Developing a recurrent memorized-attention module. This module consists of two alternately performed components: a spatial transformer layer to locate attentional regions from the convolutional feature maps in a region-proposal-free way an LSTM (Long-Short Term Memory) sub-network to sequentially predict semantic labeling scores on the located regions while capturing the global dependencies of these regions. Despite acknowledged successes, these methods take the redundant computational cost of extracting region proposals and usually over-simplify the contextual dependencies among foreground objects, leading to a sub-optimal performance in complex scenarios. â€‹ â€‹ â€‹ â€‹]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
        <tag>è®ºæ–‡è°ƒç ”</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œä¸ºè¯†åˆ«è®ºæ–‡ç¬”è®°ï¼šè¡Œä¸ºåˆ†ç±»æ·±åº¦æ¨¡åž‹çš„æ€»ç»“.md]]></title>
    <url>%2Fposts%2F679115822%2F</url>
    <content type="text"><![CDATA[æœ¬æ¬¡ä¸»è¦æ€»ç»“äº†ç›®å‰å¸¸è§ä¸€äº›ç»å…¸çš„åŸºäºŽæ·±åº¦å­¦ä¹ çš„è¡Œä¸ºåˆ†ç±»æ¨¡åž‹ã€‚å…¶ä¸­çš„ä¸»è¦å†…å®¹æ¥è‡ªäºŽè®ºæ–‡ã€ŠQuo Vadis, Action Recognition? A New Model and the Kinetics Datasetã€‹ä¸­çš„Related Workéƒ¨åˆ†çš„æ€»ç»“ã€‚ è™½ç„¶è¿‘å¹´æ¥å›¾åƒè¡¨ç¤ºä½“ç³»ç»“æž„çš„å‘å±•å·²ç»è¿…é€Ÿæˆç†Ÿï¼Œä½†è§†é¢‘çš„å‰ç«¯è¿è¡Œæž¶æž„ä»ç„¶ä¸å¤Ÿæ¸…æ™°ã€‚å½“å‰è§†é¢‘ä½“ç³»ç»“æž„ä¸­çš„ä¸€äº›ä¸»è¦å·®å¼‚åœ¨äºŽconvolutional and layers operatorsæ˜¯ä½¿ç”¨2Dï¼ˆåŸºäºŽå›¾åƒçš„ï¼‰è¿˜æ˜¯3Dï¼ˆåŸºäºŽè§†é¢‘çš„ï¼‰kernels; æ— è®ºç½‘ç»œè¾“å…¥æ˜¯RGBè§†é¢‘æˆ–è€…è¿˜æ˜¯åŒ…å«é¢„å…ˆè®¡ç®—çš„å…‰æµï¼Œåœ¨2D ConvNetsçš„æƒ…å†µä¸‹ï¼Œå¯¹äºŽä¿¡æ¯å¦‚ä½•è·¨å¸§ä¼ æ’­ï¼Œè¿™å¯ä»¥é€šè¿‡ä½¿ç”¨è¯¸å¦‚LSTMä¹‹ç±»çš„temporally-recurrent layersæˆ–è€…éšç€æ—¶é—´çš„æŽ¨ç§»è¿›è¡Œç‰¹å¾èšåˆæ¥å®Œæˆã€‚ å›¾1æ˜¾ç¤ºäº†æˆ‘ä»¬è¯„ä¼°çš„äº”ç§ä½“ç³»ç»“æž„çš„å›¾å½¢æ¦‚è¿°ã€‚ æ¨¡åž‹1ï¼šConvNet+LSTMå›¾åƒåˆ†ç±»ç½‘ç»œçš„é«˜æ€§èƒ½ä½¿å¾—æˆ‘ä»¬å°è¯•åªéœ€å¾ˆå°‘çš„æ”¹å˜å°±èƒ½å°†å…¶é‡ç”¨äºŽè§†é¢‘ä¸­ã€‚ é€šè¿‡ä½¿ç”¨å®ƒä»¬é’ˆå¯¹æ¯ä¸ªç‹¬ç«‹å¸§æå–ç‰¹å¾ï¼Œç„¶åŽé›†ä¸­åœ¨æ•´ä¸ªè§†é¢‘ä¸­æ¥æå–é¢„æµ‹ç»“æžœæ¥å®žçŽ°è¿™ä¸€ç›®æ ‡ã€‚ è¿™æ˜¯bag of wordså›¾åƒå»ºæ¨¡æ–¹æ³•çš„ç²¾ç¥ž; ä½†æ˜¯åœ¨å®žè·µä¸­ä½¿ç”¨æ–¹ä¾¿çš„åŒæ—¶ï¼Œè¿˜å­˜åœ¨å®Œå…¨å¿½ç•¥æ—¶é—´ç»“æž„çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œæ¨¡åž‹ä¸èƒ½å¾ˆå¥½çš„åŒºåˆ†å¼€é—¨å’Œå…³é—¨ï¼‰ã€‚ ç†è®ºä¸Šï¼Œæ›´ä»¤äººæ»¡æ„çš„æ–¹æ³•æ˜¯å‘æ¨¡åž‹æ·»åŠ ä¸€ä¸ªrecurrent layerï¼Œä¾‹å¦‚å¯ä»¥å¯¹çŠ¶æ€è¿›è¡Œç¼–ç çš„LSTMï¼Œå¹¶æ•èŽ·æ—¶é—´é¡ºåºå’Œé•¿ç¨‹ä¾èµ–æ€§ã€‚ æœ¬æ–‡åœ¨æœ‰512ä¸ªéšè—å•å…ƒçš„Inception-V1çš„æœ€åŽçš„å¹³å‡æ± åŒ–å±‚ä¹‹åŽé˜²æ­¢äº†ä¸€ä¸ªæœ‰ç€BNçš„LSTMå±‚ï¼Œ ä¸€ä¸ªå…¨è¿žæŽ¥å±‚è¢«æ·»åŠ åˆ°åˆ†ç±»å™¨çš„é¡¶éƒ¨ã€‚ è¯¥æ¨¡åž‹å¯¹æ‰€æœ‰æ—¶é—´æ­¥éª¤çš„è¾“å‡ºä¸Šä½¿ç”¨äº¤å‰ç†µæŸå¤±è¿›è¡Œè®­ç»ƒã€‚ åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªè€ƒè™‘æœ€åŽä¸€å¸§çš„è¾“å‡ºã€‚ æ¨¡åž‹2ï¼š3D ConvNets3D ConvNetsä¼¼ä¹Žæ˜¯ä¸€ç§æ›´è‡ªç„¶çš„è§†é¢‘å»ºæ¨¡æ–¹æ³•ï¼Œå…¶å°±åƒæ ‡å‡†çš„å·ç§¯ç½‘ç»œä¸€æ ·ï¼Œä½†æ˜¯å…·æœ‰æ—¶ç©ºå·ç§¯æ ¸ã€‚å®ƒä»¬æœ‰ä¸€ä¸ªéžå¸¸é‡è¦çš„ç‰¹å¾ï¼šå®ƒä»¬ç›´æŽ¥åˆ›å»ºæ—¶ç©ºæ•°æ®çš„åˆ†å±‚è¡¨ç¤ºã€‚è¿™äº›æ¨¡åž‹çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œç”±äºŽé™„åŠ çš„å†…æ ¸ç»´åº¦ï¼Œå®ƒä»¬æ¯”2D ConvNetsæœ‰æ›´å¤šçš„å‚æ•°ï¼Œè¿™ä½¿å¾—å®ƒä»¬æ›´éš¾ä»¥è®­ç»ƒã€‚å¦å¤–ï¼Œå®ƒä»¬ä¼¼ä¹ŽæŽ’é™¤äº†ImageNeté¢„è®­ç»ƒçš„å¥½å¤„ï¼Œå› æ­¤ä»¥å‰çš„å·¥ä½œå®šä¹‰äº†ç›¸å¯¹è¾ƒæµ…çš„æž¶æž„ï¼Œå¹¶ä¸”éƒ½æ˜¯train from scratchã€‚åŸºå‡†æµ‹è¯•çš„ç»“æžœå…·æœ‰æå‡çš„å‰æ™¯ï¼Œä½†æ˜¯ä¸Žæœ€æ–°çš„æŠ€æœ¯æ°´å¹³ç›¸æ¯”è¿˜ä¸å…·æœ‰ç«žäº‰æ€§ï¼Œä½¿å¾—è¿™ç§ç±»åž‹çš„æ¨¡åž‹æˆä¸ºè¯„ä¼°æˆ‘ä»¬å¤§åž‹æ•°æ®é›†çš„å¥½é€‰æ‹©ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å®žçŽ°äº†ä¸€ä¸ªC3Dæ¨¡åž‹çš„å°å˜ä½“ï¼Œå®ƒåœ¨é¡¶éƒ¨æœ‰8ä¸ªå·ç§¯å±‚ï¼Œ5ä¸ªæ± åŒ–å±‚å’Œ2ä¸ªå®Œå…¨è¿žæŽ¥çš„å±‚ã€‚æ¨¡åž‹çš„è¾“å…¥ä¸ŽåŽŸå§‹å®žçŽ°ç›¸åŒï¼Œä½¿ç”¨112Ã—112åƒç´ å…±16å¸§ã€‚ä¸ŽåŽŸå§‹C3Dä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨æ‰€æœ‰å·ç§¯å’Œå…¨è¿žæŽ¥å±‚ä¹‹åŽä½¿ç”¨äº†batch normalizationã€‚å¦ä¸€ä¸ªåŒºåˆ«åœ¨äºŽå¯¹äºŽç¬¬ä¸€ä¸ªæ± åŒ–å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨stride=2è€Œä¸æ˜¯stride=1ï¼Œè¿™å‡å°‘äº†å†…å­˜å ç”¨ï¼Œå¹¶å…è®¸æ›´å¤§æ‰¹é‡ - è¿™å¯¹äºŽæ‰¹é‡æ ‡å‡†åŒ–éžå¸¸é‡è¦ã€‚ä½¿ç”¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨æ ‡å‡†çš„K40 GPUåœ¨æ¯ä¸ªGPUä¸Šæ¯æ‰¹å¤„ç†15ä¸ªè§†é¢‘ã€‚ æ¨¡åž‹3ï¼šTwo-Stream Networksæ¥è‡ªConvNetsæœ€åŽå±‚çš„ç‰¹å¾ï¼ŒLSTMå¯ä»¥æ¨¡æ‹Ÿé«˜å±‚æ¬¡çš„å˜åŒ–ï¼Œä½†æ˜¯å¯èƒ½æ— æ³•æ•èŽ·åœ¨è®¸å¤šæƒ…å†µä¸‹éžå¸¸å…³é”®çš„ç²¾ç»†çš„low-levelåŠ¨ä½œã€‚è®­ç»ƒä¹Ÿæ˜¯æ˜‚è´µçš„ï¼Œå› ä¸ºå®ƒéœ€è¦é€šè¿‡å¤šå¸§æ¥å±•å¼€ç½‘ç»œä»¥ä¾¿åå‘ä¼ æ’­ã€‚ Simonyanå’ŒZissermanä»‹ç»äº†ä¸€ç§ä¸åŒçš„éžå¸¸å®žç”¨çš„æ–¹æ³•ï¼Œåœ¨é€šè¿‡ä¸¤ä¸ªå‰¯æœ¬ImageNeté¢„å…ˆè®­ç»ƒçš„ConvNetåŽï¼Œé€šè¿‡å¯¹æ¥è‡ªå•ä¸ªRGBå¸§çš„é¢„æµ‹å’Œ10ä¸ªå¤–éƒ¨è®¡ç®—çš„å…‰æµå¸§çš„é¢„æµ‹è¿›è¡Œå¹³å‡ï¼Œæ¥å¯¹è§†é¢‘çš„çŸ­æ—¶é—´å¿«ç…§è¿›è¡Œå»ºæ¨¡ã€‚å…‰æµ streamæœ‰ä¸€ä¸ªè‡ªé€‚åº”çš„è¾“å…¥å·ç§¯å±‚ï¼Œè¾“å…¥é€šé“çš„æ•°é‡æ˜¯å…‰æµå¸§çš„ä¸¤å€ï¼ˆå› ä¸ºæµé‡æœ‰ä¸¤ä¸ªé€šé“ï¼Œæ°´å¹³å’Œåž‚ç›´ï¼‰ï¼Œåœ¨æµ‹è¯•æ—¶ï¼Œå¤šä¸ªå¿«ç…§ä»Žè§†é¢‘ä¸­é‡‡æ ·ï¼Œå¹¶å¯¹åŠ¨ä½œé¢„æµ‹è¿›è¡Œå¹³å‡ã€‚è¿™è¢«è¯æ˜Žåœ¨çŽ°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸­å¾—åˆ°äº†éžå¸¸é«˜çš„æ€§èƒ½ï¼ŒåŒæ—¶éžå¸¸æœ‰æ•ˆåœ°è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚ æœ€è¿‘çš„ä¸€ä¸ªæ‰©å±•[8]å°†æœ€åŽä¸€ä¸ªç½‘ç»œå·ç§¯å±‚ä¹‹åŽçš„ç©ºé—´æµå’Œå…‰æµèžåˆèµ·æ¥ï¼Œæ˜¾ç¤ºå‡ºå¯¹HMDBçš„ä¸€äº›æ”¹è¿›ï¼ŒåŒæ—¶éœ€è¦è¾ƒå°‘çš„æµ‹è¯•æ—¶é—´å¢žé‡ï¼ˆå¿«ç…§é‡‡æ ·ï¼‰ã€‚æˆ‘ä»¬çš„å®žçŽ°å¤§è‡´ä½¿ç”¨äº†Inception-V1ã€‚ç½‘ç»œçš„è¾“å…¥æ˜¯5ä¸ªè¿žç»­çš„RGBå¸§ï¼Œç›¸éš”10å¸§ï¼Œä»¥åŠç›¸åº”çš„å…‰æµç‰‡æ®µã€‚ Inception-V1ï¼ˆ5Ã—7Ã—7ç‰¹å¾ç½‘æ ¼ï¼Œå¯¹åº”äºŽæ—¶é—´xå’Œyç»´åº¦ï¼‰çš„æœ€åŽä¸€ä¸ªå¹³å‡æ±‡èšå±‚ä¹‹å‰çš„ç©ºé—´å’Œè¿åŠ¨ç‰¹å¾é€šè¿‡å…·æœ‰512ä¸ªè¾“å‡ºé€šé“çš„3Ã—3Ã—3çš„3Då·ç§¯å±‚ï¼Œç„¶åŽæ˜¯3Ã—3Ã—3çš„3Dæœ€å¤§æ± å±‚ï¼Œå¹¶é€šè¿‡æœ€ç»ˆçš„å®Œå…¨è¿žæŽ¥å±‚ã€‚è¿™äº›æ–°å±‚çš„æƒé‡ç”¨é«˜æ–¯å™ªå£°åˆå§‹åŒ–ã€‚ ä¸¤ç§æ¨¡åž‹ï¼ˆåŽŸå§‹åŒæµå’Œ3Dèžåˆç‰ˆæœ¬ï¼‰éƒ½æ˜¯ç«¯å¯¹ç«¯è®­ç»ƒï¼ˆåŒ…æ‹¬åŽŸå§‹æ¨¡åž‹ä¸­çš„åŒæµå¹³å‡æµç¨‹ï¼‰ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
        <tag>Action Recognition</tag>
        <tag>è¡Œä¸ºè¯†åˆ«</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šDSSD]]></title>
    <url>%2Fposts%2F2938514597%2F</url>
    <content type="text"><![CDATA[Abstract æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºŽåœ¨å½“å‰æœ€å¥½çš„é€šç”¨ç›®æ ‡æ£€æµ‹å™¨ä¸­åŠ å…¥äº†é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ ä¸ºå®žçŽ°è¿™ä¸€ç›®çš„ï¼šæˆ‘ä»¬é€šè¿‡å°†ResNet-101ä¸ŽSSDç»“åˆã€‚ç„¶åŽï¼Œæˆ‘ä»¬ç”¨deconvolution layersæ¥ä¸°å¯Œäº†SSD + Residual-101ï¼Œä»¥ä¾¿åœ¨ç‰©ä½“æ£€æµ‹ä¸­å¼•å…¥é¢å¤–çš„large-scaleçš„ä¸Šä¸‹æ–‡ï¼Œå¹¶æé«˜å‡†ç¡®æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºŽå°ç‰©ä½“ï¼Œä»Žè€Œç§°ä¹‹ä¸ºDSSDã€‚ æˆ‘ä»¬é€šè¿‡ä»”ç»†çš„åŠ å…¥é¢å¤–çš„learned transformationsé˜¶æ®µï¼Œå…·ä½“æ¥è¯´æ˜¯ä¸€ä¸ªç”¨äºŽåœ¨deconvolutionä¸­å‰å‘ä¼ é€’è¿žæŽ¥çš„æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªæ–°çš„è¾“å‡ºæ¨¡åž‹ï¼Œä½¿å¾—è¿™ä¸ªæ–°çš„æ–¹æ³•å˜å¾—å¯è¡Œï¼Œå¹¶ä¸ºä¹‹åŽçš„ç ”ç©¶æä¾›ä¸€ä¸ªæ½œåœ¨çš„é“è·¯ã€‚ æˆ‘ä»¬çš„DSSDå…·æœ‰513Ã—513çš„è¾“å…¥ï¼Œåœ¨VOC2007æµ‹è¯•ä¸­è¾¾åˆ°81.5ï¼…deçš„mAPï¼ŒVOC2012æµ‹è¯•ä¸º80.0ï¼…deçš„mAPï¼ŒCOCOä¸º33.2ï¼…çš„mAPï¼Œåœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šä¼˜äºŽæœ€å…ˆè¿›çš„R-FCN ã€‚ Introduction æœ€è¿‘çš„ä¸€äº›ç›®æ ‡æ£€æµ‹æ–¹æ³•å›žå½’åˆ°äº†æ»‘åŠ¨çª—å£æŠ€æœ¯ï¼Œè¿™ç§æŠ€æœ¯éšç€æ›´å¼ºå¤§çš„æ•´åˆäº†æ·±åº¦å­¦ä¹ çš„æœºå™¨å­¦ä¹ æ¡†æž¶è€Œå›žå½’ã€‚ Faster RCNN -&gt; YOLO -&gt; SSD. å›žé¡¾æœ€è¿‘çš„è¿™äº›ä¼˜ç§€çš„ç›®æ ‡æ£€æµ‹æ¡†æž¶ï¼Œè¦æƒ³æé«˜æ£€æµ‹å‡†ç¡®çŽ‡ï¼Œä¸€ä¸ªå¾ˆæ˜Žæ˜¾çš„ç›®æ ‡å°±æ˜¯ï¼šåˆ©ç”¨æ›´å¥½çš„ç‰¹å¾ç½‘ç»œå¹¶ä¸”æ·»åŠ æ›´å¤šçš„ä¸Šä¸‹æ–‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºŽå°ç‰©ä½“ï¼Œå¦å¤–è¿˜è¦æé«˜è¾¹ç•Œæ¡†é¢„æµ‹è¿‡ç¨‹çš„ç©ºé—´åˆ†è¾¨çŽ‡ã€‚ åœ¨ç›®æ ‡æ£€æµ‹ä¹‹å¤–ï¼Œæœ€è¿‘æœ‰ä¸€ä¸ªé›†æˆä¸Šä¸‹æ–‡çš„å·¥ä½œï¼Œåˆ©ç”¨æ‰€è°“çš„â€œencoder-decoderâ€ç½‘ç»œã€‚è¯¥ç½‘ç»œä¸­é—´çš„bottleneck layerç”¨äºŽç¼–ç å…³äºŽè¾“å…¥å›¾åƒçš„ä¿¡æ¯ï¼Œç„¶åŽé€æ¸åœ°æ›´å¤§çš„å±‚å°†å…¶è§£ç åˆ°æ•´ä¸ªå›¾åƒçš„mapä¸­ã€‚æ‰€å½¢æˆçš„wideï¼Œnarrowï¼Œwideçš„ç½‘ç»œç»“æž„é€šå¸¸è¢«ç§°ä¸ºæ²™æ¼ã€‚ ä½†æ˜¯æœ‰å¿…è¦ä»”ç»†æž„å»ºç”¨äºŽé›†æˆåå·ç§¯çš„ç»„åˆæ¨¡å—å’Œè¾“å‡ºæ¨¡å—ï¼Œä»¥åœ¨è®­ç»ƒæœŸé—´éš”ç»ResNet-101å±‚ï¼Œä»Žè€Œå…è®¸æœ‰æ•ˆçš„å­¦ä¹ ã€‚ Related Work SPPnet, Fast R-CNN, Faster R-CNN, R-FCN, YOLOï¼šä½¿ç”¨å·ç§¯ç½‘ç»œçš„æœ€ä¸Šé¢çš„å±‚æ¥è¿›è¡Œä¸åŒå°ºåº¦çš„ç‰©ä½“æ£€æµ‹ã€‚ é€šè¿‡åœ¨ConvNetä¸­å¼€å‘å¤šå±‚æ¥æé«˜æ£€æµ‹ç²¾åº¦çš„æ–¹æ³•æœ‰å¤šé‡ã€‚ ç¬¬ä¸€ç§æ–¹æ³•ï¼šç»„åˆäº†ConvNetä¸åŒå±‚çš„ç‰¹å¾å›¾ï¼Œå¹¶ä½¿ç”¨ç»„åˆç‰¹å¾å›¾è¿›è¡Œé¢„æµ‹ã€‚ IONåˆ©ç”¨L2 normalizationæ¥ç»“åˆå¤šä¸ªVGGNetå’Œæ± åŒ–å±‚çš„ç‰¹å¾æ¥è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚ HyperNetä¹Ÿæ˜¯ä½¿ç”¨ç±»ä¼¼äºŽIONçš„æ–¹æ³•ã€‚ ä½†æ˜¯è¿™ç§ç»“åˆå¤šå±‚ç‰¹å¾çš„æ–¹æ³•ä¸ä»…å¢žåŠ å†…å­˜ï¼Œè€Œä¸”é™ä½Žäº†æ¨¡åž‹çš„é€Ÿåº¦ã€‚ ç¬¬äºŒç§æ–¹æ³•ï¼šä½¿ç”¨ConvNetä¸­çš„ä¸åŒå±‚æ¥é¢„æµ‹ä¸åŒå°ºåº¦çš„å¯¹è±¡ã€‚ å› ä¸ºä¸åŒå±‚ä¸­çš„èŠ‚ç‚¹å…·æœ‰ä¸åŒçš„æŽ¥æ”¶åŸŸï¼Œæ‰€ä»¥è‡ªç„¶ä¼šä»Žå…·æœ‰å¤§åž‹æŽ¥æ”¶åœºçš„å±‚é¢„æµ‹å¤§å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨å…·æœ‰å°æŽ¥æ”¶åœºçš„å±‚æ¥é¢„æµ‹å°ç‰©ä½“ã€‚ SSDå°†ä¸åŒå°ºåº¦çš„é»˜è®¤æ¡†æ‰©å±•åˆ°ConvNetä¸­çš„å¤šä¸ªå±‚ï¼Œå¹¶å¼ºåˆ¶æ‰§è¡Œæ¯ä¸€å±‚ä¸“æ³¨äºŽé¢„æµ‹ä¸€å®šè§„æ¨¡çš„å¯¹è±¡ã€‚ S-CNN [2]åœ¨ConvNetçš„å¤šå±‚åº”ç”¨åŽ»å·ç§¯ï¼Œä»¥åœ¨ä½¿ç”¨å±‚åŽ»å­¦ä¹ region proposalå’Œpool featureä¹‹å‰å¢žåŠ feature mapsçš„åˆ†è¾¨çŽ‡ã€‚ ç„¶è€Œï¼Œä¸ºäº†å¾ˆå¥½åœ°æ£€æµ‹å°ç‰©ä½“ï¼Œè¿™äº›æ–¹æ³•éœ€è¦ä»Žå…·æœ‰å°çš„æŽ¥æ”¶åœºå’Œå¯†é›†ç‰¹å¾å›¾çš„æµ…å±‚ä¸­ä½¿ç”¨ä¸€äº›ä¿¡æ¯ï¼Œè¿™å¯èƒ½å¯¼è‡´åœ¨æ£€æµ‹å°å¯¹è±¡æ€§èƒ½è¾ƒä½Žï¼Œå› ä¸ºæµ…å±‚å…·æœ‰è¾ƒå°‘çš„å…³äºŽå¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯ã€‚ é€šè¿‡ä½¿ç”¨deconvolution layerså’Œskip connections,ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¯†é›†ï¼ˆåŽ»å·ç§¯ï¼‰ç‰¹å¾å›¾ä¸­æ³¨å…¥æ›´å¤šçš„ä¿¡æ¯ï¼Œä»Žè€Œæœ‰åŠ©äºŽé¢„æµ‹å°ç‰©ä½“ã€‚ å¦å¤–è¿˜æœ‰ä¸€ä¸ªå·¥ä½œæ–¹æ³•ï¼Œå°½é‡åŽ»åŒ…æ‹¬é¢„æµ‹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ Multi-Region CNN Deconvolutional (DSSD) model Single Shot DetectionSSD SSDæž„å»ºäºŽbase networkä¹‹ä¸Šï¼Œæ·»åŠ äº†ä¸€äº›é€æ¸è§æ•ˆçš„å·ç§¯å±‚ï¼Œå¦‚ä¸Šå›¾è“è‰²éƒ¨åˆ†ã€‚ æ¯ä¸ªæ·»åŠ çš„å±‚å’Œä¸€äº›è¾ƒæ—©çš„åŸºæœ¬ç½‘ç»œå±‚ç”¨äºŽé¢„æµ‹æŸäº›é¢„å®šä¹‰çš„è¾¹ç•Œæ¡†çš„åˆ†æ•°å’Œåç§»ã€‚ è¿™äº›é¢„æµ‹ç”±3x3xï¼ƒä¸ªé€šé“ç»´æ•°çš„æ»¤æ³¢å™¨æ‰§è¡Œï¼Œä¸€ä¸ªæ»¤æ³¢å™¨ç”¨äºŽäº§ç”Ÿæ¯ä¸ªç±»åˆ«åˆ†æ•°ï¼Œä¸€ä¸ªç”¨äºŽå›žå½’è¾¹ç•Œæ¡†çš„æ¯ä¸ªç»´åº¦ã€‚ å®ƒä½¿ç”¨éžæœ€å¤§æŠ‘åˆ¶ï¼ˆNMSï¼‰å¯¹é¢„æµ‹è¿›è¡ŒåŽå¤„ç†ï¼Œä»¥èŽ·å¾—æœ€ç»ˆæ£€æµ‹ç»“æžœã€‚ Using Residual-101 in place of VGGå°†Base Networkä»ŽVGG16æ¢ä¸ºResNet-101å¹¶æœªæå‡ç»“æžœï¼Œä½†æ˜¯æ·»åŠ é¢å¤–çš„prediction moduleä¼šæ˜¾è‘—åœ°ææˆæ€§èƒ½ã€‚ prediction module åœ¨åŽŸå§‹SSDä¸­ï¼Œç›®æ ‡å‡½æ•°ç›´æŽ¥åº”ç”¨äºŽæ‰€é€‰æ‹©çš„ç‰¹å¾å›¾ï¼Œå¹¶ä¸”ç”±äºŽæ¢¯åº¦çš„å¤§å¹…åº¦ï¼Œä½¿ç”¨L2æ ‡å‡†åŒ–å±‚ç”¨äºŽconv4 3å±‚ã€‚ MS-CNNæŒ‡å‡ºï¼Œæ”¹è¿›æ¯ä¸ªä»»åŠ¡çš„å­ç½‘å¯ä»¥æé«˜å‡†ç¡®æ€§ï¼ŒæŒ‰ç…§è¿™ä¸ªåŽŸåˆ™ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªé¢„æµ‹å±‚æ·»åŠ ä¸€ä¸ªæ®‹å·®å—ï¼Œå¦‚å›¾2å˜ä½“ï¼ˆcï¼‰æ‰€ç¤ºã€‚ æˆ‘ä»¬è¿˜å°è¯•äº†åŽŸå§‹SSDæ–¹æ³•ï¼ˆaï¼‰å’Œå…·æœ‰è·³è¿‡è¿žæŽ¥ï¼ˆbï¼‰çš„æ®‹ä½™å—çš„ç‰ˆæœ¬ä»¥åŠä¸¤ä¸ªé¡ºåºçš„æ®‹ä½™å—ï¼ˆdï¼‰ã€‚ æˆ‘ä»¬æ³¨æ„åˆ°ï¼ŒResNet-101å’Œé¢„æµ‹æ¨¡å—ä¼¼ä¹Žæ˜¾è‘—ä¼˜äºŽå¯¹äºŽè¾ƒé«˜åˆ†è¾¨çŽ‡è¾“å…¥å›¾åƒæ²¡æœ‰é¢„æµ‹æ¨¡å—çš„VGGã€‚ Deconvolutional SSD ä¸ºäº†åœ¨æ£€æµ‹ä¸­åŒ…å«æ›´å¤šçš„é«˜å±‚æ¬¡ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å°†prediction moduleè½¬ç§»åˆ°åœ¨åŽŸå§‹SSDè®¾ç½®ä¹‹åŽæ”¾ç½®çš„ä¸€ç³»åˆ—åŽ»å·ç§¯å±‚ä¸­ï¼Œæœ‰æ•ˆåœ°åˆ¶ä½œäº†éžå¯¹ç§°æ²™æ¼ç½‘ç»œç»“æž„ã€‚ æ·»åŠ é¢å¤–çš„åŽ»å·ç§¯å±‚ï¼Œä»¥è¿žç»­å¢žåŠ feature maps layersçš„åˆ†è¾¨çŽ‡ã€‚ä¸ºäº†åŠ å¼ºç‰¹å¾ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ²™æ¼æ¨¡åž‹ä¸­â€œè·³è·ƒè¿žæŽ¥â€çš„æƒ³æ³•ã€‚ å°½ç®¡æ²™æ¼æ¨¡åž‹åœ¨ç¼–ç å™¨å’Œè§£ç å™¨é˜¶æ®µå‡åŒ…å«å¯¹ç§°å±‚ï¼Œä½†ç”±äºŽä¸¤ä¸ªåŽŸå› ï¼Œæˆ‘ä»¬ä½¿è§£ç å™¨é˜¶æ®µéžå¸¸æµ…ã€‚ Deconvolution Module ä¸ºäº†å¸®åŠ©æ•´åˆæ—©æœŸç‰¹å¾å›¾å’ŒåŽ»å·ç§¯å±‚çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŽ»å·ç§¯æ¨¡å—ï¼Œå¦‚å›¾3æ‰€ç¤ºã€‚ é¦–å…ˆï¼Œåœ¨æ¯ä¸ªå·ç§¯å±‚ä¹‹åŽæ·»åŠ BNå±‚ã€‚ ç¬¬äºŒï¼Œæˆ‘ä»¬ä½¿ç”¨å­¦ä¹ çš„åŽ»å·ç§¯å±‚ä»£æ›¿åŒçº¿æ€§ä¸Šé‡‡æ ·ã€‚ æœ€åŽï¼Œæˆ‘ä»¬æµ‹è¯•ä¸åŒçš„ç»„åˆæ–¹æ³•ï¼šelement-wise sum and element-wise productã€‚ Traning æˆ‘ä»¬éµå¾ªä¸ŽSSDç›¸åŒçš„è®­ç»ƒæ”¿ç­–ã€‚ åœ¨åŽŸå§‹SSDæ¨¡åž‹ä¸­ï¼Œé•¿å®½æ¯”ä¸º2å’Œ3çš„boxesä»Žå®žéªŒä¸­è¯æ˜Žæ˜¯æœ‰ç”¨çš„ã€‚ä¸ºäº†äº†è§£è®­ç»ƒæ•°æ®ï¼ˆPASCAL VOC 2007å’Œ2012å¹´ trainvalï¼‰ä¸­è¾¹ç•Œæ¡†çš„çºµæ¨ªæ¯”ï¼Œæˆ‘ä»¬ä»¥training boxè¿è¡ŒK-meansèšç±»ï¼Œä»¥æ–¹æ ¼å¹³æ–¹æ ¹ä¸ºç‰¹å¾ã€‚æˆ‘ä»¬ä»Žä¸¤ä¸ªé›†ç¾¤å¼€å§‹ï¼Œå¦‚æžœé”™è¯¯å¯ä»¥æé«˜20ï¼…ä»¥ä¸Šï¼Œå°±ä¼šå¢žåŠ é›†ç¾¤çš„æ•°é‡ã€‚ç»è¿‡è¯•éªŒå› æ­¤ï¼Œæˆ‘ä»¬å†³å®šåœ¨æ¯ä¸ªé¢„æµ‹å±‚æ·»åŠ ä¸€ä¸ªå®½é«˜æ¯”1.6ï¼Œå¹¶ä½¿ç”¨ï¼ˆ1.6, 2.0, 3.0ï¼‰ã€‚ Experiments PASCAL VOC2007 test detection results. PASCAL 2012 test detection results. COCO test-dev2015 detection results. Comparison of Speed &amp; Accuracy on PASCAL VOC2007 test.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šDeep Residual Learning for Image Recognition]]></title>
    <url>%2Fposts%2F3085218970%2F</url>
    <content type="text"><![CDATA[Abstract æœ¬æ–‡æ˜¯ä½•å‡¯æ˜Žå¤§ç¥žçš„åˆä¸€ç¯‡CVPRæœ€ä½³è®ºæ–‡ã€‚ ç½‘ç»œè¶Šæ·±è¶Šéš¾è®­ç»ƒï¼Œæ‰€ä»¥æˆ‘ä»¬æå‡ºä¸€ä¸ªresidual learning frameworkä»Žè€Œå‡è½»ç½‘ç»œçš„è®­ç»ƒï¼Œè¯¥ç½‘ç»œæ¯”ä»¥å‰ä½¿ç”¨çš„ç½‘ç»œè¦æ·±å¾—å¤šã€‚ æˆ‘ä»¬æ˜Žç¡®åœ°å°†å‚è€ƒå±‚çš„è¾“å…¥æ¥ä½œä¸ºå­¦ä¹ æ®‹å·®å‡½æ•°ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ— å‚è€ƒçš„å‡½æ•°ï¼ˆunreferenced functionsï¼‰ã€‚ æˆ‘ä»¬æä¾›å…¨é¢çš„ç»éªŒè¯æ®ï¼Œè¡¨æ˜Žè¿™äº›æ®‹ç•™ç½‘ç»œæ›´å®¹æ˜“ä¼˜åŒ–ï¼Œå¹¶å¯ä»¥ä»Žæ˜¾ç€å¢žåŠ çš„æ·±åº¦ä¸­èŽ·å¾—å‡†ç¡®æ€§ã€‚ è¿™äº›æ®‹ç•™ç½‘ç»œçš„é›†åˆåœ¨ImageNetæµ‹è¯•é›†ä¸Šè¾¾åˆ°3.57ï¼…çš„è¯¯å·®ã€‚ è¯¥ç»“æžœåœ¨ILSVRC 2015åˆ†ç±»ä»»åŠ¡ä¸­è£èŽ·ç¬¬ä¸€åã€‚ æ·±åº¦å¯¹äºŽè®¸å¤šCVé¢†åŸŸçš„ä»»åŠ¡éƒ½ååˆ†é‡è¦çš„ã€‚ç”±äºŽæˆ‘ä»¬ç½‘ç»œå¾ˆæ·±ï¼Œæˆ‘ä»¬åœ¨COCOå¯¹è±¡æ£€æµ‹æ•°æ®é›†ä¸ŠèŽ·å¾—äº†28ï¼…çš„ç›¸å¯¹æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜è£èŽ·äº†ImageNetæ£€æµ‹ï¼ŒImageNetå®šä½ï¼ŒCOCOæ£€æµ‹å’ŒCOCOåˆ†å‰²ä»»åŠ¡çš„ç¬¬ä¸€åã€‚ Introduction æ·±å±‚ç½‘ç»œè‡ªç„¶åœ°å°†ä½Ž/ä¸­/é«˜å±‚ç‰¹å¾å’Œåˆ†ç±»å™¨ä»¥ç«¯åˆ°ç«¯å¤šå±‚æ–¹å¼è¿›è¡Œé›†æˆï¼Œå¹¶ä¸”ç‰¹å¾çš„â€œçº§åˆ«â€å¯ä»¥é€šè¿‡å †å å±‚æ•°ï¼ˆæ·±åº¦ï¼‰æ¥ä¸°å¯Œã€‚ç½‘ç»œçš„æ·±åº¦æœ‰ç€ååˆ†é‡è¦çš„ä½œç”¨ã€‚ éšç€ç½‘ç»œæ·±åº¦çš„å¢žåŠ ï¼Œå¸¦æ¥ä¸€ä¸ªé—®é¢˜ï¼šå­¦ä¹ æ›´å¥½çš„ç½‘ç»œæ˜¯å¦å’Œå †å æ›´å¤šçš„å±‚ä¸€æ ·ç®€å•ï¼Ÿå›žç­”è¿™ä¸ªé—®é¢˜çš„éšœç¢æ˜¯ï¼šé€æ¸æ¶ˆå¤±çš„æ¢¯åº¦é—®é¢˜ã€‚ å½“è¾ƒæ·±çš„ç½‘ç»œèƒ½å¤Ÿå¼€å§‹æ”¶æ•›æ—¶ï¼Œæš´éœ²äº†ä¸€ä¸ªé€€åŒ–é—®é¢˜ï¼šéšç€ç½‘ç»œæ·±åº¦çš„å¢žåŠ ï¼Œç²¾åº¦é¥±å’Œï¼Œç„¶åŽè¿…é€Ÿä¸‹é™ã€‚è¿™ç§ä¸‹é™ä¸æ˜¯ç”±äºŽè¿‡æ‹Ÿåˆï¼Œæ·»åŠ å¤šå±‚ä¼šå¯¼è‡´æ›´é«˜çš„è®­ç»ƒé”™è¯¯ã€‚ ä»Žæµ…åˆ°æ·±çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼š é™„åŠ å±‚ï¼šè®¾ç½®ä¸ºâ€œæ’ç­‰â€ï¼ˆidentityï¼‰ åŽŸå§‹å±‚ï¼šç”±ä¸€ä¸ªå·²ç»å­¦ä¼šçš„è¾ƒæµ…æ¨¡åž‹å¤åˆ¶å¾—æ¥ã€‚ è¿™ç§è§£å†³æ–¹æ¡ˆçš„å­˜åœ¨è¡¨æ˜Žï¼Œè¾ƒæ·±çš„æ¨¡åž‹ä¸åº”è¯¥äº§ç”Ÿæ¯”è¾ƒæµ…çš„æ¨¡åž‹æ›´é«˜çš„è®­ç»ƒè¯¯å·®ã€‚è‡³å°‘å…·æœ‰ç›¸åŒçš„è®­ç»ƒè¯¯å·®ã€‚ ä¼˜åŒ–éš¾é¢˜ï¼šéšç€ç½‘ç»œå±‚æ•°ä¸æ–­åŠ æ·±ï¼Œæ±‚è§£å™¨ä¸èƒ½æ‰¾åˆ°è§£å†³é€”å¾„ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†æ·±åº¦æ®‹å·®å­¦ä¹ æ¡†æž¶ã€‚ å¹³åŽŸç½‘ç»œï¼š H(x)æ˜¯ä»»æ„ä¸€ç§ç†æƒ³çš„æ˜ å°„ å¹³åŽŸç½‘ç»œå¸Œæœ›ç¬¬2å±‚æƒé‡å±‚èƒ½å¤Ÿä¸ŽH(x)æ‹Ÿåˆã€‚ æ®‹å·®ç½‘ç»œï¼š H(x)æ˜¯ä»»æ„ä¸€ç§ç†æƒ³çš„æ˜ å°„ æ®‹å·®ç½‘ç»œå¸Œæœ›ç¬¬2ç±»æƒé‡å±‚èƒ½å¤Ÿä¸ŽF(x)æ‹Ÿåˆä½¿å¾—H(x) = F(x) + x F(x)æ˜¯ä¸€ä¸ªæ®‹å·®æ˜ å°„w.r.t æ’ å¦‚æžœè¯´æ’ç­‰æ˜¯ç†æƒ³ï¼Œå¾ˆå®¹æ˜“å°†æƒé‡å€¼è®¾å®šä¸º0ï¼› å¦‚æžœç†æƒ³åŒ–æ˜ å°„æ›´æŽ¥è¿‘äºŽæ’ç­‰æ˜ å°„ï¼Œä¾¿æ›´å®¹æ˜“å‘çŽ°å¾®å°æ³¢åŠ¨ã€‚ æˆ‘ä»¬å‡è®¾ä¼˜åŒ–æ®‹å·®æ˜ å°„æ¯”ä¼˜åŒ–åŽŸå§‹çš„ï¼Œæ— å‚è€ƒæ˜ å°„(unreferenced mapping)æ›´å®¹æ˜“ã€‚åœ¨æžç«¯æƒ…å†µä¸‹ï¼Œå¦‚æžœä¸€ä¸ªidentity mappingæ˜¯æœ€ä½³çš„ï¼Œé‚£ä¹ˆå°†æ®‹å·®æŽ¨åˆ°é›¶æ¯”é€šè¿‡ä¸€å †éžçº¿æ€§å±‚çš„identity mappingæ›´å®¹æ˜“ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ç›®æ ‡æ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šR-FCN]]></title>
    <url>%2Fposts%2F3678248031%2F</url>
    <content type="text"><![CDATA[Abstract æå‡ºäº†ä¸€ä¸ªregion-based, fully convolutionalçš„ç½‘ç»œæ¥å‡†ç¡®é«˜æ•ˆçš„è¿›è¡Œç‰©ä½“æ£€æµ‹ã€‚ ä¸åŒäºŽFast/Faster R-CNNï¼Œå…¶åº”ç”¨äº†è®¡ç®—æˆæœ¬å¾ˆé«˜çš„æ¯ä¸ªåŒºåŸŸå­ç½‘ç»œæ•°ç™¾æ¬¡ï¼Œæœ¬è®ºæ–‡çš„region-based detectoræ˜¯å®Œå…¨å·ç§¯åŒ–çš„ï¼Œå‡ ä¹Žä¸€å¼ å›¾åƒä¸Šæ‰€æœ‰çš„è®¡ç®—éƒ½æ˜¯å…±äº«çš„ã€‚ ä¸ºäº†å®žçŽ°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºposition-sensitive score mapsï¼Œä»¥è§£å†³åœ¨å›¾åƒåˆ†ç±»çš„å¹³ç§»ä¸å˜æ€§ï¼ˆtranslation-invarianceï¼‰å’Œç‰©ä½“æ£€æµ‹ä¸­çš„å¹³ç§»å¯å˜æ€§ï¼ˆtranslation-varianceï¼‰ä¹‹é—´çš„å›°å¢ƒã€‚ Introduction æœ€è¿‘æµè¡Œçš„ç”¨äºŽç›®æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æž¶ä¾æ®RoIå±‚çš„ä¸åŒå¯ä»¥åˆ†ä¸ºä¸¤å¤§subnetworksï¼š ä¸€ç±»æ˜¯ç‹¬ç«‹äºŽRoIsçš„ã€å…±äº«çš„ã€fully convolutionalçš„subnetworkã€‚ å¦ä¸€ç±»æ˜¯RoI-wiseçš„subnetworkï¼Œä¸å…±äº«è®¡ç®—ã€‚ åœ¨å›¾åƒåˆ†ç±»ç½‘ç»œä¸­ï¼Œä¸€ä¸ªconvolutional subnetworkä¼šä»¥ä¸€ä¸ªsptial pooling layerè·Ÿéšç€å‡ ä¸ªfully-connected layeræœ€ä¸ºç»“å°¾ï¼Œæ‰€ä»¥å›¾åƒåˆ†ç±»ä¸­çš„sptial pooling layerè‡ªç„¶è½¬åŒ–ä¸ºç›®æ ‡æ£€æµ‹ä¸­çš„RoI pooling layerã€‚ ResNetå’ŒGoogleLeNetséƒ½è¢«è®¾è®¡æˆfully convolutionalçš„ã€‚ åœ¨ResNetè®ºæ–‡ä¸­ï¼ŒFaster R-CNNä¸­çš„RoI pooling layerè¢«ä¸è‡ªç„¶çš„æ’å…¥åˆ°ä¸¤ä¸ªå·ç§¯å±‚é›†ä¹‹é—´ï¼Œå¸¦æ¥äº†å‡†ç¡®çŽ‡çš„æå‡ï¼Œä½†æ˜¯é€Ÿåº¦ç”±äºŽunshared per-RoIè®¡ç®—é™ä½Žã€‚ å¯¹äºŽå›¾åƒåˆ†ç±»ä»»åŠ¡æ¥è¯´ï¼šæ›´å€¾å‘äºŽå¹³ç§»ä¸å˜æ€§ã€‚å¯¹äºŽå›¾åƒæ£€æµ‹ä»»åŠ¡æ¥è¯´ï¼šæ›´å€¾å‘äºŽå¹³ç§»å˜æ¢æ€§ã€‚ å‡è®¾å›¾åƒåˆ†ç±»ç½‘ç»œä¸­æ›´æ·±å±‚çš„å·ç§¯å±‚å¯¹translationä¸æ•æ„Ÿï¼Œæ‰€ä»¥ä¸ºäº†è§£å†³translation invarianceå’Œtranslation varianceä¹‹é—´çš„å›°éš¾ï¼ŒResNetå°†RoI pooling layeræ’å…¥åˆ°äº†å·ç§¯ç¥žç»ç½‘ç»œä¹‹é—´ã€‚è¿™ä¸ªåŒºåŸŸç‰¹å®šçš„æ“ä½œæ‰“ç ´äº†å¹³ç§»ä¸å˜æ€§ï¼Œå¹¶ä¸”åœ¨ä¸åŒåŒºåŸŸä¹‹é—´è¿›è¡Œè¯„ä¼°æ—¶ï¼ŒRoIä¹‹åŽçš„å·ç§¯å±‚ä¸å†æ˜¯å¹³ç§»ä¸å˜çš„ã€‚ ä¸ºäº†å°†translation varianceç»“åˆåˆ°FCNä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸€ç»„ä¸“ç”¨å·ç§¯å±‚ä½œä¸ºFCNè¾“å‡ºæ¥æž„é€ ä¸€ç»„ä½ç½®æ•æ„Ÿå¾—åˆ†å›¾ï¼ˆposition-sensitive score mapsï¼‰ã€‚æ¯ä¸€ä¸ªå¾—åˆ†å›¾å°†ç›¸å¯¹äºŽç›¸å¯¹ç©ºé—´ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œâ€œåœ¨å¯¹è±¡çš„å·¦è¾¹â€ï¼‰çš„ä½ç½®ä¿¡æ¯è¿›è¡Œç¼–ç ã€‚åœ¨è¿™ä¸ªFCNä¹‹ä¸Šï¼Œæˆ‘ä»¬é™„åŠ ä¸€ä¸ªä½ç½®æ•æ„Ÿçš„RoIæ± å±‚ï¼ˆposition-sensitive RoI pooling layerï¼‰ï¼Œä»Žè¿™äº›å¾—åˆ†å›¾ä¸­èŽ·å–ä¿¡æ¯ï¼Œæ²¡æœ‰è·Ÿéšçš„æƒé‡çš„ï¼ˆå·ç§¯/ fcï¼‰å±‚ã€‚ Our approach æœ¬è®ºæ–‡çš„æ–¹æ³•å‚è€ƒR-CNNï¼Œä¹Ÿæ˜¯ä½¿ç”¨two-stageçš„ç›®æ ‡æ£€æµ‹ç­–ç•¥ã€‚ region proposal region classification è™½ç„¶ä¸ä¾èµ–äºŽregion proposalçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ç¡®å®žå­˜åœ¨ï¼Œå¦‚SSDä½•YOLOï¼Œä½†æ˜¯region-based systemä¾æ—§åœ¨å‡ ä¸ªåŸºå‡†ä¸Šä¿æŒé¢†å…ˆçš„å‡†ç¡®æ€§ã€‚ Overall architecture of R-FCN: ç”¨RPNæ¥æå‡ºcandidate RoIsï¼Œç„¶åŽè¿™äº›RoIsè¢«åº”ç”¨åˆ°score mapsï¼Œåœ¨RPNå’ŒR-FCNä¹‹é—´å…±äº«ç‰¹å¾ã€‚ ç»™å®šä¸€ä¸ªRoIï¼ŒR-FCNæž¶æž„å¯¹RoIè¿›è¡Œåˆ†ç±»ï¼ˆåˆ†ä¸ºç‰©ä½“ç±»åˆ«æˆ–è€…èƒŒæ™¯ï¼‰ã€‚æ‰€æœ‰å¯å­¦ä¹ æƒå€¼çš„å±‚éƒ½æ˜¯å·ç§¯å±‚ï¼Œå¹¶ä¸”æ˜¯åœ¨æ•´å¼ å›¾ç‰‡ä¸Šè®¡ç®—å¾—åˆ°çš„æƒé‡ã€‚æœ€åŽå·ç§¯å±‚ä¸ºæ¯ä¸ªç±»åˆ«äº§ç”Ÿä¸€ä¸ª$k^2$ä¸ªposition-sensitive score mapsï¼Œå› æ­¤å…·æœ‰å¸¦æœ‰Cä¸ªå¯¹è±¡ç±»åˆ«ï¼ˆèƒŒæ™¯ä¸º+1ï¼‰çš„$k^2(C + 1)$é€šé“çš„è¾“å‡ºå±‚ã€‚ æ¯ä¸€ä¸ªcategoryæœ‰ä¸€ä¸ª$k^2$çš„score mapï¼Œå¯¹äºŽè¿™é‡Œæ¥è¯´k=3ï¼Œæ‰€ä»¥æœ€åŽRoI poolingå±‚äº§ç”Ÿ3x3x(C+1)ç»´çš„feature mapã€‚ RPNä»¥ä¸€ä¸ªposition-sensitive RoI pooling layerç»“æŸï¼Œè¯¥å±‚èšåˆæœ€åŽå·ç§¯å±‚çš„è¾“å‡ºå¹¶äº§ç”Ÿæ¯ä¸ªRoIçš„åˆ†æ•°ã€‚æˆ‘ä»¬çš„ä½ç½®æ•æ„Ÿçš„RoI pooling layerè¿›è¡Œé€‰æ‹©æ€§åˆå¹¶ï¼Œeach of the k Ã— k bin aggregates responses from only one score map out of the bank of k Ã— k score mapsã€‚åˆ©ç”¨ç«¯åˆ°ç«¯è®­ç»ƒï¼Œè¿™ä¸ªRoIå±‚ç®¡ç†æœ€åŽçš„å·ç§¯å±‚ä»¥å­¦ä¹ ä¸“é—¨çš„position-sensitive score mapsã€‚ Backbone architecture æœ¬è®ºæ–‡R-FCNåŸºäºŽResNet-101ã€‚ ResNet-101å…·æœ‰100ä¸ªå·ç§¯å±‚ï¼ŒåŽé¢æ˜¯global average poolingå’Œä¸€ä¸ª1000-classçš„fcå±‚ã€‚æˆ‘ä»¬ç§»åŽ»äº†average pooling layer and the fc layerï¼Œä»…ä½¿ç”¨convolutional layeræ¥è®¡ç®—feature mapsã€‚ æˆ‘ä»¬ä½¿ç”¨ResNet-101ï¼Œåœ¨ImageNetä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒResNet-101ä¸­çš„æœ€åŽä¸€ä¸ªå·ç§¯å—æ˜¯2048-dï¼Œå¹¶ä¸”æˆ‘ä»¬é™„åŠ éšæœºåˆå§‹åŒ–çš„1024-d 1Ã—1å·ç§¯å±‚ä»¥å‡å°å°ºå¯¸ã€‚ç„¶åŽï¼Œæˆ‘ä»¬åº”ç”¨$k^2(C + 1)$é€šé“å·ç§¯å±‚æ¥ç”Ÿæˆåˆ†æ•°å›¾ï¼Œå¦‚ä¸‹æ‰€è¿°ã€‚ Position-sensitive score maps &amp; Position-sensitive RoI pooling. ä¸ºäº†å°†ä½ç½®ä¿¡æ¯æ˜¾å¼ç¼–ç åˆ°æ¯ä¸ªRoIä¸­ï¼Œæˆ‘ä»¬å°†RoIçŸ©å½¢åˆ’åˆ†ä¸ºk x kä¸ªbinsã€‚ æœ€åŽçš„å·ç§¯å±‚ä¸ºæ¯ä¸ªç±»åˆ«äº§ç”Ÿçš„$k^2$ä¸ªåˆ†æ•°å›¾ã€‚åœ¨ç¬¬(i, j)ä¸ªbinå†…ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªä½ç½®æ•æ„Ÿçš„RoIæ± åŒ–æ“ä½œï¼Œä»Žè€Œåªåœ¨ç¬¬(i, j)ä¸ªscore mapä¸Šè¿›è¡Œæ± åŒ–ï¼š r_c(i, j|\theta)=\sum_{(x,y)\in bin(i,j)}{z_{i,j,c}(x+x_0,y+y_0|\theta)/n} å…¶ä¸­$r_c(i, j)$è¡¨ç¤ºä»Žc-thç±»åˆ«ä¸­å¾—åˆ°çš„(i,j)-th binçš„æ± åŒ–å“åº”ã€‚ $z_{i,j,c}$æ˜¯$k^2(C+1)$ä¸ªscore mapsä¸­çš„ä¸€ä¸ªscore mapã€‚ $(x_0,y_0)$è¡¨ç¤ºä¸€ä¸ªRoIçš„å·¦ä¸Šè§’ã€‚ $n$è¡¨ç¤ºè¿™ä¸ªbinä¸­çš„åƒç´ çš„æ•°é‡ã€‚ $\theta$è¡¨ç¤ºè¿™ä¸ªç½‘ç»œä¸­æ‰€æœ‰çš„å¯å­¦ä¹ æƒé‡ã€‚ è¯¥poolingå±žäºŽAVEï¼Œä¹Ÿå¯ä»¥ç”¨MAXã€‚ å¯¹æ¯ä¸ªç±»åˆ«k*kçš„score mapè¿›è¡Œå¹³å‡ï¼Œæœ€åŽæ¯ä¸ªRoIå¾—åˆ°ä¸€ä¸ªC+1ç»´çš„å‘é‡ã€‚ç„¶åŽæ±‚lossï¼Œå®ƒä»¬ç”¨äºŽè¯„ä¼°è®­ç»ƒæœŸé—´çš„äº¤å‰ç†µæŸå¤±å’ŒæŽ¨ç†æœŸé—´çš„RoIsæŽ’åã€‚ bounding boxes regressionã€‚å¯¹æ¯ä¸ªRoIäº§ç”Ÿä¸€ä¸ª$4k^2$ç»´çš„å‘é‡ã€‚ç„¶åŽé€šè¿‡average votingå°†å…¶èšåˆæˆ4ç»´å‘é‡ã€‚ åœ¨RoIå±‚ä¹‹åŽæ²¡æœ‰å¯å­¦ä¹ çš„å±‚æ¬¡ï¼Œå®žçŽ°äº†å‡ ä¹Žæ— æˆæœ¬åœ°åŒºçš„è®¡ç®—ã€åŠ é€Ÿè®­ç»ƒå’ŒæŽ¨ç†ã€‚ Training åˆ©ç”¨æå‰è®¡ç®—å¥½çš„region proposalï¼Œå¾ˆå®¹æ˜“æ¥ç«¯åˆ°ç«¯çš„R-FCNæž¶æž„è®­ç»ƒã€‚ loss function: L(s,t_{x,y,w,h})=L_{cls}(s_{c^*})+\lambda[c^*>0]L_{reg}(t,t^*) æœ¬æ¡†æž¶å¾ˆå®¹æ˜“åœ¨è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨online hard example mining (OHEM)ã€‚ æˆ‘ä»¬çš„per-RoIè®¡ç®—å¯ä»¥è¿›è¡Œå‡ ä¹Žcost-freeçš„example miningã€‚ åœ¨å‰å‘ä¼ æ’­ä¸­ï¼šå‡è®¾æ¯å¼ å›¾ç‰‡Nä¸ªproposalsã€‚æˆ‘ä»¬è®¡ç®—æ‰€æœ‰Nä¸ªproposalçš„lossï¼ŒæŽ’åºï¼Œé€‰æ‹©æœ€é«˜çš„Bä¸ªRoIsã€‚ç„¶åŽåœ¨é€‰ä¸­çš„proposalä¸Šè¿›è¡Œåå‘ä¼ æ’­ã€‚ decayï¼š0.0005 momentumï¼š0.9 single-scale trainingã€‚ B=128 lr = 0.001 ~20k, 0.0001 ~ 10k åŒFaster R-CNNä¸€è¶Ÿï¼Œä½¿ç”¨4æ­¥alternating trainingï¼Œåœ¨è®­ç»ƒRPNå’Œè®­ç»ƒR-FCNä¹‹é—´ã€‚ Inference ä¸ºå…¬å¹³æœŸé—´ï¼Œåœ¨300ä¸ªRoIsä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æžœä¹‹åŽç”¨NMSè¿›è¡Œå¤„ç†ï¼ŒIoUé˜ˆå€¼0.3 Ã€ trous and stride å°†ResNet-10çš„æœ‰æ•ˆstrideä»Ž32å‡ä¸º16åƒç´ ï¼Œæé«˜äº†score mapçš„åˆ†è¾¨çŽ‡ã€‚ conv4é˜¶æ®µä¹‹å‰ï¼ˆstride=16ï¼‰çš„æ‰€æœ‰å±‚éƒ½æ²¡æœ‰æ”¹å˜ã€‚ ç¬¬ä¸€ä¸ªconv5å—å„¿çš„strideä»Ž2æ”¹ä¸º1ï¼Œå¹¶ä¸”conv5é˜¶æ®µçš„å·ç§¯æ ¸éƒ½è¢«æ”¹ä¸ºhole algorithmï¼Œï¼ˆAlgorithme Ã  trousï¼‰ä»¥è¡¥å¿å‡å°‘çš„æ­¥å¹…ã€‚ ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼ŒRPNåœ¨conv4ä¹‹ä¸Šè¿›è¡Œè®¡ç®—ã€‚ä»Žè€ŒRPNä¸è¢«Ã  trouså½±å“ã€‚ Related WorkR-CNNå·²ç»è¯´æ˜Žäº†å¸¦æ·±åº¦ç½‘ç»œçš„åŒºåŸŸå€™é€‰çš„æœ‰æ•ˆæ€§ã€‚R-CNNè®¡ç®—é‚£äº›å…³äºŽè£å‰ªä¸æ­£å¸¸çš„è¦†ç›–åŒºåŸŸçš„å·ç§¯ç½‘ç»œï¼Œå¹¶ä¸”è®¡ç®—åœ¨åŒºåŸŸç›´æŽ¥æ˜¯ä¸å…±äº«çš„ã€‚SPPnetï¼ŒFast R-CNNå’ŒFaster R-CNNæ˜¯åŠå·ç§¯çš„ï¼ˆsemi-convolutionalï¼‰ï¼Œåœ¨å·ç§¯å­ç½‘ç»œä¸­æ˜¯è®¡ç®—å…±äº«çš„ï¼Œåœ¨å¦ä¸€ä¸ªå­ç½‘ç»œæ˜¯å„è‡ªè®¡ç®—ç‹¬ç«‹çš„åŒºåŸŸã€‚ ç‰©ä½“æ£€æµ‹å™¨å¯ä»¥è¢«è®¤ä¸ºæ˜¯å…¨å·ç§¯æ¨¡åž‹ã€‚OverFeat æ£€æµ‹ç‰©ä½“é€šè¿‡åœ¨convolutional feature mapsä¸Šè¿›è¡Œå¤šå°ºåº¦çš„çª—å£æ»‘åŠ¨ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä»¥å°†å•ç²¾åº¦çš„æ»‘åŠ¨çª—å£æ”¹é€ æˆä¸€ä¸ªå•å±‚çš„å·ç§¯å±‚ã€‚åœ¨Faster R-CNNä¸­çš„RPNç»„ä»¶æ˜¯ä¸€ä¸ªå…¨å·ç§¯æ£€æµ‹å™¨ï¼Œç”¨æ¥é¢„æµ‹æ˜¯ä¸€ä¸ªå…³äºŽå¤šå°ºå¯¸çš„å‚è€ƒè¾¹æ¡†çš„å®žé™…è¾¹æ¡†ã€‚åŽŸå§‹çš„RPNæ˜¯class-agnosticï¼ˆclassæ— å…³çš„ï¼‰ã€‚ä½†æ˜¯å¯¹åº”çš„class-specificæ˜¯å¯åº”ç”¨çš„ã€‚ å¦ä¸€ä¸ªç”¨äºŽç‰©ä½“æ£€æµ‹çš„æ˜¯fc layerï¼ˆfully-connectedï¼‰ç”¨æ¥åŸºäºŽæ•´å¹…å›¾ç‰‡çš„å®Œæ•´ç‰©ä½“æ£€æµ‹ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šSSD]]></title>
    <url>%2Fposts%2F3118967289%2F</url>
    <content type="text"><![CDATA[çŸ¥è¯†ç‚¹ Jaccard overlap, Jaccard similarity:Jaccard coefficient: J(A,B)=\frac{|A\cap B|}{|A\cup B|}A,Båˆ†åˆ«ä»£è¡¨ç¬¦åˆæŸç§æ¡ä»¶çš„é›†åˆï¼šä¸¤ä¸ªé›†åˆäº¤é›†çš„å¤§å°/ä¸¤ä¸ªé›†åˆå¹¶é›†çš„å¤§å°ï¼Œäº¤é›†=å¹¶é›†æ„å‘³ç€2ä¸ªé›†åˆå®Œå…¨é‡åˆã€‚æ‰€ä»¥Jaccard overlapå…¶å®žå°±æ˜¯IoUã€‚ Abstract SSD: åˆ©ç”¨å•ä¸ªæ·±åº¦ç¥žç»ç½‘ç»œçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•ã€‚å°†è¾¹ç•Œæ¡†çš„è¾“å‡ºç©ºé—´ç¦»æ•£åŒ–ä¸ºä¸€ç»„é»˜è®¤æ¡†ï¼Œåœ¨æ¯ä¸ªfeature mapä½ç½®ä¸Šæœ‰ç€ä¸åŒçš„å®½é«˜æ¯”å’Œå°ºåº¦ã€‚ åœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œç½‘ç»œé’ˆå¯¹æ¯ä¸ªé»˜è®¤æ¡†ä¸­çš„æ¯ä¸ªå­˜åœ¨çš„å¯¹è±¡ç±»åˆ«äº§ç”Ÿåˆ†æ•°ï¼Œå¹¶ä¸”å¯¹æ¡†çš„è¿›è¡Œè°ƒæ•´ä»¥æ›´å¥½åœ°åŒ¹é…å¯¹è±¡å½¢çŠ¶ã€‚ åœ¨å¤šå°ºåº¦å›¾åƒå¤„ç†æ–¹é¢ï¼Œç½‘ç»œç»„åˆæ¥è‡ªå…·æœ‰ä¸åŒåˆ†è¾¨çŽ‡çš„å¤šä¸ªfeature mapçš„é¢„æµ‹ï¼Œä»¥è‡ªç„¶åœ°å¤„ç†å„ç§å°ºå¯¸çš„å¯¹è±¡ã€‚ ç›¸æ¯”äºŽåŸºäºŽobject proposalçš„æ–¹æ³•ï¼ŒSSDæ˜¯ç®€å•åœ°ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿå®Œå…¨æ¶ˆé™¤proposal generationå’ŒåŽç»­çš„åƒç´ æˆ–è€…ç‰¹å¾é‡å†²é‡‡æ ·é˜¶æ®µï¼Œæ‰€æœ‰çš„è®¡ç®—éƒ½å°è£…åœ¨å•ç‹¬çš„ç½‘ç»œä¸­ã€‚ Introduction ç›®å‰çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿæ˜¯ä»¥ä¸‹æ–¹æ³•çš„å˜ä½“ï¼šå‡è®¾è¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰ï¼Œå¯¹æ¯ä¸ªæ¡†è¿›è¡Œåƒç´ æˆ–ç‰¹å¾é‡å–æ ·ï¼Œé‡‡ç”¨é«˜è´¨é‡åˆ†ç±»å™¨ã€‚ è¯„ä¼°é€Ÿåº¦æ–¹æ³•ï¼šSPF (seconds per frame). æå‡ºç¬¬ä¸€ä¸ªåŸºäºŽæ·±åº¦ç½‘ç»œçš„ä¸éœ€è¦ä¸ºBBè¿›è¡Œresample pixels or featuresçš„ç›®æ ‡æ£€æµ‹å™¨ï¼Œå¹¶èƒ½å¤ŸåŒæ ·è¾¾åˆ°é«˜å‡†ç¡®çŽ‡ã€‚ æœ¬è®ºæ–‡çš„è´¡çŒ®ï¼ˆå…·ä½“çœ‹è®ºæ–‡ï¼‰ï¼š å¼•å…¥äº†SSDã€‚ SSDçš„æ ¸å¿ƒã€‚ ä¸ºäº†å®žçŽ°é«˜æ£€æµ‹å‡†ç¡®çŽ‡ï¼Œå¼•å…¥äº†åœ¨ä¸åŒå°ºåº¦å’Œæ¨ªçºµæ¯”çš„feature mapsä¸Šè¿›è¡Œé¢„æµ‹ã€‚ End-to-end training ä»¥åŠé«˜å‡†ç¡®çŽ‡ï¼Œæœºè¯•åœ¨ä½Žåˆ†è¾¨çŽ‡å›¾ç‰‡ã€‚ åœ¨PASCAL VOCã€COCOå’ŒILSVRCä¸Šè¿›è¡Œè¯•éªŒï¼Œå…·æœ‰å¾ˆå¼ºçš„ç«žäº‰åŠ›ã€‚ The Single Shot Detector (SSD)Model åŸºäºŽå‰å‘å·ç§¯ç¥žç»ç½‘ç»œï¼Œäº§ç”Ÿå›ºå®šå°ºå¯¸çš„BBé›†ï¼Œä»¥åŠè¿™äº›BBä¸­å­˜åœ¨ç‰©ä½“çš„åˆ†æ•°ï¼Œä¹‹åŽè·Ÿéšè€…ä¸€ä¸ªéžæžå¤§å€¼æŠ‘åˆ¶æ­¥éª¤æ¥äº§ç”Ÿæœ€ç»ˆæ£€æµ‹ã€‚ ç½‘ç»œå‰é¢çš„å‡ å±‚æ˜¯åŸºäºŽæ ‡å‡†çš„ç”¨äºŽäº§ç”Ÿé«˜è´¨é‡å›¾åƒåˆ†ç±»çš„æž¶æž„ï¼Œæˆ‘ä»¬æˆä¸ºåŸºç¡€ç½‘ç»œã€‚æˆ‘ä»¬ç»™ç½‘ç»œç„¶åŽæ·»åŠ äº†è¾…åŠ©çš„ç»“æž„æ¥äº§ç”Ÿæ£€æµ‹ç»“æž„ã€‚è¾…åŠ©ç½‘ç»œå…·å¤‡ä»¥ä¸‹å…³é”®ç‰¹å¾ï¼š ç”¨äºŽæ£€æµ‹çš„å¤šå°ºå¯¸ç‰¹å¾å›¾ã€‚åœ¨åŸºç¡€ç½‘ç»œåŽé¢æ·»åŠ é¢å¤–å‡ ä¸ªå·ç§¯å±‚ï¼Œåœ¨å°ºå¯¸ä¸Šé€å±‚é€’å‡ï¼Œä»Žè€Œèƒ½å¤Ÿåœ¨ä¸åŒå°ºå¯¸ä¸Šæ£€æµ‹ã€‚ï¼ˆOverfeatå’ŒYOLOéƒ½åªæ˜¯åœ¨å•ç‹¬å°ºå¯¸çš„feature mapä¸Šè¿›è¡Œæ“ä½œã€‚ï¼‰ ç”¨æ¥é¢„æµ‹çš„å·ç§¯é¢„æµ‹å™¨ï¼ˆConvolutional predictorsï¼‰ã€‚ é»˜è®¤çš„boxeså’Œaspect ratiosã€‚æˆ‘ä»¬å°†ä¸€ç»„é»˜è®¤è¾¹ç•Œæ¡†ä¸Žæ¯ä¸ªfeature mapå•å…ƒå…³è”ï¼Œç”¨äºŽç½‘ç»œé¡¶éƒ¨çš„å¤šä¸ªç‰¹å¾æ˜ å°„ã€‚åœ¨æ¯ä¸ªfeature mapå•å…ƒæ ¼ä¸­ï¼Œæˆ‘ä»¬é¢„æµ‹ç›¸å¯¹äºŽå•å…ƒæ ¼ä¸­çš„é»˜è®¤æ¡†å½¢çŠ¶çš„åç§»ï¼Œä»¥åŠæŒ‡ç¤ºæ¯ä¸ªæ¡†ä¸­å­˜åœ¨ç±»å®žä¾‹çš„æ¯ç±»åˆ†æ•°ã€‚ï¼ˆæœ¬è®ºæ–‡ä¸­çš„default boxesç±»ä¼¼äºŽFaster R-CNNä¸­çš„anchor boxesï¼Œç„¶è€Œæˆ‘ä»¬å°†ä»–ç”¨äºŽä¸åŒåˆ†è¾¨çŽ‡çš„å‡ ä¸ªfeature mapsä¸­ï¼‰ Training è®­ç»ƒSSDå’Œè®­ç»ƒä½¿ç”¨region proposalsçš„å…¸åž‹æ£€æµ‹å™¨ä¹‹é—´çš„å…³é”®åŒºåˆ«æ˜¯ï¼šground truthä¿¡æ¯éœ€è¦åˆ†é…ç»™å›ºå®šçš„æ£€æµ‹å™¨è¾“å‡ºé›†åˆä¸­çš„ç‰¹å®šè¾“å‡ºã€‚ è®­ç»ƒæ¶‰åŠåˆ°ï¼š choosing the set of default boxes and scales for detectionã€‚ hard negative miningã€‚ data augmentation strategiesï¼ˆæ•°æ®å¢žåŠ ç­–ç•¥ï¼‰ã€‚ Matching strategyåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯¹äºŽæ¯ä¸€ä¸ªground truthï¼Œæˆ‘ä»¬éƒ½ä»Žé»˜è®¤æ¡†ä¸­é€‰æ‹©æ¯ä¸ªä¸åŒçš„ä½ç½®ã€aspect ratioã€scaleçš„bounding boxesã€‚é¦–å…ˆåŒ¹é…æœ€å¥½çš„jaccard overlapçš„default boxï¼ˆç±»ä¼¼äºŽMultiBoxï¼‰ï¼Œä½†ä¸ŽMultiBoxä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ç„¶åŽåŒ¹é…default boxä¸Žä»»ä½•ground truthï¼Œåªè¦jaccard overlapé«˜äºŽé˜ˆå€¼ï¼ˆ0.5ï¼‰ã€‚è¿™æ ·ç®€åŒ–äº†å­¦ä¹ é—®é¢˜ã€‚ Training objectiveæ•´ä½“çš„ä»£ä»·å‡½æ•°æ˜¯localization losså’Œconfidence lossä¹‹å’Œï¼š L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g)) Næ˜¯åŒ¹é…çš„default boxesçš„æ•°é‡ï¼ŒN=0æ—¶ï¼Œloss=0ã€‚ localization lossæ˜¯predicted boxå’Œground truth boxä¹‹é—´çš„Smooth L1 lossï¼ˆç±»ä¼¼äºŽFaster R-CNNï¼‰ã€‚æˆ‘ä»¬é¢„æµ‹default boxçš„ä¸­å¿ƒ$(cx,cy)$ï¼Œä»¥åŠå®½åº¦$(w)$å’Œé•¿åº¦$(h)$ã€‚ confidence lossæ˜¯å¤šä¸ªç±»confidence$(c)$ä¹‹é—´çš„softmax lossã€‚ æƒå€¼$\alpha$é€šè¿‡äº¤å‰éªŒè¯è®¾ä¸º1ã€‚ Choosing scales and aspect ratios for default boxes ä¸åŒäºŽå°†ç…§ç‰‡å¤„ç†ä¸ºä¸åŒå°ºå¯¸å†ç»“åˆç»“æžœçš„æ–¹æ³•ï¼Œæœ¬è®ºæ–‡é€šè¿‡åˆ©ç”¨å•ä¸ªç¥žç»ç½‘ç»œä¸­ä¸åŒå±‚çš„feature mapsï¼Œå¯ä»¥è¾¾åˆ°åŒæ ·çš„æ•ˆæžœï¼ŒåŒæ—¶å¯ä»¥åœ¨æ‰€æœ‰å°ºå¯¸ä¸­å…±äº«æƒå€¼ã€‚ åˆ©ç”¨è¾ƒä½Žå±‚çš„feature mapså¯ä»¥æé«˜semantic segmentationè´¨é‡ï¼Œåº”ä¸ºè¾ƒä½Žå±‚å¾€å¾€å¯ä»¥æ•æ‰åˆ°æ›´ç²¾ç»†çš„ç»†èŠ‚ã€‚ æˆ‘ä»¬åŒæ—¶ä½¿ç”¨è¾ƒä½Žå’Œè¾ƒé«˜å±‚çš„feature mapsæ¥è¿›è¡Œæ£€æµ‹ã€‚ ç½‘ç»œä¸­ä¸åŒå±‚çš„feature mapsæœ‰ç€ä¸åŒçš„æŽ¥å—åŸŸçš„å°ºå¯¸ã€‚ å‡è®¾æˆ‘ä»¬æƒ³è¦ä½¿ç”¨mä¸ªfeature mapsç”¨æ¥æ£€æµ‹ï¼Œåˆ™æ¯ä¸ªfeature mapçš„default boxesçš„scaleå¯ä»¥è¿™æ ·è®¡ç®—ï¼š é€šè¿‡ç»“åˆåœ¨è®¸å¤šfeature mapsä¸Šæ‰€æœ‰ä½ç½®ä¸Šçš„æ‰€æœ‰çš„æœ‰ç€ä¸åŒscaleå’Œaspect ratioçš„default boxesï¼Œæˆ‘ä»¬å¯ä»¥äº§ç”Ÿå¯¹ä¸åŒç‰©ä½“å¤§å°å’Œå½¢çŠ¶çš„å„ç§é¢„æµ‹ã€‚ å¦‚ä¸‹å›¾ä¸­ï¼Œç‹—åœ¨8x8çš„feature mapä¸­æ²¡æœ‰åŒ¹é…çš„default boxï¼Œå› æ­¤åœ¨è®­ç»ƒä¸­ä¼šè¢«ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œä½†æ˜¯åœ¨4x4çš„feature mapä¸­æœ‰ç€åŒ¹é…çš„feature mapã€‚ Hard negative mining é€šè¿‡åŒ¹é…é˜¶æ®µåŽï¼Œdefault boxesä¸­ä¼šäº§ç”Ÿå¤§é‡çš„negativesï¼Œå°¤å…¶æ˜¯å½“å¯èƒ½çš„default boxesæ•°é‡éžå¸¸å¤§æ—¶ã€‚è¿™å¯¼è‡´positiveå’Œnegativeæ—¶é—´ä¸¥é‡çš„ä¸å¹³è¡¡ã€‚ æˆ‘ä»¬å°†negative examplesçš„default boxesé€šè¿‡å…¶æœ€é«˜çš„confidence lossè¿›è¡ŒæŽ’åºï¼Œç„¶åŽé€‰æ‹©è¾ƒé«˜çš„å‡ ä¸ªï¼Œä½¿negative exampleså’Œpositive examplesä¹‹é—´çš„æ¯”ä¾‹ä¿æŒåœ¨3:1ä¹‹é—´ã€‚è¿™æ ·ä¼šæ›´å¿«çš„ä¼˜åŒ–å’Œæ›´ç¨³å®šçš„è®­ç»ƒã€‚ Experimental Results æ‰€æœ‰çš„å®žéªŒéƒ½æ˜¯åŸºäºŽVGG16ã€‚ å°†fc6å’Œfc7è½¬åŒ–ä¸ºå·ç§¯å±‚ï¼Œä»Žfc6å’Œfc7ä¸­å–æ ·å­å‚æ•°ã€‚ å°†pool5ä»Ž2x2-s2è½¬åŒ–ä¸º3x3-s1ã€‚ ä½¿ç”¨a trous algorithmæ¥å¡«è¡¥â€œholesâ€ã€‚ ç§»åŽ»äº†æ‰€æœ‰çš„dropoutå±‚å’Œfc8å±‚ã€‚ ç”¨SGDè¿›è¡Œå¾®è°ƒã€‚ å­¦ä¹ çŽ‡$10^{-3}$ï¼ŒåŠ¨é‡0.9ï¼Œweight decayæ˜¯0.0005ï¼Œbatch sizeæ˜¯32. PASCAL VOC2007 â€œxavierâ€ methodæ¥åˆå§‹åŒ–æ–°åŠ å…¥çš„å±‚çš„å‚æ•°ã€‚ é€šè¿‡detection analysis toolåˆ†æžåŽï¼Œæ˜¾ç¤ºSSDæœ‰ç€æ›´å°‘çš„localizationé”™è¯¯ï¼Œå› ä¸ºå…¶èƒ½å¤Ÿç›´æŽ¥åŽ»å­¦ä¹ regressç‰©ä½“çš„å½¢çŠ¶ï¼Œå¹¶åˆ†ç±»ï¼Œè€Œéžä½¿ç”¨ä¸¤ä¸ªäº’ç›¸è§£è€¦çš„æ­¥éª¤ã€‚ ç„¶è€Œï¼ŒSSDå¯¹äºŽç›¸ä¼¼çš„ç‰©ä½“ä¼šæœ‰æ›´å¤šçš„æ··æ·†ï¼Œç‰¹åˆ«æ˜¯animalsï¼Œä¸€éƒ¨åˆ†åŽŸå› ã€‚ SSDå¯¹bounding boxeså°ºå¯¸æ˜¯ååˆ†æ•æ„Ÿçš„ã€‚æå‡è¾“å…¥å°ºå¯¸å¯èƒ½ä¼šæå‡å°ç‰©ä½“æ£€æµ‹ï¼Œä½†ä¾æ—§æœ‰è®¸å¤šç©ºé—´æå‡ã€‚ Model analysis Data augmentationå¾ˆé‡è¦ã€‚ æ›´å¤šçš„default boxesçš„å½¢çŠ¶å¯èƒ½ä¼šæ›´å¥½ã€‚ Atrous is fasterï¼šå¦‚æžœä¸ä½¿ç”¨æ›´æ”¹åŽçš„VGG-16ï¼Œè™½ç„¶ç»“æžœä¸€æ ·ï¼Œä½†æ˜¯é€Ÿåº¦å›žé™ä½Ž20%ã€‚ ä¸åŒåˆ†è¾¨çŽ‡ä¸­å¤šä¸ªè¾“å‡ºå±‚ä¼šæ›´å¥½ã€‚SSDçš„ä¸»è¦è´¡çŒ®æ˜¯åœ¨ä¸åŒè¾“å‡ºå±‚ä¸Šä½¿ç”¨ä¸åŒå°ºåº¦çš„é»˜è®¤æ¡†ã€‚ PASCAL VOC2012 å’ŒPASCAL VOC2007ä¸€æ ·çš„å®žéªŒè®¾ç½®ã€‚ åœ¨2012 trainval+2007 trainval+2007 testä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨2012 testä¸Šè¿›è¡Œæµ‹è¯•ã€‚ COCO COCOä¸­çš„ç‰©ä½“æ¯”PASCAL VOCä¸­çš„ç‰©ä½“å°ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨æ‰€æœ‰å±‚ä¸Šä½¿ç”¨æ›´å°çš„default boxes Data Augmentation for Small Object Accuracy å¯¹SSDæ¥è¯´ï¼Œå¯¹å°ç‰©ä½“åˆ†ç±»çš„ä»»åŠ¡ç›¸å¯¹Faster R-CNNæ¥è¯´ä¼šæ›´éš¾ã€‚ Data augmentationå¯¹äºŽç‰¹é«˜æ€§èƒ½æ˜¯ååˆ†æ˜¾è‘—çš„ï¼Œå°¤å…¶æ˜¯å°æ•°æ®åŠã€‚ æ”¹è¿›SSDçš„å¦ä¸€ç§æ–¹æ³•æ˜¯è®¾è®¡æ›´å¥½çš„å¹³é“ºé»˜è®¤æ¡†ï¼ˆtiling of default boxesï¼‰ï¼Œä½¿å…¶ä½ç½®å’Œå°ºåº¦æ›´å¥½åœ°ä¸Žç‰¹å¾å›¾ä¸Šæ¯ä¸ªä½ç½®çš„æŽ¥æ”¶åœºå¯¹å‡†ã€‚ Inference time è€ƒè™‘åˆ°ä»Žæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„å¤§é‡æ¡†ï¼Œæœ‰å¿…è¦åœ¨æŽ¨ç†æœŸé—´æœ‰æ•ˆåœ°æ‰§è¡Œéžæœ€å¤§æŠ‘åˆ¶ï¼ˆnmsï¼‰ã€‚ é€šè¿‡ä½¿ç”¨0.01çš„é™åˆ¶é˜ˆå€¼ï¼Œæˆ‘ä»¬å¯ä»¥è¿‡æ»¤å¤§å¤šæ•°bounding boxesã€‚ ç„¶åŽæˆ‘ä»¬åº”ç”¨nmsï¼Œæ¯ä¸ªç±»åˆ«çš„jaccardé‡å 0.45ï¼Œå¹¶ä¿æŒæ¯ä¸ªå›¾åƒå‰200ä¸ªæ£€æµ‹ã€‚ 80%çš„å‰å‘ä¼ é€’æ—¶é—´è¢«èŠ±è´¹åœ¨äº†base networkï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªæ›´å¿«çš„base networkå¯ä»¥æé«˜é€Ÿåº¦ã€‚ Related Work æœ‰ä¸¤ç§å·²å»ºç«‹çš„ç”¨äºŽå›¾åƒä¸­çš„å¯¹è±¡æ£€æµ‹çš„æ–¹æ³•ç±»åˆ«ï¼Œä¸€ç§åŸºäºŽæ»‘åŠ¨çª—å£ï¼Œå¦ä¸€ç§åŸºäºŽregion proposal classificationã€‚ Conclusion æˆ‘ä»¬æ¨¡åž‹çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§æ˜¯ä½¿ç”¨å¤šå°ºåº¦å·ç§¯è¾¹ç•Œæ¡†è¾“å‡ºé™„åŠ åˆ°ç½‘ç»œé¡¶éƒ¨çš„å¤šä¸ªç‰¹å¾å›¾ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šYOLO9000]]></title>
    <url>%2Fposts%2F2102833929%2F</url>
    <content type="text"><![CDATA[Abstract YOLO9000: a state-of-the-art, real-time çš„ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œå¯ä»¥æ£€æµ‹è¶…è¿‡9000ç§çš„ç‰©ä½“åˆ†ç±»ã€‚ æœ¬è®ºæ–‡æå‡ºä¸¤ä¸ªæ¨¡åž‹ï¼ŒYOLOv2å’ŒYOLO9000ã€‚ YOLOv2ï¼š æ˜¯å¯¹YOLOæ”¹è¿›åŽçš„æå‡æ¨¡åž‹ã€‚ åˆ©ç”¨æ–°é¢–çš„ï¼Œå¤šå°ºåº¦è®­ç»ƒçš„æ–¹æ³•ï¼ŒYOLOv2æ¨¡åž‹å¯ä»¥åœ¨å¤šç§å°ºåº¦ä¸Šè¿è¡Œï¼Œåœ¨é€Ÿåº¦ä¸Žå‡†ç¡®æ€§ä¸Šæ›´å®¹æ˜“åŽ»trade offã€‚ YOLO9000ï¼š æ˜¯æå‡ºçš„ä¸€ç§è”åˆåœ¨æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡åž‹ï¼Œè¿™ç§è”åˆè®­ç»ƒçš„æ–¹æ³•ä½¿å¾—YOLO9000èƒ½å¤Ÿä¸ºæ²¡æœ‰æ ‡ç­¾çš„æ£€æµ‹æ•°æ®ç›®æ ‡ç±»é¢„æµ‹ã€‚ å¯ä»¥æ£€æµ‹è¶…è¿‡9000ä¸ªç±»ã€‚ Introduction ç›®å‰ï¼Œè®¸å¤šæ£€æµ‹æ–¹æ³•ä¾æ—§çº¦æŸåœ¨å¾ˆå°çš„ç‰©ä½“é›†ä¸Šã€‚ ç›®å‰ï¼Œç›®æ ‡æ£€æµ‹æ•°æ®é›†ç›¸æ¯”äºŽç”¨äºŽåˆ†ç±»å’Œæ ‡æ³¨çš„æ•°æ®é›†æ¥è¯´ï¼Œæ˜¯æœ‰é™åˆ¶çš„ã€‚ æœ€å¸¸è§çš„æ£€æµ‹æ•°æ®é›†åŒ…å«æ•°ååˆ°æ•°åä¸‡çš„å›¾åƒï¼Œå…·æœ‰å‡ ååˆ°å‡ ç™¾ä¸ªæ ‡ç­¾ï¼Œæ¯”å¦‚Pascalã€CoCoã€ImageNetã€‚ åˆ†ç±»æ•°æ®é›†å…·æœ‰æ•°ä»¥ç™¾ä¸‡è®¡çš„å›¾åƒï¼Œå…·æœ‰æ•°ä¸‡æˆ–æ•°åä¸‡ç§ç±»åˆ«ï¼Œå¦‚ImageNetã€‚ ç›®æ ‡æ£€æµ‹æ•°æ®é›†æ°¸è¿œä¸ä¼šè¾¾åˆ°å’Œåˆ†ç±»æ•°æ®é›†ä¸€æ ·çš„ç­‰çº§ã€‚ æœ¬è®ºæ–‡æå‡ºä¸€ç§æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†ç±»æ•°æ®é›†æ¥ä½œä¸ºæ£€æµ‹æ•°æ®é›†ï¼Œå°†ä¸¤ç§æˆªç„¶ä¸åŒçš„æ•°æ®é›†ç»“åˆã€‚ æœ¬è®ºæ–‡æå‡ºä¸€ä¸ªåœ¨ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè”åˆè®­ç»ƒçš„æ–¹æ³•ã€‚æ­¤æ–¹æ³•åˆ©ç”¨æ ‡è®°çš„æ£€æµ‹å›¾åƒå­¦ä¹ ç²¾ç¡®å®šä½å¯¹è±¡ï¼Œè€Œå®ƒä½¿ç”¨åˆ†ç±»å›¾åƒå¢žåŠ å…¶è¯æ±‡å’Œé²æ£’æ€§ã€‚ Better YOLOäº§ç”Ÿå¾ˆå¤šçš„å®šä½é”™è¯¯ã€‚è€Œä¸”YOLOç›¸æ¯”äºŽregion proposal-basedæ–¹æ³•æœ‰ç€ç›¸å¯¹è¾ƒä½Žçš„recallï¼ˆæŸ¥å…¨çŽ‡ï¼‰ã€‚æ‰€ä»¥ä¸»è¦ä»»åŠ¡æ˜¯åœ¨ä¿æŒåˆ†ç±»å‡†ç¡®çŽ‡çš„å‰æä¸‹ï¼Œæé«˜recallå’Œå‡å°‘å®šä½é”™è¯¯ã€‚ æˆ‘ä»¬ä»Žè¿‡åŽ»çš„å·¥ä½œä¸­èžåˆäº†æˆ‘ä»¬è‡ªå·±çš„å„ç§æ–°æƒ³æ³•ï¼Œä»¥æé«˜YOLOçš„æ€§èƒ½ã€‚ ç»“æžœçš„æ‘˜è¦å¯ä»¥åœ¨è¡¨ä¸­æ‰¾åˆ°ï¼š Batch Normalization å¾—åˆ°2%çš„mAPçš„æå‡ï¼Œä½¿ç”¨Batch Normalizationï¼Œæˆ‘ä»¬å¯ä»¥ä»Žæ¨¡åž‹ä¸­åˆ é™¤dropoutï¼Œè€Œä¸ä¼šå‡ºçŽ°è¿‡åº¦ç¼ºé™·ã€‚ High Resolution Classiï¬er å¯¹äºŽYOLOv2ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ImageNetå¯¹å…¨éƒ¨448Ã—448åˆ†è¾¨çŽ‡å›¾åƒä¸Šè¿›è¡Œ10epochsçš„å¾®è°ƒæ¥è°ƒæ•´åˆ†ç±»ç½‘ç»œã€‚ ç„¶åŽæˆ‘ä»¬åœ¨æ£€æµ‹æ—¶è°ƒæ•´resulting networkã€‚ è¿™ç§é«˜åˆ†è¾¨çŽ‡åˆ†ç±»ç½‘ç»œä½¿æˆ‘ä»¬å¢žåŠ äº†è¿‘4ï¼…çš„mAPã€‚ Convolutional With Anchor Boxes YOLOåˆ©ç”¨å·ç§¯ç‰¹å¾æå–å™¨æœ€é¡¶ç«¯çš„å…¨è¿žæŽ¥å±‚æ¥ç›´æŽ¥é¢„æµ‹BBçš„åæ ‡ã€‚è€ŒFaster R-CNNæ˜¯åˆ©ç”¨é¦–é€‰çš„priorsæ¥é¢„æµ‹BBã€‚ é¢„æµ‹BBçš„åç§»è€Œä¸æ˜¯åæ ‡å¯ä»¥ç®€åŒ–é—®é¢˜ï¼Œå¹¶ä½¿ç½‘ç»œæ›´å®¹æ˜“å­¦ä¹ ã€‚æœ¬è®ºæ–‡ä»ŽYOLOä¸­ç§»åŽ»äº†å…¨è¿žæŽ¥å±‚ï¼Œå¹¶ä¸”åˆ©ç”¨anchor boxæ¥é¢„æµ‹BBã€‚ æˆ‘ä»¬ç§»åŽ»äº†poolingå±‚ï¼Œä½¿å¾—ç½‘ç»œçš„å·ç§¯å±‚çš„è¾“å‡ºæœ‰æ›´é«˜çš„åƒç´ ã€‚ åŒæ—¶å°†ç½‘ç»œç¼©å‡åˆ°åœ¨416*416åƒç´ çš„å›¾ç‰‡ä¸Šæ“ä½œã€‚ æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºæˆ‘ä»¬æƒ³è¦ç‰¹å¾å›¾ä¸­å…·æœ‰å¥‡æ•°ä¸ªä½ç½®ï¼Œå› æ­¤å­˜åœ¨å•ä¸ªä¸­å¿ƒå•å…ƒã€‚ å½“æˆ‘ä»¬ç§»åŠ¨åˆ°anchor boxesæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå°†class predictionæœºåˆ¶ä¸Žç©ºé—´ä½ç½®è§£è€¦ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªanchor boxé¢„æµ‹çš„ç±»å’Œå¯¹è±¡ã€‚ åŒYOLOä¸€æ ·ï¼Œobjectness predictionä»ç„¶é¢„æµ‹ground truthå’Œæ‰€æå‡ºçš„æ¡†çš„IOUï¼Œå¹¶ä¸”class predictionsé¢„æµ‹è¯¥ç±»çš„æ¡ä»¶æ¦‚çŽ‡ï¼Œå‡å®šå­˜åœ¨å¯¹è±¡ã€‚(æ²¡å¤ªæ‡‚) Dimension Clusters å°†YOLOä¸Žanchor boxesç»“åˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œç¬¬ä¸€ä¸ªæ˜¯anchor boxçš„é•¿å®½æ˜¯è®¤ä¸ºé€‰å®šçš„ã€‚ æˆ‘ä»¬ä¸æ˜¯æ‰‹åŠ¨é€‰æ‹©å…ˆéªŒï¼ˆpriorsï¼‰ï¼Œè€Œæ˜¯åœ¨è®­ç»ƒé›†è¾¹ç•Œæ¡†ä¸Šè¿è¡Œk-meansèšç±»ï¼Œä»¥è‡ªåŠ¨æ‰¾åˆ°å¥½çš„å…ˆéªŒã€‚ æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯å¯¼è‡´è‰¯å¥½çš„IOUåˆ†æ•°çš„priorsï¼Œè¿™æ˜¯ç‹¬ç«‹äºŽç›’å­çš„å¤§å°ã€‚ å› æ­¤ï¼Œå¯¹äºŽæˆ‘ä»¬çš„distance metricï¼Œæˆ‘ä»¬ä½¿ç”¨ï¼š d(box, centroid) = 1-IOU(box,centroid) æˆ‘ä»¬é€‰æ‹©k = 5ä½œä¸ºæ¨¡åž‹å¤æ‚æ€§å’Œé«˜å¬å›žçŽ‡ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚è¿™æ ·éžå¸¸ä¸åŒäºŽç›¸æ¯”äºŽäººå·¥é€‰æ‹©çš„boxesã€‚æ›´å¤šçš„åˆé«˜åˆç˜¦çš„boxesã€‚ Direct location prediction å°†YOLOä¸Žanchor boxesç»“åˆæœ‰ä¸¤ä¸ªé—®é¢˜ï¼Œç¬¬äºŒä¸ªæ¨¡åž‹ä¸ç¨³å®šï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸè¿­ä»£ä¸­ã€‚ å¹¶éžé¢„æµ‹åç§»ï¼Œæˆ‘ä»¬éµå¾ªYOLOçš„æ–¹æ³•å¹¶é¢„æµ‹ç›¸å¯¹äºŽç½‘æ ¼å•å…ƒçš„ä½ç½®çš„ä½ç½®åæ ‡ã€‚ è¿™å°†ground truthé™åˆ¶åœ¨0å’Œ1ä¹‹é—´ã€‚æˆ‘ä»¬ä½¿ç”¨é€»è¾‘æ¿€æ´»æ¥çº¦æŸç½‘ç»œçš„é¢„æµ‹è½åœ¨è¯¥èŒƒå›´å†…ã€‚ ç½‘ç»œä¸ºæ¯ä¸€ä¸ªBBé¢„æµ‹5ä¸ªåæ ‡ï¼š$t_x, t_y, t_w, t_h, t_o$. ç»“åˆDimension Clusterså’ŒDirect location predictionï¼ŒYOLOæå‡5%çš„mAPã€‚ Fine-Grained Features ä¿®æ”¹åŽçš„YOLOåœ¨1313çš„feature mapä¸Šè¿›è¡Œæ£€æµ‹ã€‚ è™½ç„¶è¿™å¯¹äºŽå¤§å¯¹è±¡æ˜¯è¶³å¤Ÿçš„ï¼Œä½†æ˜¯å®ƒå¯ä»¥ä»Žç”¨äºŽå®šä½è¾ƒå°å¯¹è±¡çš„*ç»†ç²’åº¦ç‰¹å¾ä¸­å—ç›Šã€‚ æ·»åŠ ä¸€ä¸ªä¼ é€’å±‚ï¼Œå°†åˆ†è¾¨çŽ‡ä»Žå‰é¢çš„å±‚å˜ä¸ºä»Ž26 x 26åˆ†è¾¨çŽ‡ã€‚ Multi-Scale Training æˆ‘ä»¬å¸Œæœ›YOLOv2å¯ä»¥è¶³å¤Ÿé²é‚¦åœ¨ä¸åŒå°ºå¯¸çš„imagesä¸Šè¿›è¡Œè®­ç»ƒã€‚ å¹¶éžä½¿ç”¨å›ºå®šçš„è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œæˆ‘ä»¬åœ¨æ¯å‡ æ¬¡è¿­ä»£åŽæ”¹å˜ç½‘ç»œã€‚æ¯10batchesï¼Œæˆ‘ä»¬çš„ç½‘ç»œéšæœºé€‰æ‹©ä¸€ä¸ªæ–°çš„å›¾åƒå°ºå¯¸ã€‚ Faster å¤§å¤šæ•°æ£€æµ‹æ¡†æž¶ä¾èµ–VGG-16ä½œä¸ºåŸºæœ¬ç‰¹å¾æå–å™¨ã€‚VGG-16æ˜¯ä¸€ä¸ªå¼ºå¤§ã€å‡†ç¡®çš„åˆ†ç±»ç½‘ç»œï¼Œä½†æ˜¯ä¹Ÿå¾ˆå¤æ‚ã€‚ YOLOæ¡†æž¶ä½¿ç”¨çš„åŸºäºŽGooglenetæž¶æž„çš„ä¿®æ”¹åŽçš„ç½‘ç»œã€‚æ¯”VGG-16å¿«é€Ÿï¼Œä½†æ˜¯å‡†ç¡®æ€§æ¯”VGG-16ç¨å·®ã€‚ Darknet-19 ä¾›YOLOv2ä½¿ç”¨çš„æ–°çš„åˆ†ç±»æ¨¡åž‹ã€‚ æœ€ç»ˆæ¨¡åž‹å«åšdarknet-19ï¼Œæœ‰ç€19ä¸ªå·ç§¯å±‚å’Œ5ä¸ªmaxpoolingå±‚ã€‚ Darknet-19å¤„ç†æ¯å¼ å›¾ç‰‡åªéœ€è¦5.58 billionçš„æ“ä½œã€‚ Training for classification åœ¨æ ‡å‡†çš„ImageNet 1000ç±»çš„æ•°æ®é›†ä¸Šåˆ©ç”¨éšæœºæ¢¯åº¦ä¸‹é™è®­ç»ƒ160 epochsã€‚å¼€å§‹å­¦ä¹ çŽ‡ä¸º0.1ï¼Œpolynomial rate decay æ˜¯4ï¼Œweight decayæ˜¯0.0005ï¼ŒåŠ¨é‡æ˜¯0.9ã€‚ åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ‡å‡†çš„æ•°æ®å¢žåŠ æŠ€å·§ï¼ŒåŒ…æ‹¬éšæœºè£å‰ªï¼Œæ—‹è½¬ï¼Œä»¥åŠè‰²è°ƒï¼Œé¥±å’Œåº¦å’Œæ›å…‰åç§»ã€‚ åœ¨224x224åˆ†è¾¨çŽ‡çš„å›¾åƒä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åŽåœ¨448x448åˆ†è¾¨çŽ‡çš„å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒã€‚ Training for detection æˆ‘ä»¬é€šè¿‡åŽ»é™¤æœ€åŽçš„å·ç§¯å±‚æ¥ä¿®æ”¹è¿™ä¸ªç½‘ç»œï¼Œå¹¶ä¸”æ›¿ä»£åœ°å¢žåŠ å…·æœ‰1024ä¸ªæ»¤æ³¢å™¨çš„ä¸‰ä¸ª3Ã—3å·ç§¯å±‚ï¼Œæ¯ä¸ªè·Ÿéšç€å…·æœ‰æˆ‘ä»¬éœ€è¦æ£€æµ‹æ‰€éœ€çš„è¾“å‡ºæ•°é‡çš„æœ€åŽçš„1Ã—1å·ç§¯å±‚ã€‚ passthroughå±‚çš„æ·»åŠ ï¼šä½¿ç½‘ç»œèƒ½å¤Ÿä½¿ç”¨fine grain featureã€‚ Stronger æœ¬è®ºæ–‡æå‡ºä¸€ç§æœºåˆ¶ï¼Œç”¨æ¥å°†åˆ†ç±»å’Œæ£€æµ‹æ•°æ®ç»“åˆèµ·æ¥å†ä¸€èµ·è®­ç»ƒã€‚ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“çœ‹åˆ°ç”¨äºŽæ£€æµ‹çš„è¢«æ ‡æ³¨çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨åŸºäºŽYOLOv2çš„ä»£ä»·å‡½æ•°è¿›è¡Œåå‘ä¼ æ’­ã€‚ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“çœ‹åˆ°åˆ†ç±»å›¾ç‰‡ï¼Œæˆ‘ä»¬åªä»Žæ¡†æž¶ä¸­ç”¨æ¥åˆ†ç±»éƒ¨åˆ†æ¥ä¼ é€’æŸå¤±ã€‚ è¿™ç§æ–¹æ³•çš„challengeï¼š æ£€æµ‹æ•°æ®é›†ä¸­çš„æ ‡ç­¾æ˜¯å¤§åˆ†ç±»ï¼Œè€Œåˆ†ç±»æ•°æ®é›†çš„æ ‡ç­¾æ˜¯å°åˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰¾ä¸€ä¸ªæ–¹æ³•æ¥èžåˆè¿™äº›æ ‡ç­¾ã€‚ ç”¨æ¥åˆ†ç±»çš„è®¸å¤šæ–¹æ³•éƒ½æ˜¯ä½¿ç”¨softmaxå±‚æ¥è®¡ç®—æœ€åŽçš„æ¦‚çŽ‡åˆ†å¸ƒï¼Œä½¿ç”¨softmaxå±‚ä¼šå‡è®¾ç±»ä¹‹é—´æ˜¯äº’æ–¥çš„ï¼Œä½†æ˜¯å¦‚ä½•ç”¨æœ¬æ–¹æ³•èžåˆæ•°æ®é›†ï¼Œç±»ä¹‹é—´æœ¬èº«ä¸æ˜¯äº’æ–¥çš„ã€‚ æˆ‘ä»¬æ‰€ä»¥ä½¿ç”¨multi-labelæ¨¡åž‹æ¥ç»“åˆæ•°æ®é›†ï¼Œä¸å‡è®¾ç±»ä¹‹é—´äº’æ–¥ã€‚è¿™ç§æ–¹æ³•å¿½ç•¥äº†æˆ‘ä»¬å·²çŸ¥çš„æ•°æ®çš„ç»“æž„ã€‚ Hierarchical classification ImageNetæ ‡ç­¾æ˜¯ä»ŽWordNetä¸­å¾—æ¥ï¼Œä¸€ç§ç»“æž„åŒ–æ¦‚å¿µå’Œæ ‡ç­¾ä¹‹é—´å¦‚ä½•è”ç³»çš„è¯­è¨€æ•°æ®åº“ã€‚ WordNetæ˜¯è¿žæŽ¥å›¾ç»“æž„ï¼Œè€Œéžæ ‘ã€‚æˆ‘ä»¬ç›¸åå¹¶ä¸å®žç”¨æ•´ä¸ªå›¾ç»“æž„ï¼Œæˆ‘ä»¬å°†é—®é¢˜ç®€åŒ–æˆä»ŽImageNetçš„æ¦‚å¿µä¸­æž„å»ºæœ‰ç»“æž„çš„æ ‘ã€‚ WordTree Dataset combination with WordTree æˆ‘ä»¬å¯ä»¥ä½¿ç”¨WordTreeæ¥ä»‹ä¸ªæ•°æ®é›†ã€‚ å°†æ•°æ®é›†ä¸­åˆ†ç±»æ˜ å°„æˆæ ‘ä¸­çš„ä¸‹ä¹‰è¯ã€‚ ä¸¾ä¾‹ï¼šå°†ImageNetå’ŒCOCOæ•°æ®é›†ç»“åˆï¼š WordNetååˆ†å¤šæ ·åŒ–ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ç§æŠ€æœ¯åˆ°å¤§å¤šæ•°æ•°æ®é›†ã€‚ Joint classiï¬cation and detection å°†COCOæ•°æ®é›†å’ŒImageNetæ•°æ®é›†ç»“åˆï¼Œè®­ç»ƒå¤„ä¸€ä¸ªç‰¹åˆ«å¤§è§„æ¨¡çš„æ£€æµ‹å™¨ã€‚ å¯¹åº”çš„WordTreeæœ‰9418ä¸ªç±»ã€‚ ImageNetæ˜¯ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡å¯¹COCOè¿›è¡Œè¿‡é‡‡æ ·æ¥å¹³è¡¡æ•°æ®é›†ï¼Œä½¿ImageNetåªä»¥4ï¼š1çš„å€æ•°æ¥å¢žå¤§ã€‚ å½“æˆ‘ä»¬çš„ç½‘ç»œçœ‹è§ä¸€å¼ ç”¨æ¥æ£€æµ‹çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬æ­£å¸¸åå‘ä¼ æ’­lossã€‚å¯¹äºŽåˆ†ç±»lossï¼Œæˆ‘ä»¬åªåœ¨è¯¥labelå¯¹åº”å±‚æ¬¡ä¹‹ä¸Šåå‘ä¼ æ’­lossã€‚æ¯”å¦‚ï¼šå¦‚æžœæ ‡ç­¾æ˜¯â€œdogâ€ï¼Œæˆ‘ä»¬ä¼šåœ¨æ ‘ä¸­çš„â€œGerman Shepherdâ€å’Œâ€œGolden Retrieverâ€ä¸­è¿›ä¸€æ­¥é¢„æµ‹é”™è¯¯ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰è¿™äº›ä¿¡æ¯ã€‚ å½“æˆ‘ä»¬çš„ç½‘ç»œçœ‹è§ä¸€å¼ ç”¨æ¥åˆ†æ¥çš„ç…§ç‰‡ï¼Œæˆ‘ä»¬åªåå‘ä¼ é€’åˆ†ç±»lossã€‚ ä½¿ç”¨è¿™ç§è”åˆè®­ç»ƒï¼ŒYOLO 9000ä½¿ç”¨COCOä¸­çš„æ£€æµ‹æ•°æ®å­¦ä¹ æ‰¾åˆ°å›¾åƒä¸­çš„å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨ImageNetä¸­çš„æ•°æ®å­¦ä¹ åˆ†ç±»å„ç§å„æ ·çš„å¯¹è±¡ã€‚ åœ¨ImageNetä¸Šåˆ©ç”¨YOLO9000æ¥åšdetectionï¼Œä»Žè€Œè¿›è¡Œè¯„ä¼°ã€‚ImageNetå’ŒCOCOåªæœ‰44ä¸ªç›¸åŒçš„ç±»åˆ†ç±»ï¼Œæ„å‘³ç€YOLO9000åœ¨åˆ©ç”¨éƒ¨åˆ†ç›‘ç£æ¥è¿›è¡Œæ£€æµ‹ã€‚ Conclusion æœ¬è®ºæ–‡æå‡ºä¸¤ä¸ªæ¨¡åž‹ï¼ŒYOLOv2å’ŒYOLO9000ã€‚ YOLOv2ï¼šæ˜¯å¯¹YOLOæ”¹è¿›åŽçš„æå‡æ¨¡åž‹ã€‚æ›´å¿«æ›´å…ˆè¿›ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥ä»¥å„ç§å›¾åƒå¤§å°è¿è¡Œï¼Œä»¥æä¾›é€Ÿåº¦å’Œç²¾åº¦ä¹‹é—´çš„æƒè¡¡ã€‚ YOLO9000ï¼šæ˜¯æå‡ºçš„ä¸€ç§è”åˆåœ¨æ£€æµ‹å’Œåˆ†ç±»æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡åž‹ï¼Œå¯ä»¥ä¸ºæ²¡æœ‰ä»»ä½•æ ‡æ³¨æ£€æµ‹æ ‡ç­¾çš„æ•°æ®è¿›è¡Œæ£€æµ‹ã€‚å¯ä»¥æ£€æµ‹è¶…è¿‡9000ä¸ªç±»ã€‚ä½¿ç”¨WordTreeæŠ€æœ¯æ¥ç»„åˆä¸åŒæ¥æºçš„æ•°æ®ã€‚ æˆ‘ä»¬åˆ›é€ å‡ºè®¸å¤šç›®æ ‡æ£€æµ‹ä¹‹å¤–çš„æŠ€æœ¯ï¼š WordTree representation. Dataset combination. Multi-scale training. ä¸‹ä¸€æ­¥å·¥ä½œï¼šæˆ‘ä»¬å¸Œæœ›åˆ©ç”¨ç›¸ä¼¼çš„æŠ€æœ¯æ¥è¿›è¡Œweakly supervised image segmentation.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šYOLO]]></title>
    <url>%2Fposts%2F2094641206%2F</url>
    <content type="text"><![CDATA[Abstract ä¹‹å‰çš„ç‰©ä½“æ£€æµ‹çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆ†ç±»å™¨æ¥è¿›è¡Œæ£€æµ‹ã€‚ ç›¸åï¼Œæœ¬è®ºæ–‡å°†å¯¹è±¡æ£€æµ‹ä½œä¸ºç©ºé—´åˆ†ç¦»çš„è¾¹ç•Œæ¡†å’Œç›¸å…³ç±»æ¦‚çŽ‡çš„å›žå½’é—®é¢˜ã€‚ æœ¬è®ºæ–‡çš„YOLOæ¨¡åž‹èƒ½è¾¾åˆ°45fpsçš„å®žæ—¶å›¾åƒå¤„ç†æ•ˆæžœã€‚ Fast YOLOï¼šå°åž‹çš„ç½‘ç»œç‰ˆæœ¬ï¼Œå¯è¾¾åˆ°155fpsã€‚ ä¸Žç›®å‰çš„æ£€æµ‹ç³»ç»Ÿç›¸æ¯”ï¼ŒYOLOä¼šäº§ç”Ÿæ›´å¤šçš„å®šä½é”™è¯¯ï¼Œä½†æ˜¯ä¼šæ›´å°‘çš„åŽ»åœ¨èƒŒæ™¯ä¸­äº§ç”Ÿfalse positiveã€‚ Introduction DPM: use a sliding window approach where the classiï¬er is run at evenly spaced locations over the entire image. R-CNN: use region proposal methods to ï¬rst generate potential bounding boxes in an image and then run a classiï¬er on these proposed boxes. å…·æœ‰slowå’Œhard to optimizeçš„ç¼ºç‚¹ã€‚ æœ¬è®ºæ–‡å°†ç›®æ ‡æ£€æµ‹é—®é¢˜é‡æ–°ç»„ç»‡æˆsingle regression problem. ä»Žå›¾åƒåƒç´ è½¬ä¸ºbounding box coordinateså’Œclass probabilities. YOLOæ¡†æž¶ï¼š A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance. YOLOæ¨¡åž‹çš„ä¼˜åŠ¿ï¼š First, YOLO is extremely fast. regression problem. no batch processing on a Titan X. Second, YOLO reasons globally about the image when making predictions. YOLO makes less than half the number of background errors compared to Fast R-CNN. Third, YOLO learns generalizable representations of objects. YOLOåœ¨å‡†ç¡®æ€§æ–¹é¢ä¾æ—§è½åŽä¸Žå…¶ä»–å…ˆè¿›çš„æ£€æµ‹ç³»ç»Ÿï¼Œä½†æ˜¯å¯ä»¥å¿«é€Ÿçš„æ ‡æ³¨å›¾ç‰‡ä¸­çš„ç‰©ä½“ï¼Œç‰¹åˆ«æ˜¯å°ç‰©ä½“ã€‚ Unified Detection æœ¬è®ºæ–‡å°†ç‰©ä½“æ£€æµ‹ä¸­å•ç‹¬çš„ç»„ä»¶ç»Ÿä¸€åˆ°ä¸€ä¸ªå•ä¸€çš„ç¥žç»ç½‘ç»œä¸­ã€‚ç½‘ç»œåˆ©ç”¨æ•´ä¸ªå›¾åƒçš„å„ä¸ªç‰¹å¾æ¥é¢„æµ‹æ¯ä¸€ä¸ªBBã€‚è€Œä¸”åŒæ—¶ä¸ºä¸€å¼ å›¾ç‰‡ä¸­æ‰€æœ‰çš„ç±»é¢„æµ‹æ‰€ç”¨çš„BBã€‚ YOLOå¯ä»¥end-to-endæ¥è®­ç»ƒï¼Œè€Œä¸”èƒ½åœ¨ä¿æŒé«˜å¹³å‡å‡†ç¡®çŽ‡çš„åŒæ—¶è¾¾åˆ°å®žæ—¶è¦æ±‚ã€‚ ç³»ç»Ÿå°†è¾“å…¥å›¾ç‰‡åˆ†ä¸º$S*S$çš„ç½‘æ ¼å•å…ƒã€‚å¦‚æžœç‰©ä½“çš„ä¸­å¿ƒè½å…¥æŸä¸ªæ ¼å­ï¼Œé‚£ä¹ˆè¿™ä¸ªæ ¼å­å°†ä¼šç”¨æ¥æ£€æµ‹è¿™ä¸ªç‰©ä½“ã€‚ æ¯ä¸ªç½‘æ ¼å•å…ƒä¼šé¢„æµ‹Bä¸ªbounding boxä»¥åŠè¿™äº›æ¡†çš„ç½®ä¿¡å€¼ã€‚ æ¯ä¸ªbounding boxä¼šæœ‰5ä¸ªé¢„æµ‹å€¼ï¼š$x,y,w,h$å’Œç½®ä¿¡å€¼confidenceï¼Œ$confidence = Pr(Object)*IOU^{truth}_{pred}$. æ¯ä¸ªç½‘æ ¼å•å…ƒä¹Ÿé¢„æµ‹Cä¸ªæ¡ä»¶ç±»æ¦‚çŽ‡ï¼Œ$Pr(Class_i|Object)$ï¼Œåœ¨ä¸€ä¸ªç½‘æ ¼å•å…ƒåŒ…å«ä¸€ä¸ªç‰©ä½“çš„å‰æä¸‹ï¼Œå®ƒå±žäºŽæŸä¸ªç±»çš„æ¦‚çŽ‡ã€‚æˆ‘ä»¬åªä¸ºæ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹ä¸€ç»„ç±»æ¦‚çŽ‡ï¼Œè€Œä¸è€ƒè™‘æ¡†Bçš„æ•°é‡ã€‚ åœ¨æµ‹è¯•çš„æ—¶å€™ï¼Œé€šè¿‡å¦‚ä¸‹å…¬å¼æ¥ç»™å‡ºå¯¹æŸä¸€ä¸ªboxæ¥è¯´æŸä¸€ç±»çš„confidence scoreï¼š Pr(Class_{i}|Object)*Pr(Object)*IOU^{truth}_{pred}=Pr(Class_{i})*IOU^{truth}_{pred} Modelç¤ºä¾‹ï¼š æ¯ä¸ªgrid cellé¢„æµ‹Bä¸ªbounding boxesï¼Œæ¯ä¸ªæ¡†çš„confidenceå’ŒCä¸ªç±»æ¦‚çŽ‡ã€‚ Network Design YOLOç½‘ç»œç»“æž„å›¾ï¼š èµ·åˆçš„å·ç§¯å±‚ç”¨æ¥ä»Žå›¾åƒä¸­æå–ç‰¹å¾ã€‚ å…¨è¿žæŽ¥å±‚ç”¨æ¥é¢„æµ‹è¾“å‡ºçš„æ¦‚çŽ‡å’Œåæ ‡ã€‚ 24ä¸ªå·ç§¯å±‚ï¼Œä¹‹åŽè·Ÿç€2ä¸ªå…¨è¿žæŽ¥å±‚ æœ€ç»ˆè¾“å‡ºæ˜¯7 x 7 x 30çš„å¼ é‡ã€‚ Fast YOLOå’ŒYOLOä¹‹é—´æ‰€æœ‰çš„è®­ç»ƒå’Œæµ‹è¯•å‚æ•°ä¸€æ ·ã€‚ åœ¨ImageNetä¸Šè¿›è¡Œå·ç§¯å±‚çš„é¢„è®­ç»ƒã€‚ Training åœ¨ImageNetä¸Šé¢„è®­ç»ƒå·ç§¯å±‚ã€‚é¢„è®­ç»ƒå‰20å±‚å·ç§¯å±‚ï¼Œä¹‹åŽè·Ÿéšè€…ä¸€ä¸ªaverage-pooling layerå’Œä¸€ä¸ªfully connected layer. å°†é¢„è®­ç»ƒçš„æ¨¡åž‹ç”¨æ¥æ£€æµ‹ï¼Œè®ºæ–‡Ren et al.æ˜¾ç¤ºç»™ä¸Žè®­ç»ƒå¥½çš„æ¨¡åž‹æ·»åŠ å·ç§¯å’Œè¿žæŽ¥å±‚èƒ½å¤Ÿæé«˜æ€§èƒ½ã€‚æ‰€ä»¥æ·»åŠ äº†é¢å¤–çš„4ä¸ªå·ç§¯å±‚å’Œ2ä¸ªå…¨è¿žæŽ¥å±‚ï¼Œå…¶æƒå€¼éšæœºåˆå§‹åŒ–ã€‚ å°†åƒç´ ä»Ž224x224æå‡åˆ°448x448ã€‚ æœ€åŽä¸€å±‚åŒæ—¶é¢„æµ‹class probabilitieså’Œbounding box coordinates. å…¶ä¸­æ¶‰åŠåˆ°BBçš„é•¿å®½è§„èŒƒåŒ–ã€‚ ç”±äºŽsum-squared errorçš„ç¼ºç‚¹ï¼Œå¢žåŠ è¾¹ç•Œæ¡†åæ ‡é¢„æµ‹çš„æŸå¤±ï¼Œå¹¶å‡å°‘å¯¹ä¸åŒ…å«å¯¹è±¡çš„æ¡†çš„ç½®ä¿¡åº¦é¢„æµ‹çš„æŸå¤±ã€‚ large boxesä¸­çš„åå·®matter less than ä¸Žsmall boxesä¸­çš„åå·®ã€‚ YOLOä¸ºæ¯ä¸€ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹å¤šä¸ªBBï¼Œä½†æ˜¯åœ¨æµ‹è¯•æœŸé—´ï¼Œæˆ‘ä»¬åªæƒ³æ¯ä¸€ä¸ªç‰©ä½“æœ‰ä¸€ä¸ªBBé¢„æµ‹æ¡†æ¥åšå“åº”ï¼Œæˆ‘ä»¬é€‰æ‹©å…·æœ‰æœ€é«˜IOUçš„BBæ¥ä½œä¸ºå“åº”æ¡†ã€‚ æ€»çš„loss function: 135 epochs batch sizeï¼š64 åŠ¨é‡ï¼š0.9 decayï¼š0.0005 ä¸ºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬ä½¿ç”¨dropoutå’Œextensive data augmentationæŠ€æœ¯ã€‚ Inference åœ¨æµ‹è¯•å›¾åƒä¸­é¢„æµ‹æ£€æµ‹åªéœ€è¦ä¸€ä¸ªç½‘ç»œè¯„ä¼°ï¼Œä¸Žä¸€èˆ¬çš„classifier-based methodsä¸åŒã€‚ Non-maximal suppressionå¯ä»¥ç”¨æ¥ä¿®å¤multiple detectionsã€‚ Comparison to Other Detection Systems æ£€æµ‹æµæ°´çº¿å¾€å¾€å¼€å§‹äºŽæå–å¥å£®ç‰¹å¾é›†ï¼ˆHaar, SIFT, HOG, convolutional featuresï¼‰,ç„¶åŽåˆ†ç±»å™¨æˆ–è€…å®šä½å™¨ç”¨æ¥è¯†åˆ«ç‰¹å¾ç©ºé—´çš„ç‰©ä½“ï¼Œè¿™äº›åˆ†ç±»å™¨æˆ–è€…å®šä½å™¨å¾€å¾€åœ¨æ•´ä¸ªå›¾åƒä¸Šæˆ–è€…åœ¨å›¾åƒçš„å­åŒºåŸŸä¸­æ»‘åŠ¨çª—å£ã€‚ ä¸ŽDPMçš„æ¯”è¾ƒã€‚ ä¸ŽR-CNNçš„æ¯”è¾ƒã€‚æ¯ä¸ªå›¾ç‰‡å€¼é¢„æµ‹98ä¸ªbounding boxesã€‚ ä¸Žå…¶ä»–å¿«é€Ÿæ£€æµ‹å™¨çš„æ¯”è¾ƒã€‚ç›¸æ¯”äºŽå•ç±»æ£€æµ‹å™¨ï¼ŒYOLOå¯ä»¥åŒæ—¶æ£€æµ‹å¤šç§ç‰©ä½“ã€‚ ä¸ŽDeep MultiBoxçš„æ¯”è¾ƒã€‚YOLOæ˜¯ä¸€ä¸ªå®Œæ•´çš„æ£€æµ‹ç³»ç»Ÿã€‚ ä¸ŽOverFeatçš„æ¯”è¾ƒã€‚OverFeatæ˜¯ä¸€ä¸ªdisjointçš„ç³»ç»Ÿï¼ŒOverFeatä¼˜åŒ–å®šä½ï¼Œè€Œéžæ£€æµ‹æ€§èƒ½ã€‚éœ€è¦å¤§é‡çš„åŽå¤„ç†ã€‚ ä¸ŽMultiGraspçš„æ¯”è¾ƒã€‚æ‰§è¡Œæ¯”ç›®æ ‡æ£€æµ‹æ›´ç®€å•çš„ä»»åŠ¡ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ å®žè·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒCaltechæ•°æ®é›†â€”â€”ä¿®æ”¹è¯»å†™æŽ¥å£]]></title>
    <url>%2Fposts%2F4113466123%2F</url>
    <content type="text"><![CDATA[å‰è¨€è¿™éƒ¨åˆ†ä¸»è¦è®²å¦‚ä½•ä¿®æ”¹Faster R-CNNçš„ä»£ç ï¼Œæ¥è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†ï¼Œé¦–å…ˆç¡®ä¿ä½ å·²ç»ç¼–è¯‘å®‰è£…äº†py-faster-rcnnï¼Œå¹¶ä¸”å‡†å¤‡å¥½äº†æ•°æ®é›†ï¼Œå…·ä½“å¯å‚è€ƒæˆ‘ä¸Šä¸€ç¯‡æ–‡ç« ã€‚ py-faster-rcnnæ–‡ä»¶ç»“æž„ caffe-fast-rcnnè¿™é‡Œæ˜¯caffeæ¡†æž¶ç›®å½•ï¼Œç”¨æ¥è¿›è¡Œcaffeç¼–è¯‘å®‰è£… dataç”¨æ¥å­˜æ”¾pre trainedæ¨¡åž‹ï¼Œæ¯”å¦‚ImageNetä¸Šçš„ï¼Œè¦è®­ç»ƒçš„æ•°æ®é›†ä»¥åŠè¯»å–æ–‡ä»¶çš„cacheç¼“å­˜ã€‚ experimentså­˜æ”¾é…ç½®æ–‡ä»¶ï¼Œè¿è¡Œçš„logæ–‡ä»¶ï¼Œå¦å¤–è¿™ä¸ªç›®å½•ä¸‹æœ‰scripts ç”¨æ¥èŽ·å–imagenetçš„æ¨¡åž‹ï¼Œä»¥åŠä½œè€…è®­ç»ƒå¥½çš„fast rcnnæ¨¡åž‹ï¼Œä»¥åŠç›¸åº”çš„pascal-vocæ•°æ®é›† libç”¨æ¥å­˜æ”¾ä¸€äº›pythonæŽ¥å£æ–‡ä»¶ï¼Œå¦‚å…¶ä¸‹çš„datasetsä¸»è¦è´Ÿè´£æ•°æ®åº“è¯»å–ï¼Œconfigè´Ÿè´£cnnä¸€äº›è®­ç»ƒçš„é…ç½®é€‰é¡¹ matlabæ”¾ç½®matlabä¸Žpythonçš„æŽ¥å£ï¼Œç”¨matlabæ¥è°ƒç”¨å®žçŽ°detection modelsé‡Œé¢å­˜æ”¾äº†ä¸‰ä¸ªæ¨¡åž‹æ–‡ä»¶ï¼Œå°åž‹ç½‘ç»œçš„ZFï¼Œå¤§åž‹ç½‘ç»œVGG16ï¼Œä¸­åž‹ç½‘ç»œVGG_CNN_M_1024 outputè¿™é‡Œå­˜æ”¾çš„æ˜¯è®­ç»ƒå®ŒæˆåŽçš„è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¼šåœ¨defaultæ–‡ä»¶å¤¹ä¸‹ toolsé‡Œé¢å­˜æ”¾çš„æ˜¯è®­ç»ƒå’Œæµ‹è¯•çš„Pythonæ–‡ä»¶ ä¿®æ”¹è®­ç»ƒä»£ç æ‰€è¦æ“ä½œæ–‡ä»¶ç»“æž„ä»‹ç»æ‰€æœ‰éœ€è¦ä¿®æ”¹çš„è®­ç»ƒä»£ç éƒ½æ”¾åˆ°äº†py-faster-rcnn/libæ–‡ä»¶å¤¹ä¸‹ï¼Œæˆ‘ä»¬è¿›å…¥æ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¸»è¦ç”¨åˆ°çš„æ–‡ä»¶å¤¹æœ‰ï¼š datasetsï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾è¯»å†™æ•°æ®æŽ¥å£ã€‚ fast-rcnnï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾çš„æ˜¯pythonçš„è®­ç»ƒå’Œæµ‹è¯•è„šæœ¬ï¼Œä»¥åŠè®­ç»ƒçš„é…ç½®æ–‡ä»¶ã€‚ roi_data_layerï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾ä¸€äº›ROIå¤„ç†æ“ä½œæ–‡ä»¶ã€‚ utilsï¼šè¯¥ç›®å½•ä¸‹ä¸»è¦å­˜æ”¾ä¸€äº›é€šç”¨æ“ä½œæ¯”å¦‚éžæžå¤§å€¼nmsï¼Œä»¥åŠè®¡ç®—bounding boxçš„é‡å çŽ‡ç­‰å¸¸ç”¨åŠŸèƒ½ã€‚ è¯»å†™æ•°æ®æŽ¥å£éƒ½æ”¾åœ¨datasets/æ–‡ä»¶å¤¹ä¸‹ï¼Œæˆ‘ä»¬è¿›å…¥æ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¸»è¦æ–‡ä»¶æœ‰ï¼š factory.pyï¼šè¿™æ˜¯ä¸ªå·¥åŽ‚ç±»ï¼Œç”¨ç±»ç”Ÿæˆimdbç±»å¹¶ä¸”è¿”å›žæ•°æ®åº“å…±ç½‘ç»œè®­ç»ƒå’Œæµ‹è¯•ä½¿ç”¨ã€‚ imdb.pyï¼šè¿™æ˜¯æ•°æ®åº“è¯»å†™ç±»çš„åŸºç±»ï¼Œåˆ†è£…äº†è®¸å¤šdbçš„æ“ä½œï¼Œä½†æ˜¯å…·ä½“çš„ä¸€äº›æ–‡ä»¶è¯»å†™éœ€è¦ç»§æ‰¿ç»§ç»­è¯»å†™ pascal_voc.pyï¼šè¿™æ˜¯imdbçš„å­ç±»ï¼Œé‡Œé¢å®šä¹‰è®¸å¤šå‡½æ•°ç”¨æ¥è¿›è¡Œæ‰€æœ‰çš„æ•°æ®è¯»å†™æ“ä½œã€‚ ä»Žä¸Šé¢å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬ä¸»è¦å¯¹pascal_voc.pyæ–‡ä»¶è¿›è¡Œä¿®æ”¹ã€‚ pascal_voc.pyæ–‡ä»¶ä»£ç åˆ†æžæˆ‘ä»¬ä¸»è¦æ˜¯åŸºäºŽpasca_voc.pyè¿™ä¸ªæ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œé‡Œé¢æœ‰å‡ ä¸ªé‡è¦çš„å‡½æ•°éœ€è¦ä»‹ç»ï¼š 123456789101112131415161718192021def __init__(self, image_set, devkit_path=None): # è¿™ä¸ªæ˜¯åˆå§‹åŒ–å‡½æ•°ï¼Œå®ƒå¯¹åº”ç€çš„æ˜¯pascal_vocçš„æ•°æ®é›†è®¿é—®æ ¼å¼ã€‚ def image_path_at(self, i): # æ ¹æ®ç¬¬iä¸ªå›¾åƒæ ·æœ¬è¿”å›žå…¶å¯¹åº”çš„pathï¼Œå…¶è°ƒç”¨image_path_from_index(self, index):ä½œä¸ºå…¶å…·ä½“å®žçŽ°ã€‚ def image_path_from_index(self, index): # å®žçŽ°äº† image_pathçš„å…·ä½“åŠŸèƒ½def _load_image_set_index(self): # åŠ è½½äº†æ ·æœ¬çš„listæ–‡ä»¶ï¼Œæ ¹æ®ImageSet/Main/æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶è¿›è¡Œimage_indexçš„åŠ è½½ã€‚ def _get_default_path(self): # èŽ·å¾—æ•°æ®é›†åœ°å€def gt_roidb(self): # è¯»å–å¹¶è¿”å›žground_truthçš„db def rpn_roidb(self): # åŠ è½½rpnäº§ç”Ÿçš„roiï¼Œè°ƒç”¨_load_rpn_roidb(self, gt_roidb):å‡½æ•°ä½œä¸ºå…¶å…·ä½“å®žçŽ° def _load_rpn_roidb(self, gt_roidb): # åŠ è½½rpn_file def _load_pascal_annotation(self, index): # è¿™ä¸ªå‡½æ•°æ˜¯è¯»å–gtçš„å…·ä½“å®žçŽ° def _write_voc_results_file(self, all_boxes): # å°†vocçš„æ£€æµ‹ç»“æžœå†™å…¥åˆ°æ–‡ä»¶ def _do_python_eval(self, output_dir = 'output'): # æ ¹æ®pythonçš„evluationæŽ¥å£æ¥åšç»“æžœçš„åˆ†æž ä¿®æ”¹pascal_voc.pyæ–‡ä»¶è¦æƒ³å¯¹è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œè¯»å–ï¼Œæˆ‘ä»¬ä¸»è¦æ˜¯è¿›è¡Œpascal_voc.pyæ–‡ä»¶çš„ä¿®æ”¹ï¼Œä½†æ˜¯ä¸ºäº†ä¸ç ´åæºæ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†pascal_voc.pyè¿›è¡Œæ‹·è´å¤åˆ¶ï¼Œä»Žè€Œè¿›è¡Œä¿®æ”¹ã€‚è¿™é‡Œæˆ‘å°†pascal_voc.pyæ–‡ä»¶æ‹·è´æˆcaltech.pyæ–‡ä»¶ï¼š 1cp pascal_voc.py caltech.py ä¸‹é¢æˆ‘ä»¬å¯¹caltech.pyæ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œåœ¨è¿™é‡Œæˆ‘ä¼šä¸€ä¸€åˆ—ä¸¾æ¯ä¸ªæˆ‘ä¿®æ”¹è¿‡çš„å‡½æ•°ã€‚è¿™é‡ŒæŒ‰ç…§æ–‡ä»¶ä¸­çš„é¡ºåºæŽ’åˆ—ã€‚ã€‚ initå‡½æ•°ä¿®æ”¹è¿™é‡Œæ˜¯åŽŸå§‹çš„pascal_vocçš„initå‡½æ•°ï¼Œåœ¨è¿™é‡Œï¼Œç”±äºŽæˆ‘ä»¬è‡ªå·±çš„æ•°æ®é›†å¾€å¾€æ¯”vocçš„æ•°æ®é›†è¦æ›´ç®€å•çš„ä¸€äº›ï¼Œåœ¨ä½œè€…é¢ä»£ç é‡Œé¢ç”¨äº†å¾ˆå¤šçš„è·¯å¾„æ‹¼æŽ¥ï¼Œæˆ‘ä»¬ä¸ç”¨åŽ»è¿Žåˆä»–çš„æ ¼å¼ï¼Œå°†è¿™äº›æ“ä½œç®€å•åŒ–å³å¯ã€‚ åŽŸå§‹çš„å‡½æ•°123456789101112131415161718192021222324252627282930313233def __init__(self, image_set, year, devkit_path=None): imdb.__init__(self, 'voc_' + year + '_' + image_set) self._year = year self._image_set = image_set self._devkit_path = self._get_default_path() if devkit_path is None \ else devkit_path self._data_path = os.path.join(self._devkit_path, 'VOC' + self._year) self._classes = ('__background__', # always index 0 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor') self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes))) self._image_ext = '.jpg' self._image_index = self._load_image_set_index() # Default to roidb handler self._roidb_handler = self.selective_search_roidb self._salt = str(uuid.uuid4()) self._comp_id = 'comp4' # PASCAL specific config options self.config = &#123;'cleanup' : True, 'use_salt' : True, 'use_diff' : False, 'matlab_eval' : False, 'rpn_file' : None, 'min_size' : 2&#125; assert os.path.exists(self._devkit_path), \ 'VOCdevkit path does not exist: &#123;&#125;'.format(self._devkit_path) assert os.path.exists(self._data_path), \ 'Path does not exist: &#123;&#125;'.format(self._data_path) ä¿®æ”¹åŽçš„å‡½æ•°123456789101112131415161718192021222324252627def __init__(self, image_set, devkit_path=None):# initial functionï¼ŒæŠŠyearåˆ é™¤ imdb.__init__(self, image_set) # imageset is train.txt or test.txt self._image_set = image_set self._devkit_path = devkit_path # devkit_path = '~/py-faster-rcnn/data/VOCdevkit' self._data_path = os.path.join(self._devkit_path, 'Caltech') # _data_path = '~/py-faster-rcnn/data/VOCdevkit/Caltech' self._classes = ('__background__', # always index 0 'person') # æˆ‘åªæœ‰â€˜backgroundâ€™å’Œâ€˜personâ€™ä¸¤ç±» self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes))) self._image_ext = '.jpg' self._image_index = self._load_image_set_index() # Default to roidb handler self._roidb_handler = self.selective_search_roidb self._salt = str(uuid.uuid4()) self._comp_id = 'comp4' # PASCAL specific config options self.config = &#123;'cleanup' : True, 'use_salt' : True, 'use_diff' : True, # æˆ‘æŠŠuse_diffæ”¹ä¸ºtrueäº†ï¼Œå› ä¸ºæˆ‘çš„æ•°æ®é›†xmlæ–‡ä»¶ä¸­æ²¡æœ‰&lt;difficult&gt;æ ‡ç­¾ï¼Œå¦åˆ™ä¹‹åŽè®­ç»ƒä¼šæŠ¥é”™ 'matlab_eval' : False, 'rpn_file' : None, 'min_size' : 2&#125; assert os.path.exists(self._devkit_path), \ 'VOCdevkit path does not exist: &#123;&#125;'.format(self._devkit_path) assert os.path.exists(self._data_path), \ 'Path does not exist: &#123;&#125;'.format(self._data_path) _load_image_set_indexå‡½æ•°ä¿®æ”¹åŽŸå§‹çš„å‡½æ•°12345678910111213def _load_image_set_index(self): """ Load the indexes listed in this dataset's image set file. """ # Example path to image set file: # self._devkit_path + /VOCdevkit2007/VOC2007/ImageSets/Main/val.txt image_set_file = os.path.join(self._data_path, 'ImageSets', 'Main', self._image_set + '.txt') assert os.path.exists(image_set_file), \ 'Path does not exist: &#123;&#125;'.format(image_set_file) with open(image_set_file) as f: image_index = [x.strip() for x in f.readlines()] return image_index ä¿®æ”¹åŽçš„å‡½æ•°1234567891011121314def _load_image_set_index(self): """ Load the indexes listed in this dataset's image set file. """ # Example path to image set file: # self._devkit_path + /VOCdevkit2007/VOC2007/ImageSets/Main/val.txt # /home/jk/py-faster-rcnn/data/VOCdevkit/Caltech/ImageSets/Main/train.txt image_set_file = os.path.join(self._data_path, 'ImageSets', 'Main', self._image_set + '.txt') assert os.path.exists(image_set_file), \ 'Path does not exist: &#123;&#125;'.format(image_set_file) with open(image_set_file) as f: image_index = [x.strip() for x in f.readlines()] return image_index å…¶å®žæ²¡æ”¹ï¼Œåªæ˜¯åŠ äº†ä¸€è¡Œæ³¨é‡Šï¼Œä»Žè€Œæ›´å¥½ç†è§£è·¯å¾„é—®é¢˜ã€‚ _get_default_pathå‡½æ•°ä¿®æ”¹ç›´æŽ¥æ³¨é‡Šå³å¯ _load_pascal_annotationå‡½æ•°ä¿®æ”¹åŽŸå§‹çš„å‡½æ•°123456789101112131415161718192021222324252627282930313233343536373839404142434445def _load_pascal_annotation(self, index): """ Load image and bounding boxes info from XML file in the PASCAL VOC format. """ filename = os.path.join(self._data_path, 'Annotations', index + '.xml') tree = ET.parse(filename) objs = tree.findall('object') if not self.config['use_diff']: # Exclude the samples labeled as difficult non_diff_objs = [ obj for obj in objs if int(obj.find('difficult').text) == 0] # if len(non_diff_objs) != len(objs): # print 'Removed &#123;&#125; difficult objects'.format( # len(objs) - len(non_diff_objs)) objs = non_diff_objs num_objs = len(objs) boxes = np.zeros((num_objs, 4), dtype=np.uint16) gt_classes = np.zeros((num_objs), dtype=np.int32) overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32) # "Seg" area for pascal is just the box area seg_areas = np.zeros((num_objs), dtype=np.float32) # Load object bounding boxes into a data frame. for ix, obj in enumerate(objs): bbox = obj.find('bndbox') # Make pixel indexes 0-based x1 = float(bbox.find('xmin').text) - 1 y1 = float(bbox.find('ymin').text) - 1 x2 = float(bbox.find('xmax').text) - 1 y2 = float(bbox.find('ymax').text) - 1 cls = self._class_to_ind[obj.find('name').text.lower().strip()] boxes[ix, :] = [x1, y1, x2, y2] gt_classes[ix] = cls overlaps[ix, cls] = 1.0 seg_areas[ix] = (x2 - x1 + 1) * (y2 - y1 + 1) overlaps = scipy.sparse.csr_matrix(overlaps) return &#123;'boxes' : boxes, 'gt_classes': gt_classes, 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : seg_areas&#125; ä¿®æ”¹åŽçš„å‡½æ•°12345678910111213141516171819202122232425262728293031323334353637383940414243444546def _load_pascal_annotation(self, index): """ Load image and bounding boxes info from XML file in the PASCAL VOC format. """ filename = os.path.join(self._data_path, 'Annotations', index + '.xml') tree = ET.parse(filename) objs = tree.findall('object') if not self.config['use_diff']: # Exclude the samples labeled as difficult non_diff_objs = [ obj for obj in objs if int(obj.find('difficult').text) == 0] # if len(non_diff_objs) != len(objs): # print 'Removed &#123;&#125; difficult objects'.format( # len(objs) - len(non_diff_objs)) objs = non_diff_objs num_objs = len(objs) boxes = np.zeros((num_objs, 4), dtype=np.uint16) gt_classes = np.zeros((num_objs), dtype=np.int32) overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32) # "Seg" area for pascal is just the box area seg_areas = np.zeros((num_objs), dtype=np.float32) # Load object bounding boxes into a data frame. for ix, obj in enumerate(objs): bbox = obj.find('bndbox') # Make pixel indexes 0-based # è¿™é‡Œæˆ‘æŠŠâ€˜-1â€™å…¨éƒ¨åˆ é™¤æŽ‰äº†ï¼Œé˜²æ­¢æœ‰çš„æ•°æ®æ˜¯0å¼€å§‹ï¼Œç„¶åŽâ€˜-1â€™å¯¼è‡´å˜ä¸ºè´Ÿæ•°ï¼Œäº§ç”ŸAssertErroré”™è¯¯ x1 = float(bbox.find('xmin').text) y1 = float(bbox.find('ymin').text) x2 = float(bbox.find('xmax').text) y2 = float(bbox.find('ymax').text) cls = self._class_to_ind[obj.find('name').text.lower().strip()] boxes[ix, :] = [x1, y1, x2, y2] gt_classes[ix] = cls overlaps[ix, cls] = 1.0 seg_areas[ix] = (x2 - x1 + 1) * (y2 - y1 + 1) overlaps = scipy.sparse.csr_matrix(overlaps) return &#123;'boxes' : boxes, 'gt_classes': gt_classes, 'gt_overlaps' : overlaps, 'flipped' : False, 'seg_areas' : seg_areas&#125; mainå‡½æ•°ä¿®æ”¹åŽŸå§‹çš„å‡½æ•° 12345if __name__ == '__main__': from datasets.pascal_voc import pascal_voc d = pascal_voc('trainval', '2007') res = d.roidb from IPython import embed; embed() ä¿®æ”¹åŽçš„å‡½æ•° 12345if __name__ == '__main__': from datasets.caltech import caltech # å¯¼å…¥caltechåŒ… d = caltech('train', '/home/jk/py-faster-rcnn/data/VOCdevkit')#è°ƒç”¨æž„é€ å‡½æ•°ï¼Œä¼ å…¥imagesetå’Œè·¯å¾„ res = d.roidb from IPython import embed; embed() è‡³æ­¤è¯»å–æŽ¥å£ä¿®æ”¹å®Œæ¯•ï¼Œè¯¥æ–‡ä»¶ä¸­çš„å…¶ä»–å‡½æ•°å¹¶æœªä¿®æ”¹ã€‚ ä¿®æ”¹factory.pyæ–‡ä»¶å½“ç½‘ç»œè®­ç»ƒæ—¶ä¼šè°ƒç”¨factoryé‡Œé¢çš„getæ–¹æ³•èŽ·å¾—ç›¸åº”çš„imdbï¼Œé¦–å…ˆåœ¨æ–‡ä»¶å¤´import æŠŠpascal_vocæ”¹æˆcaltech åœ¨è¿™ä¸ªæ–‡ä»¶ä½œè€…ç”Ÿæˆäº†å¤šä¸ªæ•°æ®åº“çš„è·¯å¾„ï¼Œæˆ‘ä»¬è‡ªå·±æ•°æ®åº“åªè¦ç»™å®šæ ¹è·¯å¾„å³å¯ï¼Œä¿®æ”¹ä¸»è¦æœ‰ä»¥ä¸‹4ä¸ª å‡½æ•°ä¹‹åŽæœ‰ä¸¤ä¸ªå¤šçº§çš„forå¾ªçŽ¯ï¼Œä¹Ÿå°†å…¶æ³¨é‡Š ç›´æŽ¥å®šä¹‰devkitã€‚ åˆ©ç”¨åˆ›å»ºè‡ªå·±çš„è®­ç»ƒå’Œæµ‹è¯•çš„imdb setï¼Œè¿™é‡Œçš„nameçš„æ ¼å¼ä¸ºcaltech_{}ã€‚ åŽŸå§‹çš„ä»£ç 123456789101112131415161718192021222324252627282930313233343536373839404142# --------------------------------------------------------# Fast R-CNN# Copyright (c) 2015 Microsoft# Licensed under The MIT License [see LICENSE for details]# Written by Ross Girshick# --------------------------------------------------------"""Factory method for easily getting imdbs by name."""__sets = &#123;&#125;from datasets.pascal_voc import pascal_vocfrom datasets.coco import cocoimport numpy as np# Set up voc_&lt;year&gt;_&lt;split&gt; using selective search "fast" modefor year in ['2007', '2012']: for split in ['train', 'val', 'trainval', 'test']: name = 'voc_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: pascal_voc(split, year))# Set up coco_2014_&lt;split&gt;for year in ['2014']: for split in ['train', 'val', 'minival', 'valminusminival']: name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: coco(split, year))# Set up coco_2015_&lt;split&gt;for year in ['2015']: for split in ['test', 'test-dev']: name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split) __sets[name] = (lambda split=split, year=year: coco(split, year))def get_imdb(name): """Get an imdb (image database) by name.""" if not __sets.has_key(name): raise KeyError('Unknown dataset: &#123;&#125;'.format(name)) return __sets[name]()def list_imdbs(): """List all registered imdbs.""" return __sets.keys() ä¿®æ”¹åŽçš„æ–‡ä»¶123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# --------------------------------------------------------# Fast R-CNN# Copyright (c) 2015 Microsoft# Licensed under The MIT License [see LICENSE for details]# Written by Ross Girshick# --------------------------------------------------------"""Factory method for easily getting imdbs by name."""__sets = &#123;&#125;from datasets.caltech import caltech # å¯¼å…¥caltechåŒ…#from datasets.coco import coco#import numpy as npdevkit = '/home/jk/py-faster-rcnn/data/VOCdevkit'# Set up voc_&lt;year&gt;_&lt;split&gt; using selective search "fast" mode#for year in ['2007', '2012']:# for split in ['train', 'val', 'trainval', 'test']:# name = 'voc_&#123;&#125;_&#123;&#125;'.format(year, split)# __sets[name] = (lambda split=split, year=year: pascal_voc(split, year))# Set up coco_2014_&lt;split&gt;#for year in ['2014']:# for split in ['train', 'val', 'minival', 'valminusminival']:# name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split)# __sets[name] = (lambda split=split, year=year: coco(split, year))# Set up coco_2015_&lt;split&gt;#for year in ['2015']:# for split in ['test', 'test-dev']:# name = 'coco_&#123;&#125;_&#123;&#125;'.format(year, split)# __sets[name] = (lambda split=split, year=year: coco(split, year))# Set up caltech_&lt;split&gt;for split in ['train', 'test']: name = 'caltech_&#123;&#125;'.format(split) __sets[name] = (lambda imageset=split, devkit=devkit: caltech(imageset, devkit))def get_imdb(name): """Get an imdb (image database) by name.""" if not __sets.has_key(name): raise KeyError('Unknown dataset: &#123;&#125;'.format(name)) return __sets[name]()def list_imdbs(): """List all registered imdbs.""" return __sets.keys() ä¿®æ”¹init.pyæ–‡ä»¶åœ¨è¡Œé¦–æ·»åŠ ä¸Š from .caltech import caltech æ€»ç»“ åæ ‡çš„é¡ºåºæˆ‘å†è¯´ä¸€æ¬¡ï¼Œè¦å·¦ä¸Šå³ä¸‹ï¼Œå¹¶ä¸”x1å¿…é¡»è¦å°äºŽx2ï¼Œè¿™ä¸ªæ˜¯åŸºæœ¬ï¼Œåäº†ä¼šåœ¨åæ ‡æ°´å¹³å˜æ¢çš„æ—¶å€™ä¼šå‡ºé”™ï¼Œåæ ‡ä»Ž0å¼€å§‹ï¼Œå¦‚æžœå·²ç»æ˜¯0ï¼Œåˆ™ä¸éœ€è¦å†-1ã€‚ è®­ç»ƒå›¾åƒçš„å¤§å°ä¸è¦å¤ªå¤§ï¼Œå¦åˆ™ç”Ÿæˆçš„OPä¹Ÿä¼šå¤ªå¤šï¼Œé€Ÿåº¦å¤ªæ…¢ï¼Œå›¾åƒæ ·æœ¬å¤§å°æœ€å¥½è°ƒæ•´åˆ°500ï¼Œ600å·¦å³ï¼Œç„¶åŽå†æå–OP å¦‚æžœè¯»å–å¹¶ç”Ÿæˆpklæ–‡ä»¶ä¹‹åŽï¼Œå®žé™…æ•°æ®å†…å®¹æˆ–è€…é¡ºåºè¿˜æœ‰é—®é¢˜ï¼Œè®°å¾—è¦æŠŠdata/cache/ä¸‹é¢çš„pklæ–‡ä»¶ç»™åˆ æŽ‰ã€‚ å‚è€ƒåšå®¢ Fast RCNNè®­ç»ƒè‡ªå·±çš„æ•°æ®é›† ï¼ˆ2ä¿®æ”¹è¯»å†™æŽ¥å£ï¼‰ Faster R-CNNæ•™ç¨‹]]></content>
      <categories>
        <category>ç»éªŒ</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ å®žè·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒCaltechæ•°æ®é›†â€”â€”è®­ç»ƒæ£€æµ‹]]></title>
    <url>%2Fposts%2F464905881%2F</url>
    <content type="text"><![CDATA[å‰è¨€å‰é¢å·²ç»ä»‹ç»äº†å¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä¿®æ”¹æ•°æ®é›†è¯»å†™æŽ¥å£æ¥æ“ä½œæ•°æ®é›†ï¼ŒæŽ¥ä¸‹æ¥æˆ‘æ¥è¯´æ˜Žä¸€ä¸‹æ€Žä¹ˆæ¥è®­ç»ƒç½‘ç»œå’Œä¹‹åŽçš„æ£€æµ‹è¿‡ç¨‹ã€‚ ä¿®æ”¹æ¨¡åž‹æ–‡ä»¶faster rcnnæœ‰ä¸¤ç§å„ç§è®­ç»ƒæ–¹å¼: Alternative training(alt-opt) Approximate joint training(end-to-end) ä¸¤ç§æ–¹æ³•æœ‰ä»€ä¹ˆä¸åŒï¼Œå¯ä»¥å‚è€ƒæˆ‘è¿™ç¯‡åšå®¢ï¼ŒæŽ¨èä½¿ç”¨ç¬¬äºŒç§ï¼Œå› ä¸ºç¬¬äºŒç§ä½¿ç”¨çš„æ˜¾å­˜æ›´å°ï¼Œè€Œä¸”è®­ç»ƒä¼šæ›´å¿«ï¼ŒåŒæ—¶å‡†ç¡®çŽ‡å·®ä¸å¤šï¼Œä¸¤ç§æ–¹å¼éœ€è¦ä¿®æ”¹çš„ä»£ç æ˜¯ä¸ä¸€æ ·çš„ï¼ŒåŒæ—¶faster rcnnæä¾›äº†ä¸‰ç§è®­ç»ƒæ¨¡åž‹ï¼Œå°åž‹çš„ZF modelï¼Œä¸­åž‹çš„VGG_CNN_M_1024å’Œå¤§åž‹çš„VGG16,è®ºæ–‡ä¸­è¯´VGG16æ•ˆæžœæ¯”å…¶ä»–ä¸¤ä¸ªå¥½ï¼Œä½†æ˜¯åŒæ—¶å ç”¨æ›´å¤§çš„GPUæ˜¾å­˜(~11GB) æˆ‘ä½¿ç”¨çš„æ˜¯VGG model + alternative trainingï¼Œéœ€è¦æ£€æµ‹çš„ç±»åˆ«åªæœ‰ä¸€ç±»ï¼ŒåŠ ä¸ŠèƒŒæ™¯æ‰€ä»¥æ€»å…±æ˜¯ä¸¤ç±»(background + person)ã€‚ ä¸‹é¢ä¿®æ”¹æ¨¡åž‹æ–‡ä»¶ï¼š py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage1_fast_rcnn_train.pt 123456789101112131415layer &#123; name: &apos;data&apos; type: &apos;Python&apos; top: &apos;data&apos; top: &apos;rois&apos; top: &apos;labels&apos; top: &apos;bbox_targets&apos; top: &apos;bbox_inside_weights&apos; top: &apos;bbox_outside_weights&apos; python_param &#123; module: &apos;roi_data_layer.layer&apos; layer: &apos;RoIDataLayer&apos; param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 &#125; &#125; 1234567891011121314151617181920212223layer &#123; name: &quot;cls_score&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;cls_score&quot; param &#123; lr_mult: 1.0 &#125; param &#123; lr_mult: 2.0 &#125; inner_product_param &#123; num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 weight_filler &#123; type: &quot;gaussian&quot; std: 0.01 &#125; bias_filler &#123; type: &quot;constant&quot; value: 0 &#125; &#125; &#125; 1234567891011121314151617181920212223layer &#123; name: &quot;bbox_pred&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;bbox_pred&quot; param &#123; lr_mult: 1.0 &#125; param &#123; lr_mult: 2.0 &#125; inner_product_param &#123; num_output: 8 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4ï¼Œå››ä¸ªé¡¶ç‚¹åæ ‡ weight_filler &#123; type: &quot;gaussian&quot; std: 0.001 &#125; bias_filler &#123; type: &quot;constant&quot; value: 0 &#125; &#125; &#125; py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage1_rpn_train.pt 123456789101112layer &#123; name: &apos;input-data&apos; type: &apos;Python&apos; top: &apos;data&apos; top: &apos;im_info&apos; top: &apos;gt_boxes&apos; python_param &#123; module: &apos;roi_data_layer.layer&apos; layer: &apos;RoIDataLayer&apos; param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 &#125; &#125; py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_train.pt 123456789101112131415layer &#123; name: &apos;data&apos; type: &apos;Python&apos; top: &apos;data&apos; top: &apos;rois&apos; top: &apos;labels&apos; top: &apos;bbox_targets&apos; top: &apos;bbox_inside_weights&apos; top: &apos;bbox_outside_weights&apos; python_param &#123; module: &apos;roi_data_layer.layer&apos; layer: &apos;RoIDataLayer&apos; param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 &#125; &#125; 1234567891011121314151617181920212223layer &#123; name: &quot;cls_score&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;cls_score&quot; param &#123; lr_mult: 1.0 &#125; param &#123; lr_mult: 2.0 &#125; inner_product_param &#123; num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 weight_filler &#123; type: &quot;gaussian&quot; std: 0.01 &#125; bias_filler &#123; type: &quot;constant&quot; value: 0 &#125; &#125; &#125; 1234567891011121314151617181920212223layer &#123; name: &quot;bbox_pred&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;bbox_pred&quot; param &#123; lr_mult: 1.0 &#125; param &#123; lr_mult: 2.0 &#125; inner_product_param &#123; num_output: 8 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4,å››ä¸ªé¡¶ç‚¹åæ ‡ weight_filler &#123; type: &quot;gaussian&quot; std: 0.001 &#125; bias_filler &#123; type: &quot;constant&quot; value: 0 &#125; &#125; &#125; py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage2_rpn_train.pt 123456789101112layer &#123; name: &apos;input-data&apos; type: &apos;Python&apos; top: &apos;data&apos; top: &apos;im_info&apos; top: &apos;gt_boxes&apos; python_param &#123; module: &apos;roi_data_layer.layer&apos; layer: &apos;RoIDataLayer&apos; param_str: &quot;&apos;num_classes&apos;: 2&quot; #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 &#125; &#125; py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt 12345678910111213141516171819layer &#123; name: &quot;cls_score&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;cls_score&quot; inner_product_param &#123; num_output: 2 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºç±»åˆ«æ•°+1 &#125; &#125; layer &#123; name: &quot;bbox_pred&quot; type: &quot;InnerProduct&quot; bottom: &quot;fc7&quot; top: &quot;bbox_pred&quot; inner_product_param &#123; num_output: 84 #æŒ‰è®­ç»ƒé›†ç±»åˆ«æ”¹ï¼Œè¯¥å€¼ä¸ºï¼ˆç±»åˆ«æ•°+1ï¼‰*4,å››ä¸ªé¡¶ç‚¹åæ ‡ &#125; &#125; è®­ç»ƒæµ‹è¯•è®­ç»ƒå‰è¿˜éœ€è¦æ³¨æ„å‡ ä¸ªåœ°æ–¹ï¼š cacheé—®é¢˜ï¼š å‡å¦‚ä½ ä¹‹å‰è®­ç»ƒäº†å®˜æ–¹çš„VOC2007çš„æ•°æ®é›†æˆ–å…¶ä»–çš„æ•°æ®é›†ï¼Œæ˜¯ä¼šäº§ç”Ÿcacheçš„é—®é¢˜çš„ï¼Œå»ºè®®åœ¨é‡æ–°è®­ç»ƒæ–°çš„æ•°æ®ä¹‹å‰å°†å…¶åˆ é™¤ã€‚ py-faster-rcnn/output py-faster-rcnn/data/cache è®­ç»ƒå‚æ•° å‚æ•°æ”¾åœ¨å¦‚ä¸‹æ–‡ä»¶: py-faster-rcnn/models/pascal_voc/VGG16/faster_rcnn_alt_opt/stage_fast_rcnn_solver*.pt 12345base_lr: 0.001lr_policy: &apos;step&apos;step_size: 30000display: 20.... è¿­ä»£æ¬¡æ•°åœ¨æ–‡ä»¶py-faster-rcnn/tools/train_faster_rcnn_alt_opt.pyä¸­è¿›è¡Œä¿®æ”¹: 1max_iters = [80000, 40000, 80000, 40000] åˆ†åˆ«å¯¹åº”rpnç¬¬1é˜¶æ®µï¼Œfast rcnnç¬¬1é˜¶æ®µï¼Œrpnç¬¬2é˜¶æ®µï¼Œfast rcnnç¬¬2é˜¶æ®µçš„è¿­ä»£æ¬¡æ•°ï¼Œè‡ªå·±ä¿®æ”¹å³å¯ï¼Œä¸è¿‡æ³¨æ„è¿™é‡Œçš„å€¼ä¸è¦å°äºŽä¸Šé¢çš„solveré‡Œé¢çš„step_sizeçš„å¤§å°ï¼Œå¤§å®¶è‡ªå·±ä¿®æ”¹å§ å¼€å§‹è®­ç»ƒé¦–å…ˆä¿®æ”¹experiments/scripts/faster_rcnn_alt_opt.shæˆå¦‚ä¸‹ï¼Œä¿®æ”¹åœ°æ–¹å·²æ ‡æ³¨ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bash# Usage:# ./experiments/scripts/faster_rcnn_alt_opt.sh GPU NET DATASET [options args to &#123;train,test&#125;_net.py]# DATASET is only pascal_voc for now## Example:# ./experiments/scripts/faster_rcnn_alt_opt.sh 0 VGG_CNN_M_1024 pascal_voc \# --set EXP_DIR foobar RNG_SEED 42 TRAIN.SCALES "[400, 500, 600, 700]"set -xset -eexport PYTHONUNBUFFERED="True"GPU_ID=$1NET=$2NET_lc=$&#123;NET,,&#125;DATASET=$3array=( $@ )len=$&#123;#array[@]&#125;EXTRA_ARGS=$&#123;array[@]:3:$len&#125;EXTRA_ARGS_SLUG=$&#123;EXTRA_ARGS// /_&#125;case $DATASET in caltech) # è¿™é‡Œå°†pascal_vocæ”¹ä¸ºcaltech TRAIN_IMDB="caltech_train" # æ”¹ä¸ºä¸Žfactor.pyä¸­å‘½åçš„nameæ ¼å¼ç›¸åŒï¼Œä¸ºcaltech_train TEST_IMDB="caltech_test" # æ”¹ä¸ºä¸Žfactor.pyä¸­å‘½åçš„nameæ ¼å¼ç›¸åŒï¼Œä¸ºcaltech_test PT_DIR="caltech" # è¿™é‡Œå°†pascal_vocæ”¹ä¸ºcaltech ITERS=40000 ;; coco) echo "Not implemented: use experiments/scripts/faster_rcnn_end2end.sh for coco" exit ;; *) echo "No dataset given" exit ;;esacLOG="experiments/logs/faster_rcnn_alt_opt_$&#123;NET&#125;_$&#123;EXTRA_ARGS_SLUG&#125;.txt.`date +'%Y-%m-%d_%H-%M-%S'`"exec &amp;&gt; &gt;(tee -a "$LOG")echo Logging output to "$LOG"time ./tools/train_faster_rcnn_alt_opt.py --gpu $&#123;GPU_ID&#125; \ --net_name $&#123;NET&#125; \ --weights data/imagenet_models/$&#123;NET&#125;.v2.caffemodel \ --imdb $&#123;TRAIN_IMDB&#125; \ --cfg experiments/cfgs/faster_rcnn_alt_opt.yml \ $&#123;EXTRA_ARGS&#125;set +xNET_FINAL=`grep "Final model:" $&#123;LOG&#125; | awk '&#123;print $3&#125;'`set -xtime ./tools/test_net.py --gpu $&#123;GPU_ID&#125; \ --def models/$&#123;PT_DIR&#125;/$&#123;NET&#125;/faster_rcnn_alt_opt/faster_rcnn_test.pt \ --net $&#123;NET_FINAL&#125; \ #--net output/faster_rcnn_alt_opt/train/ZF_faster_rcnn_final.caffemodel \ --imdb $&#123;TEST_IMDB&#125; \ --cfg experiments/cfgs/faster_rcnn_alt_opt.yml \ $&#123;EXTRA_ARGS&#125; è°ƒç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œè®­ç»ƒåŠæµ‹è¯•ï¼Œä»Žä¸Šé¢ä»£ç å¯ä»¥çœ‹å‡ºï¼Œè¯¥shellæ–‡ä»¶åœ¨è®­ç»ƒå®ŒåŽä¼šæŽ¥ç€è¿›è¡Œæµ‹è¯•ï¼Œä½†æ˜¯æˆ‘çš„æµ‹è¯•é›†æ²¡æœ‰æ ‡æ³¨ï¼Œæ‰€ä»¥æµ‹è¯•çš„æ—¶å€™ä¼šæŠ¥é”™ï¼Œä½†æ˜¯ç”±äºŽCaltechæ•°æ®é›†çš„æµ‹è¯•ç»“æžœæœ‰ä¸“é—¨çš„è¯„ä¼°ä»£ç ï¼Œæ‰€ä»¥æˆ‘ä¸ç”¨faster r-cnnæä¾›çš„ä»£ç è¿›è¡Œæµ‹è¯•ï¼Œè€Œæ˜¯ç›´æŽ¥è¿›è¡Œæ£€æµ‹ç”Ÿæˆåæ ‡ï¼Œç”¨ä¸“é—¨çš„è¯„ä¼°ä»£ç è¿›è¡Œæ£€æµ‹ã€‚ 12cd py-faster-rcnn./experiments/scripts/faster_rcnn_alt_opt.sh 0 VGG16 caltech å‚æ•°1ï¼šæŒ‡å®šgpu_idã€‚ å‚æ•°2ï¼šæŒ‡å®šç½‘ç»œæ¨¡åž‹å‚æ•°ã€‚ å‚æ•°3ï¼šæ•°æ®é›†åç§°ï¼Œç›®å‰åªèƒ½ä¸ºpascal_vocã€‚ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šè°ƒç”¨py_faster_rcnn/tools/train_faster_rcnn_alt_opt.pyæ–‡ä»¶å¼€å§‹è®­ç»ƒç½‘ç»œã€‚ å¯èƒ½ä¼šå‡ºçŽ°çš„BugsAssertionError: assert (boxes[:, 2] &gt;= boxes[:, 0]).all()é—®é¢˜é‡çŽ°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‡ºçŽ°å¦‚ä¸‹æŠ¥é”™ï¼š 1234File &quot;/py-faster-rcnn/tools/../lib/datasets/imdb.py&quot;, line 108, in append_flipped_images assert (boxes[:, 2] &gt;= boxes[:, 0]).all() AssertionError é—®é¢˜åˆ†æžæ£€æŸ¥è‡ªå·±æ•°æ®å‘çŽ°ï¼Œå·¦ä¸Šè§’åæ ‡ (x, y) å¯èƒ½ä¸º0ï¼Œæˆ–æ ‡å®šåŒºåŸŸæº¢å‡ºå›¾ç‰‡ï¼ˆå³åæ ‡ä¸ºè´Ÿæ•°ï¼‰ï¼Œè€Œfaster rcnnä¼šå¯¹Xmin,Ymin,Xmax,Ymaxè¿›è¡Œå‡ä¸€æ“ä½œï¼Œå¦‚æžœXminä¸º0ï¼Œå‡ä¸€åŽå˜ä¸º65535ï¼Œä»Žè€Œåœ¨å·¦å³ç¿»è½¬å›¾ç‰‡æ—¶å¯¼è‡´å¦‚ä¸Šé”™è¯¯å‘ç”Ÿã€‚ é—®é¢˜è§£å†³ ä¿®æ”¹lib/datasets/imdb.pyä¸­çš„append_flipped_images()å‡½æ•°ï¼š æ•°æ®æ•´ç†ï¼Œåœ¨ä¸€è¡Œä»£ç ä¸º boxes[:, 2] = widths[i] - oldx1 - 1ä¸‹åŠ å…¥ä»£ç ï¼š 123for b in range(len(boxes)): if boxes[b][2]&lt; boxes[b][0]: boxes[b][0] = 0 ä¿®æ”¹lib/datasets/caltech.pyï¼Œ_load_pascal_annotation()å‡½æ•°ï¼Œå°†å¯¹Xmin,Ymin,Xmax,Ymaxå‡ä¸€åŽ»æŽ‰ï¼Œå˜ä¸ºï¼š 1234567891011121314# Load object bounding boxes into a data frame. for ix, obj in enumerate(objs): bbox = obj.find('bndbox') # Make pixel indexes 0-based # è¿™é‡Œæˆ‘æŠŠâ€˜-1â€™å…¨éƒ¨åˆ é™¤æŽ‰äº†ï¼Œé˜²æ­¢æœ‰çš„æ•°æ®æ˜¯0å¼€å§‹ï¼Œç„¶åŽâ€˜-1â€™å¯¼è‡´å˜ä¸ºè´Ÿæ•°ï¼Œäº§ç”ŸAssertErroré”™è¯¯ x1 = float(bbox.find('xmin').text) y1 = float(bbox.find('ymin').text) x2 = float(bbox.find('xmax').text) y2 = float(bbox.find('ymax').text) cls = self._class_to_ind[obj.find('name').text.lower().strip()] boxes[ix, :] = [x1, y1, x2, y2] gt_classes[ix] = cls overlaps[ix, cls] = 1.0 seg_areas[ix] = (x2 - x1 + 1) * (y2 - y1 + 1) ï¼ˆå¯é€‰ï¼‰å¦‚æžœ1å’Œ2å¯ä»¥è§£å†³é—®é¢˜ï¼Œå°±æ²¡å¿…è¦ç”¨æ–¹æ³•3ã€‚ä¿®æ”¹lib/fast_rcnn/config.pyï¼Œä¸ä½¿å›¾ç‰‡å®žçŽ°ç¿»è½¬ï¼Œå¦‚ä¸‹æ”¹ä¸ºï¼š 12# Use horizontally-flipped images during training? __C.TRAIN.USE_FLIPPED = False å¦‚æžœå¦‚ä¸Šä¸‰ç§æ–¹æ³•éƒ½æ— æ³•è§£å†³è¯¥é—®é¢˜ï¼Œé‚£ä¹ˆè‚¯å®šæ˜¯ä½ çš„æ•°æ®é›†åæ ‡å‡ºçŽ°å°äºŽç­‰äºŽ0çš„æ•°ï¼Œä½ åº”è¯¥ä¸€ä¸€æŽ’æŸ¥ã€‚ è®­ç»ƒfast rcnnæ—¶å‡ºçŽ°loss=nançš„æƒ…å†µã€‚é—®é¢˜é‡çŽ° é—®é¢˜åˆ†æžè¿™æ˜¯ç”±äºŽæ¨¡åž‹ä¸æ”¶æ•›ï¼Œå¯¼è‡´lossè¿…é€Ÿå¢žé•¿ã€‚ è€Œæˆ‘å‡ºçŽ°ä»¥ä¸ŠçŽ°è±¡çš„åŽŸå› ä¸»è¦æ˜¯å› ä¸ºæˆ‘åœ¨å‡ºçŽ°AssertionErrorçš„æ—¶å€™ç›´æŽ¥ä½¿ç”¨äº†ç¬¬ä¸‰ç§æ–¹æ³•å¯¼è‡´çš„ã€‚ä¹Ÿå°±æ˜¯ç¦ç”¨å›¾ç‰‡ç¿»è½¬ã€‚ é—®é¢˜è§£å†³å¯ç”¨å›¾ç‰‡ç¿»è½¬ã€‚ è®­ç»ƒç»“æžœè®­ç»ƒåŽçš„æ¨¡åž‹æ”¾åœ¨output/faster_rcnn_alt_opt/train/VGG16_faster_rcnn_final.caffemodelï¼Œè¯¥æ¨¡åž‹å¯ä»¥ç”¨äºŽä¹‹åŽçš„æ£€æµ‹ã€‚ æ£€æµ‹æ£€æµ‹æ­¥éª¤ç»è¿‡ä»¥ä¸Šè®­ç»ƒåŽï¼Œå°±å¯ä»¥ç”¨å¾—åˆ°çš„æ¨¡åž‹æ¥è¿›è¡Œæ£€æµ‹äº†ã€‚æ£€æµ‹æ‰€å‚è€ƒçš„ä»£ç æ˜¯tools/demo.pyï¼Œå…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š å°†output/faster_rcnn_alt_opt/train/VGG16_faster_rcnn_final.caffemodelï¼Œæ‹·è´åˆ°data/faster_rcnn_modelsä¸‹ï¼Œå‘½åä¸ºVGG16_Caltech_faster_rcnn__final.caffemodel è¿›å…¥tools/æ–‡ä»¶å¤¹ä¸­ï¼Œæ‹·è´demo.pyä¸ºdemo_caltech.pyã€‚ ä¿®æ”¹demo_caltech.pyä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154#!/usr/bin/env python# --------------------------------------------------------# Faster R-CNN# Copyright (c) 2015 Microsoft# Licensed under The MIT License [see LICENSE for details]# Written by Ross Girshick# --------------------------------------------------------import matplotlibmatplotlib.use('Agg');"""Demo script showing detections in sample images.See README.md for installation instructions before running."""import _init_pathsfrom fast_rcnn.config import cfgfrom fast_rcnn.test import im_detectfrom fast_rcnn.nms_wrapper import nmsfrom utils.timer import Timerimport matplotlib.pyplot as pltimport numpy as npimport scipy.io as sioimport caffe, os, sys, cv2import argparseCLASSES = ('__background__', # è¿™é‡Œæ”¹ä¸ºè‡ªå·±çš„ç±»åˆ« 'person')NETS = &#123;'vgg16': ('VGG16', 'VGG16_Caltech_faster_rcnn_final.caffemodel'), #è¿™é‡Œéœ€è¦ä¿®æ”¹ä¸ºè®­ç»ƒåŽå¾—åˆ°çš„æ¨¡åž‹çš„åç§° 'zf': ('ZF', 'ZF_Caltech_faster_rcnn_final.caffemodel')&#125; #è¿™é‡Œéœ€è¦ä¿®æ”¹ä¸ºè®­ç»ƒåŽå¾—åˆ°çš„æ¨¡åž‹çš„åç§°def vis_detections(im, image_name, class_name, dets, thresh=0.5): """Draw detected bounding boxes.""" inds = np.where(dets[:, -1] &gt;= thresh)[0] if len(inds) == 0: return im = im[:, :, (2, 1, 0)] fig, ax = plt.subplots(figsize=(12, 12)) ax.imshow(im, aspect='equal') for i in inds: bbox = dets[i, :4] score = dets[i, -1] ax.add_patch( plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], fill=False, edgecolor='red', linewidth=3.5) ) ax.text(bbox[0], bbox[1] - 2, '&#123;:s&#125; &#123;:.3f&#125;'.format(class_name, score), bbox=dict(facecolor='blue', alpha=0.5), fontsize=14, color='white') ax.set_title(('&#123;&#125; detections with ' 'p(&#123;&#125; | box) &gt;= &#123;:.1f&#125;').format(class_name, class_name, thresh), fontsize=14) plt.axis('off') plt.tight_layout() plt.draw() plt.savefig('/home/jk/py-faster-rcnn/output/faster_rcnn_alt_opt/test/'+image_name) #å°†æ£€æµ‹åŽçš„å›¾ç‰‡ä¿å­˜åˆ°ç›¸åº”çš„è·¯å¾„def demo(net, image_name): """Detect object classes in an image using pre-computed object proposals.""" # Load the demo image im_file = os.path.join(cfg.DATA_DIR, 'VOCdevkit/Caltech/JPEGImages', image_name) im = cv2.imread(im_file) # Detect all object classes and regress object bounds timer = Timer() timer.tic() scores, boxes = im_detect(net, im) timer.toc() print ('Detection took &#123;:.3f&#125;s for ' '&#123;:d&#125; object proposals').format(timer.total_time, boxes.shape[0]) # Visualize detections for each class CONF_THRESH = 0.85 # è®¾ç½®æƒå€¼ï¼Œè¶Šä½Žæ£€æµ‹å‡ºçš„æ¡†è¶Šå¤š NMS_THRESH = 0.3 for cls_ind, cls in enumerate(CLASSES[1:]): cls_ind += 1 # because we skipped background cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)] cls_scores = scores[:, cls_ind] dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])).astype(np.float32) keep = nms(dets, NMS_THRESH) dets = dets[keep, :] vis_detections(im, image_name, cls, dets, thresh=CONF_THRESH)def parse_args(): """Parse input arguments.""" parser = argparse.ArgumentParser(description='Faster R-CNN demo') parser.add_argument('--gpu', dest='gpu_id', help='GPU device id to use [0]', default=0, type=int) parser.add_argument('--cpu', dest='cpu_mode', help='Use CPU mode (overrides --gpu)', action='store_true') parser.add_argument('--net', dest='demo_net', help='Network to use [vgg16]', choices=NETS.keys(), default='vgg16') args = parser.parse_args() return argsif __name__ == '__main__': cfg.TEST.HAS_RPN = True # Use RPN for proposals args = parse_args() prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][0], 'faster_rcnn_alt_opt', 'faster_rcnn_test.pt') caffemodel = os.path.join(cfg.DATA_DIR, 'faster_rcnn_models', NETS[args.demo_net][1]) if not os.path.isfile(caffemodel): raise IOError(('&#123;:s&#125; not found.\nDid you run ./data/script/' 'fetch_faster_rcnn_models.sh?').format(caffemodel)) if args.cpu_mode: caffe.set_mode_cpu() else: caffe.set_mode_gpu() caffe.set_device(args.gpu_id) cfg.GPU_ID = args.gpu_id net = caffe.Net(prototxt, caffemodel, caffe.TEST) print '\n\nLoaded network &#123;:s&#125;'.format(caffemodel) # Warmup on a dummy image im = 128 * np.ones((300, 500, 3), dtype=np.uint8) for i in xrange(2): _, _= im_detect(net, im) testfile_path = '/home/jk/py-faster-rcnn/data/VOCdevkit/Caltech/ImageSets/Main/test.txt' with open(testfile_path) as f: im_names = [x.strip()+'.jpg' for x in f.readlines()] # ä»Žtest.txtæ–‡ä»¶ä¸­è¯»å–å›¾ç‰‡æ–‡ä»¶åï¼Œæ‰¾åˆ°ç›¸åº”çš„å›¾ç‰‡è¿›è¡Œæ£€æµ‹ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„æ–¹æ³•ï¼ŒæŠŠé¡¹æ£€æµ‹çš„å›¾ç‰‡å­˜åˆ°tools/demo/æ–‡ä»¶å¤¹ä¸‹è¿›è¡Œè¯»å–æ£€æµ‹ #im_names = ['set06_V002_I00023.jpg', 'set06_V002_I00072.jpg', 'set06_V002_I00097.jpg', # 'set06_V002_I00151.jpg', 'set07_V010_I00247.jpg'] for im_name in im_names: print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~' print 'Demo for data/demo/&#123;&#125;'.format(im_name) demo(net, im_name) plt.show() åœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥ä¸€ä¸‹å‘½ä»¤è¿›è¡Œæ£€æµ‹ï¼š 1python tools/demo_caltech.py æ£€æµ‹ç»“æžœæ”¾å‡ å¼ æ£€æµ‹åŽçš„ç»“æžœå›¾ï¼Œæ„Ÿè§‰æ£€æµ‹æ•ˆæžœå¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œå¾ˆå¤šæŠŠèƒŒæ™¯å½“æˆè¡Œäººçš„é”™è¯¯ï¼š å‚è€ƒåšå®¢ ä½¿ç”¨Faster-Rcnnè¿›è¡Œç›®æ ‡æ£€æµ‹(å®žè·µç¯‡) Train Fast-RCNN on Another Dataset]]></content>
      <categories>
        <category>ç»éªŒ</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ å®žè·µç»éªŒï¼šç”¨Faster R-CNNè®­ç»ƒè¡Œäººæ£€æµ‹æ•°æ®é›†Caltechâ€”â€”å‡†å¤‡å·¥ä½œ]]></title>
    <url>%2Fposts%2F2093106769%2F</url>
    <content type="text"><![CDATA[å‰è¨€Faster R-CNNæ˜¯Ross Girshickå¤§ç¥žåœ¨Fast R-CNNåŸºç¡€ä¸Šæå‡ºçš„åˆä¸€ä¸ªæ›´åŠ å¿«é€Ÿã€æ›´é«˜mAPçš„ç”¨äºŽç›®æ ‡æ£€æµ‹çš„æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼Œå®ƒå¯¹Fast R-CNNè¿›è¡Œçš„æœ€ä¸»è¦çš„ä¼˜åŒ–å°±æ˜¯åœ¨Region Proposalé˜¶æ®µï¼Œå¼•å…¥äº†Region Proposal Network (RPN)æ¥è¿›è¡ŒRegion Proposalï¼ŒåŒæ—¶å¯ä»¥è¾¾åˆ°å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾çš„ç›®æ ‡ï¼Œä½¿å¾—region proposalå‡ ä¹Žæ˜¯cost freeçš„ã€‚ å…³äºŽFaster R-CNNçš„è¯¦ç»†ä»‹ç»ï¼Œå¯ä»¥å‚è€ƒæˆ‘ä¸Šä¸€ç¯‡åšå®¢ã€‚ Faster R-CNNçš„ä»£ç æ˜¯å¼€æºçš„ï¼Œæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼šMATLABç‰ˆæœ¬(faster_rcnn)ï¼ŒPythonç‰ˆæœ¬(py-faster-rcnn)ã€‚ è¿™é‡Œæˆ‘ä¸»è¦ä½¿ç”¨çš„æ˜¯Pythonç‰ˆæœ¬ï¼ŒPythonç‰ˆæœ¬åœ¨æµ‹è¯•æœŸé—´ä¼šæ¯”MATLABç‰ˆæœ¬æ…¢10%ï¼Œå› ä¸ºPython layersä¸­çš„ä¸€äº›æ“ä½œæ˜¯åœ¨CPUä¸­æ‰§è¡Œçš„ï¼Œä½†æ˜¯å‡†ç¡®çŽ‡åº”è¯¥æ˜¯å·®ä¸å¤šçš„ã€‚ å‡†å¤‡å·¥ä½œ1â€”â€”py-faster-rcnnçš„ç¼–è¯‘å®‰è£…æµ‹è¯•py-faster-rcnnçš„ç¼–è¯‘å®‰è£… å…‹éš†Faster R-CNNä»“åº“ï¼š 1git clone --recursive https://github.com/rbgirshick/py-faster-rcnn.git ä¸€å®šè¦åŠ ä¸Š--recursiveæ ‡å¿—ï¼Œå‡è®¾å…‹éš†åŽçš„æ–‡ä»¶å¤¹åå­—å«py-faster-rcnn ç¼–è¯‘Cythonæ¨¡å—ï¼š 12cd py-faster-rcnn/libmake ç¼–è¯‘é‡Œé¢çš„Caffeå’Œpycaffeï¼š 12345cd py-faster-rcnn/caffe-fast-rcnn# æŒ‰ç…§ç¼–è¯‘Caffeçš„æ–¹æ³•ï¼Œè¿›è¡Œç¼–è¯‘# æ³¨æ„Makefile.configçš„ä¿®æ”¹ï¼Œè¿™é‡Œä¸å†èµ˜è¿°Caffeçš„å®‰è£…# ç¼–è¯‘make -j8 &amp;&amp; make pycaffe è¿™é‡Œè´´ä¸Šæˆ‘çš„Makefile.configæ–‡ä»¶ä»£ç ï¼Œæ ¹æ®ä½ çš„æƒ…å†µè¿›è¡Œç›¸åº”ä¿®æ”¹ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114## Refer to http://caffe.berkeleyvision.org/installation.html# Contributions simplifying and improving our build system are welcome!# cuDNN acceleration switch (uncomment to build with cuDNN).USE_CUDNN := 1# CPU-only switch (uncomment to build without GPU support).# CPU_ONLY := 1# uncomment to disable IO dependencies and corresponding data layers# USE_OPENCV := 0# USE_LEVELDB := 0# USE_LMDB := 0# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)# You should not set this flag if you will be reading LMDBs with any# possibility of simultaneous read and write# ALLOW_LMDB_NOLOCK := 1# Uncomment if you're using OpenCV 3OPENCV_VERSION := 3# To customize your choice of compiler, uncomment and set the following.# N.B. the default for Linux is g++ and the default for OSX is clang++# CUSTOM_CXX := g++# CUDA directory contains bin/ and lib/ directories that we need.CUDA_DIR := /usr/local/cuda# On Ubuntu 14.04, if cuda tools are installed via# "sudo apt-get install nvidia-cuda-toolkit" then use this instead:# CUDA_DIR := /usr# CUDA architecture setting: going with all of them.# For CUDA &lt; 6.0, comment the *_50 lines for compatibility.CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \-gencode arch=compute_20,code=sm_21 \-gencode arch=compute_30,code=sm_30 \-gencode arch=compute_35,code=sm_35 \-gencode arch=compute_50,code=sm_50 \-gencode arch=compute_50,code=compute_50# BLAS choice:# atlas for ATLAS (default)# mkl for MKL# open for OpenBlasBLAS :=mkl# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.# Leave commented to accept the defaults for your choice of BLAS# (which should work)!# BLAS_INCLUDE := /path/to/your/blas# BLAS_LIB := /path/to/your/blas# Homebrew puts openblas in a directory that is not on the standard search path# BLAS_INCLUDE := $(shell brew --prefix openblas)/include# BLAS_LIB := $(shell brew --prefix openblas)/lib# This is required only if you will compile the matlab interface.# MATLAB directory should contain the mex binary in /bin.MATLAB_DIR := /usr/local/MATLAB/R2016b# MATLAB_DIR := /Applications/MATLAB_R2012b.app# NOTE: this is required only if you will compile the python interface.# We need to be able to find Python.h and numpy/arrayobject.h.# PYTHON_INCLUDE := /usr/include/python2.7 \/usr/lib/python2.7/dist-packages/numpy/core/include# Anaconda Python distribution is quite popular. Include path:# Verify anaconda location, sometimes it's in root.ANACONDA_HOME := $(HOME)/anacondaPYTHON_INCLUDE := $(ANACONDA_HOME)/include \$(ANACONDA_HOME)/include/python2.7 \$(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include \$ /usr/include/python2.7# Uncomment to use Python 3 (default is Python 2)# PYTHON_LIBRARIES := boost_python3 python3.5m# PYTHON_INCLUDE := /usr/include/python3.5m \# /usr/lib/python3.5/dist-packages/numpy/core/include# We need to be able to find libpythonX.X.so or .dylib.# PYTHON_LIB := /usr/libPYTHON_LIB := $(ANACONDA_HOME)/lib# Homebrew installs numpy in a non standard path (keg only)# PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include# PYTHON_LIB += $(shell brew --prefix numpy)/lib# Uncomment to support layers written in Python (will link against Python libs)WITH_PYTHON_LAYER := 1# Whatever else you find you need goes here.# INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include# LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/libINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies# INCLUDE_DIRS += $(shell brew --prefix)/include# LIBRARY_DIRS += $(shell brew --prefix)/lib# Uncomment to use `pkg-config` to specify OpenCV library paths.# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)# USE_PKG_CONFIG := 1# N.B. both build and distribute dirs are cleared on `make clean`BUILD_DIR := buildDISTRIBUTE_DIR := distribute# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171# DEBUG := 1# The ID of the GPU that 'make runtest' will use to run unit tests.TEST_GPUID := 0# enable pretty build (comment to see full commands)Q ?= @ Demoè¿è¡Œä¸ºäº†æ£€éªŒä½ çš„py-faster-rcnnæ˜¯å¦æˆåŠŸå®‰è£…ï¼Œä½œè€…ç»™å‡ºäº†ä¸€ä¸ªdemoï¼Œå¯ä»¥åˆ©ç”¨åœ¨PASCAL VOC2007æ•°æ®é›†ä¸Šä½“çŽ°è®­ç»ƒå¥½çš„æ¨¡åž‹ï¼Œæ¥è¿›è¡Œdemoçš„è¿è¡Œï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š ä¸‹è½½é¢„è®­ç»ƒå¥½çš„Faster R-CNNæ£€æµ‹å™¨ï¼š 12cd py-faster-rcnn./data/scripts/fetch_faster_rcnn_models.sh è¿™æ¡å‘½ä»¤ä¼šè‡ªåŠ¨ä¸‹è½½åä¸ºfaster_rcnn_models.tgzçš„æ–‡ä»¶ï¼Œè§£åŽ‹åŽä¼šåˆ›å»ºdata/faster_rcnn_modelsæ–‡ä»¶å¤¹ï¼Œé‡Œé¢ä¼šæœ‰ä¸¤ä¸ªæ¨¡åž‹ï¼š ZF_faster_rcnn_final.caffemodelï¼šåœ¨ZFç½‘ç»œæ¨¡åž‹ä¸‹è®­ç»ƒæ‰€å¾— VGG16_faster_rcnn_final.caffemodelï¼šåœ¨VGG16ç½‘ç»œæ¨¡åž‹ä¸‹è®­ç»ƒæ‰€å¾—ã€‚ è¿è¡Œdemoï¼š 12cd py-faster-rcnn./tools/demo.py demoä¼šæ£€æµ‹5å¼ å›¾ç‰‡ï¼Œè¿™5å¼ å›¾ç‰‡æ”¾åœ¨data/demo/æ–‡ä»¶å¤¹ä¸‹ï¼Œå…¶ä¸­ä¸€å¼ çš„æ£€æµ‹ç»“æžœå¦‚ä¸‹ï¼š è‡³æ­¤å¦‚æžœä¸Šè¿°è¿‡ç¨‹æ²¡æœ‰å‡ºé”™ï¼Œé‚£ä¹ˆpy-faster-rcnnç®—æ˜¯æˆåŠŸç¼–è¯‘å®‰è£…ã€‚ è‹¥å‡ºçŽ°æŠ¥é”™å¦‚ä¸‹ï¼š 1ImportError: /xx/xx/xx/py-faster-rcnn/tools/../lib/nms/cpu_nms.so: undefined symbol: PyFPE_jbuf éœ€è¦å°†lib/fast_rcnn/nms_wrapper.pyæ–‡ä»¶ä¸­çš„from nms.cpu_nms import cpu_nmsæ³¨é‡ŠæŽ‰å³å¯ã€‚ å‡†å¤‡å·¥ä½œ2â€”â€”Caltechæ•°æ®é›†ç”±äºŽFaster R-CNNçš„ä¸€éƒ¨åˆ†å®žéªŒæ˜¯åœ¨PASCAL VOC2007æ•°æ®é›†ä¸Šè¿›è¡Œçš„ï¼Œæ‰€ä»¥è¦æƒ³ç”¨Faster R-CNNè®­ç»ƒæˆ‘ä»¬è‡ªå·±çš„æ•°æ®é›†ï¼Œé¦–å…ˆåº”è¯¥æžæ¸…æ¥šPASCAL VOC2007æ•°æ®é›†ä¸­çš„ç›®å½•ã€å›¾ç‰‡ã€æ ‡æ³¨æ ¼å¼ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½ç”¨è‡ªå·±çš„æ•°æ®é›†åˆ¶ä½œå‡ºç±»ä¼¼äºŽPASCAL VOC2007ç±»ä¼¼çš„æ•°æ®é›†ï¼Œä¾›Faster R-CNNæ¥è¿›è¡Œè®­ç»ƒåŠæµ‹è¯•ã€‚ èŽ·å–PASCAL VOC2007æ•°æ®é›†è¿™ä¸€éƒ¨åˆ†ä¸æ˜¯å¿…é¡»çš„ï¼Œå¦‚æžœä½ éœ€è¦PASCAL VOC2007æ•°æ®é›†ï¼Œå¯ä»¥åˆ©ç”¨ä»¥ä¸‹å‘½ä»¤èŽ·å–æ•°æ®é›†ï¼Œä½†æˆ‘ä»¬ä¸‹è½½VOCæ•°æ®é›†çš„ç›®çš„ä¸»è¦æ˜¯è§‚å¯Ÿä»–çš„æ–‡ä»¶ç»“æž„å’Œæ–‡ä»¶å†…å®¹ï¼Œä»¥ä¾¿äºŽæˆ‘ä»¬æž„å»ºç¬¦åˆè¦æ±‚çš„è‡ªå·±çš„æ•°æ®é›†ã€‚ åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨æ¥å­˜æ•°æ®é›†çš„åœ°æ–¹ï¼Œå‡è®¾æ˜¯$HOME/dataæ–‡ä»¶å¤¹ã€‚ ä¸‹è½½PASCAL VOC2007çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼š 123cd $HOME/datawget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tarwget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar ä¸‹è½½å®ŒåŽç”¨ä»¥ä¸‹å‘½ä»¤è§£åŽ‹ï¼š 12tar xvf VOCtrainval_06-Nov-2007.tartar xvf VOCtest_06-Nov-2007.tar ä¼šå¾—åˆ°å¦‚ä¸‹æ–‡ä»¶ç»“æž„ï¼š 123456$HOME/data/VOCdevkit/ # æ ¹æ–‡ä»¶å¤¹$HOME/data/VOCdevkit/VOC2007 # VOC2007æ–‡ä»¶å¤¹$HOME/data/VOCdevkit/VOC2007/Annotations # æ ‡è®°æ–‡ä»¶å¤¹$HOME/data/VOCdevkit/VOC2007/ImageSets # ä¾›train.txtã€test.txtã€val.txtç­‰æ–‡ä»¶å­˜æ”¾çš„æ–‡ä»¶å¤¹$HOME/data/VOCdevkit/VOC2007/JPEGImages # å­˜æ”¾å›¾ç‰‡æ–‡ä»¶å¤¹# ... ä»¥åŠå…¶ä»–çš„æ–‡ä»¶å¤¹åŠå­æ–‡ä»¶å¤¹ ... åˆ›å»ºå¿«æ·æ–¹å¼symlinksæ¥è¿žæŽ¥åˆ°VOCæ•°æ®é›†å­˜æ”¾çš„åœ°æ–¹ï¼š 12cd py-faster-rcnn/dataln -s $HOME/data/VOCdevkit/ VOCdevkit è¿™é‡Œéœ€è¦æŠŠ$HOME/data/VOCdevkit/æ”¹ä¸ºä½ å­˜æ”¾VOCdevkitæ–‡ä»¶å¤¹çš„è·¯å¾„ æœ€å¥½ä½¿ç”¨symlinksæ¥åœ¨å…±äº«åŒä¸€ä»½æ•°æ®é›†ï¼Œé˜²æ­¢æ•°æ®é›†å¤šå¤„æ‹·è´ï¼Œå ç”¨ç©ºé—´ã€‚ è‡³æ­¤VOCæ•°æ®é›†åˆ›å»ºå®Œæ¯•ã€‚ PASCAL VOCæ•°æ®é›†çš„åˆ†æžPASCAL VOCæ•°æ®é›†çš„æ–‡ä»¶ç»“æž„ï¼Œå¦‚ä¸‹ï¼š 12345678910â””â”€â”€ VOCdevkit â””â”€â”€ VOC2007 â”œâ”€â”€ Annotations â”œâ”€â”€ ImageSets â”‚ â”œâ”€â”€ Layout â”‚ â”œâ”€â”€ Main â”‚ â””â”€â”€ Segmentation â”œâ”€â”€ JPEGImages â”œâ”€â”€ SegmentationClass â””â”€â”€ SegmentationObject Annotationsè¯¥æ–‡ä»¶å¤¹ä¸»è¦ç”¨æ¥å­˜æ”¾å›¾ç‰‡æ ‡æ³¨ï¼ˆå³ä¸ºground truthï¼‰ï¼Œæ–‡ä»¶æ˜¯.xmlæ ¼å¼ï¼Œæ¯å¼ å›¾ç‰‡éƒ½æœ‰ä¸€ä¸ª.xmlæ–‡ä»¶ä¸Žä¹‹å¯¹åº”ã€‚é€‰å–å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œå¦‚ä¸‹åˆ†æžï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;annotation&gt; &lt;folder&gt;VOC2007&lt;/folder&gt; # å¿…é¡»æœ‰ï¼Œçˆ¶æ–‡ä»¶å¤¹çš„åç§° &lt;filename&gt;000005.jpg&lt;/filename&gt; # å¿…é¡»æœ‰ &lt;source&gt; # å¯æœ‰å¯æ—  &lt;database&gt;The VOC2007 Database&lt;/database&gt; &lt;annotation&gt;PASCAL VOC2007&lt;/annotation&gt; &lt;image&gt;flickr&lt;/image&gt; &lt;flickrid&gt;325991873&lt;/flickrid&gt; &lt;/source&gt; &lt;owner&gt; # å¯æœ‰å¯æ—  &lt;flickrid&gt;archintent louisville&lt;/flickrid&gt; &lt;name&gt;?&lt;/name&gt; &lt;/owner&gt; &lt;size&gt; # è¡¨ç¤ºå›¾åƒå¤§å° &lt;width&gt;500&lt;/width&gt; &lt;height&gt;375&lt;/height&gt; &lt;depth&gt;3&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;0&lt;/segmented&gt; # ç”¨äºŽåˆ†å‰² &lt;object&gt; # ç›®æ ‡ä¿¡æ¯ï¼Œç±»åˆ«ï¼Œbboxä¿¡æ¯ï¼Œå›¾ç‰‡ä¸­æ¯ä¸ªç›®æ ‡å¯¹åº”ä¸€ä¸ª&lt;object&gt;æ ‡ç­¾ &lt;name&gt;chair&lt;/name&gt; &lt;pose&gt;Rear&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;263&lt;/xmin&gt; &lt;ymin&gt;211&lt;/ymin&gt; &lt;xmax&gt;324&lt;/xmax&gt; &lt;ymax&gt;339&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;chair&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;1&lt;/truncated&gt; &lt;difficult&gt;1&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;5&lt;/xmin&gt; &lt;ymin&gt;244&lt;/ymin&gt; &lt;xmax&gt;67&lt;/xmax&gt; &lt;ymax&gt;374&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt;&lt;/annotation&gt; éœ€è¦æ³¨æ„çš„ï¼Œå¯¹äºŽæˆ‘ä»¬è‡ªå·±å‡†å¤‡çš„xmlæ ‡è®°æ–‡ä»¶ä¸­ï¼Œæ¯ä¸ª&lt;object&gt;æ ‡ç­¾ä¸­çš„&lt;xmin&gt;å’Œ&lt;ymin&gt;æ ‡ç­¾ä¸­æ‰€å¯¹åº”çš„åæ ‡å€¼æœ€å¥½å¤§äºŽ0ï¼Œåƒä¸‡ä¸èƒ½ä¸ºè´Ÿæ•°ï¼Œå¦åˆ™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæŠ¥é”™ï¼šAssertionError: assert (boxes[:, 2]) &gt;= boxes[:, 0]).all()ï¼Œå¦‚ä¸‹ï¼š æ‰€ä»¥ä¸ºäº†èƒ½å¤Ÿé¡ºåˆ©è®­ç»ƒï¼Œä¸€å®šè¦ä»”ç»†æ£€æŸ¥è‡ªå·±çš„xmlæ–‡ä»¶ä¸­çš„å·¦ä¸Šè§’çš„åæ ‡æ˜¯å¦éƒ½ä¸ºæ­£ã€‚æˆ‘è¢«è¿™ä¸ªbugå¡äº†ä¸€ä¸¤å¤©ï¼Œæœ€ç»ˆæŠŠè‡ªå·±æ ‡è®°ä¸­æ‰€æœ‰çš„é”™è¯¯åæ ‡æ‰¾å‡ºæ¥ï¼Œæ‰å¾—ä»¥é¡ºåˆ©è®­ç»ƒã€‚ ImageSetsImageSetsæ–‡ä»¶å¤¹ä¸‹æœ‰ä¸‰ä¸ªå­æ–‡ä»¶å¤¹ï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€å…³æ³¨Mainæ–‡ä»¶å¤¹å³å¯ã€‚Mainæ–‡ä»¶å¤¹ä¸‹ä¸»è¦ç”¨åˆ°çš„æ˜¯train.txtã€val.txtã€test.txtã€trainval.txtæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä¸­å†™ç€ä¾›è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æ‰€ç”¨çš„æ–‡ä»¶åçš„é›†åˆï¼Œå¦‚ä¸‹ï¼š JPEGImagesJPEGImagesæ–‡ä»¶å¤¹ä¸‹ä¸»è¦å­˜æ”¾ç€æ‰€æœ‰çš„.jpgæ–‡ä»¶æ ¼å¼çš„è¾“å…¥å›¾ç‰‡ï¼Œä¸åœ¨èµ˜è¿°ã€‚ åˆ¶ä½œVOCç±»ä¼¼çš„Caltechæ•°æ®é›†ç»è¿‡ä»¥ä¸Šå¯¹PASCAL VOCæ•°æ®é›†æ–‡ä»¶ç»“æž„çš„åˆ†æžï¼Œæˆ‘ä»¬ä»¿ç…§å…¶ï¼Œåˆ›å»ºé¦–å…ˆåˆ›å»ºç±»ä¼¼çš„æ–‡ä»¶ç»“æž„å³å¯ï¼š 1234567â””â”€â”€ VOCdevkit â””â”€â”€ VOC2007 â””â”€â”€ Caltech â”œâ”€â”€ Annotations â”œâ”€â”€ ImageSets â”‚ â””â”€â”€ Main â””â”€â”€ JPEGImages æˆ‘å»ºè®®å°†Caltechæ–‡ä»¶åˆ›å»ºä¸€ä¸ªsymlinksé“¾æŽ¥åˆ°VOCdevkitæ–‡ä»¶å¤¹ä¹‹ä¸‹ï¼Œå› ä¸ºè¿™æ ·ä¼šæ–¹ä¾¿ä¹‹åŽè®­ç»ƒä»£ç çš„ä¿®æ”¹ã€‚ è‡³äºŽCaltechæ•°æ®é›†å¦‚ä½•ä»Ž.seqæ–‡ä»¶è½¬åŒ–ä¸ºä¸€å¼ å¼ .jpgå›¾ç‰‡ï¼Œè¿™é‡Œå¯ä»¥å‚è€ƒè¿™é‡Œã€‚ è‡³äºŽAnnotationsä¸­ä¸€ä¸ªä¸ª.xmlæ ‡è®°æ–‡ä»¶æ˜¯å®žéªŒå®¤å¸ˆå…„ç»™æˆ‘çš„ï¼Œä¸Šé¢æåˆ°çš„æ–¹æ³•ä¹Ÿå¯ä»¥è½¬åŒ–ï¼Œä½†æ˜¯å¹¶ä¸ç¬¦åˆè¦æ±‚ã€‚ è‡³äºŽImageSetsä¸­çš„train.txtæ˜¯æ ¹æ®.xmlæ–‡ä»¶å¾—æ¥çš„ï¼Œtest.txtæ˜¯æ¯ä¸ªseqä¸­æ¯éš”30å¸§å–ä¸€å¸§å›¾ç‰‡å¾—æ¥çš„ã€‚ ä»¥ä¸Šæ‰€æœ‰å’ŒCaltechæ•°æ®é›†æœ‰å…³çš„æ–‡ä»¶ï¼Œéƒ½å¯ä»¥ç›´æŽ¥é‚®ä»¶ä¸Žæˆ‘è”ç³»ï¼Œæˆ‘ç›´æŽ¥å‘ç»™ä½ ï¼Œå¯ä»¥çœä¸‹ä¸å°‘åˆ¶ä½œæ•°æ®é›†çš„æ—¶é—´ã€‚ å‚è€ƒåšå®¢ FastRCNN è®­ç»ƒè‡ªå·±æ•°æ®é›† (1ç¼–è¯‘é…ç½®) ç›®æ ‡æ£€æµ‹â€”Faster RCNN2]]></content>
      <categories>
        <category>ç»éªŒ</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šFaster R-CNN]]></title>
    <url>%2Fposts%2F3802700508%2F</url>
    <content type="text"><![CDATA[Abstract Region Proposalçš„è®¡ç®—æ˜¯åŸºäºŽRegion Proposalç®—æ³•æ¥å‡è®¾ç‰©ä½“ä½ç½®çš„ç‰©ä½“æ£€æµ‹ç½‘ç»œæ¯”å¦‚ï¼šSPPnet, Fast R-CNNè¿è¡Œæ—¶é—´çš„ç“¶é¢ˆã€‚ Faster R-CNNå¼•å…¥äº†Region Proposal Networkï¼ˆRPNï¼‰æ¥å’Œæ£€æµ‹ç½‘ç»œå…±äº«æ•´ä¸ªå›¾ç‰‡çš„å·ç§¯ç½‘ç»œç‰¹å¾ï¼Œå› æ­¤ä½¿å¾—region proposalå‡ ä¹Žæ˜¯cost freeçš„ã€‚ RPN-&gt;é¢„æµ‹ç‰©ä½“è¾¹ç•Œï¼ˆobject boundsï¼‰å’Œåœ¨æ¯ä¸€ä½ç½®çš„åˆ†æ•°ï¼ˆobjectness scoreï¼‰ é€šè¿‡åœ¨ä¸€ä¸ªç½‘ç»œä¸­å…±äº«RPNå’ŒFast R-CNNçš„å·ç§¯ç‰¹å¾æ¥èžåˆä¸¤è€…â€”â€”ä½¿ç”¨â€œattentionâ€æœºåˆ¶ã€‚ 300 proposals pre image. Introduction RPæ˜¯å½“å‰è®¸å¤šå…ˆè¿›æ£€æµ‹ç³»ç»Ÿçš„ç“¶é¢ˆã€‚ Region proposal methods: Selective Search: one of the most popular method EdgeBoxes: trade off between proposal quality and speed. region proposalè¿™ä¸€æ­¥ä¾æ—§å’Œæ£€æµ‹ç½‘ç»œèŠ±è´¹åŒæ ·å¤šçš„æ—¶é—´ã€‚ Fast R-CNNç”Ÿæˆçš„feature map ä¹Ÿèƒ½ç”¨æ¥ç”ŸæˆRPã€‚åœ¨è¿™äº›å·ç§¯ç‰¹å¾ä¹‹ä¸Šæˆ‘ä»¬é€šè¿‡è¿™æ ·çš„æ–¹å¼æž„å»ºRPNï¼šé€šè¿‡æ·»åŠ å‡ ä¸ªé¢å¤–çš„å·ç§¯å±‚æ¥æ¨¡æ‹Ÿä¸€ä¸ªregular gridä¸Šæ¯ä¸€ä¸ªä½ç½®çš„regress region boundså’Œobjectness scoresã€‚æ‰€ä»¥RPNä¹Ÿæ˜¯ä¸€ç§fully convolutional network(FCN)ï¼Œä»Žè€Œå¯ä»¥ç«¯åˆ°ç«¯è®­ç»ƒæ¥äº§ç”Ÿdetection proposalsã€‚ anchor boxesï¼šreferences at multiple scales and aspect ratios. æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥çœ‹æˆpyramid of regression referenceï¼Œä»Žè€Œé¿å…æžšä¸¾å¤šå°ºå¯¸ã€å¤šæ¨ªçºµæ¯”çš„imagesæˆ–è€…filters Related Work R-CNNä¸»è¦æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œä»–ä¸èƒ½é¢„æµ‹object boundsï¼Œä»–çš„å‡†ç¡®æ€§ä¾èµ–äºŽRegion proposalæ¨¡å—çš„è¡¨çŽ° Faster R-CNN ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼š ç¬¬ä¸€ä¸ªæ¨¡å—ï¼šA deep fuuly convolutional network that proposes regionsï¼Œç”¨æ¥proposes regions. ç¬¬äºŒä¸ªæ¨¡å—ï¼šFast R-CNNæ£€æµ‹å™¨ï¼Œä½¿ç”¨ç¬¬ä¸€æ¨¡å—æå‡ºçš„regionsã€‚ Attention mechanismsï¼šRPN moduleå‘Šè¯‰Fast R-CNN module å¾€å“ªé‡Œçœ‹ï¼ˆwhere to lookï¼‰ Region Proposal Networks è¾“å…¥ï¼šä¸€å¼ ä»»æ„å°ºå¯¸çš„å›¾ç‰‡ã€‚ è¾“å‡ºï¼šä¸€ç»„çŸ©å½¢object proposalï¼Œæ¯ä¸ªproposaléƒ½æœ‰ä¸€ä¸ªscoreã€‚ æ˜¯ä¸€ä¸ªfully convolutional networkï¼ˆFCNï¼‰ï¼Œç”±äºŽæˆ‘ä»¬éœ€è¦åœ¨RPNå’ŒFast RCNNä¹‹é—´å…±äº«æƒå€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å‡è®¾ä¸¤ä¸ªç½‘ç»œå…±äº«ä¸€ç»„å…±åŒçš„å·ç§¯å±‚ã€‚ ä¸ºäº†ç”Ÿæˆregion proposalsï¼Œæˆ‘ä»¬åœ¨æœ€åŽä¸€å±‚å…±äº«å·ç§¯å±‚è¾“å‡ºçš„feature mapä¸Šæ»‘åŠ¨ä¸€ä¸ªå¾®åž‹ç½‘ç»œã€‚è¿™ä¸ªå¾®åž‹ç½‘ç»œå°†è¾“å…¥çš„feature mapä¸Šçš„nxnçš„ç©ºé—´çª—å£ä½œä¸ºè¾“å…¥ã€‚æ¯ä¸€ä¸ªæ»‘åŠ¨çª—å£è¢«æ˜ å°„ä¸ºä¸€ä¸ªä½Žç»´ç‰¹å¾(ZF: 256-d, VGG: 512-d, ä¹‹åŽè·Ÿç€ReLUå±‚)ã€‚è¿™äº›ç‰¹å¾ç„¶åŽè¢«é€åˆ°ä¸¤ä¸ªsiblingå…¨è¿žæŽ¥å±‚ä¸­â€”â€”ä¸€ä¸ªbox-regression(reg)å±‚å’Œä¸€ä¸ªbox-classification(cls)å±‚ã€‚ æ³¨æ„ï¼šå› ä¸ºå¾®åž‹ç½‘ç»œä»¥æ»‘åŠ¨çª—å£æ–¹å¼æ“ä½œï¼Œæ‰€ä»¥å®Œå…¨è¿žæŽ¥å±‚åœ¨æ‰€æœ‰ç©ºé—´ä½ç½®ä¸Šå…±äº«ã€‚ è¿™ç§ç»“æž„è‡ªç„¶åœ°é€šè¿‡ä¸€ä¸ªnÃ—nå·ç§¯å±‚ï¼ŒåŽé¢æ˜¯ä¸¤ä¸ªåŒçº§1Ã—1å·ç§¯å±‚ï¼ˆåˆ†åˆ«ç”¨äºŽrpn_regå’Œrpn_clsï¼‰æ¥å®žçŽ°ã€‚ ç”Ÿæˆregion proposalçš„æ€è·¯ï¼š rpnç½‘ç»œç»“æž„å®šä¹‰å¦‚ä¸‹ï¼š â€‹ â€‹ Anchors å‡è®¾æ¯ä¸ªä½ç½®æœ€å¤§å¯èƒ½çš„proposalçš„æ•°é‡ä¸ºkï¼Œåœ¨æ¯ä¸ªsliding-windowä½ç½®ï¼ŒåŒæ—¶é¢„æµ‹å‡ ä¸ªRPï¼š reg layerï¼šæœ‰4kä¸ªè¾“å‡º cls layerï¼šæœ‰2kä¸ªè¾“å‡ºï¼ŒæŒ‡å‡ºè¯¥æ¯ä¸€ä¸ªproposalæ˜¯å¦æ˜¯objectï¼Œestimate probability of object or not object for each proposalã€‚ kä¸ªproposalç›¸å¯¹äºŽkä¸ªå‚è€ƒæ¡†ï¼ˆreference boxesï¼‰è€Œå‚æ•°åŒ–ï¼Œæˆ‘ä»¬å°†å‚è€ƒæ¡†ç§°ä¸ºanchorã€‚ ä¸€ä¸ªanchorä½äºŽsliding windowçš„ä¸­é—´ï¼ŒåŒæ—¶å…³è”ç€ä¸€ä¸ªscaleå’Œaspect rationã€‚ Translation-Invariant Anchors(å¹³ç§»ä¸å˜æ€§) å¦‚æžœç§»åŠ¨äº†ä¸€å¼ å›¾åƒä¸­çš„ä¸€ä¸ªç‰©ä½“ï¼Œè¿™proposalåº”è¯¥ä¹Ÿç§»åŠ¨äº†ï¼Œè€Œä¸”ç›¸åŒçš„å‡½æ•°å¯ä»¥é¢„æµ‹å‡ºçƒ­è®®æœªçŸ¥çš„proposalã€‚MultiBoxä¸å…·å¤‡å¦‚æ­¤åŠŸèƒ½ å¹³ç§»ä¸å˜æ€§å¯ä»¥å‡å°‘æ¨¡åž‹å¤§å°ã€‚ Multi-Scale Anchor as Regression References Two popular ways for multi-scale predictions: ç¬¬ä¸€ç§ï¼šbased on image/feature pyramids, å¦‚ï¼šDPM and CNN-based methodsã€‚å›¾åƒè¢«resizedæˆä¸åŒå°ºå¯¸ï¼Œç„¶åŽä¸ºæ¯ä¸€ç§å°ºå¯¸è®¡ç®—feature maps(HOGæˆ–è€…deep convolutional features)ã€‚è¿™ç§æ–¹æ³•æ¯”è¾ƒè´¹æ—¶ã€‚ ç¬¬äºŒç§ï¼šuse sliding windows of multiple scales (and/or aspect ratios) on the feature maps.â€”â€”filtersé‡‘å­—å¡”ã€‚ç¬¬äºŒç§æ–¹æ³•ç»å¸¸å’Œç¬¬ä¸€ç§æ–¹æ³•è”åˆä½¿ç”¨ æœ¬è®ºæ–‡çš„æ–¹æ³•ï¼šanchoré‡‘å­—å¡”â€”â€”more cost-efficientï¼Œåªä¾é å•å°ºå¯¸çš„å›¾åƒå’Œfeature mapã€‚ The design of multiscale anchors is a key component for sharing features without extra cost for addressing scales. Loss Function ä¸ºäº†è®­ç»ƒRPNï¼Œæˆ‘ä»¬ç»™æ¯ä¸ªanchorè®¾ç½®äº†ä¸€ä¸ªäºŒå…ƒæ ‡ç­¾ï¼ˆæ˜¯ç‰©ä½“æˆ–è€…ä¸æ˜¯ç‰©ä½“ï¼‰ ä¸¤ç±»anchoræ˜¯æœ‰æ­£æ ‡ç­¾ï¼ˆis objectï¼‰çš„ï¼š anchor/anchors with highest IoU overlap with a ground-truth boxã€‚ an anchor that has IoU overlap higher than 0.7 with any ground-truth box. ç¬¬äºŒç§æ–¹æ³•æ›´å¥½æ£€æµ‹æ­£æ ·æœ¬ï¼Œåœ¨ç¬¬äºŒç§æƒ…å†µä¸‹å¦‚æžœæ‰¾ä¸åˆ°æ­£æ ·æœ¬ï¼Œé‚£ä¹ˆä½¿ç”¨ç¬¬ä¸€ç§ã€‚ å¦‚æžœä¸€ä¸ªanchorå’Œä»»ä½•ground-truth boxesçš„IoUå€¼å°äºŽ0.3ï¼Œé‚£ä¹ˆè¯¥anchorä¸ºè´Ÿæ ‡ç­¾ éžæ­£éžè´Ÿæ ·æœ¬å¯¹training objectiveæ²¡æœ‰ç”¨ã€‚ Loss Functionï¼š â€‹ $N{cls}=256,N{reg}=256*9=2304,\lambda=10$ï¼Œè¿™æ ·ä¸¤ä¸ªlosså°±å¯ä»¥æƒé‡åŸºæœ¬ç›¸å½“äº†ã€‚ Bounding box regression è¿™ä¸ªå¯ä»¥è€ƒè™‘ä¸ºä»Žanchor boxå›žå½’åˆ°é™„è¿‘çš„ground truth boxã€‚ å’ŒR-CNNå’ŒFast R-CNNçš„bounding box regressionæ–¹æ³•ä¸åŒçš„æ˜¯ï¼š å‰ä¸¤ç§çš„å›žå½’æ˜¯åœ¨ä»Žä»»æ„å¤§å°RoIä¸­æå–çš„ç‰¹å¾è¿›è¡Œå›žå½’çš„ï¼Œæ‰€ä»¥regression weightsåœ¨æ‰€æœ‰å°ºå¯¸ä¸­å…±äº«ã€‚ åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œç”¨äºŽå›žå½’çš„ç‰¹å¾éƒ½æ˜¯åŒä¸€ä¸ª3x3çš„ç©ºé—´ç‰¹å¾ã€‚è€ƒè™‘åˆ°å˜åŒ–çš„å°ºå¯¸ï¼Œæœ‰kä¸ªä¸åŒçš„bounding boxeå›žå½’å™¨åŽ»å­¦ä¹ ï¼Œæ¯ä¸€ä¸ªå›žå½’å™¨è´Ÿè´£åŽ»å­¦ä¹ ä¸€ä¸ªå°ºå¯¸ä¸€ä¸ªè¡¡é‡æ¯”çš„anchorã€‚æ‰€ä»¥kä¸ªå›žå½’å™¨æ˜¯ä¸å…±äº«æƒå€¼çš„ã€‚æ‰€ä»¥å¾—ç›ŠäºŽanchorçš„è®¾è®¡ï¼Œå³ä½¿ç‰¹å¾è§„å®šï¼Œæˆ‘ä»¬ä¾æ—§å¯ä»¥åŽ»é¢„æµ‹ä¸åŒå°ºå¯¸çš„boxã€‚ Training RPNs image-centric sampling strategy mini-batch: arises from a single image that contains many positive and negative example anchors. éšæœºåœ¨ä¸€å¼ å›¾ç‰‡ä¸­é‡‡æ ·256ä¸ªanchorsæ¥è®¡ç®—ä¸€ä¸ªmini-batchçš„loss functionã€‚æ­£è´Ÿanchors = 1:1. all new layersçš„æƒå€¼åˆå§‹åŒ–ï¼šé«˜æ–¯åˆ†å¸ƒ$(\mu = 0, \sigma = 0.01)$ï¼Œall other layersï¼ˆæ¯”å¦‚å…±äº«å·ç§¯å±‚ï¼‰ç”¨ImageNetæ¥æƒå€¼åˆå§‹åŒ–ã€‚ç”¨ZF netæ¥è¿›è¡Œè¿›è¡Œå¾®è°ƒã€‚ å­¦ä¹ çŽ‡ï¼š0.001(60k)-&gt;0.0001(20k) åŠ¨é‡ï¼š0.9 weight decay: 0.0005 Sharing Feature for RPN and Fast R-CNN sharing convolutional layers between the two networks, rather than learning two separate networks ä¸‰ç§ç‰¹å¾å…±äº«çš„æ–¹æ³•ï¼š Alternating trainingï¼šè¿­ä»£ï¼Œå…ˆè®­ç»ƒPRNï¼Œç„¶åŽç”¨proposalåŽ»è®­ç»ƒFast R-CNNã€‚è¢«Fast R-CNNå¾®è°ƒçš„ç½‘ç»œç„¶åŽç”¨æ¥åˆå§‹åŒ–PRNï¼Œä»¥æ­¤è¿­ä»£ã€‚æœ¬è®ºæ–‡æ‰€æœ‰çš„å®žçŽ°éƒ½æ˜¯ä½¿ç”¨è¯¥æ–¹æ³•ã€‚ Approximate joint trainingï¼š RPNå’ŒFast R-CNNèžåˆåˆ°ä¸€ä¸ªç½‘ç»œä¸­è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¯æ¬¡SGDè¿­ä»£è¿‡ç¨‹ä¸­ï¼š å‰å‘ä¼ é€’ï¼šRPNäº§ç”Ÿregion proposalsï¼Œè¿™äº›proposalsè¢«å½“åšå›ºå®šçš„ã€æå‰è®¡ç®—å¥½çš„proposalæ¥è®­ç»ƒFast R-CNNæ£€æµ‹å™¨ã€‚ åå‘ä¼ é€’ï¼šå¯¹äºŽå…±äº«å±‚æ¥è¯´ï¼Œæ¥è‡ªRPNçš„losså’ŒFast R-CNNçš„lossç»“åˆ. ä½†æ˜¯è¿™ç§æ–¹æ³•ä¸è€ƒè™‘Bounding Boxesï¼Œå¿½ç•¥äº†proposal boxesçš„åæ ‡ä¹Ÿæ˜¯ç½‘ç»œçš„è¾“å‡ºã€‚æ‰€ä»¥è¿™ç§æ–¹æ³•å«åšapproximate Non-approximate joint training: è€ƒè™‘Bounding Boxesã€‚ 4-step Alternating Training: Step 1: train the RPN, initialized with an ImageNet-pre-trained model and ï¬ne-tuned end-to-end for the region proposal task. Step 2: train a separate detection network by Fast R-CNN using the proposals generated by the step-1 RPN. åŒæ ·ä½¿ç”¨ImageNet-pre-trained modelæ¥åˆå§‹åŒ–ã€‚æ­¤æ—¶ä¸¤ä¸ªç½‘ç»œå¹¶æ²¡æœ‰å…±äº«å·ç§¯å±‚ã€‚ Step 3: use the detector network to initialize RPN training but we ï¬x the shared convolutional layers and only ï¬ne-tune the layers unique to RPN. çŽ°åœ¨ä¸¤ä¸ªç½‘ç»œå…±äº«å·ç§¯å±‚ Step 4: keeping the shared convolutional layers ï¬xed, we ï¬ne-tune the unique layers of Fast R-CNN. Implementation Details Multi-scaleä¸Žspeed-accuracyä¹‹é—´çš„trade-off To reduce redundancy, we adopt non-maximum suppression (NMS) on the proposal regions based on their cls scores.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šFast R-CNN]]></title>
    <url>%2Fposts%2F1679631826%2F</url>
    <content type="text"><![CDATA[çŸ¥è¯†ç‚¹ mAPï¼šdetection quality. Abstract æœ¬æ–‡æå‡ºä¸€ç§åŸºäºŽå¿«é€ŸåŒºåŸŸçš„å·ç§¯ç½‘ç»œæ–¹æ³•ï¼ˆå¿«é€ŸR-CNNï¼‰ç”¨äºŽå¯¹è±¡æ£€æµ‹ã€‚ å¿«é€ŸR-CNNé‡‡ç”¨å¤šé¡¹åˆ›æ–°æŠ€æœ¯æ¥æé«˜è®­ç»ƒå’Œæµ‹è¯•é€Ÿåº¦ï¼ŒåŒæ—¶æé«˜æ£€æµ‹ç²¾åº¦ã€‚ é‡‡ç”¨VGG16çš„ç½‘ç»œï¼šVGG: 16 layers of 3x3 convolution interleaved with max pooling + 3 fully-connected layers Introduction ç‰©ä½“æ£€æµ‹ç›¸å¯¹äºŽå›¾åƒåˆ†ç±»æ˜¯æ›´å¤æ‚çš„ï¼Œåº”ä¸ºéœ€è¦ç‰©ä½“å‡†ç¡®çš„ä½ç½®ã€‚ é¦–å…ˆï¼Œå¿…é¡»å¤„ç†è®¸å¤šå€™é€‰å¯¹è±¡ä½ç½®ï¼ˆé€šå¸¸ç§°ä¸ºâ€œproposalâ€ï¼‰ã€‚ å…¶æ¬¡ï¼Œè¿™äº›å€™é€‰è€…åªæä¾›ç²—ç•¥çš„å®šä½ï¼Œå¿…é¡»è¿›è¡Œç²¾ç¡®å®šä½æ‰èƒ½å®žçŽ°ç²¾ç¡®å®šä½ã€‚ è¿™äº›é—®é¢˜çš„è§£å†³æ–¹æ¡ˆç»å¸¸æŸå®³ é€Ÿåº¦ ï¼Œ å‡†ç¡®æ€§ æˆ– ç®€å•æ€§ ã€‚ R-CNN and SPPnet R-CNN(Region-based Convolution Network)å…·æœ‰å‡ ä¸ªæ˜¾è‘—çš„ç¼ºç‚¹ï¼š è®­ç»ƒæ˜¯ä¸€ä¸ªå¤šçº§ç®¡é“ã€‚ è®­ç»ƒåœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šæ˜¯æ˜‚è´µçš„ã€‚ ç‰©ä½“æ£€æµ‹é€Ÿåº¦å¾ˆæ…¢ã€‚ R-CNNæ˜¯æ…¢çš„ï¼Œå› ä¸ºå®ƒå¯¹æ¯ä¸ªå¯¹è±¡proposalæ‰§è¡ŒConvNetæ­£å‘ä¼ é€’ï¼Œè€Œä¸å…±äº«è®¡ç®—ï¼ˆsharing computationï¼‰ã€‚ Spatial pyramid pooling networksï¼ˆSPPnetsï¼‰ï¼Œåˆ©ç”¨sharing computationå¯¹R-CNNè¿›è¡Œäº†åŠ é€Ÿï¼Œä½†æ˜¯SPPnetsä¹Ÿå…·æœ‰æ˜Žæ˜¾çš„ç¼ºç‚¹ï¼ŒåƒR-CNNä¸€æ ·ï¼ŒSPPnetsä¹Ÿéœ€è¦ï¼š è®­ç»ƒæ˜¯ä¸€ä¸ªå¤šé˜¶æ®µæµç¨‹ï¼Œ æ¶‰åŠæå–ç‰¹å¾ï¼Œ ç”¨å¯¹æ•°æŸå¤±ç²¾ç®€ç½‘ç»œ è®­ç»ƒSVM èµ‹äºˆè¾¹ç•Œæ¡†å›žå½’ã€‚ ç‰¹å¾ä¹Ÿéœ€è¦ä¹Ÿå†™å…¥ç£ç›˜ã€‚ ä½†ä¸ŽR-CNN ä¸åŒ ï¼Œåœ¨[11]ä¸­æå‡ºçš„fine-tuningç®—æ³•ä¸èƒ½æ›´æ–°åœ¨ç©ºé—´é‡‘å­—å¡”æ± ä¹‹å‰çš„å·ç§¯å±‚ã€‚ ä¸å‡ºæ‰€æ–™ï¼Œè¿™ç§é™åˆ¶ï¼ˆå›ºå®šçš„å·ç§¯å±‚ï¼‰é™åˆ¶äº†éžå¸¸æ·±çš„ç½‘ç»œçš„ç²¾åº¦ã€‚ Contributions Fast R-CNNä¼˜ç‚¹ï¼š æ¯”R-CNNï¼ŒSPPnetæ›´é«˜çš„æ£€æµ‹è´¨é‡ï¼ˆmAPï¼‰ è®­ç»ƒæ˜¯å•é˜¶æ®µçš„ï¼Œä½¿ç”¨å¤šä»»åŠ¡æŸå¤±ï¼ˆmulti-task lossï¼‰ è®­ç»ƒå¯ä»¥æ›´æ–°æ‰€æœ‰ç½‘ç»œå±‚ ç‰¹å¾ç¼“å­˜ä¸éœ€è¦ç£ç›˜å­˜å‚¨ Fast R-CNN architecture and training æ•´ä½“æ¡†æž¶ å¿«é€ŸR-CNNç½‘ç»œå°†æ•´ä¸ªå›¾åƒå’Œä¸€ç»„object proposalsä½œä¸ºè¾“å…¥ã€‚ ç½‘ç»œé¦–å…ˆä½¿ç”¨å‡ ä¸ªå·ç§¯ï¼ˆconvï¼‰å’Œæœ€å¤§æ± å±‚æ¥å¤„ç†æ•´ä¸ªå›¾åƒï¼Œä»¥äº§ç”Ÿconv feature mapã€‚ ç„¶åŽï¼Œå¯¹äºŽæ¯ä¸ªå¯¹è±¡proposalï¼Œ æ„Ÿå…´è¶£åŒºåŸŸï¼ˆRoIï¼‰æ± å±‚ ä»Žç‰¹å¾å›¾ä¸­æŠ½å–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚ æ¯ä¸ªç‰¹å¾å‘é‡è¢«é¦ˆé€åˆ°å®Œå…¨è¿žæŽ¥ï¼ˆfcï¼‰å±‚åºåˆ—ï¼Œå…¶æœ€ç»ˆåˆ†æ”¯æˆä¸¤ä¸ªåŒçº§è¾“å‡ºå±‚ï¼š ä¸€ä¸ªäº§ç”Ÿå¯¹Kä¸ªå¯¹è±¡ç±»åŠ ä¸Šå…¨éƒ¨æ•èŽ·çš„â€œèƒŒæ™¯â€ç±»çš„softmaxæ¦‚çŽ‡ä¼°è®¡(one that produces softmax probability estimates over K object classes plus a catch-all â€œbackgroundâ€ class) å¦ä¸€ä¸ªå¯¹æ¯ä¸ªKå¯¹è±¡ç±»è¾“å‡ºå››ä¸ªå®žæ•°ï¼Œæ¯ç»„4ä¸ªå€¼ç¼–ç æç‚¼å®šä¹‰Kä¸ªç±»ä¸­çš„ä¸€ä¸ªçš„çš„è¾¹ç•Œæ¡†ä½ç½®ã€‚(another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes reï¬ned bounding-box positions for one of the K classes.) The RoI pooling layer Rol pooling layerçš„ä½œç”¨ä¸»è¦æœ‰ä¸¤ä¸ªï¼š ä¸€ä¸ªæ˜¯å°†imageä¸­çš„RoIå®šä½åˆ°feature mapä¸­å¯¹åº”patch å¦ä¸€ä¸ªæ˜¯ç”¨ä¸€ä¸ªå•å±‚çš„SPP layerå°†è¿™ä¸ªfeature map patchä¸‹é‡‡æ ·ä¸ºå¤§å°å›ºå®šçš„featureå†ä¼ å…¥å…¨è¿žæŽ¥å±‚ã€‚ RoIæ± å±‚ä½¿ç”¨æœ€å¤§æ± åŒ–å°†ä»»ä½•æœ‰æ•ˆçš„RoIåŒºåŸŸå†…çš„ç‰¹å¾è½¬æ¢æˆå…·æœ‰HÃ—Wï¼ˆä¾‹å¦‚ï¼Œ7Ã—7ï¼‰çš„å›ºå®šç©ºé—´èŒƒå›´çš„å°feature mapï¼Œå…¶ä¸­Hå’ŒWæ˜¯å±‚è¶…å‚æ•° å®ƒä»¬ç‹¬ç«‹äºŽä»»ä½•ç‰¹å®šçš„RoIã€‚ åœ¨æœ¬æ–‡ä¸­ï¼ŒRoIæ˜¯conv feature mapä¸­çš„ä¸€ä¸ªçŸ©å½¢çª—å£ã€‚ æ¯ä¸ªRoIç”±å®šä¹‰å…¶å·¦ä¸Šè§’ï¼ˆrï¼Œcï¼‰åŠå…¶é«˜åº¦å’Œå®½åº¦ï¼ˆhï¼Œwï¼‰çš„å››å…ƒç»„ï¼ˆrï¼Œcï¼Œhï¼Œwï¼‰å®šä¹‰ã€‚ RoIå±‚ä»…ä»…æ˜¯Sppnetsä¸­çš„spatial pyramid pooling layerçš„ç‰¹æ®Šå½¢å¼ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªé‡‘å­—å¡”å±‚. Initializing from pre-trained networks ç”¨äº†3ä¸ªé¢„è®­ç»ƒçš„ImageNetç½‘ç»œï¼ˆCaffeNet/ VGG_CNN_M_1024 /VGG16ï¼‰ã€‚é¢„è®­ç»ƒçš„ç½‘ç»œåˆå§‹åŒ–Fast RCNNè¦ç»è¿‡ä¸‰æ¬¡å˜å½¢ï¼š æœ€åŽä¸€ä¸ªmax poolingå±‚æ›¿æ¢ä¸ºRoI poolingå±‚ï¼Œè®¾ç½®Hâ€™å’ŒWâ€™ä¸Žç¬¬ä¸€ä¸ªå…¨è¿žæŽ¥å±‚å…¼å®¹ã€‚ æœ€åŽä¸€ä¸ªå…¨è¿žæŽ¥å±‚å’Œsoftmaxï¼ˆåŽŸæœ¬æ˜¯1000ä¸ªç±»ï¼‰æ›¿æ¢ä¸ºsoftmaxçš„å¯¹K+1ä¸ªç±»åˆ«çš„åˆ†ç±»å±‚ï¼Œå’Œbounding box å›žå½’å±‚ã€‚ è¾“å…¥ä¿®æ”¹ä¸ºä¸¤ç§æ•°æ®ï¼šä¸€ç»„Nä¸ªå›¾å½¢ï¼ŒRä¸ªRoIï¼Œbatch sizeå’ŒROIæ•°ã€å›¾åƒåˆ†è¾¨çŽ‡éƒ½æ˜¯å¯å˜çš„ã€‚ Fine-tuning for detection åˆ©ç”¨åå‘ä¼ æ’­ç®—æ³•è¿›è¡Œè®­ç»ƒæ‰€æœ‰ç½‘ç»œçš„æƒé‡æ˜¯Fast R-CNNå¾ˆé‡è¦çš„ä¸€ä¸ªèƒ½åŠ›ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›´æœ‰æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨åœ¨è®­ç»ƒæœŸé—´çš„ç‰¹å¾å…±äº«ï¼ˆfeature sharing during trainingï¼‰ã€‚ åœ¨Fast R-CNNè®­ç»ƒä¸­ï¼Œ éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰å°æ‰¹é‡åˆ†å±‚é‡‡æ · ï¼Œé¦–å…ˆé€šè¿‡é‡‡æ ·Nä¸ªå›¾åƒï¼Œç„¶åŽé€šè¿‡ä»Žæ¯ä¸ªå›¾åƒé‡‡æ · R/Nä¸ª RoIsã€‚ å…³é”®çš„æ˜¯ï¼Œæ¥è‡ªåŒä¸€å›¾åƒçš„RoIåœ¨å‘å‰å’Œå‘åŽä¼ é€’ä¸­ å…±äº«è®¡ç®— å’Œå­˜å‚¨ã€‚ æ­¤å¤–ä¸ºäº†åˆ†å±‚é‡‡æ ·ï¼ŒFast R-CNNä½¿ç”¨äº†ä¸€ä¸ªæµæ°´çº¿è®­ç»ƒè¿‡ç¨‹ï¼Œåˆ©ç”¨ä¸€ä¸ªfine-tuningé˜¶æ®µæ¥è”åˆä¼˜åŒ–ä¸€ä¸ªsoftmaxåˆ†ç±»å™¨å’Œbounding boxå›žå½’ï¼Œè€Œéžè®­ç»ƒä¸€ä¸ªsoftmaxåˆ†ç±»å™¨ï¼ŒSVMsï¼Œå’Œregressionåœ¨ä¸‰ä¸ªç‹¬ç«‹çš„é˜¶æ®µã€‚ Multi-task lossï¼š ä¸¤ä¸ªsiblingè¾“å‡ºå±‚ï¼š ç¬¬ä¸€å±‚ï¼šè¾“å‡ºç¦»æ•£æ¦‚çŽ‡åˆ†å¸ƒï¼ˆé’ˆå¯¹æ¯ä¸ªRoIsï¼‰ï¼Œ$p=(p_0,â€¦,p_K)$ï¼Œåˆ†åˆ«å¯¹åº”$K+1$ä¸ªç±»ã€‚pæ˜¯åœ¨ä¸€ä¸ªå…¨è¿žæŽ¥å±‚çš„$K+1$ä¸ªè¾“å‡ºä¸Šçš„softmaxã€‚ ç¬¬äºŒå±‚ï¼šè¾“å‡ºbounding-boxçš„å›žå½’åç§»(bounding-box regression offsets)ï¼Œé’ˆå¯¹K object classesä¸­çš„æ¯ä¸€ä¸ªç±»ï¼Œè®¡ç®—$t^k=(t^k_x,t^k_y,t^k_w,t^k_h)$ï¼Œå…·ä½“è§R-CNNå¾—è¡¥å……ææ–™ï¼Œé‡Œé¢æœ‰å¾ˆè¯¦ç»†çš„ä»‹ç»bounding box regressionã€‚ æ¯ä¸€ä¸ªè®­ç»ƒRoIsè¢«æ ‡æ³¨ä¸€ä¸ªground truthç±»$u$ï¼Œå’Œä¸€ä¸ªground truth bounding box å›žå½’ç›®æ ‡$v$ã€‚ ä¸¤ä¸ªlossï¼Œä»¥ä¸‹åˆ†åˆ«ä»‹ç»ï¼š å¯¹äºŽåˆ†ç±»lossï¼Œæ˜¯ä¸€ä¸ªN+1è·¯çš„softmaxè¾“å‡ºï¼Œå…¶ä¸­çš„Næ˜¯ç±»åˆ«ä¸ªæ•°ï¼Œ1æ˜¯èƒŒæ™¯ã€‚ å¯¹äºŽå›žå½’lossï¼Œæ˜¯ä¸€ä¸ª4xNè·¯è¾“å‡ºçš„regressorï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹äºŽæ¯ä¸ªç±»åˆ«éƒ½ä¼šè®­ç»ƒä¸€ä¸ªå•ç‹¬çš„regressorçš„æ„æ€ï¼Œæ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯ï¼Œè¿™é‡Œregressorçš„lossä¸æ˜¯L2çš„ï¼Œè€Œæ˜¯ä¸€ä¸ªå¹³æ»‘çš„L1ï¼Œå½¢å¼å¦‚ä¸‹ï¼š æˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªmulti-task loss L åœ¨æ¯ä¸ªè¢«æ ‡æ³¨çš„RoIä¸Šæ¥è”åˆè®­ç»ƒåˆ†ç±»å™¨å’Œbounding box regression Mini-batch samplingï¼šåœ¨å¾®è°ƒæ—¶ï¼Œæ¯ä¸ªSGDçš„mini-batchæ˜¯éšæœºæ‰¾ä¸¤ä¸ªå›¾ç‰‡ï¼ŒRä¸º128ï¼Œå› æ­¤æ¯ä¸ªå›¾ä¸Šå–æ ·64ä¸ªRoIã€‚ä»Žobject proposalä¸­é€‰25%çš„RoIï¼Œå°±æ˜¯å’Œground-truthäº¤å è‡³å°‘ä¸º0.5çš„ã€‚å‰©ä¸‹çš„ä½œä¸ºèƒŒæ™¯ã€‚ Back-propagation through RoI pooling layersï¼š RoI poolingå±‚è®¡ç®—æŸå¤±å‡½æ•°å¯¹æ¯ä¸ªè¾“å…¥å˜é‡xçš„åå¯¼æ•°ï¼Œå¦‚ä¸‹ï¼š yæ˜¯poolingåŽçš„è¾“å‡ºå•å…ƒï¼Œxæ˜¯poolingå‰çš„è¾“å…¥å•å…ƒï¼Œå¦‚æžœyç”±x poolingè€Œæ¥ï¼Œåˆ™å°†æŸå¤±Lå¯¹yçš„åå¯¼è®¡å…¥ç´¯åŠ å€¼ï¼Œæœ€åŽç´¯åŠ å®ŒRä¸ªRoIä¸­çš„æ‰€æœ‰è¾“å‡ºå•å…ƒã€‚ä¸‹é¢æ˜¯æˆ‘ç†è§£çš„xã€yã€rçš„å…³ç³»ï¼š Scale invariance è¿™é‡Œè®¨è®ºobjectçš„scaleé—®é¢˜ï¼Œå°±æ˜¯ç½‘ç»œå¯¹äºŽobjectçš„scaleåº”è¯¥æ˜¯è¦ä¸æ•æ„Ÿçš„ã€‚è¿™é‡Œè¿˜æ˜¯å¼•ç”¨äº†SPPçš„æ–¹æ³•ï¼Œæœ‰ä¸¤ç§: brute force ï¼ˆsingle scaleï¼‰ï¼Œä¹Ÿå°±æ˜¯ç®€å•è®¤ä¸ºobjectä¸éœ€è¦é¢„å…ˆresizeåˆ°ç±»ä¼¼çš„scaleå†ä¼ å…¥ç½‘ç»œï¼Œç›´æŽ¥å°†imageå®šæ­»ä¸ºæŸç§scaleï¼Œç›´æŽ¥è¾“å…¥ç½‘ç»œæ¥è®­ç»ƒå°±å¥½äº†ï¼Œç„¶åŽæœŸæœ›ç½‘ç»œè‡ªå·±èƒ½å¤Ÿå­¦ä¹ åˆ°scale-invarianceçš„è¡¨è¾¾ã€‚ image pyramids ï¼ˆmulti scaleï¼‰ï¼Œä¹Ÿå°±æ˜¯è¦ç”Ÿæˆä¸€ä¸ªé‡‘å­—å¡”ï¼Œç„¶åŽå¯¹äºŽobjectï¼Œåœ¨é‡‘å­—å¡”ä¸Šæ‰¾åˆ°ä¸€ä¸ªå¤§å°æ¯”è¾ƒæŽ¥è¿‘227x227çš„æŠ•å½±ç‰ˆæœ¬ï¼Œç„¶åŽç”¨è¿™ä¸ªç‰ˆæœ¬åŽ»è®­ç»ƒç½‘ç»œã€‚ å¯ä»¥çœ‹å‡ºï¼Œ2åº”è¯¥æ¯”1æ›´åŠ å¥½ï¼Œä½œè€…ä¹Ÿåœ¨5.2è®¨è®ºäº†ï¼Œ2çš„è¡¨çŽ°ç¡®å®žæ¯”1å¥½ï¼Œä½†æ˜¯å¥½çš„ä¸ç®—å¤ªå¤šï¼Œå¤§æ¦‚æ˜¯1ä¸ªmAPå·¦å³ï¼Œä½†æ˜¯æ—¶é—´è¦æ…¢ä¸å°‘ï¼Œæ‰€ä»¥ä½œè€…å®žé™…é‡‡ç”¨çš„æ˜¯ç¬¬ä¸€ä¸ªç­–ç•¥ï¼Œä¹Ÿå°±æ˜¯single scaleã€‚ è¿™é‡Œï¼ŒFRCNæµ‹è¯•ä¹‹æ‰€ä»¥æ¯”SPPå¿«ï¼Œå¾ˆå¤§åŽŸå› æ˜¯å› ä¸ºè¿™é‡Œï¼Œå› ä¸ºSPPç”¨äº†2ï¼Œè€ŒFRCNç”¨äº†1ã€‚ Fast R-CNN detection å¤§åž‹å…¨è¿žæŽ¥å±‚å¾ˆå®¹æ˜“çš„å¯ä»¥é€šè¿‡å°†ä»–ä»¬ä¸Ž truncated SVD(å¥‡å¼‚å€¼åˆ†è§£) åŽ‹ç¼©æ¥åŠ é€Ÿè®¡ç®—ã€‚ Main results All Fast R-CNN results in this paper using VGG16 ï¬ne-tune layers conv3 1 and up; all experments with models S and M ï¬ne-tune layers conv2 and up. Design evaluationDo we need more training data? åœ¨è®­ç»ƒæœŸé—´ï¼Œä½œè€…åšè¿‡çš„å”¯ä¸€ä¸€ä¸ªæ•°æ®å¢žé‡çš„æ–¹å¼æ˜¯æ°´å¹³ç¿»è½¬ã€‚ ä½œè€…ä¹Ÿè¯•è¿‡å°†VOC12çš„æ•°æ®ä¹Ÿä½œä¸ºæ‹“å±•æ•°æ®åŠ å…¥åˆ°finetuneçš„æ•°æ®ä¸­ï¼Œç»“æžœVOC07çš„mAPä»Ž66.9åˆ°äº†70.0ï¼Œè¯´æ˜Žå¯¹äºŽç½‘ç»œæ¥è¯´ï¼Œ æ•°æ®è¶Šå¤šå°±æ˜¯è¶Šå¥½çš„ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šSpatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition]]></title>
    <url>%2Fposts%2F3054155989%2F</url>
    <content type="text"><![CDATA[Abstract çŽ°æœ‰çš„æ·±å·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰éœ€è¦å›ºå®šå°ºå¯¸ï¼ˆä¾‹å¦‚ï¼Œ224Ã—224ï¼‰çš„è¾“å…¥å›¾åƒã€‚ æ–°çš„ç½‘ç»œç»“æž„ï¼Œç§°ä¸ºSPP-netï¼Œå¯ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œè€Œä¸ç®¡å›¾åƒå¤§å°/è§„æ¨¡ã€‚ ä½¿ç”¨SPP-netï¼Œæˆ‘ä»¬ä»Žæ•´ä¸ªå›¾åƒåªè®¡ç®—ä¸€æ¬¡ç‰¹å¾å›¾ï¼Œç„¶åŽåœ¨ä»»æ„åŒºåŸŸï¼ˆå­å›¾åƒï¼‰ä¸­æ± ç‰¹å¾ä»¥ç”Ÿæˆå›ºå®šé•¿åº¦è¡¨ç¤ºä»¥è®­ç»ƒæ£€æµ‹å™¨ã€‚ INTRODUCTION åœ¨CNNçš„è®­ç»ƒå’Œæµ‹è¯•ä¸­å­˜åœ¨æŠ€æœ¯é—®é¢˜ï¼šæ™®éçš„CNNéœ€è¦å›ºå®šçš„è¾“å…¥å›¾åƒå¤§å°ï¼ˆä¾‹å¦‚ï¼Œ224Ã—224ï¼‰ï¼Œå…¶é™åˆ¶äº†è¾“å…¥å›¾åƒçš„å®½é«˜æ¯”å’Œæ¯”ä¾‹ã€‚ Cropping Warping-&gt;unwanted geometric distortion(ä¸éœ€è¦çš„å‡ ä½•å¤±çœŸ) é‚£ä¹ˆä¸ºä»€ä¹ˆCNNéœ€è¦å›ºå®šè¾“å…¥å¤§å°ï¼Ÿ CNNä¸»è¦ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šå·ç§¯å±‚å’Œè·Ÿéšçš„å®Œå…¨è¿žæŽ¥çš„å±‚ã€‚ äº‹å®žä¸Šï¼Œå·ç§¯å±‚ä¸éœ€è¦å›ºå®šçš„å›¾åƒå¤§å°ï¼Œå¹¶ä¸”å¯ä»¥ç”Ÿæˆä»»ä½•å¤§å°çš„ç‰¹å¾å›¾ å¦ä¸€æ–¹é¢ï¼Œæ ¹æ®å®šä¹‰ï¼šå®Œå…¨è¿žæŽ¥çš„å±‚éœ€è¦å…·æœ‰å›ºå®šå°ºå¯¸/é•¿åº¦è¾“å…¥ã€‚æ‰€ä»¥å›ºå®šå°ºå¯¸å®Œå…¨æ¥è‡ªäºŽ å…¨è¿žæŽ¥å±‚ æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªspatial pyramid poolingï¼ˆç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚ï¼‰æ¥åŽ»æŽ‰é¢æ˜‚ç½—å›ºå®šè¾“å…¥çš„çº¦æŸã€‚ å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨æœ€åŽä¸€ä¸ªå·ç§¯å±‚çš„é¡¶éƒ¨æ·»åŠ ä¸€ä¸ªSPPå±‚ã€‚ SPPå±‚æ±‡é›†ç‰¹å¾å¹¶äº§ç”Ÿå›ºå®šé•¿åº¦çš„è¾“å‡ºï¼Œç„¶åŽé¦ˆé€åˆ°å®Œå…¨è¿žæŽ¥çš„å±‚ï¼ˆæˆ–å…¶ä»–åˆ†ç±»å™¨ï¼‰ã€‚ SPPå¯¹äºŽæ·±åº¦CNNæœ‰ç€ä¸€äº›æ˜¾è‘—çš„ç‰¹æ€§ï¼š 1ï¼‰SPPèƒ½å¤Ÿç”Ÿæˆå›ºå®šé•¿åº¦çš„è¾“å‡ºï¼Œè€Œä¸ç®¡è¾“å…¥å¤§å°ï¼Œè€Œåœ¨ä»¥å‰çš„æ·±åº¦ç½‘ç»œ[3]ä¸­ä½¿ç”¨çš„æ»‘åŠ¨çª—å£æ± ä¸èƒ½; 2ï¼‰SPPä½¿ç”¨å¤šçº§ç©ºé—´ä»“ï¼Œè€Œæ»‘åŠ¨çª—å£æ± ä»…ä½¿ç”¨å•ä¸ªçª—å£å¤§å°ã€‚ å¤šå±‚æ± åŒ–å·²è¢«è¯æ˜Žå¯¹äºŽå¯¹è±¡å˜å½¢æ˜¯é²æ£’çš„[15]; 3ï¼‰ç”±äºŽè¾“å…¥å°ºåº¦çš„çµæ´»æ€§ï¼ŒSPPå¯ä»¥åœ¨å¯å˜å°ºåº¦ä¸Šæå–çš„ç‰¹å¾ã€‚ å®žéªŒè¡¨æ˜Žï¼Œè¿™ç§å¤šå°ºå¯¸è®­ç»ƒä¸Žä¼ ç»Ÿçš„å•å°ºå¯¸è®­ç»ƒä¸€æ ·æ”¶æ•›ï¼Œå¹¶å¯¼è‡´æ›´å¥½çš„æµ‹è¯•ç²¾åº¦ã€‚ SPPçš„ä¼˜ç‚¹æ˜¯ä¸Žç‰¹å®šçš„CNNè®¾è®¡æ˜¯æ­£äº¤çš„ã€‚ Caltech101: L. Fei-Fei, R. Fergus, and P. Perona, â€œLearning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories,â€ CVIU, 2007. VOC 2007: M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman, â€œThe PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results,â€ 2007. ä½†æ˜¯R-CNNä¸­çš„ç‰¹å¾è®¡ç®—æ˜¯è€—æ—¶çš„ï¼Œå› ä¸ºå®ƒå¯¹æ¯ä¸ªå›¾åƒçš„æ•°åƒä¸ªwrapedåŒºåŸŸçš„åŽŸå§‹åƒç´ é‡å¤åº”ç”¨æ·±å·ç§¯ç½‘ç»œã€‚è€Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥åœ¨ä¸€æ•´å¼ å›¾åƒä¸Šåªè·‘ä¸€æ¬¡å·ç§¯å±‚ DEEP NETWORKS WITH SPATIAL PYRAMID POOLING è¾“å…¥å›¾åƒä¸­çš„è¿™äº›å½¢çŠ¶æ¿€æ´»åœ¨ç›¸åº”ä½ç½®çš„feature map The Spatial Pyramid Pooling Layer Bag-of-Words (BoW) approach-&gt;ç”¨æ¥å°†ç”Ÿæˆçš„ç‰¹å¾è¿›è¡Œpoolä»Žè€Œäº§ç”Ÿå›ºå®šé•¿åº¦çš„å‘é‡ã€‚ ç©ºé—´é‡‘å­—å¡”æ± æé«˜BoWï¼Œå› ä¸ºå®ƒå¯ä»¥é€šè¿‡åœ¨å±€éƒ¨ç©ºé—´ä»“ä¸­æ±‡é›†æ¥ ç»´æŠ¤ç©ºé—´ä¿¡æ¯ ã€‚ â€œglobal poolingâ€ operation a global average pooling a global average pooling Training the Network Single-size training Multi-size training SPP-NET FOR IMAGE CLASSIFICATIONSPP-NET FOR OBJECT DETECTION å¯¹äºŽR-CNNæ¥è¯´ï¼ŒFeature extraction is the major timing bottleneck in testing. å¯¹äºŽæˆ‘ä»¬çš„SPP-netæ¥è¯´ï¼Œæˆ‘ä»¬ä»Žä¸€æ•´å¼ å›¾ç‰‡ä¸­å€¼æå–ä¸€æ¬¡ç‰¹å¾ã€‚ On the contrary, our method enables feature extraction in arbitrary windows from the deep convolutional feature maps. Detection Algorithm]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è®ºæ–‡ç¬”è®°ï¼šRich feature hierarchies for accurate object detection and semantic segmentation]]></title>
    <url>%2Fposts%2F4241353321%2F</url>
    <content type="text"><![CDATA[Abstract mAP: mean average precisionï¼Œå¹³å‡å‡†ç¡®åº¦ æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆä¸¤ä¸ªå…³é”®çš„è§è§£ï¼š ç¬¬ä¸€ï¼šé‡‡ç”¨é«˜å®¹é‡çš„å·ç§¯ç¥žç»ç½‘ç»œæ¥ä»Žä¸Šåˆ°ä¸‹çš„è¿›è¡Œregion proposalï¼Œä»Žè€Œå®žçŽ°å®šä½å’Œåˆ†å‰²ç‰©ä½“ã€‚ å½“æ ‡è®°çš„è®­ç»ƒæ•°æ®ç¨€ç¼ºæ—¶ï¼Œå¯ä»¥å…ˆå¯¹è¾…åŠ©æ•°æ®é›†ï¼ˆä»»åŠ¡ï¼‰è¿›è¡Œå—ç›‘ç£çš„é¢„è®­ç»ƒï¼Œ éšåŽæ˜¯åŸºäºŽåŸŸè¿›è¡Œç‰¹å®šè°ƒæ•´ï¼Œäº§ç”Ÿæ˜¾ç€çš„æ€§èƒ½æå‡ã€‚ Introduction å…³äºŽå„ç§è§†è§‰è¯†åˆ«ä»»åŠ¡çš„ä¸Šä¸€ä¸ªåå¹´çš„è¿›å±•ä¸»è¦åŸºäºŽSIFTå’ŒHOGçš„ä½¿ç”¨ å®žçŽ°è¿™ä¸ªç»“æžœéœ€è¦è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼š åˆ©ç”¨æ·±åº¦ç½‘ç»œå°†å¯¹è±¡å®šä½ ä»…åˆ©ç”¨å°‘é‡çš„æ³¨é‡Šæ£€æµ‹æ•°æ®æ¥è®­ç»ƒè®­ç»ƒé«˜å®¹é‡æ¨¡åž‹ã€‚ æˆ‘ä»¬é€šè¿‡åœ¨â€œä½¿ç”¨åŒºåŸŸè¯†åˆ«â€èŒƒä¾‹å†…æ“ä½œï¼Œæ¥è§£å†³CNNå®šä½é—®é¢˜ åœ¨æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºè¾“å…¥å›¾åƒç”Ÿæˆå¤§çº¦2000ä¸ªç±»åˆ«æ— å…³åŒºåŸŸææ¡ˆï¼Œä½¿ç”¨CNNä»Žæ¯ä¸ªproposalä¸­æå–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œç„¶åŽä½¿ç”¨ç±»åˆ«ç‰¹å®šçš„çº¿æ€§SVMå¯¹æ¯ä¸ªåŒºåŸŸè¿›è¡Œåˆ†ç±»ã€‚ æ£€æµ‹ä¸­é¢ä¸´çš„ç¬¬äºŒä¸ªæŒ‘æˆ˜æ˜¯æ ‡è®°çš„æ•°æ®ä¸è¶³ï¼Œç›®å‰å¯ç”¨çš„æ•°æ®æ•°é‡ä¸è¶³ä»¥è®­ç»ƒå¤§åž‹CNNã€‚è¿™ä¸ªé—®é¢˜çš„å¸¸è§„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ— ç›‘ç£é¢„è®­ç»ƒï¼Œç„¶åŽæ˜¯ç›‘ç£ fine-tuningã€‚ æˆ‘ä»¬å‘çŽ°ï¼Œå¯¹äºŽCNNï¼Œæœ‰å¾ˆå¤§æ¯”ä¾‹çš„å‚æ•°ï¼ˆ94%ï¼‰å¯ä»¥åœ¨æ£€æµ‹ç²¾åº¦çš„é€‚åº¦é™ä½Žçš„æƒ…å†µä¸‹è¢«åŽ»é™¤ã€‚ æˆ‘ä»¬è¯æ˜Žä¸€ä¸ªç®€å•çš„ è¾¹ç•Œæ¡†å›žå½’æ–¹æ³•ï¼ˆbounding box regressionï¼‰ æ˜¾ç€å‡å°‘è¯¯å®šä½ï¼Œè¿™æ˜¯ä¸»è¦çš„è¯¯å·®æ¨¡å¼(error mode)ã€‚ åœ¨å¼€å‘æŠ€æœ¯ç»†èŠ‚ä¹‹å‰ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°ï¼Œå› ä¸ºR-CNNåœ¨æ˜¯åŒºåŸŸä¸Šæ“ä½œï¼Œæ‰€ä»¥å¾ˆè‡ªç„¶å°†å…¶æ‰©å±•åˆ°è¯­ä¹‰åˆ†å‰²ï¼ˆsemantic segmentationï¼‰çš„ä»»åŠ¡ã€‚ Object detection with R-CNN æˆ‘ä»¬çš„å¯¹è±¡æ£€æµ‹ç³»ç»Ÿç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆ: é¦–å…ˆç”Ÿæˆç±»åˆ«ç‹¬ç«‹(category-independent)åŒºåŸŸproposalã€‚ è¿™äº›proposalå®šä¹‰äº†å¯ç”¨äºŽæ£€æµ‹å™¨çš„å€™é€‰æ£€æµ‹é›†åˆã€‚ ç¬¬äºŒä¸ªæ¨¡å—æ˜¯å¤§å·ç§¯ç¥žç»ç½‘ç»œï¼Œä»Žæ¯ä¸ªåŒºåŸŸæå–å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚ ç¬¬ä¸‰ä¸ªæ¨¡å—æ˜¯ä¸€ç±»ç‰¹å®šç±»åž‹çš„çº¿æ€§SVMã€‚ Module design Region proposals: ç›®å‰æœ‰å¾ˆå¤šç”¨æ¥ç”Ÿæˆcategory-independentçš„region proposalçš„æ–¹æ³•ï¼š Objectness selective search category-independent object proposals constrained parametric min-cuts (CPMC) multi-scale combinatorial grouping detect mitotic cells by applying a CNN to regularly-spaced square crops, which are a special case of region proposals.(é€šè¿‡å°†CNNåº”ç”¨äºŽè§„åˆ™é—´éš”çš„æ–¹å½¢ä½œç‰©æ¥æ£€æµ‹æœ‰ä¸åˆ†è£‚ç»†èƒžï¼Œè¿™æ˜¯åŒºåŸŸææ¡ˆçš„ç‰¹æ®Šæƒ…å†µã€‚) è™½ç„¶R-CNNä¸Žç‰¹å®šåŒºåŸŸå»ºè®®æ–¹æ³•æ— å…³ï¼Œä½†æˆ‘ä»¬ä½¿ç”¨é€‰æ‹©æ€§æœç´¢(selective search)æ¥å®žçŽ°ä¸Žå…ˆå‰æ£€æµ‹å·¥ä½œçš„å—æŽ§æ¯”è¾ƒ Feature extraction:æˆ‘ä»¬ä»Žæ¯ä¸ªåŒºåŸŸææ¡ˆä¸­æå–ä¸€ä¸ª4096ç»´ç‰¹å¾å‘é‡ï¼Œç‰¹å¾é€šè¿‡å‰å‘ä¼ æ’­å¯¹227Ã—227 RGBå›¾åƒé€šè¿‡ äº”ä¸ªå·ç§¯å±‚å’Œä¸¤ä¸ªå®Œå…¨è¿žæŽ¥çš„å±‚ è®¡ç®—ã€‚ æ— è®ºå€™é€‰åŒºåŸŸçš„å¤§å°æˆ–å®½é«˜æ¯”å¦‚ä½•ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†å…¶å‘¨å›´çš„ç´§å¯†è¾¹ç•Œæ¡†ä¸­çš„æ‰€æœ‰åƒç´ è£…åˆ°æ‰€éœ€çš„å¤§å°(227x227åƒç´ å°ºå¯¸)ã€‚ Test-time detection åœ¨æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬å¯¹æµ‹è¯•å›¾åƒè¿è¡Œé€‰æ‹©æ€§æœç´¢ä»¥æå–å¤§çº¦2000ä¸ªåŒºåŸŸå»ºè®®ï¼ˆæˆ‘ä»¬åœ¨æ‰€æœ‰å®žéªŒä¸­ä½¿ç”¨é€‰æ‹©æ€§æœç´¢çš„â€œå¿«é€Ÿæ¨¡å¼ï¼ˆfast modeï¼‰â€ï¼‰ã€‚ ç»™å®šå›¾åƒä¸­çš„æ‰€æœ‰å¾—åˆ†åŒºåŸŸï¼Œæˆ‘ä»¬åº”ç”¨è´ªå¿ƒéžæœ€å¤§æŠ‘åˆ¶(greedy non-maximum suppression)ï¼ˆå¯¹äºŽæ¯ä¸ªç±»ç‹¬ç«‹åœ°ï¼‰ï¼Œå¦‚æžœä¸Žçš„é¥­è¾ƒé«˜çš„åŒºåŸŸæœ‰é‡å ï¼Œä¸”IoUå¤§äºŽå­¦ä¹ åˆ°çš„é˜ˆå€¼ï¼Œåˆ™è¯¥æ‹’ç»åŒºåŸŸã€‚ Run-time analysis.ä¸¤ä¸ªå±žæ€§ä½¿æ£€æµ‹æ›´é«˜æ ¡ã€‚ é¦–å…ˆï¼Œæ‰€æœ‰CNNå‚æ•°åœ¨æ‰€æœ‰ç±»åˆ«ä¸­å…±äº«ã€‚ ç¬¬äºŒï¼ŒCNNè®¡ç®—çš„ç‰¹å¾å‘é‡ä¸Žå…¶ä»–å¸¸è§æ–¹æ³•ï¼ˆä¾‹å¦‚å…·æœ‰è§†è§‰è¯è¢‹ç¼–ç çš„ç©ºé—´æ£±é‡‘å­—å¡”ï¼‰ç›¸æ¯”æ˜¯ ä½Žç»´çš„ ã€‚ å”¯ä¸€çš„ç±»ç‰¹å®š(class-specific)è®¡ç®—æ˜¯ç‰¹å¾å’ŒSVMæƒé‡ä¹‹é—´çš„ç‚¹ç§¯å’Œéžæœ€å¤§æŠ‘åˆ¶ã€‚ Training é™¤äº†ç”¨éšæœºåˆå§‹åŒ–çš„21è·¯åˆ†ç±»å±‚ï¼ˆå¯¹äºŽ20ä¸ªVOCç±»åŠ ä¸ŠèƒŒæ™¯ï¼‰æ›¿æ¢CNNçš„ImageNetç‰¹å®šçš„1000è·¯åˆ†ç±»å±‚ä¹‹å¤–ï¼ŒCNNæž¶æž„æ˜¯ä¸å˜çš„ã€‚ æˆ‘ä»¬å°†æ‰€æœ‰region proposalä¸Žä¸€ä¸ªground-truthé‡å ä¸ºIoU&gt;0.5ï¼Œä½œä¸ºè¯¥æ¡†ç±»çš„é˜³æ€§ï¼Œå…¶ä½™ä½œä¸ºé˜´æ€§ã€‚ æˆ‘ä»¬ä»¥0.001çš„å­¦ä¹ é€ŸçŽ‡ï¼ˆåˆå§‹é¢„è®­ç»ƒé€ŸçŽ‡çš„1/10ï¼‰å¼€å§‹SGDï¼Œè¿™å…è®¸ç²¾ç»†è°ƒæ•´è¿›è¡Œï¼Œè€Œä¸æ˜¯ç ´ååˆå§‹åŒ–ã€‚ ä¸€æ—¦æå–ç‰¹å¾å¹¶åº”ç”¨è®­ç»ƒæ ‡ç­¾ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªç±»ä¼˜åŒ–ä¸€ä¸ªçº¿æ€§SVMã€‚ ç”±äºŽè®­ç»ƒæ•°æ®å¤ªå¤§ï¼Œæ— æ³•è®°å¿†ï¼Œæˆ‘ä»¬é‡‡ç”¨æ ‡å‡† hard negative mining method ã€‚ Results on PASCAL VOC 2010-12Visualization, ablation, and modes of errorVisualizing learned features pool-5ï¼Œæ˜¯ç½‘ç»œç¬¬äº”ä¸ªä¹Ÿæ˜¯æœ€åŽä¸€ä¸ªå·åŸºå±‚çš„max-poolå±‚çš„è¾“å‡ºã€‚ï¼ˆæ˜¯ä¸€ä¸ªmax-poolingå±‚ï¼‰ The pool-5 feature map is 6 Ã— 6 Ã— 256 = 9216ç»´ã€‚ å¿½ç•¥è¾¹ç•Œæ•ˆåº”ï¼Œæ¯ä¸ªpool-5å•å…ƒåœ¨åŽŸå§‹227Ã—227åƒç´ è¾“å…¥ä¸­å…·æœ‰195Ã—195åƒç´ çš„æŽ¥æ”¶åœºã€‚ Ablation studies Fc6ä¸Žpool-5å…¨è¿žæŽ¥ï¼Œä¸ºäº†è®¡ç®—ç‰¹å¾ï¼Œä»–å®ƒå°† 4096Ã—9216çš„æƒé‡çŸ©é˜µä¹˜ä»¥pool-5çš„feature map ï¼ˆé‡æ–°å½¢æˆä¸º9216ç»´çŸ¢é‡ï¼‰ï¼Œç„¶åŽæ·»åŠ åå·®çŸ¢é‡ã€‚ Fc7æ˜¯ç½‘ç»œçš„æœ€åŽä¸€å±‚ï¼Œé€šè¿‡å°†ç”±fc 6è®¡ç®—çš„ç‰¹å¾ä¹˜ä»¥ 4096Ã—4096 æƒé‡çŸ©é˜µï¼Œå¹¶ç±»ä¼¼åœ°æ·»åŠ åç½®çŸ¢é‡å’Œåº”ç”¨åŠæ³¢æ•´æµæ¥å®žçŽ°ã€‚ å¤§å¤šæ•°CNNçš„è¡¨ç¤ºèƒ½åŠ›æ¥è‡ªå®ƒçš„å·ç§¯å±‚ï¼Œè€Œä¸æ˜¯æ¥è‡ªå¤§å¾—å¤šçš„å¯†é›†è¿žæŽ¥çš„å±‚ã€‚ All R-CNN variants strongly outperform the three DPM baselines Detection error analysisBounding box regressionSemantic segmentation full fg full+fg The fg strategy slightly outperforms full, indicating that the masked region shape provides a stronger signal, matching our intuition. Conclusion ä¹‹å‰æœ€å¥½çš„æ€§èƒ½ç³»ç»Ÿæ˜¯å°†å¤šä¸ªä½Žçº§å›¾åƒç‰¹å¾ä¸Žæ¥è‡ªå¯¹è±¡æ£€æµ‹å™¨å’Œåœºæ™¯åˆ†ç±»å™¨çš„é«˜çº§ä¸Šä¸‹æ–‡ç»„åˆåœ¨ä¸€èµ·çš„å¤æ‚é›†åˆã€‚ æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç®€å•å’Œå¯æ‰©å±•çš„å¯¹è±¡æ£€æµ‹ç®—æ³•ï¼Œä¸ŽPASCAL VOC 2012ä¸Šçš„æœ€ä½³ä»¥å‰çš„ç»“æžœç›¸æ¯”æä¾›30ï¼…çš„ç›¸å¯¹æ”¹è¿›ã€‚ æˆ‘ä»¬æŽ¨æµ‹â€œsupervised pre-training/domain-speciï¬c ï¬ne-tuningâ€èŒƒä¾‹å°†å¯¹å„ç§æ•°æ®ç¼ºä¹çš„è§†è§‰é—®é¢˜é«˜åº¦æœ‰æ•ˆã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šFused DNN - A deep neural network fusion approach to fast and robust pedestrian detection]]></title>
    <url>%2Fposts%2F2553947436%2F</url>
    <content type="text"><![CDATA[ç›¸å…³çŸ¥è¯†ç‚¹ L1èŒƒæ•° ä¹Ÿç§°ä¸ºæœ€å°ç»å¯¹åå·®ï¼ˆLADï¼‰ï¼Œæœ€å°ç»å¯¹è¯¯å·®ï¼ˆLAEï¼‰ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„ç»å¯¹å·®(S)çš„å’Œ L2èŒƒæ•°ä¹Ÿç§°ä¸ºæœ€å°äºŒä¹˜ã€‚å®ƒåŸºæœ¬ä¸Šæœ€å°åŒ–ç›®æ ‡å€¼(Yi)å’Œä¼°è®¡å€¼(f(xi))ä¹‹é—´çš„å·®(S)çš„å¹³æ–¹çš„å’Œ Abstract æ‰€æå‡ºçš„ç½‘ç»œèžåˆæž¶æž„å…è®¸å¤šä¸ªç½‘ç»œçš„å¹¶è¡Œå¤„ç†æ¥æé«˜é€Ÿåº¦ã€‚ é¦–å…ˆæ˜¯ä¸€ä¸ªæ·±åº¦å·ç§¯ç½‘ç»œè¢«è®­ç»ƒä¸ºä¸€ä¸ªç‰©ä½“æ£€æµ‹å™¨æ¥ç”Ÿæˆæ‰€æœ‰æœ‰å¯èƒ½çš„ä¸åŒå°ºå¯¸å’Œé®æŒ¡çš„è¡Œäººå€™é€‰é›†ã€‚ ç„¶åŽï¼Œå¤šä¸ªæ·±åº¦ç¥žç»ç½‘ç»œè¢«å¹¶è¡Œä½¿ç”¨æ¥ä¹‹åŽæç‚¼è¿™äº›è¡Œäººå€™é€‰é›†ã€‚ æˆ‘ä»¬å¼•å…¥åŸºäºŽè½¯æ‹’ç»çš„ç½‘ç»œèžåˆæ–¹æ³•å°†æ¥è‡ªæ‰€æœ‰ç½‘ç»œçš„è½¯åº¦é‡èžåˆåœ¨ä¸€èµ·ï¼Œä»¥äº§ç”Ÿæœ€ç»ˆç½®ä¿¡åˆ†æ•°ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºŽå°†é€åƒç´ è¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼ˆ pixel-wise semantic segmentation networkï¼‰é›†æˆåˆ°ç½‘ç»œèžåˆæž¶æž„ä¸­ä½œä¸ºè¡Œäººæ£€æµ‹å™¨çš„åŠ å¼ºçš„æ–¹æ³•ã€‚ Introduction Tradeoff between accuracy and speed. å…¶ä»–å› ç´ ï¼Œå¦‚æ‹¥æŒ¤çš„åœºæ™¯ï¼Œéžäººå µå¡žç‰©ä½“(non-person occluding objects)æˆ–ä¸åŒçš„è¡Œäººå¤–è§‚ï¼ˆä¸åŒçš„å§¿åŠ¿æˆ–æœè£…é£Žæ ¼ï¼‰ä¹Ÿä½¿è¿™ä¸ªReal-timeè¡Œäººæ£€æµ‹é—®é¢˜å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ è¡Œäººæ£€æµ‹çš„ä¸€èˆ¬æ¡†æž¶å¯ä»¥åˆ†è§£ä¸ºï¼š region proposal generation, feature extraction, pedestrian verification Fused Deep Neural Network(F-DNN) è¯¥æž¶æž„åŒ…æ‹¬è¡Œäººpedestrian candidiate generatorï¼Œå…¶é€šè¿‡è®­ç»ƒæ·±å·ç§¯ç¥žç»ç½‘ç»œèŽ·å¾—ä»¥ï¼Œä»Žè€Œå…·æœ‰é«˜æ£€æµ‹çŽ‡ï¼Œè™½ç„¶æœ‰å¤§çš„å‡é˜³æ€§çŽ‡ã€‚ ä½¿ç”¨æ·±åº¦æ‰©å±•å·ç§¯å’Œä¸Šä¸‹æ–‡èšåˆçš„å¹¶è¡Œè¯­ä¹‰åˆ†å‰²ç½‘ç»œ[30]ä¸ºå€™é€‰è¡Œäººæä¾›äº†å¦ä¸€ä¸ªè½¯çš„ä¿¡ä»»æŠ•ç¥¨ï¼Œå®ƒè¿›ä¸€æ­¥ä¸Žå€™é€‰ç”Ÿæˆå™¨å’Œåˆ†ç±»ç½‘ç»œèžåˆã€‚ The Fused Deep Neural Network æå‡ºçš„ç½‘ç»œæž¶æž„åŒ…æ‹¬è¡Œäººå€™é€‰ç”Ÿæˆå™¨ï¼Œåˆ†ç±»ç½‘ç»œå’Œåƒç´ çº§è¯­ä¹‰åˆ†å‰²ç½‘ç»œã€‚ SSD: a single shot multi-box detector(å•é•œå¤´å¤šç®±æ£€æµ‹å™¨)ï¼Œè¡Œäººå€™é€‰ç”Ÿæˆå™¨æ˜¯ä¸€ä¸ªsingle shot multi-box detectorï¼ˆSSDï¼‰ æ¯ä¸ªè¡Œäººå€™é€‰è€…ä¸Žå…¶å®šä½BBåæ ‡å’Œç½®ä¿¡åº¦å¾—åˆ†ç›¸å…³è”ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç½‘ç»œèžåˆæ–¹æ³•â€”â€”ç§°ä¸ºåŸºäºŽè½¯æ‹’ç»çš„ç½‘ç»œèžåˆï¼ˆSNFï¼‰ã€‚å¹¶éžæ˜¯æ‰§è¡ŒæŽ¥å—æˆ–æ‹’ç»å€™é€‰è€…çš„ç¡¬äºŒè¿›åˆ¶åˆ†ç±»ï¼Œè€Œæ˜¯åŸºäºŽæ¥è‡ªåˆ†ç±»å™¨çš„å€™é€‰è€…çš„ èšåˆåº¦ æ¥æå‡æˆ–æŠ˜æ‰£è¡Œäººå€™é€‰è€…çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚ æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åˆ©ç”¨å…·æœ‰è¯­ä¹‰åˆ†å‰²ï¼ˆSSï¼‰çš„ä¸Šä¸‹æ–‡èšé›†æ‰©å±•å·ç§¯ç½‘ç»œï¼ˆcontext aggregation dilated convolutional network with semantic segmentationï¼‰ä½œä¸ºå¦ä¸€ä¸ªåˆ†ç±»å™¨å¹¶å°†å…¶é›†æˆåˆ°æˆ‘ä»¬çš„ç½‘ç»œèžåˆæž¶æž„ä¸­çš„æ–¹æ³•ã€‚ä½†æ˜¯åœ¨é€Ÿåº¦ä¸Šä¼šå˜å¾—ç‰¹åˆ«æ…¢ã€‚ Pedestrian Candidate Generator SSDæ˜¯å…·æœ‰æˆªæ–­VGG16(truncated VGG16)ä½œä¸ºåŸºç¡€ç½‘ç»œçš„å‰é¦ˆå·ç§¯ç½‘ç»œã€‚ SSDçš„ç»“æž„ï¼š L2å½’ä¸€åŒ–æŠ€æœ¯ç”¨äºŽç¼©å°ç‰¹å¾é‡ å¯¹äºŽå¤§å°ä¸ºmÃ—nÃ—pçš„æ¯ä¸ªè¾“å‡ºå±‚ï¼Œåœ¨æ¯ä¸ªä½ç½®å¤„è®¾ç½®ä¸åŒå°ºåº¦å’Œçºµæ¨ªæ¯”çš„ä¸€ç»„é»˜è®¤BBã€‚ å°†3Ã—3Ã—pä¸ªå·ç§¯å†…æ ¸åº”ç”¨äºŽæ¯ä¸ªä½ç½®ä»¥äº§ç”Ÿå…³äºŽé»˜è®¤BBä½ç½®çš„åˆ†ç±»åˆ†æ•°å’ŒBBä½ç½®åç§»ã€‚ è®­ç»ƒçš„ç›®æ ‡å‡½æ•°æ˜¯ï¼š Classiï¬cation Network and Soft-rejection based DNN Fusion åˆ†ç±»ç½‘ç»œç”±å¤šä¸ªäºŒå…ƒåˆ†ç±»æ·±å±‚ç¥žç»ç½‘ç»œç»„æˆï¼Œè¿™äº›ç½‘ç»œåœ¨ç¬¬ä¸€é˜¶æ®µçš„ç”Ÿæˆçš„è¡Œäººå€™é€‰é›†ä¸­è®­ç»ƒã€‚ SNFï¼šè€ƒè™‘ä¸€ä¸ªè¡Œäººå€™é€‰äººå’Œä¸€ä¸ªåˆ†ç±»å™¨ã€‚å¦‚æžœåˆ†ç±»å™¨å¯¹å€™é€‰äººæœ‰é«˜çš„ä¿¡ä»»åº¦ï¼Œæˆ‘ä»¬é€šè¿‡ä¹˜ä»¥å¤§äºŽ1çš„ç½®ä¿¡å› å­ä¹˜ä»¥å€™é€‰å‘ç”Ÿå™¨æ¥æé«˜å…¶åŽŸå§‹åˆ†æ•°ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬ä»¥å°äºŽ1çš„ç¼©æ”¾å› å­å‡å°å…¶å¾—åˆ†ã€‚æˆ‘ä»¬å°†â€œç½®ä¿¡â€å®šä¹‰ä¸ºè‡³å°‘ä¸ºacçš„åˆ†ç±»æ¦‚çŽ‡ã€‚ä¸ºäº†èžåˆæ‰€æœ‰Mä¸ªåˆ†ç±»å™¨ï¼Œæˆ‘ä»¬å°†å€™é€‰è€…çš„åŽŸå§‹ä¿¡ä»»å¾—åˆ†ä¸Žåˆ†ç±»ç½‘ç»œä¸­æ‰€æœ‰åˆ†ç±»å™¨çš„ä¿¡ä»»ç¼©æ”¾å› å­çš„ä¹˜ç§¯ç›¸ä¹˜ã€‚ SNFèƒŒåŽçš„å…³é”®æ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬ä¸ç›´æŽ¥æŽ¥å—æˆ–æ‹’ç»ä»»ä½•å€™é€‰è¡Œäººï¼Œè€Œæ˜¯åŸºäºŽåˆ†ç±»æ¦‚çŽ‡çš„å› ç´ æ¥æ‰©å±•å®ƒä»¬ã€‚ Pixel-wise semantic segmentation for object detection reinforcement ä¸ºäº†æ‰§è¡Œå¯†é›†é¢„æµ‹ï¼ŒSSç½‘ç»œç”±å®Œå…¨å·ç§¯çš„VGG16ç½‘ç»œç»„æˆï¼Œå…¶é€‚åº”äºŽä½œä¸ºå‰ç«¯é¢„æµ‹æ¨¡å—çš„æ‰©å±•å·ç§¯ï¼Œå…¶è¾“å‡ºè¢«é¦ˆé€åˆ°å¤šå°ºåº¦ä¸Šä¸‹æ–‡èšåˆæ¨¡å—ï¼Œè¯¥å¤šå°ºåº¦ä¸Šä¸‹æ–‡èšåˆæ¨¡å—ç”±å®Œå…¨å·ç§¯ç½‘ç»œç»„æˆï¼Œå…¶å·ç§¯å±‚å…·æœ‰å¢žåŠ æ‰©å¼ å› å­ã€‚ è¾“å…¥å›¾åƒè¢«ç¼©æ”¾å¹¶ç”±SSç½‘ç»œç›´æŽ¥å¤„ç†ï¼ŒSSç½‘ç»œäº§ç”Ÿå…·æœ‰æ˜¾ç¤ºå‡ºè¡Œäººç±»æ¿€æ´»åƒç´ çš„ä¸€ç§é¢œè‰²å’Œæ˜¾ç¤ºå‡ºèƒŒæ™¯çš„å…¶ä»–é¢œè‰²çš„äºŒè¿›é®ç½©ã€‚ æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ç­–ç•¥æ¥èžåˆç»“æžœï¼šå¦‚æžœè¡Œäººåƒç´ å æ®å€™é€‰BBåŒºåŸŸçš„è‡³å°‘20ï¼…ï¼Œæˆ‘ä»¬æŽ¥å—å€™é€‰è€…å¹¶ä¿æŒå…¶å¾—åˆ†ä¸å˜; å¦åˆ™ï¼Œæˆ‘ä»¬åº”ç”¨SNFæ¥ç¼©æ”¾åŽŸå§‹çš„ä¿¡ä»»åˆ†æ•°ã€‚ Experiments and result analysisData and evaluation settingsTraining details and results ç¡¬æ‹’ç»ï¼ˆHard Rejectionï¼‰ è¢«å®šä¹‰ä¸ºæ¶ˆé™¤ç”±ä»»ä½•åˆ†ç±»å™¨åˆ†ç±»ä¸ºå‡é˜³æ€§çš„ä»»ä½•å€™é€‰è€…ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šRobust Real-Time Face Detection]]></title>
    <url>%2Fposts%2F2903903730%2F</url>
    <content type="text"><![CDATA[çŸ¥è¯†ç‚¹ å‚…é‡Œå¶å˜æ¢çš„ä¸€ä¸ªæŽ¨è®ºï¼š ä¸€ä¸ªæ—¶åŸŸä¸‹çš„å¤æ‚ä¿¡å·å‡½æ•°å¯ä»¥åˆ†è§£æˆå¤šä¸ªç®€å•ä¿¡å·å‡½æ•°çš„å’Œï¼Œç„¶åŽå¯¹å„ä¸ªå­ä¿¡å·å‡½æ•°åšå‚…é‡Œå¶å˜æ¢å¹¶å†æ¬¡æ±‚å’Œï¼Œå°±æ±‚å‡ºäº†åŽŸä¿¡å·çš„å‚…é‡Œå¶å˜æ¢ã€‚ å·ç§¯å®šç†(Convolution Theorem)ï¼šä¿¡å·få’Œä¿¡å·gçš„å·ç§¯çš„å‚…é‡Œå¶å˜æ¢ï¼Œç­‰äºŽfã€gå„è‡ªçš„å‚…é‡Œå¶å˜æ¢çš„ç§¯ æ•´ä¸ªè¿‡ç¨‹çš„æ ¸å¿ƒå°±æ˜¯â€œï¼ˆåè½¬ï¼‰ï¼Œç§»åŠ¨ï¼Œä¹˜ç§¯ï¼Œæ±‚å’Œâ€ äºŒç»´å·ç§¯ æ•°å­¦å®šä¹‰ äºŒç»´å·ç§¯åœ¨å›¾åƒå¤„ç†ä¸­ä¼šç»å¸¸é‡åˆ°ï¼Œå›¾åƒå¤„ç†ä¸­ç”¨åˆ°çš„å¤§å¤šæ˜¯äºŒç»´å·ç§¯çš„ç¦»æ•£å½¢å¼ï¼š å›¾åƒå¤„ç†ä¸­çš„äºŒç»´å·ç§¯ï¼ŒäºŒç»´å·ç§¯å°±æ˜¯ä¸€ç»´å·ç§¯çš„æ‰©å±•ï¼ŒåŽŸç†å·®ä¸å¤šã€‚æ ¸å¿ƒè¿˜æ˜¯ï¼ˆåè½¬ï¼‰ï¼Œç§»åŠ¨ï¼Œä¹˜ç§¯ï¼Œæ±‚å’Œã€‚è¿™é‡ŒäºŒç»´çš„åè½¬å°±æ˜¯å°†å·ç§¯æ ¸æ²¿åå¯¹è§’çº¿ç¿»è½¬ï¼Œæ¯”å¦‚ï¼šä¹‹åŽï¼Œå·ç§¯æ ¸åœ¨äºŒç»´å¹³é¢ä¸Šå¹³ç§»ï¼Œå¹¶ä¸”å·ç§¯æ ¸çš„æ¯ä¸ªå…ƒç´ ä¸Žè¢«å·ç§¯å›¾åƒå¯¹åº”ä½ç½®ç›¸ä¹˜ï¼Œå†æ±‚å’Œã€‚é€šè¿‡å·ç§¯æ ¸çš„ä¸æ–­ç§»åŠ¨ï¼Œæˆ‘ä»¬å°±æœ‰äº†ä¸€ä¸ªæ–°çš„å›¾åƒï¼Œ è¿™ä¸ªå›¾åƒå®Œå…¨ç”±å·ç§¯æ ¸åœ¨å„ä¸ªä½ç½®æ—¶çš„ä¹˜ç§¯æ±‚å’Œçš„ç»“æžœç»„æˆã€‚ å·´æ‹¿èµ«ç©ºé—´ï¼šæ›´ç²¾ç¡®åœ°è¯´ï¼Œå·´æ‹¿èµ«ç©ºé—´æ˜¯ä¸€ä¸ªå…·æœ‰èŒƒæ•°å¹¶å¯¹æ­¤èŒƒæ•°å®Œå¤‡çš„å‘é‡ç©ºé—´ã€‚ è®¸å¤šåœ¨æ•°å­¦åˆ†æžä¸­å­¦åˆ°çš„æ— é™ç»´å‡½æ•°ç©ºé—´éƒ½æ˜¯å·´æ‹¿èµ«ç©ºé—´ã€‚ å·´æ‹¿èµ«ç©ºé—´æœ‰ä¸¤ç§å¸¸è§çš„ç±»åž‹ï¼šâ€œå®žå·´æ‹¿èµ«ç©ºé—´â€åŠâ€œå¤å·´æ‹¿èµ«ç©ºé—´â€ï¼Œåˆ†åˆ«æ˜¯æŒ‡å°†å·´æ‹¿èµ«ç©ºé—´çš„å‘é‡ç©ºé—´å®šä¹‰äºŽç”±å®žæ•°æˆ–å¤æ•°ç»„æˆçš„åŸŸä¹‹ä¸Šã€‚ Overcompleteï¼š å¯¹äºŽBanach space Xä¸­çš„ä¸€ä¸ªå­é›†ï¼Œå¦‚æžœXä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½å¯ä»¥åˆ©ç”¨å­é›†ä¸­çš„å…ƒç´ åœ¨èŒƒæ•°å†…è¿›è¡Œæœ‰é™çº¿æ€§ç»„åˆæ¥è‰¯å¥½è¿‘ä¼¼ï¼Œåˆ™è¯¥ç³»ç»ŸXæ˜¯å®Œå¤‡Completeçš„ã€‚ è¯¥å®Œå¤‡ç³»ç»Ÿæ˜¯è¿‡å®Œå¤‡ï¼ˆOvercompleteï¼‰çš„ï¼Œå¦‚æžœä»Žå­é›†ä¸­ç§»åŽ»ä¸€ä¸ªå…ƒç´ ï¼Œè¯¥ç³»ç»Ÿä¾æ—§æ˜¯å®Œå¤‡çš„ï¼Œåˆ™è¯¥ç³»ç»Ÿç§°ä¸ºè¿‡å®Œå¤‡çš„ã€‚ åœ¨ä¸åŒçš„ç ”ç©¶ä¸­ï¼Œæ¯”å¦‚ä¿¡å·å¤„ç†å’ŒåŠŸèƒ½è¿‘ä¼¼ï¼Œè¿‡å®Œå¤‡å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜è¾¾åˆ°ä¸€ä¸ªæ›´ç¨³å®šã€æ›´å¥å£®ï¼Œæˆ–è€…ç›¸æ¯”äºŽä½¿ç”¨åŸºå‘é‡æ›´ç´§å‡‘çš„åˆ†è§£ã€‚ å¦‚æžœ # (basis vectoråŸºå‘é‡)&gt;è¾“å…¥çš„ç»´åº¦ï¼Œåˆ™æˆ‘ä»¬æœ‰ä¸€ä¸ªovercomplete representation. ROCæ›²çº¿ï¼šåœ¨ä¿¡å·æ£€æµ‹ç†è®ºä¸­ï¼ŒæŽ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼ˆreceiver operating characteristic curveï¼Œæˆ–è€…å«ROCæ›²çº¿ï¼‰æ˜¯ä¸€ç§åæ ‡å›¾å¼çš„åˆ†æžå·¥å…·ï¼Œç”¨äºŽ (1) é€‰æ‹©æœ€ä½³çš„ä¿¡å·ä¾¦æµ‹æ¨¡åž‹ã€èˆå¼ƒæ¬¡ä½³çš„æ¨¡åž‹ã€‚ (2) åœ¨åŒä¸€æ¨¡åž‹ä¸­è®¾å®šæœ€ä½³é˜ˆå€¼ã€‚ ä»Ž (0, 0) åˆ° (1,1) çš„å¯¹è§’çº¿å°†ROCç©ºé—´åˆ’åˆ†ä¸ºå·¦ä¸Šï¼å³ä¸‹ä¸¤ä¸ªåŒºåŸŸï¼Œåœ¨è¿™æ¡çº¿çš„ ä»¥ä¸Šçš„ç‚¹ ä»£è¡¨äº†ä¸€ä¸ª å¥½ çš„åˆ†ç±»ç»“æžœï¼ˆèƒœè¿‡éšæœºåˆ†ç±»ï¼‰ï¼Œè€Œåœ¨è¿™æ¡çº¿ ä»¥ä¸‹çš„ç‚¹ ä»£è¡¨äº† å·® çš„åˆ†ç±»ç»“æžœï¼ˆåŠ£äºŽéšæœºåˆ†ç±»ï¼‰ã€‚ å®Œç¾Žçš„é¢„æµ‹æ˜¯ä¸€ä¸ªåœ¨å·¦ä¸Šè§’çš„ç‚¹. æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰ï¼šROCæ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ï¼Œè‹¥éšæœºæŠ½å–ä¸€ä¸ªé˜³æ€§æ ·æœ¬å’Œä¸€ä¸ªé˜´æ€§æ ·æœ¬ï¼Œåˆ†ç±»å™¨æ­£ç¡®åˆ¤æ–­é˜³æ€§æ ·æœ¬çš„å€¼é«˜äºŽé˜´æ€§æ ·æœ¬ä¹‹æœºçŽ‡=AUCã€‚ç®€å•è¯´ï¼šAUCå€¼è¶Šå¤§çš„åˆ†ç±»å™¨ï¼Œæ­£ç¡®çŽ‡è¶Šé«˜ã€‚ Abstract ä»‹ç»ä¸€ä¸ªè„¸éƒ¨æ£€æµ‹æ¡†æž¶ã€‚ ä¸‰ä¸ªè´¡çŒ®ï¼š å¼•å…¥æ–°å›¾åƒè¡¨ç¤ºâ€”â€”ç§°ä¸ºâ€œç§¯åˆ†å›¾åƒâ€ï¼Œå…¶å…è®¸æˆ‘ä»¬çš„æ£€æµ‹å™¨éžå¸¸å¿«é€Ÿåœ°è®¡ç®—æ‰€ä½¿ç”¨çš„ç‰¹å¾ã€‚ æå‡ºä¸€ä¸ªåˆ©ç”¨AdaBostå­¦ä¹ ç®—æ³•æž„å»ºçš„ç®€å•æœ‰æ•ˆçš„åˆ†ç±»å™¨ï¼Œæ¥ä»Žæžå¤§æ½œåœ¨ç‰¹å¾é›†ä¸­é€‰å‡ºå¾ˆå°‘çš„å…³é”®è§†è§‰ç‰¹å¾ã€‚ åœ¨çº§è”ä¸­ç»„åˆåˆ†ç±»å™¨ï¼Œä»Žè€Œå¿«é€Ÿä¸¢å¼ƒå›¾åƒçš„èƒŒæ™¯åŒºåŸŸï¼ŒåŒæ—¶åœ¨æœ‰å¯èƒ½çš„é¢éƒ¨åŒºåŸŸä¸ŠèŠ±è´¹æ›´å¤šçš„è®¡ç®—ã€‚ Introduction Haar Basis å‡½æ•°ï¼š Integral image: ç±»ä¼¼äºŽè®¡ç®—æœºå›¾å½¢å­¦ä¸­åˆ©ç”¨æ±‚å’ŒåŒºåŸŸè¡¨æ¥è¿›è¡Œçº¹ç†æ˜ å°„ã€‚ Haar-like featuresï¼šå°±æ˜¯mountä¸¤ä¸ªæˆ–å¤šä¸ªåŒºåŸŸçš„åƒç´ å€¼ä¹‹å’Œçš„å·®å€¼ã€‚ AdaBoostï¼šè‡ªé€‚åº”å¢žå¼ºï¼Œ å…·ä½“è¯´æ¥ï¼Œæ•´ä¸ªAdaboost è¿­ä»£ç®—æ³•å°±3æ­¥ï¼š åˆå§‹åŒ–è®­ç»ƒæ•°æ®çš„æƒå€¼åˆ†å¸ƒã€‚å¦‚æžœæœ‰Nä¸ªæ ·æœ¬ï¼Œåˆ™æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬æœ€å¼€å§‹æ—¶éƒ½è¢«èµ‹äºˆç›¸åŒçš„æƒå€¼ï¼š1/Nã€‚ è®­ç»ƒå¼±åˆ†ç±»å™¨ã€‚å…·ä½“è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚æžœæŸä¸ªæ ·æœ¬ç‚¹å·²ç»è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆåœ¨æž„é€ ä¸‹ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œå®ƒçš„æƒå€¼å°±è¢«é™ä½Žï¼›ç›¸åï¼Œå¦‚æžœæŸä¸ªæ ·æœ¬ç‚¹æ²¡æœ‰è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆå®ƒçš„æƒå€¼å°±å¾—åˆ°æé«˜ã€‚ç„¶åŽï¼Œæƒå€¼æ›´æ–°è¿‡çš„æ ·æœ¬é›†è¢«ç”¨äºŽè®­ç»ƒä¸‹ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹å¦‚æ­¤è¿­ä»£åœ°è¿›è¡Œä¸‹åŽ»ã€‚ å°†å„ä¸ªè®­ç»ƒå¾—åˆ°çš„å¼±åˆ†ç±»å™¨ç»„åˆæˆå¼ºåˆ†ç±»å™¨ã€‚å„ä¸ªå¼±åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹ç»“æŸåŽï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®çŽ‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå¤§çš„å†³å®šä½œç”¨ï¼Œè€Œé™ä½Žåˆ†ç±»è¯¯å·®çŽ‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œä½¿å…¶åœ¨æœ€ç»ˆçš„åˆ†ç±»å‡½æ•°ä¸­èµ·ç€è¾ƒå°çš„å†³å®šä½œç”¨ã€‚æ¢è¨€ä¹‹ï¼Œè¯¯å·®çŽ‡ä½Žçš„å¼±åˆ†ç±»å™¨åœ¨æœ€ç»ˆåˆ†ç±»å™¨ä¸­å çš„æƒé‡è¾ƒå¤§ï¼Œå¦åˆ™è¾ƒå°ã€‚ çº§è”æ£€æµ‹è¿‡ç¨‹çš„ç»“æž„åŸºæœ¬ä¸Šæ˜¯ç®€å¹¶å†³ç­–æ ‘çš„ç»“æž„ Features åŸºäºŽç‰¹å¾çš„ç³»ç»Ÿæ“ä½œè‚¯å®šæ¯”ä¸€ä¸ªåŸºäºŽåƒç´ çš„ç³»ç»Ÿæ›´æ›´å¿« ï¼ˆTwo-rectangle featureï¼‰ä¸¤çŸ©å½¢ç‰¹å¾çš„å€¼æ˜¯ä¸¤ä¸ªçŸ©å½¢åŒºåŸŸå†…çš„åƒç´ ä¹‹å’Œçš„å·® (Three-rectangle feature)ä¸‰çŸ©å½¢ç‰¹å¾è®¡ç®—ä»Žä¸­å¿ƒçŸ©å½¢ä¸­çš„å’Œå‡åŽ»çš„ä¸¤ä¸ªå¤–éƒ¨çŸ©å½¢çš„å’Œã€‚ (Four-rectangle feature)å››çŸ©å½¢ç‰¹å¾è®¡ç®—çŸ©å½¢å¯¹è§’çº¿å¯¹ä¹‹é—´çš„å·®å¼‚ã€‚ çŸ©é˜µç‰¹å¾=ä»Žç°è‰²çŸ©å½¢ä¸­çš„åƒç´ çš„å’Œä¸­å‡åŽ»ä½äºŽç™½è‰²çŸ©å½¢å†…çš„åƒç´ çš„å’Œã€‚ Integral Image çŸ©é˜µç‰¹å¾å¯ä»¥é€šè¿‡å›¾åƒçš„ä¸­é—´è¡¨ç¤ºæ¥å¿«é€Ÿè®¡ç®—ï¼Œä»Žè€Œæˆä¸ºIntegral Image. ç§¯åˆ†å›¾çš„æ¯ä¸€ç‚¹ï¼ˆx, yï¼‰çš„å€¼æ˜¯åŽŸå›¾ä¸­å¯¹åº”ä½ç½®çš„å·¦ä¸Šè§’åŒºåŸŸçš„æ‰€æœ‰å€¼å¾—å’Œã€‚ ç§¯åˆ†å›¾æ¯ä¸€ç‚¹çš„ï¼ˆx, yï¼‰å€¼æ˜¯ï¼š ä½ç½®xï¼Œyå¤„çš„ç§¯åˆ†å›¾åƒåŒ…å«xï¼Œyï¼ˆåŒ…æ‹¬ç«¯ç‚¹ï¼‰ä¸Šæ–¹å’Œå·¦ä¾§çš„åƒç´ çš„å’Œ: ii(x, y) is the integral image i(x, y) is the original image sï¼ˆxï¼Œyï¼‰æ˜¯ç´¯ç§¯è¡Œå’Œ s(x, âˆ’1) = 0, ii(âˆ’1, y) = 0) ç§¯åˆ†å›¾å¯ä»¥åªéåŽ†ä¸€æ¬¡å›¾åƒå³å¯æœ‰æ•ˆçš„è®¡ç®—å‡ºæ¥ ä½¿ç”¨ç§¯åˆ†å›¾åƒï¼Œå¯ä»¥åœ¨å››ä¸ªé˜µåˆ—å‚è€ƒä¸­è®¡ç®—ä»»ä½•çŸ©å½¢å’Œã€‚ Two-rectangle featureï¼šéœ€è¦6ä¸ªé˜µåˆ—å‚è€ƒ Three-rectangle featureï¼šéœ€è¦8ä¸ªé˜µåˆ—å‚è€ƒ Four-rectangle featureï¼šéœ€è¦9ä¸ªé˜µåˆ—å‚è€ƒ åœ¨çº¿æ€§è¿ç®—ï¼ˆä¾‹å¦‚f.gï¼‰çš„æƒ…å†µä¸‹ï¼Œå¦‚æžœå…¶é€†è¢«åº”ç”¨äºŽç»“æžœï¼Œåˆ™ä»»ä½•å¯é€†çº¿æ€§ç®—å­å¯ä»¥åº”ç”¨äºŽfæˆ–gã€‚ ä¾‹å¦‚åœ¨å·ç§¯çš„æƒ…å†µä¸‹ï¼Œå¦‚æžœå¯¼æ•°è¿ç®—ç¬¦è¢«åº”ç”¨äºŽå›¾åƒå’Œå·ç§¯æ ¸ï¼Œåˆ™ç»“æžœå¿…é¡»è¢«åŒé‡ç§¯åˆ†. å¦‚æžœfå’Œgçš„å¯¼æ•°ç¨€ç–ï¼ˆæˆ–å¯ä»¥è¿™æ ·åšï¼‰ï¼Œå·ç§¯å¯ä»¥æ˜¾ç€åŠ é€Ÿã€‚ ç±»ä¼¼çš„ä¸€ä¸ªè®¤è¯†æ˜¯ï¼šå¦‚æžœå…¶é€†è¢«åº”ç”¨äºŽgï¼Œåˆ™ä¸€ä¸ªå¯é€†çº¿æ€§ç®—å­å¯ä»¥åº”ç”¨äºŽfã€‚ åœ¨è¯¥æ¡†æž¶ä¸­è§‚å¯Ÿï¼ŒçŸ©å½¢å’Œçš„è®¡ç®—å¯ä»¥è¡¨ç¤ºä¸ºç‚¹ç§¯iÂ·rï¼Œå…¶ä¸­iæ˜¯å›¾åƒï¼Œræ˜¯box carå›¾åƒï¼ˆåœ¨æ„Ÿå…´è¶£çš„çŸ©å½¢å†…çš„å€¼ä¸º1ï¼Œå¤–é¢æ˜¯0ï¼‰ã€‚ æ­¤æ“ä½œå¯ä»¥é‡å†™ï¼š ç§¯åˆ†å›¾åƒå®žé™…ä¸Šæ˜¯å›¾åƒçš„äºŒé‡ç§¯åˆ†ï¼ˆé¦–å…ˆæ²¿è¡Œï¼Œç„¶åŽæ²¿åˆ—ï¼‰ã€‚ çŸ©å½¢çš„äºŒé˜¶å¯¼æ•°ï¼ˆç¬¬ä¸€è¡Œåœ¨è¡Œä¸­ï¼Œç„¶åŽåœ¨åˆ—ä¸­ï¼‰åœ¨çŸ©å½¢çš„è§’å¤„äº§ç”Ÿå››ä¸ªdeltaå‡½æ•°ã€‚ ç¬¬äºŒç‚¹ç§¯çš„è¯„ä¼°é€šè¿‡å››ä¸ªé˜µåˆ—è®¿é—®æ¥å®Œæˆã€‚ Feature Discussion ä¸Žå¯æ“çºµæ»¤æ³¢å™¨ï¼ˆSteerable filtersï¼‰ç­‰æ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ï¼ŒçŸ©å½¢ç‰¹æ€§æœ‰ç‚¹åŽŸå§‹ã€‚ å¯æŽ§æ»¤æ³¢å™¨å¯¹è¾¹ç•Œçš„è¯¦ç»†åˆ†æžï¼Œå›¾åƒåŽ‹ç¼©å’Œçº¹ç†åˆ†æžçš„éžå¸¸æœ‰ç”¨ã€‚ ç”±äºŽæ­£äº¤æ€§ä¸æ˜¯è¿™ä¸ªç‰¹å¾é›†çš„ä¸­å¿ƒï¼Œæˆ‘ä»¬é€‰æ‹©ç”Ÿæˆä¸€ä¸ªéžå¸¸å¤§è€Œä¸”å„ç§å„æ ·çš„çŸ©å½¢ç‰¹å¾é›†ã€‚ ä»Žç»éªŒä¸Šçœ‹ï¼Œä¼¼ä¹ŽçŸ©å½¢ç‰¹å¾é›†æä¾›äº†ä¸°å¯Œçš„å›¾åƒè¡¨ç¤ºï¼Œèƒ½æ”¯æŒæœ‰æ•ˆçš„å­¦ä¹ ã€‚ ä¸ºäº†åˆ©ç”¨ç§¯åˆ†å›¾åƒæŠ€æœ¯çš„è®¡ç®—æœ‰äº‹ï¼Œè€ƒè™‘ç”¨æ›´å¸¸è§„çš„æ–¹æ³•åŽ»è®¡ç®—å›¾åƒé‡‘å­—å¡”ã€‚ åƒå¤§å¤šæ•°é¢éƒ¨æ£€æµ‹ç³»ç»Ÿä¸€æ ·ï¼Œæˆ‘ä»¬çš„æ£€æµ‹å™¨åœ¨è®¸å¤šå°ºåº¦æ‰«æè¾“å…¥; ä»Žä»¥å°ºå¯¸ä¸º24Ã—24åƒç´ æ£€æµ‹é¢éƒ¨çš„åŸºæœ¬åˆ»åº¦å¼€å§‹ï¼Œåœ¨12ä¸ªåˆ»åº¦ä»¥å¤§äºŽä¸Šä¸€ä¸ªçš„1.25å€çš„å› å­æ‰«æ384Ã—288åƒç´ çš„å›¾åƒã€‚ Learning Classification Functions ç»™å®šæ£€æµ‹å™¨çš„åŸºæœ¬åˆ†è¾¨çŽ‡æ˜¯24Ã—24ï¼ŒçŸ©å½¢ç‰¹å¾çš„ç©·å°½é›†æ˜¯ç›¸å½“å¤§çš„ï¼Œ160000. æˆ‘ä»¬çš„å‡è®¾æ˜¯ï¼Œç”±å®žéªŒè¯æ˜Žï¼Œéžå¸¸å°‘æ•°çš„çŸ©å½¢ç‰¹å¾å¯ä»¥ç»„åˆå½¢æˆä¸€ä¸ªæœ‰æ•ˆçš„åˆ†ç±»å™¨ã€‚ ä¸»è¦çš„æŒ‘æˆ˜æ˜¯æ‰¾åˆ°è¿™äº›åŠŸèƒ½ã€‚ Adaboostï¼šå°†å¤šä¸ªå¼±åˆ†ç±»å™¨ç»„åˆæˆä¸€ä¸ªå¼ºåˆ†ç±»å™¨ã€‚ï¼ˆä¸€ä¸ªç®€å•å­¦ä¹ ç®—æ³•å«åšweak learnerï¼‰ã€‚ ä¼ ç»Ÿçš„çš„AdaBoostè¿‡ç¨‹å¯ä»¥å®¹æ˜“åœ°è§£é‡Šä¸ºè´ªå¿ƒç‰¹å¾é€‰æ‹©è¿‡ç¨‹ã€‚ ä¸€ä¸ª æŒ‘æˆ˜ æ˜¯å°†å¤§çš„æƒé‡ä¸Žæ¯ä¸ªè‰¯å¥½çš„åˆ†ç±»å‡½æ•°ç›¸å…³è”ï¼Œå¹¶å°†è¾ƒå°çš„æƒé‡ä¸Žè¾ƒå·®çš„å‡½æ•°ç›¸å…³è”ã€‚ AdaBoostæ˜¯ä¸€ä¸ªç”¨äºŽæœç´¢å°‘æ•°å…·æœ‰æ˜¾ç€å“ç§çš„è‰¯å¥½â€œç‰¹å¾â€çš„æœ‰æ•ˆç¨‹åºã€‚ å°†ä¸€ä¸ªweak learné™åˆ¶åˆ°åˆ†ç±»å‡½æ•°å‡ ä½•ä¸­ï¼Œæ¯ä¸€ä¸ªå‡½æ•°éƒ½åªä¾èµ–äºŽä¸€ä¸ªå•ä¸€çš„ç‰¹å¾ã€‚ è‹¥å­¦ä¹ å®£å‘é€‰æ‹©å•ä¸€çš„èƒ½å¤Ÿæœ€å¥½åˆ†å¼€æ­£å’Œè´Ÿæ ·æœ¬çš„çŸ©å½¢ç‰¹å¾ã€‚ å¯¹äºŽæ¯ä¸€ä¸ªç‰¹å¾ï¼Œweak learnerå†³å®šæœ€ä¼˜åˆ†ç±»å‡½æ•°é˜ˆå€¼ï¼Œä»Žè€Œå¯ä»¥ä½¿å¾—æœ€å°‘æ•°ç›®çš„æ ·æœ¬è¢«é”™åˆ†ã€‚ ä¸€ä¸ªå¼±åˆ†ç±»å™¨h(x, f, p, Î¸)å› æ­¤åŒ…å«ä¸€ä¸ªç‰¹å¾fï¼Œä¸€ä¸ªé˜ˆå€¼Î¸ï¼Œä¸€ä¸ªæ˜¾ç¤ºä¸ç­‰å¼æ–¹å‘çš„æžæ€§pï¼š è¿™é‡Œxæ˜¯ä¸€ä¸ªå›¾ç‰‡24*24åƒç´ çš„å­çª—å£ã€‚ æˆ‘ä»¬ä½¿ç”¨çš„å¼±åˆ†ç±»å™¨ï¼ˆé˜ˆå€¼å•ä¸€ç‰¹å¾ï¼‰å¯ä»¥è¢«è§†ä¸ºå•èŠ‚ç‚¹å†³ç­–æ ‘ã€‚ Boosting ç®—æ³• ï¼šTæ˜¯åˆ©ç”¨æ¯ä¸ªå•ä¸ªç‰¹å¾æž„é€ çš„å‡è®¾ï¼Œæœ€ç»ˆå‡è®¾æ˜¯Tä¸ªå‡è®¾çš„åŠ æƒçº¿æ€§ç»„åˆï¼Œå…¶ä¸­æƒé‡ä¸Žè®­ç»ƒè¯¯å·®æˆåæ¯”ã€‚ ç»™å®šæ ·æœ¬å›¾ç‰‡(x1, y1), (x2, y2), â€¦, (xn, yn)ã€‚å…¶ä¸­yi=0, 1åˆ†åˆ«ä¸ºè´Ÿæ ·æœ¬å’Œæ­£æ ·æœ¬ã€‚ åˆå§‹åŒ–æƒå€¼w1, i=1/(2m), 1/(2l)åˆ†åˆ«å½“yi=0, 1ã€‚å…¶ä¸­må’Œlåˆ†åˆ«æ˜¯è´Ÿæ ·æœ¬å’Œæ­£æ ·æœ¬çš„æ•°é‡ã€‚ For t=1, â€¦, T: å½’ä¸€åŒ–æƒé‡, æ ¹æ®åŠ æƒé”™è¯¯é€‰æ‹©æœ€ä½³å¼±åˆ†ç±»å™¨ï¼š å®šä¹‰ ht(x) = h(x, ft, pt,Î¸t) å…¶ä¸­ft, pt, å’Œ Î¸t æ˜¯Îµtçš„æœ€å°å€¼. æ›´æ–°æƒå€¼ï¼šå…¶ä¸­ei=0å½“æ ·ä¾‹xiè¢«æ­£ç¡®çš„åˆ†ç±»ï¼Œå¦åˆ™ei=1ï¼Œå¹¶ä¸” æœ€åŽçš„å¼ºåˆ†ç±»å™¨æ˜¯ï¼š å…¶ä¸­ Learning Discussion å¼±åˆ†ç±»å™¨é€‰æ‹©ç®—æ³•è¿‡ç¨‹å¦‚ä¸‹ï¼š å¯¹äºŽæ¯ä¸ªç‰¹å¾ï¼Œæ ¹æ®ç‰¹å¾å€¼å¯¹æ ·ä¾‹è¿›è¡ŒæŽ’åºã€‚ è¯¥ç‰¹å¾çš„AdaBoostæœ€ä½³é˜ˆå€¼å¯ä»¥åœ¨è¯¥æŽ’åºåˆ—è¡¨ä¸Šçš„å•æ¬¡é€šè¿‡ä¸­è®¡ç®—ã€‚ å¯¹äºŽæŽ’åºåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œå››ä¸ªå’Œè¢«ç»´æŠ¤å’Œè¯„ä¼°ï¼š æ­£å®žä¾‹æƒé‡T+çš„æ€»å’Œã€‚ è´Ÿå®žä¾‹æƒé‡T-çš„æ€»å’Œã€‚ å½“å‰ç¤ºä¾‹S+ä¹‹ä¸‹çš„æ­£æƒé‡çš„å’Œã€‚ å½“å‰ç¤ºä¾‹S-ä¹‹ä¸‹çš„è´Ÿæƒé‡çš„å’Œã€‚ åœ¨æŽ’åºä¸€ä¸ªåˆ’åˆ†å½“å‰å’Œä¸Šä¸€ç¤ºä¾‹ä¹‹é—´çš„èŒƒå›´çš„é˜ˆå€¼çš„é”™è¯¯æ˜¯ï¼š Learning Results åœ¨çŽ°å®žåº”ç”¨ä¸­ï¼Œå‡æ­£ä¾‹çŽ‡å¿…é¡»æŽ¥è¿‘1/1000000ã€‚ æ‰€é€‰æ‹©çš„ ç¬¬ä¸€ç‰¹å¾ ä¼¼ä¹Žé›†ä¸­äºŽå±žæ€§å³çœ¼ç›çš„åŒºåŸŸé€šå¸¸æ¯”é¼»å­å’Œè„¸é¢Šçš„åŒºåŸŸæ›´æš—ã€‚ æ‰€é€‰æ‹©çš„ ç¬¬äºŒç‰¹å¾ ä¾èµ–äºŽçœ¼ç›æ¯”é¼»æ¢æ›´æš—çš„ç‰¹æ€§ã€‚ æé«˜æ€§èƒ½æœ€ç›´æŽ¥æŠ€æœ¯æ˜¯æ·»åŠ æ›´å¤šçš„ç‰¹å¾ï¼Œä½†è¿™æ ·ç›´æŽ¥å¯¼è‡´è®¡ç®—æ—¶é—´çš„å¢žåŠ ã€‚ Receiver operating characteristic (ROC)æ›²çº¿ï¼š The Attentional Cascade æœ¬èŠ‚æè¿°äº†ç”¨äºŽæž„é€ çº§è”çš„åˆ†ç±»å™¨çš„ç®—æ³•ï¼Œå…¶å®žçŽ°äº†æé«˜çš„æ£€æµ‹æ€§èƒ½ï¼ŒåŒæ—¶ä»Žæ ¹æœ¬ä¸Šå‡å°‘äº†è®¡ç®—æ—¶é—´ã€‚ é˜ˆå€¼è¶Šä½Žï¼Œæ£€æµ‹çŽ‡è¶Šé«˜ï¼Œå‡æ­£ä¾‹çŽ‡è¶Šé«˜ã€‚ ä»ŽåŒç‰¹å¾å¼ºåˆ†ç±»å™¨å¼€å§‹ï¼Œå¯ä»¥é€šè¿‡ è°ƒæ•´å¼ºåˆ†ç±»å™¨é˜ˆå€¼ ä»¥æœ€å°åŒ–å‡é˜´æ€§æ¥èŽ·å¾—æœ‰æ•ˆçš„é¢éƒ¨æ»¤æ³¢å™¨ã€‚ å¯ä»¥è°ƒæ•´åŒç‰¹å¾åˆ†ç±»å™¨ä»¥50ï¼…çš„å‡é˜³æ€§çŽ‡æ¥æ£€æµ‹100ï¼…çš„é¢éƒ¨ã€‚ æ•´ä½“çš„æ£€æµ‹è¿‡ç¨‹å½¢å¼æ˜¯ç®€å¹¶å†³ç­–æ ‘çš„å½¢å¼ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œçº§è”â€ã€‚ åœ¨ä»»ä½•ç‚¹ä¸Šçš„å¦å®šç»“æžœç«‹å³å¯¼è‡´å¯¹è¯¥å­çª—å£çš„æ‹’ç»ã€‚ æ›´æ·±çš„åˆ†ç±»å™¨é¢ä¸´çš„æ›´å›°éš¾çš„ä¾‹å­,å°†æ•´ä¸ªROCæ›²çº¿å‘ä¸‹æŽ¨ã€‚ åœ¨ç»™å®šçš„æ£€æµ‹çŽ‡ä¸‹ï¼Œè¾ƒæ·±çš„åˆ†ç±»å™¨å…·æœ‰ç›¸åº”è¾ƒé«˜çš„å‡é˜³æ€§çŽ‡ã€‚ Training a Cascade of Classifiers Given a trained cascade of classifiers, the false positive rate of the cascade isï¼š The detection rate is: The expected number of features which are evaluated is: ç”¨äºŽè®­ç»ƒåŽç»­å±‚çš„è´Ÿæ ·ä¾‹é›†åˆæ˜¯é€šè¿‡è¿è¡Œæ£€æµ‹å™¨æ”¶é›†é€šè¿‡åœ¨ä¸åŒ…å«ä»»ä½•é¢éƒ¨å®žä¾‹çš„ä¸€ç»„å›¾åƒä¸Šè€Œæ‰¾åˆ°çš„æ‰€æœ‰é”™è¯¯æ£€æµ‹æ¥èŽ·å¾—ã€‚ æž„å»ºä¸€ä¸ªç»ƒçº§æ£€æµ‹å™¨çš„è®­ç»ƒç®—æ³•ï¼š Simple ExperimentDetector Cascade Discussion å°†æ£€æµ‹å™¨è®­ç»ƒä¸ºåˆ†ç±»å™¨åºåˆ—çš„éšè—å¥½å¤„æ˜¯:æœ€ç»ˆæ£€æµ‹å™¨çœ‹åˆ°çš„æœ‰æ•ˆæ•°ç›®çš„è´Ÿæ ·ä¾‹æ•°ç›®å¯èƒ½éžå¸¸å¤§ã€‚ åœ¨å®žè·µä¸­ï¼Œç”±äºŽæˆ‘ä»¬çš„æ£€æµ‹å™¨çš„å½¢å¼å’Œå®ƒä½¿ç”¨çš„ç‰¹æ€§æ˜¯éžå¸¸é«˜æ•ˆçš„ï¼Œæ‰€ä»¥åœ¨æ¯ä¸ªå°ºåº¦å’Œä½ç½®è¯„ä¼°æˆ‘ä»¬çš„æ£€æµ‹å™¨çš„ æ‘Šé”€æˆæœ¬ æ¯”åœ¨æ•´ä¸ªå›¾åƒä¸­æ‰¾åˆ°å¹¶åˆ†ç»„è¾¹ç¼˜æ›´å¿«ã€‚ ResultsTraining Dataset äº‹å®žä¸Šï¼ŒåŒ…å«åœ¨è¾ƒå¤§å­çª—å£ä¸­çš„é™„åŠ ä¿¡æ¯å¯ä»¥ç”¨äºŽåœ¨æ£€æµ‹çº§è”ä¸­è¾ƒæ—©åœ°æ‹’ç»non-faceã€‚ Structure of the Detector Cascade æœ€ç»ˆçš„æ£€æµ‹å™¨æ˜¯38å±‚åˆ†çº§å™¨ï¼ŒåŒ…æ‹¬æ€»å…±6060ä¸ªç‰¹å¾ã€‚ çº§è”ä¸­çš„ç¬¬ä¸€ä¸ªåˆ†ç±»å™¨æ˜¯ä½¿ç”¨ä¸¤ä¸ªç‰¹å¾æž„é€ çš„ï¼Œåœ¨æ£€æµ‹100%çš„é¢éƒ¨æ—¶å¯ä»¥æ‹’ç»50%çš„non-faces. ä¸‹ä¸€ä¸ªåˆ†ç±»å™¨å…·æœ‰åä¸ªç‰¹å¾ï¼Œå¹¶ä¸”åœ¨æ£€æµ‹å‡ ä¹Ž100ï¼…çš„é¢éƒ¨æ—¶æ‹’ç»80ï¼…çš„éžé¢éƒ¨ã€‚ æŽ¥ä¸‹æ¥çš„ä¸¤å±‚æ˜¯25ä¸ªç‰¹å¾åˆ†ç±»å™¨ï¼Œå…¶åŽæ˜¯ä¸‰ä¸ª50ç‰¹å¾åˆ†ç±»å™¨ï¼Œå†ä¹‹åŽæ˜¯å…·æœ‰æ ¹æ®è¡¨2ä¸­çš„ç®—æ³•é€‰æ‹©çš„å„ç§ä¸åŒæ•°ç›®çš„ç‰¹å¾çš„åˆ†ç±»å™¨ã€‚ æ·»åŠ æ›´å¤šå±‚ï¼Œç›´åˆ°éªŒè¯é›†ä¸Šçš„å‡é˜³æ€§çŽ‡æŽ¥è¿‘é›¶ï¼ŒåŒæ—¶ä»ä¿æŒé«˜çš„æ­£ç¡®æ£€æµ‹çŽ‡ã€‚ Speed of the Final Detector çº§è”æ£€æµ‹å™¨çš„é€Ÿåº¦ç›´æŽ¥ä¸Žæ¯ä¸ªè¢«æ‰«æçš„å­çª—å£çš„ç‰¹å¾æ•°é‡ç›¸å…³ã€‚ Image Processing ç”¨äºŽè®­ç»ƒçš„æ‰€æœ‰ç¤ºä¾‹å­çª—å£è¢« æ–¹å·®å½’ä¸€ åŒ–ä»¥ä½¿ä¸åŒç…§æ˜Žæ¡ä»¶çš„å½±å“æœ€å°åŒ–ã€‚ å¯ä»¥ä½¿ç”¨ ä¸€å¯¹ç§¯åˆ†å›¾åƒ æ¥å¿«é€Ÿè®¡ç®—å›¾åƒå­çª—å£çš„æ–¹å·®ã€‚ åœ¨æ‰«ææœŸé—´ï¼Œå¯ä»¥é€šè¿‡å¯¹ç‰¹å¾å€¼è¿›è¡ŒåŽä¹˜ï¼Œè€Œä¸æ˜¯å¯¹åƒç´ è¿›è¡Œæ“ä½œæ¥å®žçŽ°å›¾åƒå½’ä¸€åŒ–çš„æ•ˆæžœã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šHow Far are We from Solving Pedestrian Detection?]]></title>
    <url>%2Fposts%2F2397281138%2F</url>
    <content type="text"><![CDATA[æ–‡ç« ç–‘é—®ç‚¹ Human Baseline çš„æ ‡å‡†æ˜¯å¦‚ä½•ç¡®å®šçš„? Ground-truthæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ Groun-truth æŒ‡çš„æ˜¯æ­£ç¡®çš„æ ‡æ³¨ï¼ˆçœŸå®žå€¼ï¼‰ åœ¨æœ‰ç›‘ç£å­¦ä¹ ä¸­ï¼Œæ•°æ®æ˜¯æœ‰æ ‡æ³¨çš„ï¼Œä»¥(x, t)çš„å½¢å¼å‡ºçŽ°ï¼Œå…¶ä¸­xæ˜¯è¾“å…¥æ•°æ®ï¼Œtæ˜¯æ ‡æ³¨.æ­£ç¡®çš„tæ ‡æ³¨æ˜¯ground truthï¼Œé”™è¯¯çš„æ ‡è®°åˆ™ä¸æ˜¯ã€‚ï¼ˆä¹Ÿæœ‰äººå°†æ‰€æœ‰æ ‡æ³¨æ•°æ®éƒ½å«åšground truthï¼‰ã€‚ Intersection over Unionï¼ˆIoUï¼‰æ˜¯ä»€ä¹ˆï¼Ÿ Intersection over Union is an evaluation metric used to measure the accuracy of an object detector on a particular dataset. Any algorithm that provides predicted bounding boxes as output can be evaluated using IoU. As long as we have these two sets of bounding boxes we can apply Intersection over Union. An Intersection over Union score &gt; 0.5 is normally considered a â€œgoodâ€ prediction. FPPI: False Positive Per Image Oracle Experiment: An oracle experiment is used to compare your actual system to how your system would behave if some component of it always did the right thing. Abstract è°ƒæŸ¥äº†å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ä¸Žâ€œå®Œç¾Žå•å¸§æ£€æµ‹å™¨â€ä¹‹é—´çš„å·®è·ã€‚ åŸºäºŽCaltechæ•°æ®é›†åˆ›å»ºäº†ä¸€ä¸ªäººå·¥çš„åŸºå‡†ã€‚ æ‰‹å·¥èšåˆäº†é¡¶çº§æ£€æµ‹å™¨ç»å¸¸å‡ºçŽ°çš„é”™è¯¯ã€‚ åˆ»ç”»äº†å®šä½ï¼Œå‰æ™¯ vs èƒŒæ™¯ä¸¤æ–¹é¢çš„é”™è¯¯ é’ˆå¯¹å®šä½é”™è¯¯ï¼šç ”ç©¶äº†è®­ç»ƒé›†æ ‡è®°å™ªå£°å¯¹æ£€æµ‹å™¨æ€§èƒ½çš„å½±å“ å‰æ™¯ vs èƒŒæ™¯é”™è¯¯ï¼šç ”ç©¶äº†convnetsï¼Œè®¨è®ºäº†å“ªäº›å› ç´ å½±å“å…¶æ€§èƒ½ æä¾›äº†ä¸€ä¸ªæ–°çš„ã€æ›´çº¯å‡€çš„è®­ç»ƒ/æµ‹è¯•æ ‡æ³¨é›†ã€‚ Introduction æˆ‘ä»¬çš„ç»“æžœæ˜¾ç¤ºlocalizationæ˜¯é«˜ç½®ä¿¡åº¦false positivesçš„é‡è¦æ¥æº PreliminariesCaltech-USA pedestrian detection benchmark æœ€æµè¡Œçš„æ•°æ®é›†ï¼šCaltech-USAã€KITTI Caltech-USAæœ‰2.5å°æ—¶ã€30Hzçš„ä»ŽLAè¡—é“çš„ä¸€ä¸ªchecké‡Œé¢å½•åˆ¶çš„ ä¸€å…±350000ä¸ªæ ‡æ³¨ã€è¦†ç›–2300å„å•ä¸€çš„è¡Œäºº æµ‹è¯•é›†ï¼š4024å¸§ MR: miss rate Filtered channel features detector æˆªæ­¢åˆ°æœ€è¿‘çš„ä¸»è¦ä¼šè®®ï¼ˆCVPR 15ï¼‰ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯ Checkerboards Checkerboardsï¼šæ˜¯ICFçš„ä¸€ç§ï¼ŒICF(Integral Channels Feature detector) ç›®å‰æœ€å¥½çš„æ‰§è¡Œconvnetsæ–¹æ³•å¯¹åº•å±‚æ£€æµ‹å»ºè®®å¾ˆæ•æ„Ÿï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä¼˜åŒ–è¿‡æ»¤çš„é€šé“ç‰¹å¾æ£€æµ‹å™¨æ¥å…³æ³¨è¿™äº›å»ºè®®ã€‚ çŽ¯å¢ƒå’Œå…‰æµå¯ä»¥æé«˜æ£€æµ‹ï¼ˆé¢å¤–çš„æç¤ºï¼‰ Analyzing the state of the artAre we reaching saturation? åœ¨çŽ°åœ¨çš„åŸºå‡†ä¸Šï¼Œæˆ‘ä»¬è¿˜æœ‰å¤šå°‘æå‡ç©ºé—´ï¼Ÿä¸ºäº†å›žç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå¯ä¸€ä¸ªäººå·¥çš„åŸºå‡†çº¿ä½œä¸ºæœ€ä½Žæžé™ã€‚ æœºå™¨æ£€æµ‹ç®—æ³•åº”è¯¥è¾¾åˆ°è‡³å°‘äººç±»æ°´å¹³ï¼Œæœ€ç»ˆè¶…è¿‡äººç±»æ°´å¹³ã€‚ äººå·¥åŸºå‡†çº¿â€”â€”ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œå…³æ³¨äºŽå•å¸§å•ç›®æ£€æµ‹ï¼Œæ³¨é‡Šå™¨éœ€è¦æ ¹æ®è¡Œäººå¤–è¡¨å’Œå•å¸§çŽ¯å¢ƒæ¥æ³¨é‡Šã€‚ Intersection over Union (IoU) â‰¥ 0.5 matching criterionã€‚ åœ¨æ‰€æœ‰æƒ…å†µä¸‹äººç±»åŸºå‡†çº¿è¡¨çŽ°è¿œè¿œè¶…è¿‡å½“å‰æœ€å¥½çš„æ£€æµ‹å™¨ï¼Œè¯´æ˜Žå¯¹äºŽè‡ªåŠ¨æ–¹æ³•æ¥è¯´ï¼Œè¿˜æœ‰æå‡ç©ºé—´ã€‚ Failure analysisError sources ä¸€ä¸ªæ£€æµ‹å™¨å¯ä»¥æœ‰ä¸¤ç±»é”™è¯¯ï¼š å‡é˜³æ€§ï¼ˆæ£€æµ‹åˆ°äº†èƒŒæ™¯ï¼Œæˆ–è€…å¾ˆå¼±çš„å®šä½æ£€æµ‹ï¼‰ å‡é˜´æ€§ï¼ˆä½Žå¾—åˆ†çŽ‡æˆ–è€…é”™è¿‡æŸäº›è¡Œäººæ£€æµ‹ï¼Œæ£€æµ‹ä¸å…¨ï¼‰ FPèšç±»æˆ11ä¸ªåˆ†ç±» FNèšç±»æˆ6ä¸ªåˆ†ç±»ï¼Œå…¶ä¸­side view å’Œ cyclistsæ˜¯ç”±äºŽæ•°æ®é›†åå·®å¯¼è‡´çš„ï¼Œç”¨è¿™äº›æ¡ˆä¾‹çš„å¤–éƒ¨å›¾åƒå¢žå¼ºè®­ç»ƒé›†å¯èƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç­–ç•¥ã€‚ å¯¹äºŽsmall pedestrainsï¼Œå‘çŽ°ä½Žåƒç´ æ˜¯ä¸»è¦å›°éš¾æ¥æºï¼Œæ‰€ä»¥åˆç†çš„åˆ©ç”¨æ‰€æœ‰åƒç´ ï¼Œä»¥åŠå‘¨å›´ä¸Šä¸‹æ–‡æ˜¯å¾ˆå¿…è¦çš„ã€‚ Oracle test cases å¯¹äºŽå¤§å¤šæ•°æ‰§è¡Œæœ€å¥½çš„æ–¹æ³•ï¼Œlocalizationå’Œbackground-vs-forgroundè¯¯å·®å¯¹æ£€æµ‹è´¨é‡å…·æœ‰ç›¸ç­‰çš„å½±å“ã€‚ ä»–ä»¬åŒæ ·é‡è¦ã€‚ Improved Caltech-USA annotations åŽŸå§‹æ³¨é‡Šæ˜¯åŸºäºŽè·¨è¶Šå¤šä¸ªå¸§å†…æ’ç¨€ç–æ³¨é‡Šï¼ˆinterpolating sparse annotations ï¼‰ï¼Œå¹¶ä¸”è¿™äº›ç¨€ç–æ³¨é‡Šä¸ä¸€å®šä½äºŽè¯„ä¼°çš„å¸§ä¸Šã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¸¤æ–¹é¢ï¼š åœ¨ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¸Œæœ›æä¾›å¯¹çŽ°æœ‰æŠ€æœ¯çš„æ›´å‡†ç¡®çš„è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯é€‚åˆäºŽæŽ¥è¿‘è¯¥é—®é¢˜çš„â€œæœ€åŽ20ï¼…â€çš„è¯„ä¼°ã€‚ å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰è®­ç»ƒæ³¨é‡Šï¼Œå¹¶è¯„ä¼°æ”¹è¿›çš„æ³¨é‡Šå¯¼æ€Žä¹ˆæ ·æ›´å¥½çš„æ£€æµ‹ã€‚ æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„æ–°æ³¨é‡Šä¸Žäººç±»åŸºçº¿åœ¨ä»¥ä¸‹æ–¹é¢ä¸åŒï¼šè®­ç»ƒå’Œæµ‹è¯•é›†éƒ½è¢«æ³¨é‡Šï¼Œå¿½ç•¥åŒºåŸŸå’Œé—­å¡žä¹Ÿè¢«æ³¨é‡Šï¼Œå®Œæ•´çš„è§†é¢‘æ•°æ®ç”¨äºŽå†³ç­–ï¼Œå¹¶ä¸”å…è®¸åŒä¸€å›¾åƒçš„å¤šä¸ªä¿®è®¢ã€‚ Improving the state of the artImpact of training annotations Pruning benefits: ä»ŽåŽŸå§‹åˆ°ä¿®å‰ªæ³¨é‡Šçš„ä¸»è¦å˜åŒ–æ˜¯åˆ é™¤æ³¨é‡Šé”™è¯¯ï¼Œä»Žä¿®å‰ªåˆ°æ–°çš„ï¼Œä¸»è¦çš„å˜åŒ–æ˜¯æ›´å¥½çš„å¯¹é½ã€‚ æˆ‘ä»¬åœ¨MRN-2ä¸­çœ‹åˆ°ï¼Œæ›´å¼ºçš„æ£€æµ‹å™¨æ›´å¥½åœ°å—ç›ŠäºŽæ›´å¥½çš„æ•°æ®ï¼Œå¹¶ä¸”æ£€æµ‹è´¨é‡çš„æœ€å¤§å¢žç›Šæ¥è‡ªç§»é™¤æ³¨é‡Šé”™è¯¯ã€‚ Alignment benefits: ä¸ºäº†åˆ©ç”¨æ–°çš„1Ã—æ³¨é‡Šæ¥åˆ©ç”¨9Ã—å‰©ä½™æ•°æ®ï¼Œæˆ‘ä»¬åœ¨æ–°çš„æ³¨é‡Šä¸Šè®­ç»ƒæ¨¡åž‹ï¼Œå¹¶ä½¿ç”¨è¯¥æ¨¡åž‹åœ¨9Ã—éƒ¨åˆ†ä¸Šé‡æ–°å¯¹å‡†åŽŸå§‹æ³¨é‡Šã€‚ å› ä¸ºæ–°çš„æ³¨é‡Šæ›´å¥½åœ°å¯¹é½ï¼Œæ‰€ä»¥æˆ‘ä»¬æœŸæœ›è¯¥æ¨¡åž‹èƒ½å¤Ÿä¿®å¤åŽŸå§‹æ³¨é‡Šä¸­çš„è½»å¾®ä½ç½®å’Œç¼©æ”¾é”™è¯¯ã€‚ ç»“æžœè¡¨æ˜Žï¼Œä½¿ç”¨æ£€æµ‹å™¨æ¨¡åž‹æ¥æé«˜æ•´ä½“æ•°æ®å¯¹å‡†ç¡®å®žæ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”æ›´å¥½åœ°å¯¹å‡†è®­ç»ƒæ•°æ®å¯¼è‡´æ›´å¥½çš„æ£€æµ‹è´¨é‡ï¼ˆåœ¨MROå’ŒMRNä¸­ï¼‰ã€‚ ä½¿ç”¨é«˜è´¨é‡æ³¨é‡Šè¿›è¡Œè®­ç»ƒå¯æé«˜æ•´ä½“æ£€æµ‹è´¨é‡ï¼Œè¿™å¾—ç›ŠäºŽæ”¹è¿›çš„å¯¹é½å’Œå‡å°‘çš„æ³¨é‡Šé”™è¯¯ã€‚ Convnets for pedestrian detection AlexNet å’Œ VGG16éƒ½åœ¨ImageNetä¸Šè¿›è¡Œäº†é¢„å…ˆè®­ç»ƒï¼Œå¹¶ä½¿ç”¨SquaresChnFtrså»ºè®®å¯¹Caltech 10Ã—ï¼ˆåŽŸå§‹æ³¨é‡Šï¼‰è¿›è¡Œäº†å¾®è°ƒã€‚ å¯ä»¥çœ‹å‡ºï¼ŒVGGæ˜¾ç€åœ°å‡å°‘äº†èƒŒæ™¯è¯¯å·®ï¼Œè€ŒåŒæ—¶ç¨å¾®å¢žåŠ äº†å®šä½è¯¯å·®ã€‚ è™½ç„¶å·ç§¯åœ¨å›¾åƒåˆ†ç±»å’Œä¸€èˆ¬ç‰©ä½“æ£€æµ‹ä¸­å…·æœ‰å¾ˆå¼ºçš„ç»“æžœï¼Œä½†æ˜¯å½“åœ¨å°ç‰©ä½“å‘¨å›´äº§ç”Ÿè‰¯å¥½çš„å±€éƒ¨æ£€æµ‹åˆ†æ•°æ—¶ï¼Œå®ƒä»¬ä¼¼ä¹Žæœ‰å±€é™æ€§ã€‚ è¾¹ç•Œæ¡†å›žå½’ï¼ˆå’ŒNMSï¼‰æ˜¯å½“å‰æž¶æž„çš„ä¸€ä¸ªå…³é”®å› ç´ ã€‚ è¡¨æ˜Žç¥žç»ç½‘ç»œçš„åŽŸå§‹åˆ†ç±»èƒ½åŠ›ä»æœ‰æ”¹è¿›çš„ä½™åœ°ã€‚ Summary ç›¸å¯¹äºŽhuman baseline, there is a 10Ã— gap still to be closed. è¯¯å·®ç‰¹æ€§å¯¼è‡´å…³äºŽå¦‚ä½•è®¾è®¡æ›´å¥½çš„æ£€æµ‹å™¨ï¼ˆåœ¨3.2èŠ‚ä¸­æåŠ;ä¾‹å¦‚ï¼Œå¯¹äºŽäººside-viewçš„æ•°æ®å¢žåŠ æˆ–åœ¨åž‚ç›´è½´ä¸Šå»¶ä¼¸æ£€æµ‹å™¨æŽ¥æ”¶åœºï¼‰çš„å…·ä½“å»ºè®®ã€‚ æˆ‘ä»¬é€šè¿‡è¡¡é‡æ›´å¥½çš„æ³¨é‡Šå¯¹æœ¬åœ°åŒ–å‡†ç¡®æ€§çš„å½±å“ï¼Œä»¥åŠé€šè¿‡è°ƒæŸ¥ä½¿ç”¨convnetsæ¥æ”¹å–„the background to foreground discriminationï¼Œæ¥éƒ¨åˆ†è§£å†³äº†ä¸€äº›é—®é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œé€šè¿‡é€‚å½“è®­ç»ƒçš„ICFæ£€æµ‹å™¨å¯ä»¥å®žçŽ°æ˜¾ç€æ›´å¥½çš„Alignmentï¼Œå¹¶ä¸”ï¼Œå¯¹äºŽè¡Œäººæ£€æµ‹ï¼ŒConventåœ¨localizationä¸Šèƒ½åŠ›ä¸å¼ºï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡è¾¹ç•Œæ¡†å›žå½’ï¼ˆbounding box regressionï¼‰éƒ¨åˆ†è§£å†³ã€‚ å¯¹äºŽåŽŸå§‹å’Œæ–°æ³¨é‡Šï¼Œæ‰€æè¿°çš„æ£€æµ‹æ–¹æ³•éƒ½èƒ½è¾¾åˆ°æœ€é«˜æ€§èƒ½ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Review</tag>
        <tag>ç»¼è¿°</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šTen Years of Pedestrian Detection, What Have We Learned?]]></title>
    <url>%2Fposts%2F287090227%2F</url>
    <content type="text"><![CDATA[Abstract è¿™ç§æ–°çš„å†³ç­–æž—æŽ¢æµ‹å™¨åœ¨æŒ‘æˆ˜æ€§çš„Caltech-USAæ•°æ®é›†ä¸Šå®žçŽ°äº†å½“å‰æœ€å¥½çš„å·²çŸ¥æ€§èƒ½ã€‚ Introduction æ›´é‡è¦çš„æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰ç€å·²å»ºç«‹çš„åŸºå‡†å’Œè¯„ä¼°æŒ‡æ ‡çš„è‰¯å¥½å®šä¹‰çš„é—®é¢˜ã€‚ ç”¨äºŽå¯¹è±¡æ£€æµ‹çš„çš„ä¸»è¦èŒƒä¾‹æœ‰â€”â€”â€Violaï¼†Joneså˜ä½“â€œï¼ŒHOG + SVMæ¨¡æ¿ï¼Œå¯å˜å½¢éƒ¨åˆ†æ£€æµ‹å™¨ï¼ˆDPMï¼‰å’Œå·ç§¯ç¥žç»ç½‘ç»œï¼ˆConvNetsï¼‰éƒ½å·²ç»è¢«æŽ¢ç´¢ç”¨äºŽæ­¤ä»»åŠ¡ã€‚ Datasets INRIA, ETH, TUD-Brussels, Daimler, Caltech-USA, and KITTIæ˜¯ä½¿ç”¨æœ€å¹¿çš„æ•°æ®é›†ã€‚ INRIAï¼šINRIAæ˜¯æœ€å¤è€çš„ï¼Œå› æ­¤å…·æœ‰ç›¸å¯¹è¾ƒå°‘çš„å›¾åƒã€‚ ç„¶è€Œï¼Œä»Žä¸åŒè®¾ç½®ï¼ˆåŸŽå¸‚ï¼Œæµ·æ»©ï¼Œå±±è„‰ç­‰ï¼‰çš„è¡Œäººçš„é«˜è´¨é‡æ³¨é‡Šï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆå®ƒè¢«æ™®éé€‰æ‹©ç”¨æ¥è®­ç»ƒã€‚ Daimleræ²¡æœ‰è¢«æ‰€æœ‰çš„æ–¹æ³•è€ƒè™‘ï¼Œå› ä¸ºå®ƒç¼ºä¹é¢œè‰²é€šé“ã€‚ Daimler stereoï¼ŒETHå’ŒKITTIæä¾›ç«‹ä½“å£°ä¿¡æ¯ã€‚ æ‰€æœ‰æ•°æ®é›†ä½†INRIAéƒ½æ˜¯ä»Žè§†é¢‘èŽ·å–çš„ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨å…‰æµä½œä¸ºé™„åŠ æç¤ºã€‚ ä»Šå¤©ï¼ŒCaltech-USAå’ŒKITTYæ˜¯è¡Œäººæ£€æµ‹çš„ä¸»è¦åŸºå‡†ã€‚ ä¸¤è€…éƒ½ç›¸å¯¹è¾ƒå¤§å’Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚ Main approaches to improve pedestrian detection 40+ç§è¡Œäººæ£€æµ‹çš„æ–¹æ³•ï¼š æˆ‘ä»¬ä¸æ˜¯è®¨è®ºæ–¹æ³•çš„ä¸ªä½“ç‰¹æ€§ï¼Œè€Œæ˜¯è¯†åˆ«åŒºåˆ†æ¯ç§æ–¹æ³•ï¼ˆè¡¨1çš„å¯¹å·ï¼‰çš„å…³é”®æ–¹é¢ï¼Œå¹¶å¯¹å…¶è¿›è¡Œåˆ†ç»„ã€‚ æˆ‘ä»¬åœ¨ä¸‹é¢çš„å°èŠ‚è®¨è®ºè¿™äº›æ–¹é¢ã€‚ Training dataSolution families æ€»ä½“ä¸Šï¼Œæˆ‘ä»¬æ³¨æ„åˆ°åœ¨40å¤šç§æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¾¨åˆ«ä¸‰ä¸ªå®¶åº­ï¼š DPMå˜ä½“ï¼ˆMultiResC [33]ï¼ŒMT-DPM [39]ç­‰ï¼‰ æ·±åº¦ç½‘ç»œï¼ˆJointDeep [40]ï¼ŒConvNet [13] ]ç­‰ï¼‰ å†³ç­–æž—ï¼ˆChnFtrsï¼ŒRoereiç­‰ï¼‰ã€‚ åœ¨è¡¨1ä¸­ï¼Œæˆ‘ä»¬å°†è¿™äº›å®¶æ—åˆ†åˆ«è¯†åˆ«ä¸ºDPMï¼ŒDNå’ŒDFã€‚ Better classiï¬ers ç‰¹å¾å’Œåˆ†ç±»å™¨ä¹‹é—´çš„æ²¡æœ‰æ˜Žç¡®çš„ç•Œé™ Additional data ä¸€äº›æ–¹æ³•æŽ¢ç´¢åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶é—´åˆ©ç”¨é¢å¤–çš„ä¿¡æ¯æ¥æ”¹è¿›æ£€æµ‹ã€‚ ä»–ä»¬è€ƒè™‘ç«‹ä½“å›¾åƒ[45]ï¼Œå…‰æµï¼ˆä½¿ç”¨ä»¥å‰çš„å¸§ï¼Œä¾‹å¦‚MultiFtr + Motion [22]å’ŒACF + SDt [42]ï¼‰ï¼Œè·Ÿè¸ª[46]æˆ–æ¥è‡ªå…¶ä»–ä¼ æ„Ÿå™¨ ã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä»…åŸºäºŽå•ä¸ªå•ç›®å›¾åƒå¸§çš„æ–¹æ³•å·²ç»èƒ½å¤Ÿè·Ÿä¸Šç”±é™„åŠ ä¿¡æ¯å¼•å…¥çš„æ€§èƒ½æ”¹è¿›ã€‚ Exploiting context ä¸Šä¸‹æ–‡ä¸ºè¡Œäººæ£€æµ‹æä¾›äº†ä¸€è‡´çš„æ”¹è¿›ï¼Œè™½ç„¶æ”¹è¿›çš„è§„æ¨¡æ¯”é¢å¤–çš„æµ‹è¯•æ•°æ®ï¼ˆÂ§3.4ï¼‰å’Œæ·±å±‚æž¶æž„ï¼ˆÂ§3.8ï¼‰è¦ä½Žã€‚ å¤§éƒ¨åˆ†æ£€æµ‹è´¨é‡å¿…é¡»æ¥è‡ªå…¶ä»–æ¥æºã€‚ Deformable parts å¯¹äºŽè¡Œäººæ£€æµ‹ï¼Œç»“æžœæ˜¯æœ‰ç«žäº‰æ€§çš„ï¼Œä½†ä¸æ˜¾ç€ã€‚ å¯¹äºŽè¡Œäººæ£€æµ‹ï¼Œé™¤äº†é®æŒ¡å¤„ç†çš„æƒ…å†µä¹‹å¤–ï¼Œä»ç„¶æ²¡æœ‰å…³äºŽéƒ¨ä»¶å’Œéƒ¨ä»¶çš„å¿…è¦æ€§çš„æ˜Žç¡®è¯æ®ã€‚ Multi-scale models æœ€è¿‘å·²ç»æ³¨æ„åˆ°ï¼Œä¸åŒåˆ†è¾¨çŽ‡çš„è®­ç»ƒä¸åŒæ¨¡åž‹ç³»ç»Ÿåœ°å°†æ€§èƒ½æé«˜1ã€œ2MRç™¾åˆ†ç‚¹ å°½ç®¡ä¸æ–­æ”¹è¿›ï¼Œä»–ä»¬å¯¹æœ€ç»ˆè´¨é‡çš„è´¡çŒ®æ˜¯ç›¸å½“å°çš„ã€‚ Deep architectures å°½ç®¡æœ‰å…±åŒçš„å™è¿°ï¼Œä»ç„¶æ²¡æœ‰æ˜Žç¡®çš„è¯æ®è¡¨æ˜Žæ·±å±‚ç½‘ç»œæœ‰åˆ©äºŽè¡Œäººæ£€æµ‹çš„å­¦ä¹ åŠŸèƒ½ æœ€æˆåŠŸçš„æ–¹æ³•ä½¿ç”¨è¿™æ ·çš„æž¶æž„æ¥æ¨¡æ‹Ÿéƒ¨ä»¶ï¼Œé®æŒ¡å’Œä¸Šä¸‹æ–‡çš„æ›´é«˜çº§åˆ«æ–¹é¢ã€‚ èŽ·å¾—çš„ç»“æžœä¸ŽDPMå’Œå†³ç­–æž—æ–¹æ³•ç›¸åŒï¼Œä½¿å¾—ä½¿ç”¨è¿™æ ·æ¶‰åŠçš„ç»“æž„çš„ ä¼˜ç‚¹ä»ä¸æ¸…æ¥š ã€‚ Better features ç‰¹å¾æ›´å¤šï¼Œå…·æœ‰æ›´ä¸°å¯Œå’Œæ›´é«˜ç»´çš„è¡¨ç¤ºï¼Œåˆ†ç±»ä»»åŠ¡å˜å¾—æ›´å®¹æ˜“ï¼Œä»Žè€Œæ”¹å–„ç»“æžœã€‚ è¶Šæ¥è¶Šå¤šæ ·åŒ–çš„ç‰¹æ€§å·²ç»æ˜¾ç¤ºç³»ç»Ÿåœ°æé«˜æ€§èƒ½ã€‚ å°½ç®¡é€šè¿‡æ·»åŠ è®¸å¤šæ¸ é“çš„æ”¹è¿›ï¼Œé¡¶çº§æ€§èƒ½æ£€æµ‹å™¨ä»ç„¶è¾¾åˆ°ä»…æœ‰10ä¸ªé€šé“ï¼š 6ä¸ªæ¢¯åº¦æ–¹å‘ï¼Œ 1ä¸ªæ¢¯åº¦å¹…åº¦ 3ä¸ªé¢œè‰²é€šé“ æˆ‘ä»¬å‘½åè¿™äº› HOG + LUV ã€‚ åº”å½“æ³¨æ„ï¼Œè¿˜æ²¡æœ‰æ›´å¥½çš„ç”¨äºŽè¡Œäººæ£€æµ‹çš„ç‰¹å¾å¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•èŽ·å¾—ã€‚ ä¸‹ä¸€ä¸ªç§‘å­¦çš„æ­¥éª¤å°†æ˜¯å¼€å‘ä¸€ä¸ªæ›´æ·±åˆ»çš„ç†è§£ï¼Œä»€ä¹ˆä½¿å¥½çš„åŠŸèƒ½æ›´å“ˆç€ï¼Œä»¥åŠå¦‚ä½•è®¾è®¡æ›´å¥½çš„ç‰¹å¾ã€‚ Experiments åŸºäºŽæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­çš„åˆ†æžï¼Œåœ¨å¯¹æ£€æµ‹è´¨é‡çš„å½±å“æ–¹é¢ï¼Œä¸‰ä¸ªæ–¹é¢ä¼¼ä¹Žæ˜¯æœ€æœ‰å¸Œæœ›çš„ï¼š æ›´å¥½çš„ç‰¹å¾ï¼ˆÂ§3.9 é™„åŠ æ•°æ®ï¼ˆÂ§3.4ï¼‰ ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆÂ§3.5ï¼‰ Reviewing the eï¬€ect of features(ç‰¹å¾çš„å½±å“) DCT: (discrete cosine transform)ç¦»æ•£ä½™å¼¦å˜æ¢ è‡ªVJä»¥æ¥çš„è®¸å¤šè¿›å±•å¯ä»¥é€šè¿‡ä½¿ç”¨åŸºäºŽå®šå‘æ¢¯åº¦å’Œé¢œè‰²ä¿¡æ¯çš„æ›´å¥½çš„ç‰¹å¾æ¥è§£é‡Šã€‚ å¯¹è¿™äº›ä¼—æ‰€å‘¨çŸ¥çš„ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºŽDCTçš„æŠ•å½±ï¼‰çš„ç®€å•è°ƒæ•´ä»ç„¶å¯ä»¥äº§ç”Ÿæ˜¾ç€çš„æ”¹è¿›ã€‚ Complementarity of approaches åœ¨é‡æ–°å®¡è§†4.1èŠ‚ä¸­å•å¸§ç‰¹å¾çš„å½±å“ä¹‹åŽï¼Œæˆ‘ä»¬çŽ°åœ¨è€ƒè™‘æ›´å¥½çš„ç‰¹å¾ï¼ˆHOG + LUV + DCTï¼‰ï¼Œé™„åŠ æ•°æ®ï¼ˆé€šè¿‡å…‰æµï¼‰å’Œä¸Šä¸‹æ–‡ï¼ˆé€šè¿‡äººå¯¹äººçš„äº¤äº’ï¼‰çš„äº’è¡¥ã€‚ æˆ‘ä»¬çš„å®žéªŒè¡¨æ˜Žï¼Œå³ä½¿ä»Žå¼ºæ£€æµ‹å™¨å¼€å§‹ï¼Œæ·»åŠ é¢å¤–çš„ç‰¹å¾ï¼Œæµé‡å’Œä¸Šä¸‹æ–‡ä¿¡æ¯åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯äº’è¡¥çš„ï¼ˆå¢žåŠ 12ï¼…ï¼Œè€Œä¸æ˜¯3 + 7 + 5ï¼…ï¼‰ã€‚ Conclusion è™½ç„¶è¿™äº›åŠŸèƒ½ä¸­çš„ä¸€äº›å¯èƒ½æ˜¯ç”±å­¦ä¹ é©±åŠ¨çš„ï¼Œä½†å®ƒä»¬ä¸»è¦æ˜¯é€šè¿‡å°è¯•å’Œé”™è¯¯æ‰‹å·¥åˆ¶ä½œçš„ã€‚ Better features + optical flow + contextçš„ç»“åˆå¯ä»¥åœ¨Caltech-USAä¸Šäº§ç”Ÿæœ€å¥½çš„æ£€æµ‹æ€§èƒ½ã€‚ The main challenge ahead seems to develop a deeper understanding of what makes good features good, so as to enable the design of even better ones.]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Review</tag>
        <tag>ç»¼è¿°</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[æ·±åº¦å­¦ä¹ è¯»ä¹¦ç¬”è®°ï¼šDeepLearningBook - Chapter 9 - Conventional Networks]]></title>
    <url>%2Fposts%2F783616645%2F</url>
    <content type="text"><![CDATA[Chapter 9 Convolutional Networksï¼ˆå·ç§¯ç¥žç»ç½‘ç»œï¼‰ å·ç§¯ç½‘ç»œä»…ä»…æ˜¯åœ¨å…¶è‡³å°‘ä¸€ä¸ªå±‚ä¸­ä½¿ç”¨å·ç§¯ä»£æ›¿ä¸€èˆ¬çŸ©é˜µä¹˜æ³•çš„ç¥žç»ç½‘ç»œã€‚ The Convolution Operation The convolution operation is typically denoted with an asterisk: åœ¨å·ç§¯ç½‘ç»œæœ¯è¯­ä¸­ï¼Œå·ç§¯çš„ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºå‡½æ•°xï¼‰é€šå¸¸ç§°ä¸º è¾“å…¥ ï¼Œç¬¬äºŒä¸ªå‚æ•°ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºå‡½æ•°wï¼‰ä½œä¸º å†…æ ¸ ã€‚ è¾“å‡º æœ‰æ—¶ç§°ä¸º ç‰¹å¾æ˜ å°„(feature map) ã€‚ åœ¨æœºå™¨å­¦ä¹ åº”ç”¨ä¸­ï¼Œ è¾“å…¥ é€šå¸¸æ˜¯å¤šç»´æ•°æ®æ•°ç»„ï¼Œå¹¶ä¸” å†…æ ¸ é€šå¸¸æ˜¯ç”±å­¦ä¹ ç®—æ³•è°ƒæ•´çš„å¤šç»´å‚æ•°æ•°ç»„ã€‚ æˆ‘ä»¬å°†è¿™äº›å¤šç»´æ•°ç»„ç§°ä¸º å¼ é‡ï¼ˆtensorsï¼‰ ã€‚ è¿™æ„å‘³ç€åœ¨å®žè·µä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å®žçŽ°æ— é™æ±‚å’Œä½œä¸ºå¯¹æœ‰é™æ•°é‡çš„æ•°ç»„å…ƒç´ çš„æ±‚å’Œã€‚ äºŒç»´å·ç§¯ï¼štwo-dimensional kernel K å·ç§¯æ˜¯å¯äº¤æ¢çš„ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç­‰ä»·åœ°å†™ï¼Œä½†è¿™æ ·ä¼šå¸¦æ¥ kernel-ï¬‚ippingåŽä¸€ç§ä¼šæ›´æ›´å®¹æ˜“ç”¨æœºå™¨å­¦ä¹ åº“æ¥å®žçŽ°ã€‚ è®¸å¤šç¥žç»ç½‘ç»œåº“å®žçŽ°äº†ä¸€ä¸ªç§°ä¸ºäº’ç›¸å…³ï¼ˆcross-correlationï¼‰çš„ç›¸å…³å‡½æ•°ï¼Œå®ƒä¸Žå·ç§¯ç›¸åŒï¼Œä½†æ˜¯æ²¡æœ‰ç¿»è½¬ï¼ˆflippingï¼‰å†…æ ¸ï¼š å·ç§¯çš„ä¸€ä¸ªä¾‹å­ï¼š ç¦»æ•£å·ç§¯å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¹˜ä»¥çŸ©é˜µçš„ä¹˜æ³•ã€‚ ToeplitzçŸ©é˜µï¼šå¸¸å¯¹è§’çŸ©é˜µï¼ˆåˆç§°ç‰¹æ™®åˆ©èŒ¨çŸ©é˜µï¼‰æ˜¯æŒ‡æ¯æ¡å·¦ä¸Šè‡³å³ä¸‹çš„å¯¹è§’çº¿å‡ä¸ºå¸¸æ•°çš„çŸ©é˜µï¼Œä¸è®ºæ˜¯æ­£æ–¹å½¢æˆ–é•¿æ–¹å½¢çš„ã€‚ åœ¨äºŒç»´ä¸­ï¼ŒåŒå—å¾ªçŽ¯çŸ©é˜µï¼ˆdoubly block circulant matrixï¼‰å¯¹åº”äºŽå·ç§¯ã€‚ å·ç§¯é€šå¸¸å¯¹åº”äºŽéžå¸¸ç¨€ç–çš„çŸ©é˜µã€‚ ä»»ä½•ä¸ŽçŸ©é˜µä¹˜æ³•ä¸€èµ·ä½œç”¨å¹¶ä¸”ä¸ä¾èµ–äºŽçŸ©é˜µç»“æž„çš„ç‰¹å®šå±žæ€§çš„ç¥žç»ç½‘ç»œç®—æ³•éƒ½åº”è¯¥ä¸Žå·ç§¯ä¸€èµ·å·¥ä½œï¼Œè¿™æ ·å°±ä¸éœ€è¦å¯¹ç¥žç»ç½‘ç»œçš„ä»»ä½•è¿›ä¸€æ­¥çš„æ”¹å˜ã€‚ Motivation å·ç§¯åˆ©ç”¨ä¸‰ä¸ªé‡è¦çš„æƒ³æ³•ï¼Œå¯ä»¥å¸®åŠ©æ”¹è¿›æœºå™¨å­¦ä¹ ç³»ç»Ÿ: ç¨€ç–çš„è¿žæŽ¥ï¼ˆsparse interactionsï¼‰ å‚æ•°å…±äº«ï¼ˆparameter sharingï¼‰ ç­‰å€¼è¡¨ç¤ºï¼ˆequivariant representationsï¼‰ æ­¤å¤–å·ç§¯å¯ä»¥å¤„ç†å„ç§å¤§å°è¾“å…¥ã€‚ Sparse Interactionsï¼šè¿™æ˜¯é€šè¿‡ä½¿å†…æ ¸å°äºŽè¾“å…¥æ¥å®žçŽ°çš„ã€‚ æˆ‘ä»¬éœ€è¦å­˜å‚¨æ›´å°‘çš„å‚æ•°ï¼Œè¿™æ—¢å‡å°‘äº†æ¨¡åž‹çš„å†…å­˜éœ€æ±‚ï¼Œåˆæé«˜äº†å…¶ç»Ÿè®¡æ•ˆçŽ‡ã€‚ è®¡ç®—è¾“å‡ºéœ€è¦æ›´å°‘çš„æ“ä½œã€‚ åœ¨æ·±å·ç§¯ç½‘ç»œä¸­ï¼Œè¾ƒæ·±å±‚ä¸­çš„å•å…ƒå¯ä»¥ä¸Žè¾“å…¥çš„è¾ƒå¤§éƒ¨åˆ†é—´æŽ¥äº¤äº’ï¼ŒThis allows the network to eï¬ƒciently describe complicated interactions between many variables by constructing such interactions from simple building blocks that each describe only sparse interactions. Sparse connectivity, viewed from below Sparse connectivity, viewed from above åœ¨å·ç§¯ç½‘ç»œçš„è¾ƒæ·±å±‚ä¸­çš„å•å…ƒçš„æŽ¥æ”¶åœºå¤§äºŽåœ¨æµ…å±‚ä¸­çš„å•å…ƒçš„æŽ¥æ”¶åœºã€‚è¿™æ„å‘³ç€å³ä½¿å·ç§¯ç½‘ç»œä¸­çš„ç›´æŽ¥è¿žæŽ¥éžå¸¸ç¨€ç–ï¼Œæ›´æ·±å±‚ä¸­çš„å•å…ƒä¹Ÿå¯ä»¥é—´æŽ¥åœ°è¿žæŽ¥åˆ°æ‰€æœ‰æˆ–å¤§éƒ¨åˆ†è¾“å…¥å›¾åƒã€‚ Parameter sharingï¼šå‚æ•°å…±äº«æ˜¯æŒ‡å¯¹æ¨¡åž‹ä¸­çš„å¤šä¸ªå‡½æ•°ä½¿ç”¨ç›¸åŒçš„å‚æ•°ã€‚ ä¹Ÿå¯ä»¥å« Tied Weightsï¼ˆæ†ç»‘æƒå€¼ï¼‰ï¼Œå› ä¸ºåº”ç”¨äºŽä¸€ä¸ªè¾“å…¥çš„æƒé‡çš„å€¼ä¸Žåœ¨å…¶ä»–åœ°æ–¹åº”ç”¨çš„æƒé‡çš„å€¼æœ‰å…³ã€‚ åœ¨å·ç§¯ç¥žç»ç½‘ç»œä¸­ï¼Œå·ç§¯æ ¸ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½ä¼šåœ¨inputä¸­çš„æ¯ä¸€ä¸ªä½ç½®ä½¿ç”¨ã€‚ åœ¨å­˜å‚¨å™¨è¦æ±‚å’Œç»Ÿè®¡æ•ˆçŽ‡æ–¹é¢ï¼Œå·ç§¯æ¯”å¯†é›†çŸ©é˜µä¹˜æ³•æ˜¾ç€æ›´æœ‰æ•ˆã€‚ é»‘è‰²ç®­å¤´è¡¨ç¤ºåœ¨å·ç§¯æ¨¡åž‹ä¸­3å…ƒç´ æ ¸çš„ä¸­å¿ƒå…ƒç´ çš„ä½¿ç”¨ã€‚ Equivariantï¼šè¯´ä¸€ä¸ªå‡½æ•°æ˜¯ç­‰å˜çš„æ„å‘³ç€å¦‚æžœè¾“å…¥æ”¹å˜ï¼Œè¾“å‡ºä»¥ç›¸åŒçš„æ–¹å¼æ”¹å˜ã€‚ ä¸€ä¸ªå‡½æ•°f(x)ä¸Žå‡½æ•°g ç­‰å˜ å¦‚æžœf(g(x)) = g(f(x)). å½“å¤„ç†æ—¶é—´åºåˆ—æ•°æ®æ—¶ï¼Œè¿™æ„å‘³ç€å·ç§¯äº§ç”Ÿä¸€ç§æ—¶é—´çº¿ï¼Œæ˜¾ç¤ºè¾“å…¥ä¸­ä¸åŒç‰¹å¾çš„å‡ºçŽ°ã€‚ This is useful for when we know that some function of a small number of neighboring pixels is useful when applied to multiple input locations. å·ç§¯ä¸æ˜¯è‡ªç„¶åœ°ç­‰åŒäºŽä¸€äº›å…¶ä»–å˜æ¢ï¼Œä¾‹å¦‚å›¾åƒçš„å°ºåº¦æˆ–æ—‹è½¬çš„å˜åŒ–ã€‚ å·ç§¯æ˜¯æè¿°åœ¨æ•´ä¸ªè¾“å…¥ä¸Šåº”ç”¨å°çš„å±€éƒ¨åŒºåŸŸçš„ç›¸åŒçº¿æ€§å˜æ¢çš„å˜æ¢çš„éžå¸¸æœ‰æ•ˆçš„æ–¹å¼ã€‚ Pooling å·ç§¯ç½‘ç»œçš„ä¸€ä¸ªå…¸åž‹å±‚ç”±ä¸‰ä¸ªé˜¶æ®µç»„æˆ: åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè¯¥å±‚å¹¶è¡Œæ‰§è¡Œå‡ ä¸ªå·ç§¯ä»¥äº§ç”Ÿä¸€ç»„çº¿æ€§æ¿€æ´»ï¼ˆlinear activationï¼‰ã€‚ åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¯ä¸ªçº¿æ€§æ¿€æ´»é€šè¿‡éžçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œä¾‹å¦‚æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚è¿™ä¸€é˜¶æ®µæˆä¸º detector stage. åœ¨ç¬¬ä¸‰é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨æ± åŒ–å‡½æ•°ï¼ˆpooing functionï¼‰æ¥è¿›ä¸€æ­¥ä¿®æ”¹å±‚çš„è¾“å‡ºã€‚ pooling functionæ˜¯ç”¨é™„è¿‘çš„æ±‡æ€»ç»Ÿè®¡æ¥æ›¿æ¢ç‰¹å®šä½ç½®çš„ç½‘ç»œçš„è¾“å‡ºã€‚ åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæ± åŒ–æœ‰åŠ©äºŽä½¿è¡¨ç¤ºå˜å¾—å¯¹äºŽç›¸å¯¹äºŽ è¾“å…¥çš„å°å¹³ç§» å‡ ä¹Žä¸å˜ï¼ˆinvariantï¼‰ã€‚ å¦‚æžœæˆ‘ä»¬æ›´å…³å¿ƒæŸäº›ç‰¹å¾æ˜¯å¦å­˜åœ¨è€Œä¸æ˜¯å®Œå…¨åœ¨å“ªé‡Œï¼Œé‚£ä¹ˆæœ¬åœ°å˜æ¢çš„ä¸å˜æ€§å¯ä»¥æ˜¯éžå¸¸æœ‰ç”¨çš„å±žæ€§ã€‚ æ± çš„ä½¿ç”¨å¯ä»¥è¢«è§†ä¸ºæ·»åŠ ä¸€ä¸ªæ— é™å¼ºçš„å…ˆéªŒï¼Œå±‚æ‰€å­¦ä¹ çš„å‡½æ•°å¿…é¡»å¯¹å°çš„å˜æ¢æ˜¯ä¸å˜çš„ã€‚ å¦‚æžœæˆ‘ä»¬åœ¨å•ç‹¬çš„å‚æ•°åŒ–çš„å·ç§¯è¾“å‡ºä¸Šè¿›è¡Œèµ¤åŒ–ï¼Œåˆ™ç‰¹å¾å¯ä»¥å­¦ä¹ åˆ°å¯¹å“ªä¸€ç§å˜æ¢è¿›è¡Œä¸å˜ã€‚ åˆ©ç”¨å·ç§¯å’Œpoolingçš„å·ç§¯ç½‘ç»œæž¶æž„ï¼š Convolution and Pooling as an Inï¬nitely Strong Prior å¼±å…ˆéªŒæ˜¯å…·æœ‰é«˜ç†µçš„å…ˆéªŒåˆ†å¸ƒï¼Œä¾‹å¦‚å…·æœ‰é«˜æ–¹å·®çš„é«˜æ–¯åˆ†å¸ƒã€‚ å¼ºå…ˆéªŒå…·æœ‰éžå¸¸ä½Žçš„ç†µï¼Œä¾‹å¦‚å…·æœ‰ä½Žæ–¹å·®çš„é«˜æ–¯åˆ†å¸ƒã€‚è¿™æ ·çš„å…ˆéªŒåœ¨ç¡®å®šå‚æ•°åœ¨å“ªé‡Œç»“æŸæ–¹é¢èµ·æ›´ç§¯æžçš„ä½œç”¨ã€‚ æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºå·ç§¯å¯ä»¥ç”¨æ¥ä¸ºä¸€ä¸ªå±‚çš„å‚æ•°å¼•å…¥ä¸€ä¸ªæ— é™å¼ºçš„å…ˆéªŒæ¦‚çŽ‡åˆ†å¸ƒã€‚ åŒæ ·ï¼Œæ± çš„ä½¿ç”¨æ˜¯ä¿è¯æ¯ä¸ªå•ä½å¯¹å°çš„å˜æ¢ä¿æŒä¸å˜æ€§çš„æ— é™å¼ºçš„å…ˆéªŒã€‚ ä½†æ˜¯å°†å·ç§¯ç½‘è§†ä¸ºå…·æœ‰æ— é™å¼ºçš„å…ˆéªŒçš„å®Œå…¨è¿žæŽ¥çš„ç½‘ç»œå¯ä»¥ç»™æˆ‘ä»¬ä¸€äº›å…³äºŽå·ç§¯ç½‘å¦‚ä½•å·¥ä½œçš„è§è§£ã€‚ ä¸€ä¸ªå…³é”®çš„è§è§£æ˜¯å·ç§¯å’Œæ± åŒ–å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆã€‚ ä»Žè¿™ä¸ªè§‚ç‚¹çš„å¦ä¸€ä¸ªå…³é”®çš„è§è§£æ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥åªæ¯”è¾ƒå·ç§¯æ¨¡åž‹ä¸Žç»Ÿè®¡å­¦ä¹ æ€§èƒ½åŸºå‡†ä¸­çš„å…¶ä»–å·ç§¯æ¨¡åž‹ã€‚å¯¹äºŽè®¸å¤šå›¾åƒæ•°æ®é›†ï¼Œå¯¹äºŽæŽ’åˆ—ä¸å˜çš„æ¨¡åž‹å­˜åœ¨å•ç‹¬çš„åŸºå‡†ï¼Œå¹¶ä¸”å¿…é¡»é€šè¿‡å­¦ä¹ å‘çŽ°æ‹“æ‰‘çš„æ¦‚å¿µï¼Œä»¥åŠå…·æœ‰ç”±ä»–ä»¬çš„è®¾è®¡è€…ç¡¬ç¼–ç åˆ°å…¶ä¸­çš„ç©ºé—´å…³ç³»çš„çŸ¥è¯†çš„æ¨¡åž‹ã€‚ Variants of the Basic Convolution Function é¦–å…ˆï¼Œå½“æˆ‘ä»¬åœ¨ç¥žç»ç½‘ç»œçš„ä¸Šä¸‹æ–‡ä¸­æåˆ°å·ç§¯æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å®žé™…ä¸Šæ„å‘³ç€ä¸€ç§ç”±è®¸å¤šå·ç§¯åº”ç”¨å¹¶è¡Œç»„æˆçš„æ“ä½œã€‚ è¿™æ˜¯å› ä¸ºå•ä¸ªå†…æ ¸çš„å·ç§¯åªèƒ½æå–ä¸€ç§ç‰¹å¾ï¼Œè™½ç„¶åœ¨è®¸å¤šç©ºé—´ä½ç½®ã€‚ é€šå¸¸æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬ç½‘ç»œçš„æ¯ä¸€å±‚éƒ½èƒ½åœ¨è®¸å¤šä½ç½®æå–å¤šç§ç‰¹å¾ã€‚ æ­¤å¤–ï¼Œè¾“å…¥é€šå¸¸ä¸ä»…ä»…æ˜¯æ˜¯ä¸€ä¸ªç½‘æ ¼çš„çœŸæ˜¯æ•°æ®ï¼Œåè€Œæ˜¯çŸ¢é‡å€¼çš„è§‚æµ‹ç½‘æ ¼ã€‚ è¿™äº›å¤šé€šé“æ“ä½œå¯äº¤æ¢ï¼Œä»…å½“æ¯ä¸ªæ“ä½œå…·æœ‰ä¸Žè¾“å…¥é€šé“ç›¸åŒæ•°é‡çš„è¾“å‡ºé€šé“ã€‚ æˆ‘ä»¬å¯èƒ½æƒ³è·³è¿‡å†…æ ¸çš„ä¸€äº›ä½ç½®ï¼Œä»¥å‡å°‘è®¡ç®—æˆæœ¬ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºè¿™æ˜¯ä¸‹é‡‡æ ·å…¨å·ç§¯å‡½æ•°çš„è¾“å‡ºã€‚ å¦‚æžœæˆ‘ä»¬åªæƒ³å¯¹è¾“å‡ºä¸­æ¯ä¸ªæ–¹å‘çš„æ¯sä¸ªåƒç´ è¿›è¡Œé‡‡æ ·ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸‹é‡‡æ ·å·ç§¯å‡½æ•°cï¼šæˆ‘ä»¬å°†sç§°ä¸ºè¿™ä¸ªä¸‹é‡‡æ ·å·ç§¯çš„æ­¥å¹…ã€‚ ä¹Ÿå¯ä»¥ä¸ºæ¯ä¸ªè¿åŠ¨æ–¹å‘å®šä¹‰ä¸€ä¸ªå•ç‹¬çš„æ­¥å¹…ã€‚ é›¶å¡«å……ï¼š ä»»ä½•å·ç§¯ç½‘ç»œå®žçŽ°çš„ä¸€ä¸ªåŸºæœ¬ç‰¹å¾æ˜¯å…·å¤‡éšå«åœ°å¯¹è¾“å…¥Vè¿›è¡Œé›¶å¡«å……ä»¥ä¾¿ä½¿å…¶æ›´å®½çš„èƒ½åŠ›ã€‚ é›¶å¡«å……è¾“å…¥å…è®¸æˆ‘ä»¬ç‹¬ç«‹åœ°æŽ§åˆ¶å†…æ ¸å®½åº¦å’Œè¾“å‡ºçš„å¤§å°ã€‚ æ²¡æœ‰é›¶å¡«å……ï¼Œæˆ‘ä»¬è¢«è¿«é€‰æ‹©å¿«é€Ÿç¼©å°ç½‘ç»œçš„ç©ºé—´èŒƒå›´å¹¶ä¸”ä½¿ç”¨å°å†…æ ¸ - è¿™ä¸¤ä¸ªæ–¹æ¡ˆï¼Œæ˜¾ç€åœ°é™åˆ¶äº†ç½‘ç»œçš„è¡¨è¾¾åŠ›ã€‚ ä¸‰ç§zero-paddingçš„æƒ…å†µï¼š valid convolution same convolution full convolution Unshared convolution Tiled convolutionï¼šåœ¨å·ç§¯å±‚å’Œæœ¬åœ°è¿žæŽ¥å±‚ä¹‹é—´æä¾›äº†æŠ˜ä¸­ã€‚æˆ‘ä»¬ä¸æ˜¯åœ¨æ¯ä¸ªç©ºé—´ä½ç½®å­¦ä¹ ä¸€ç»„ç‹¬ç«‹çš„æƒé‡ï¼Œè€Œæ˜¯å­¦ä¹ ä¸€ç»„å†…æ ¸ï¼Œä»Žè€Œæˆ‘ä»¬åœ¨ç©ºé—´ç§»åŠ¨æ—¶æ—‹è½¬å†…æ ¸ã€‚ è¿™ä¸‰ä¸ªæ“ä½œåšå¤Ÿè®¡ç®—æ‰€æœ‰è®­ç»ƒä¸€ä¸ªå‰å‘å·ç§¯ç½‘ç»œéœ€è¦çš„æ¢¯åº¦ï¼Œä»¥åŠåŸºäºŽå·ç§¯çš„è½¬ç½®æ¥è®­ç»ƒå…·æœ‰é‡å»ºå‡½æ•°çš„å·ç§¯ç½‘ç»œã€‚ å·ç§¯ ä»Žè¾“å‡ºåˆ°æƒå€¼åå‘ä¼ æ’­ ä»Žè¾“å‡ºåˆ°è¾“å…¥åå‘ä¼ æ’­ Structured Outputs å·ç§¯ç½‘ç»œå¯ä»¥ç”¨äºŽè¾“å‡ºé«˜ç»´åº¦çš„ç»“æž„åŒ–å¯¹è±¡ï¼Œè€Œä¸ä»…ä»…æ˜¯é¢„æµ‹åˆ†ç±»ä»»åŠ¡çš„ç±»æ ‡ç­¾æˆ–å›žå½’ä»»åŠ¡çš„å®žé™…å€¼ã€‚ Pixel labelingï¼šåƒç´ æ ‡è®° å¾ªçŽ¯å‘¨æœŸå·ç§¯ç½‘ç»œï¼ˆrecurrent convolutional networkï¼‰ï¼š Data Types ä¸Žå·ç§¯ç½‘ç»œä¸€èµ·ä½¿ç”¨çš„æ•°æ®é€šå¸¸ç”±å‡ ä¸ªé€šé“ç»„æˆï¼Œæ¯ä¸ªé€šé“æ˜¯åœ¨ç©ºé—´æˆ–æ—¶é—´çš„æŸä¸ªç‚¹è§‚å¯Ÿä¸åŒçš„é‡ã€‚ å·ç§¯ç½‘ç»œçš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯å®ƒä»¬è¿˜å¯ä»¥å¤„ç†å…·æœ‰å˜åŒ–çš„ç©ºé—´èŒƒå›´çš„è¾“å…¥ã€‚ æœ‰æ—¶ï¼Œç½‘ç»œçš„è¾“å‡ºå…è®¸å…·æœ‰ å¯å˜å¤§å°ä»¥åŠè¾“å…¥ ï¼Œä¾‹å¦‚å¦‚æžœæˆ‘ä»¬æƒ³è¦ä¸ºè¾“å…¥çš„æ¯ä¸ªåƒç´ åˆ†é…ç±»æ ‡ç­¾ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸éœ€è¦é¢å¤–çš„è®¾è®¡å·¥ä½œäº† ã€‚ åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œç½‘ç»œå¿…é¡»äº§ç”Ÿä¸€äº›å›ºå®šå¤§å°çš„è¾“å‡ºï¼Œä¾‹å¦‚ï¼Œå¦‚æžœæˆ‘ä»¬è¦ä¸ºæ•´ä¸ªå›¾åƒåˆ†é…å•ä¸ªç±»æ ‡ç­¾ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»è¿›è¡Œä¸€äº›é¢å¤–çš„è®¾è®¡æ­¥éª¤ ï¼Œä¾‹å¦‚æ’å…¥ä¸€ä¸ªæ± åŒ–å±‚ï¼Œå…¶æ± åŒºåŸŸçš„å¤§å°ä¸Žè¾“å…¥çš„å¤§å°æˆæ¯”ä¾‹ï¼Œä»¥ ä¿æŒå›ºå®šæ•°é‡ çš„æ± åŒ–è¾“å‡ºã€‚ Eï¬ƒcient Convolution Algorithms çŽ°ä»£å·ç§¯ç½‘ç»œåº”ç”¨é€šå¸¸æ¶‰åŠåŒ…å«è¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªå•å…ƒçš„ç½‘ç»œã€‚ å·ç§¯ç­‰æ•ˆäºŽä½¿ç”¨å‚…ç«‹å¶å˜æ¢å°†è¾“å…¥å’Œå†…æ ¸ä¸¤è€…è½¬æ¢åˆ°é¢‘åŸŸï¼Œæ‰§è¡Œä¸¤ä¸ªä¿¡å·çš„é€ç‚¹ä¹˜æ³•ï¼Œå¹¶ä½¿ç”¨é€†å‚…é‡Œå¶å˜æ¢è½¬æ¢å›žåˆ°æ—¶åŸŸã€‚ å½“å†…æ ¸æ˜¯å¯åˆ†ç¦»çš„ï¼ŒåŽŸå§‹çš„å·ç§¯æ˜¯æ•ˆçŽ‡ä½Žä¸‹çš„ã€‚ è®¾è®¡æ›´å¿«çš„æ‰§è¡Œå·ç§¯æˆ–è¿‘ä¼¼å·ç§¯çš„æ–¹æ³•ï¼Œè€Œä¸æŸå®³æ¨¡åž‹çš„å‡†ç¡®æ€§æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚ Random or Unsupervised Features é€šå¸¸ï¼Œå·ç§¯ç½‘ç»œè®­ç»ƒä¸­æœ€æ˜‚è´µçš„éƒ¨åˆ†æ˜¯å­¦ä¹ ç‰¹å¾ã€‚ é™ä½Žå·ç§¯ç½‘ç»œè®­ç»ƒæˆæœ¬çš„ä¸€ç§æ–¹å¼æ˜¯ä½¿ç”¨æœªä»¥å—ç›‘ç£æ–¹å¼è®­ç»ƒçš„ç‰¹å¾ã€‚ æœ‰ä¸‰ç§ä¸éœ€è¦ç›‘ç£å­¦ä¹ æ¥èŽ·å¾—å·ç§¯å†…æ ¸çš„ç­–ç•¥ï¼š ä¸€ä¸ªæ˜¯ç®€å•åœ° éšæœºåˆå§‹åŒ– å®ƒä»¬ã€‚ å¦ä¸€ä¸ªæ˜¯ç”¨æ‰‹è®¾è®¡å®ƒä»¬ï¼Œä¾‹å¦‚é€šè¿‡è®¾ç½®æ¯ä¸ªå†…æ ¸ä»¥åœ¨ç‰¹å®šæ–¹å‘æˆ–å°ºåº¦æ£€æµ‹è¾¹ç¼˜ã€‚ æœ€åŽï¼Œå¯ä»¥ä½¿ç”¨æ— ç›‘ç£æ ‡å‡†æ¥å­¦ä¹ å†…æ ¸ã€‚ éšæœºæ»¤æ³¢å™¨åœ¨å·ç§¯ç½‘ç»œä¸­é€šå¸¸å·¥ä½œå¾—å¾ˆå¥½ ä¸€ä¸ªæŠ˜ä¸­çš„æ–¹æ³•æ˜¯å­¦ä¹ ç‰¹å¾ï¼Œä½†ä½¿ç”¨ï¼š æ¯ä¸ªæ¢¯åº¦æ­¥éª¤ä¸éœ€è¦å®Œå…¨æ­£å‘å’Œåå‘ä¼ æ’­çš„ æ–¹æ³•ã€‚ ä¸Žå¤šå±‚æ„ŸçŸ¥å™¨ä¸€æ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨ è´ªå©ªå±‚å¼é¢„è®­ç»ƒ ï¼Œç‹¬ç«‹åœ°è®­ç»ƒç¬¬ä¸€å±‚ï¼Œç„¶åŽä»Žç¬¬ä¸€å±‚æå–ä¸€æ¬¡æ‰€æœ‰ç‰¹å¾ï¼Œç„¶åŽåˆ©ç”¨è¿™äº›ç‰¹å¾éš”ç¦»çš„è®­ç»ƒç¬¬äºŒå±‚ï¼Œç­‰ç­‰ã€‚ ä¸æ˜¯ä¸€æ¬¡è®­ç»ƒæ•´ä¸ªå·ç§¯å±‚ï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒä¸€ä¸ªå°è¡¥ä¸çš„æ¨¡åž‹ï¼Œå¦‚ç”¨k-meansã€‚ ç„¶åŽï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¥è‡ªè¿™ä¸ªpatch-basedçš„æ¨¡åž‹çš„å‚æ•°æ¥å®šä¹‰å·ç§¯å±‚çš„å†…æ ¸ã€‚ ä»Šå¤©ï¼Œå¤§å¤šæ•°å·ç§¯ç½‘ç»œä»¥çº¯ç²¹ç›‘ç£çš„æ–¹å¼è®­ç»ƒï¼Œåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ä½¿ç”¨é€šè¿‡æ•´ä¸ªç½‘ç»œçš„å®Œå…¨æ­£å‘å’Œåå‘ä¼ æ’­ã€‚ The Neuroscientiï¬c Basis for Convolutional NetworksConvolutional Networks and the History of Deep Learning ä¸ºäº†å¤„ç†ä¸€ç»´ï¼Œé¡ºåºæ•°æ®ï¼Œæˆ‘ä»¬æŽ¥ä¸‹æ¥è½¬å‘ç¥žç»ç½‘ç»œæ¡†æž¶çš„å¦ä¸€ä¸ªå¼ºå¤§çš„ä¸“ä¸šåŒ–ï¼š å¾ªçŽ¯ç¥žç»ç½‘ç»œï¼ˆRecurrent neural networksï¼‰ ã€‚]]></content>
      <categories>
        <category>è¯»ä¹¦ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šHistograms of Oriented Gradients for Human Detection]]></title>
    <url>%2Fposts%2F3084343215%2F</url>
    <content type="text"><![CDATA[ç›¸å…³çŸ¥è¯†ç‚¹ ä»ŽTPã€FPã€TNã€FNåˆ°ROCæ›²çº¿ã€miss rate TPï¼štrue positiveï¼Œå®žé™…æ˜¯æ­£ä¾‹ï¼Œé¢„æµ‹ä¸ºæ­£ä¾‹ FPï¼šfalse positiveï¼Œå®žé™…ä¸ºè´Ÿä¾‹ï¼Œé¢„æµ‹ä¸ºæ­£ä¾‹ TNï¼štrue negativeï¼Œå®žé™…ä¸ºè´Ÿä¾‹ï¼Œé¢„æµ‹ä¸ºè´Ÿä¾‹ FNï¼šfalse negativeï¼Œå®žé™…ä¸ºæ­£ä¾‹ï¼Œé¢„æµ‹ä¸ºè´Ÿä¾‹ fnr+tpr=1, fpr+tnr=1 miss rate = FNR = 1 - true positive å¯¹äºŽä¸€ä¸ªç¡®å®šçš„é˜ˆå€¼tï¼ŒFPRå’ŒTPRæ˜¯ç¡®å®šçš„ï¼Œå¾—åˆ°ä¸€ä¸ª(fpr,tpr)å…ƒç»„ã€‚ å½“tå¢žåŠ ï¼Œ # FPä¹Ÿå‡å°ï¼Œ # TNå¢žåŠ ï¼Œåˆ™fprå‡å°ï¼› å½“tå¢žåŠ ï¼Œ # TPå‡å°ï¼Œ # FNå¢žåŠ ï¼Œåˆ™tprå‡å°ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“é˜ˆå€¼tä»Ž0å˜åŒ–åˆ°1ï¼Œfprå’Œtprä¹Ÿå•è°ƒå‡å°ï¼Œä»Ž(1ï¼Œ1)å‡å°åˆ°(0,0) miss rate = 1 - true positive rateï¼Œé‚£ä¹ˆå¯¹åº”çš„YoXå›¾åƒï¼Œä¹Ÿå°±æ˜¯miss rate - false positive rateå›¾åƒï¼Œå°±åº”å½“æ˜¯å•è°ƒä¸‹é™çš„æ›²çº¿ã€‚ Abstract å®šå‘æ¢¯åº¦ç›´æ–¹å›¾ï¼ˆHOGï¼‰æè¿°ç¬¦çš„ç½‘æ ¼æ˜¾è‘—ä¼˜äºŽçŽ°æœ‰çš„äººä½“æ£€æµ‹ç‰¹å¾é›†ã€‚ åœ¨é‡å æè¿°ç¬¦å—ä¸­çš„ ç²¾ç»†å°ºåº¦æ¢¯åº¦ ï¼Œ ç²¾ç»†å®šå‘åˆ†ç®± ï¼Œ ç›¸å¯¹ç²—ç•¥çš„ç©ºé—´åˆ†ç®± å’Œ é«˜è´¨é‡å±€éƒ¨å¯¹æ¯”åº¦æ ‡å‡†åŒ– å¯¹äºŽè‰¯å¥½çš„ç»“æžœéƒ½æ˜¯é‡è¦çš„ã€‚ æ–°çš„æ•°æ®é›† Introduction ç¬¬ä¸€éœ€æ±‚ï¼šrobust feature set. æˆ‘ä»¬ç ”ç©¶äº†äººç±»ç›‘æµ‹çš„ç‰¹å¾é›†é—®é¢˜ï¼Œå‘çŽ° æœ¬åœ°å½’ä¸€åŒ–çš„å®šå‘æ¢¯åº¦ç›´æ–¹å›¾ï¼ˆHOGï¼‰ æè¿°ç¬¦æä¾›ä¼˜å¼‚çš„æ€§èƒ½ç›¸å¯¹äºŽå…¶ä»–çŽ°æœ‰ç‰¹å¾é›†åŒ…æ‹¬å°æ³¢ã€‚ æå‡ºçš„æè¿°ç¬¦è®©äººè”æƒ³åˆ° è¾¹ç¼˜æ–¹å‘ç›´æ–¹å›¾ [4,5]ï¼Œ SIFTæè¿°ç¬¦ [12]å’Œ å½¢çŠ¶ä¸Šä¸‹æ–‡ [1]ï¼Œä½†ä¸Žå®ƒä»¬çš„ä¸åŒç‚¹æ˜¯ï¼šHOGæè¿°å™¨æ˜¯åœ¨ä¸€ä¸ªç½‘æ ¼å¯†é›†çš„å¤§å°ç»Ÿä¸€çš„ç»†èƒžå•å…ƒï¼ˆdense grid of uniformly spaced cellsï¼‰ä¸Šè®¡ç®—ï¼Œè€Œä¸”ä¸ºäº†æé«˜æ€§èƒ½ï¼Œè¿˜é‡‡ç”¨äº†é‡å çš„å±€éƒ¨å¯¹æ¯”åº¦å½’ä¸€åŒ–ï¼ˆoverlapping local contrast normalizationï¼‰æŠ€æœ¯ã€‚ Previous WorkOverview of the Method The method is based on evaluating well-normalized local histograms of image gradient orientations in a dense grid. åŸºæœ¬æ€æƒ³æ˜¯ï¼Œåœ¨ä¸€å‰¯å›¾åƒä¸­ï¼Œå±€éƒ¨ç›®æ ‡çš„ è¡¨è±¡ å’Œ å½¢çŠ¶ ï¼ˆappearance and shapeï¼‰èƒ½å¤Ÿè¢«æ¢¯åº¦æˆ–è¾¹ç¼˜çš„æ–¹å‘å¯†åº¦åˆ†å¸ƒå¾ˆå¥½åœ°æè¿°ï¼Œå³ä½¿æ²¡æœ‰å¯¹åº”çš„æ¢¯åº¦æˆ–è¾¹ç¼˜ä½ç½®çš„ç²¾ç¡®çŸ¥è¯†ã€‚ å…·ä½“çš„å®žçŽ°æ–¹æ³•æ˜¯ï¼šé¦–å…ˆå°†å›¾åƒåˆ†æˆå°çš„è¿žé€šåŒºåŸŸï¼Œæˆ‘ä»¬æŠŠå®ƒå«ç»†èƒžå•å…ƒï¼ˆcellï¼‰ã€‚ç„¶åŽé‡‡é›†ç»†èƒžå•å…ƒä¸­å„åƒç´ ç‚¹çš„æ¢¯åº¦çš„æˆ–è¾¹ç¼˜çš„æ–¹å‘ç›´æ–¹å›¾ã€‚æœ€åŽæŠŠè¿™äº›ç›´æ–¹å›¾ç»„åˆèµ·æ¥å°±å¯ä»¥æž„æˆç‰¹å¾æè¿°å™¨ã€‚ ä¸ºäº†æé«˜æ€§èƒ½ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æŠŠè¿™äº›å±€éƒ¨ç›´æ–¹å›¾åœ¨å›¾åƒçš„æ›´å¤§çš„èŒƒå›´å†…ï¼ˆæˆ‘ä»¬æŠŠå®ƒå«åŒºé—´æˆ–blockï¼‰è¿›è¡Œå¯¹æ¯”åº¦å½’ä¸€åŒ–ï¼ˆcontrast-normalizedï¼‰ï¼Œæ‰€é‡‡ç”¨çš„æ–¹æ³•æ˜¯ï¼šå…ˆè®¡ç®—å„ç›´æ–¹å›¾åœ¨è¿™ä¸ªåŒºé—´ï¼ˆblockï¼‰ä¸­çš„å¯†åº¦ï¼Œç„¶åŽæ ¹æ®è¿™ä¸ªå¯†åº¦å¯¹åŒºé—´ä¸­çš„å„ä¸ªç»†èƒžå•å…ƒåšå½’ä¸€åŒ–ã€‚ é€šè¿‡è¿™ä¸ªå½’ä¸€åŒ–åŽï¼Œèƒ½å¯¹å…‰ç…§å˜åŒ–å’Œé˜´å½±èŽ·å¾—æ›´å¥½çš„æ•ˆæžœã€‚ æ•´ä½“çš„ç‰©ä½“æ£€æµ‹é“¾ï¼š è¿™äº›åŸºäºŽç¨€ç–ç‰¹å¾çš„è¡¨ç¤ºçš„æˆåŠŸæœ‰ç‚¹é®è”½äº†HOGä½œä¸ºå¯†é›†å›¾åƒæè¿°ç¬¦çš„èƒ½åŠ›å’Œç®€å•æ€§ã€‚ HOG/SIFTè¡¨ç¤ºæ–¹æ³•æœ‰å‡ ä¸ªä¼˜ç‚¹ã€‚ ç”±äºŽHOGæ–¹æ³•æ˜¯åœ¨å›¾åƒçš„å±€éƒ¨ç»†èƒžå•å…ƒä¸Šæ“ä½œï¼Œæ‰€ä»¥å®ƒå¯¹å›¾åƒå‡ ä½•çš„ï¼ˆgeometricï¼‰å’Œå…‰å­¦çš„ï¼ˆphotometricï¼‰å½¢å˜éƒ½èƒ½ä¿æŒå¾ˆå¥½çš„ä¸å˜æ€§ï¼Œè¿™ä¸¤ç§å½¢å˜åªä¼šå‡ºçŽ°åœ¨æ›´å¤§çš„ç©ºé—´é¢†åŸŸä¸Šã€‚ ä»–æ•æ‰äº†å±€éƒ¨å½¢çŠ¶éžå¸¸å…·æœ‰ç‰¹å¾æ€§çš„è¾¹å’Œæ¢¯åº¦ç‰¹å¾ã€‚ åœ¨å±€éƒ¨è¡¨ç¤ºä¸­å¯¹å±€éƒ¨çš„å‡ ä½•å’Œå…‰åº¦å˜æ¢çš„ä¸å˜æ€§æ›´å®¹æ˜“æŽ§åˆ¶ã€‚ å¦‚æžœå®ƒä»¬è¿œå°äºŽå±€éƒ¨ç©ºé—´æˆ–æ–¹å‘ä»“å°ºå¯¸ï¼Œåˆ™å¹³ç§»æˆ–æ—‹è½¬å‡ ä¹Žæ²¡æœ‰å·®åˆ«ã€‚ ä½œè€…é€šè¿‡å®žéªŒå‘çŽ°ï¼Œåœ¨ç²—çš„ç©ºåŸŸæŠ½æ ·ï¼ˆcoarse spatial samplingï¼‰ã€ç²¾ç»†çš„æ–¹å‘æŠ½æ ·ï¼ˆfine orientation samplingï¼‰ä»¥åŠè¾ƒå¼ºçš„å±€éƒ¨å…‰å­¦å½’ä¸€åŒ–ï¼ˆstrong local photometric normalizationï¼‰ç­‰æ¡ä»¶ä¸‹ï¼Œåªè¦è¡Œäººå¤§ä½“ä¸Šèƒ½å¤Ÿä¿æŒç›´ç«‹çš„å§¿åŠ¿ï¼Œå°±å®¹è®¸è¡Œäººæœ‰ä¸€äº›ç»†å¾®çš„è‚¢ä½“åŠ¨ä½œï¼Œè¿™äº›ç»†å¾®çš„åŠ¨ä½œå¯ä»¥è¢«å¿½ç•¥è€Œä¸å½±å“æ£€æµ‹æ•ˆæžœã€‚ç»¼ä¸Šæ‰€è¿°ï¼ŒHOGæ–¹æ³•æ˜¯ç‰¹åˆ«é€‚åˆäºŽåšå›¾åƒä¸­çš„è¡Œäººæ£€æµ‹çš„ã€‚ Data Sets and Methodology hard examples Detection Error Tradeoff (DET) curves on a log-log scale. miss rate(1-Recall / FN/(TP+FN)) verses FPPW. å€¼è¶Šä½Žè¶Šå¥½ã€‚ DETå›¾å’ŒROCå›¾æä¾›çš„ä¿¡æ¯ä¸€çœ¼ï¼Œä½†æ˜¯å‰è€…å…è®¸å°æ¦‚çŽ‡æ›´å®¹æ˜“çš„åŽ»åˆ†å¸ƒã€‚ FPPWï¼šNUMBER_OF_FALSE_POSITIVE/NUMBER_OF_WINDOWS æˆ‘ä»¬çš„DETæ›²çº¿é€šå¸¸ç›¸å½“æµ…ï¼Œæ‰€ä»¥å³ä½¿éžå¸¸å°çš„ç¼ºå¤±çŽ‡çš„æ”¹å–„ä¹Ÿç­‰åŒäºŽåœ¨ä¸å˜ç¼ºå¤±çŽ‡ä¸‹çš„æƒ…å†µä¸‹FPPWä¸­çš„å¤§å¢žç›Šã€‚ Overview of Results Generalized Haar Wavelets. PCA-SIFT. Shape Contexts. Implementation and Performance Study é»˜è®¤æ£€æµ‹å™¨ï¼š RGB colour space with no gamma correction [âˆ’1, 0, 1] gradient filter with no smoothing linear gradient voting into 9 orientation bins in 0â—¦ â€“180â—¦ 16Ã—16 pixel blocks of four 8Ã—8 pixel cells Gaussian spatial win- dow with Ïƒ = 8 pixel L2-Hys (Lowe-style clipped L2 norm) block normalization block spacing stride of 8 pixels (hence 4-fold coverage of each cell) 64Ã—128 detection window; linear SVM classifier. ä¸»è¦çš„ç»“è®ºæ˜¯ï¼Œä¸ºäº†è‰¯å¥½çš„æ€§èƒ½ï¼Œåº”è¯¥ä½¿ç”¨ç»†å°ºåº¦å¯¼æ•°ï¼ˆåŸºæœ¬ä¸Šæ²¡æœ‰å¹³æ»‘ï¼‰ï¼Œè®¸å¤šå®šå‘ä»“,ä¸­ç­‰å¤§å°ï¼Œå¼ºå½’ä¸€åŒ–ï¼Œé‡å çš„æè¿°ç¬¦å—ã€‚ Gamma/Colour NormalizationGradient Computation æœ€é€šå¸¸ç”¨çš„æ–¹æ³•å°±æ˜¯ç®€å•çš„åº”ç”¨ä¸€ä¸ªä¸€ç»´çš„ç¦»æ•£çš„æ¢¯åº¦æ¨¡ç‰ˆåˆ†åˆ«åº”ç”¨åœ¨æ°´å¹³å’Œåž‚ç›´æ–¹å‘ä¸ŠåŽ»ã€‚å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å·ç§¯æ ¸è¿›è¡Œå·ç§¯ï¼š Spatial / Orientation Binning(æ–¹å‘å•å…ƒåˆ’åˆ†) æ¯ä¸ªå—å†…çš„æ¯ä¸ªåƒç´ å¯¹ æ–¹å‘ç›´æ–¹å›¾ è¿›è¡ŒæŠ•ç¥¨ æ¯ä¸ªåƒç´ åŸºäºŽä»¥å…¶ä¸ºä¸­å¿ƒçš„æ¢¯åº¦å…ƒç´ çš„æ–¹å‘è®¡ç®—è¾¹ç¼˜å–å‘ç›´æ–¹å›¾é€šé“çš„ åŠ æƒæŠ•ç¥¨ï¼Œå¹¶ä¸”æŠ•ç¥¨è¢«ç´¯ç§¯åˆ°åœ¨ç§°ä¸º å•å…ƒ çš„å±€éƒ¨ç©ºé—´åŒºåŸŸä¸Šçš„ æ–¹å‘ä»“ ä¸­ã€‚ æ¯ä¸ªå—çš„å½¢çŠ¶å¯ä»¥æ˜¯çŸ©å½¢æˆ–åœ†å½¢çš„ æ–¹å‘ç›´æ–¹å›¾çš„æ–¹å‘å–å€¼å¯ä»¥æ˜¯0-180åº¦æˆ–è€…0-360åº¦ï¼Œè¿™å–å†³äºŽæ¢¯åº¦æ˜¯å¦æœ‰ç¬¦å·ã€‚æ— ç¬¦å·æ¢¯åº¦ï¼ˆ0-180Âºï¼‰ï¼Œæœ‰ç¬¦å·æ¢¯åº¦ï¼ˆ0-360Âºï¼‰ ä¸ºäº†å‡å°‘æ··å ï¼ŒæŠ•ç¥¨åœ¨ç›¸é‚»ä»“ä¸­å¿ƒä¹‹é—´ä»¥å–å‘å’Œä½ç½®åŒå‘å†…æ’ã€‚ è‡³äºŽæŠ•ç¥¨çš„æƒé‡ï¼Œå¯ä»¥æ˜¯æ¢¯åº¦çš„å¹…åº¦æœ¬èº«æˆ–è€…æ˜¯å®ƒçš„å‡½æ•°ã€‚æŠ•ç¥¨æ˜¯åƒç´ å¤„çš„æ¢¯åº¦å¹…åº¦çš„å‡½æ•°ï¼Œæˆ–è€…æ˜¯å¹…åº¦æœ¬èº«ã€å…¶å¹³æ–¹ã€å…¶å¹³æ–¹æ ¹æˆ–è€…è¡¨ç¤ºåƒç´ çš„è¾¹ç¼˜çš„è½¯å‡ºçŽ°/ç¼ºå¤±çš„å¹…åº¦çš„é™å¹…å½¢å¼ã€‚åœ¨å®šå‘ç¼–ç å¯¹äºŽè‰¯å¥½çš„æ€§èƒ½æ˜¯è‡³å…³é‡è¦çš„ã€‚ æ¢¯åº¦å¹…åº¦æœ¬èº«é€šå¸¸äº§ç”Ÿæœ€å¥½çš„ç»“æžœã€‚å…¶å®ƒå¯é€‰çš„æ–¹æ¡ˆæ˜¯é‡‡ç”¨å¹…åº¦çš„å¹³æ–¹æˆ–å¼€æ–¹ï¼Œæˆ–è€…å¹…åº¦çš„è£å‰ªç‰ˆæœ¬ã€‚ Dalalå’ŒTriggså‘çŽ°åœ¨äººçš„æ£€æµ‹å®žéªŒä¸­ï¼ŒæŠŠæ–¹å‘åˆ†ä¸º 9ä¸ªé€šé“(bin) æ•ˆæžœæœ€å¥½ Normalization and Descriptor Blocks ç”±äºŽç…§æ˜Žçš„å±€éƒ¨å˜åŒ–å’Œå‰æ™¯-èƒŒæ™¯å¯¹æ¯”åº¦ï¼Œæ¢¯åº¦å¼ºåº¦åœ¨å¯ä»¥åœ¨å¾ˆå®½èŒƒå›´å†…å˜åŒ–ã€‚æ‰€ä»¥æ¢¯åº¦å¼ºåº¦å¿…é¡»è¦å±€éƒ¨åœ°å½’ä¸€åŒ–ï¼Œè¿™éœ€è¦æŠŠæ–¹æ ¼(cells)é›†ç»“æˆæ›´å¤§ã€åœ¨ç©ºé—´ä¸Šè¿žç»“çš„åŒº() æœ‰æ•ˆçš„å±€éƒ¨å¯¹æ¯”åº¦å½’ä¸€åŒ– å¯¹äºŽè‰¯å¥½çš„æ€§èƒ½æ˜¯å¿…ä¸å¯å°‘çš„ã€‚ æˆ‘ä»¬è¯„ä¼°äº†å¤šç§ä¸åŒçš„ å½’ä¸€åŒ–schemes(normalization schemes) ï¼Œä»–ä»¬å¤§å¤šæ•°éƒ½æ˜¯åŸºäºŽå°†å•å…ƒæ ¼ï¼ˆcellsï¼‰åˆ†ç»„æˆæ›´å¤§çš„ç©ºé—´å—ï¼ˆspatial blocksï¼‰ å¹¶ä¸”å¯¹æ¯”åœ°å•ç‹¬å¯¹æ¯ä¸ªå—è¿›è¡Œå½’ä¸€åŒ–ã€‚ æœ€ç»ˆæè¿°ç¬¦ æ˜¯æ¥è‡ªæ£€æµ‹çª—å£ä¸­çš„æ‰€æœ‰å—çš„å½’ä¸€åŒ–å•å…ƒå“åº”çš„æ‰€æœ‰åˆ†é‡çš„ å‘é‡ ã€‚ R-HOGï¼šR-HOGå—å’ŒSIFTæè¿°ç¬¦æœ‰è®¸å¤šç›¸ä¼¼ä¹‹å¤„ï¼Œä½†æ˜¯ä»–ä»¬ç”¨é€”ååˆ†ä¸åŒã€‚ R-HOGè·ŸSIFTæè¿°å™¨çœ‹èµ·æ¥å¾ˆç›¸ä¼¼ï¼Œä½†ä»–ä»¬çš„ä¸åŒä¹‹å¤„æ˜¯ï¼š R-HOGæ˜¯åœ¨å•ä¸€å°ºåº¦ä¸‹ã€å¯†é›†çš„ç½‘æ ¼å†…ã€æ²¡æœ‰å¯¹æ–¹å‘æŽ’åºçš„æƒ…å†µä¸‹è¢«è®¡ç®—å‡ºæ¥ï¼› è€ŒSIFTæè¿°å™¨æ˜¯åœ¨å¤šå°ºåº¦ä¸‹ã€ç¨€ç–çš„å›¾åƒå…³é”®ç‚¹ä¸Šã€å¯¹æ–¹å‘æŽ’åºçš„æƒ…å†µä¸‹è¢«è®¡ç®—å‡ºæ¥ã€‚ R-HOGæ˜¯å„åŒºé—´è¢«ç»„åˆèµ·æ¥ç”¨äºŽå¯¹ç©ºåŸŸä¿¡æ¯è¿›è¡Œç¼–ç ï¼Œè€ŒSIFTçš„å„æè¿°å™¨æ˜¯å•ç‹¬ä½¿ç”¨çš„ã€‚ å®ƒä»¬åœ¨å¯†é›†ç½‘æ ¼ä¸­ä»¥å•ä¸ªå°ºåº¦è®¡ç®—è€Œæ²¡æœ‰ä¸»è¦å–å‘å¯¹å‡†ï¼Œå¹¶ä¸”ç”¨ä½œéšå¼åœ°åŽ»ç¼–ç ç›¸å¯¹äºŽæ£€æµ‹çª—å£çš„ç©ºé—´ä½ç½®çš„è¾ƒå¤§ä»£ç çŸ¢é‡çš„ä¸€éƒ¨åˆ†ï¼Œè€ŒSIFTåœ¨ç¨€ç–é›†åˆçš„ å°ºåº¦ä¸å˜å…³é”®ç‚¹å¤„ è¢«è®¡ç®—ï¼Œæ—‹è½¬ä»¥å¯¹å‡†å®ƒä»¬çš„ä¸»å¯¼æ–¹å‘ï¼Œå¹¶å•ç‹¬ä½¿ç”¨ã€‚ SIFTè¢«ä¼˜åŒ–ç”¨äºŽç¨€ç–å®½åŸºçº¿åŒ¹é…ï¼ŒR-HOGç”¨äºŽç©ºé—´å½¢å¼çš„å¯†é›†é²æ£’ç¼–ç ã€‚ R-HOGåŒºå—ä¸€èˆ¬æ¥è¯´æ˜¯å¤šä¸ªæ–¹æ ¼å­ç»„æˆçš„ï¼Œç”±ä¸‰ä¸ªå‚æ•°è¡¨ç¤ºï¼š æ¯ä¸ªåŒºå—(block)æœ‰å¤šå°‘æ–¹æ ¼(cell)ã€ æ¯ä¸ªæ–¹æ ¼(cell)æœ‰å‡ ä¸ªåƒç´ (pixel)ã€ æ¯ä¸ªæ–¹æ ¼(cell)ç›´æ–¹å›¾æœ‰å¤šå°‘é¢‘é“(bin)ã€‚ å¯¹äºŽäººä½“æ£€æµ‹ï¼Œ3x3çš„å•å…ƒå—ï¼Œ6x6çš„åƒç´ å•å…ƒå—å„¿è¡¨çŽ°æœ€å¥½ï¼ŒåŒæ—¶ç›´æ–¹å›¾æ˜¯9é€šé“ã€‚ å½“å…¶å¤ªå°ï¼ˆ1Ã—1å•å…ƒå—ï¼Œå³ï¼Œå•ç‹¬å–å‘ä¸Šçš„å½’ä¸€åŒ–ï¼‰æ—¶ï¼Œæœ‰ä»·å€¼çš„ç©ºé—´ä¿¡æ¯è¢«æŠ‘åˆ¶ã€‚ åœ¨å¯¹ç›´æ–¹å›¾åšå¤„ç†ä¹‹å‰ï¼Œç»™æ¯ä¸ªåŒºé—´åŠ ä¸€ä¸ªé«˜æ–¯ç©ºåŸŸçª—å£æ˜¯éžå¸¸å¿…è¦çš„ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥é™ä½Žè¾¹ç¼˜çš„å‘¨å›´åƒç´ ç‚¹çš„æƒé‡ã€‚ C-HOG æ¯ä¸ªç©ºé—´å•å…ƒåŒ…å«æ¢¯åº¦åŠ æƒå–å‘å•å…ƒçš„å †å è€Œä¸æ˜¯å•ä¸ªå–å‘æ— å…³çš„è¾¹ç¼˜è®¡æ•°ã€‚ å¯¹æ•°æžåæ ‡ç½‘æ ¼æœ€åˆæ˜¯ç”±å…è®¸é™„è¿‘ç»“æž„çš„ç²¾ç»†ç¼–ç ä¸Žè¾ƒå®½ä¸Šä¸‹æ–‡çš„ç²—ç•¥ç¼–ç ç›¸ç»“åˆçš„æ€æƒ³ï¼Œä»¥åŠä»Žçµé•¿ç±»åŠ¨ç‰©çš„ è§†é‡Ž åˆ° V1çš®å±‚ çš„å˜æ¢æ˜¯ å¯¹æ•°çš„ ç„¶è€Œï¼Œå…·æœ‰éžå¸¸å°‘çš„å¾„å‘ç®±çš„å°æè¿°ç¬¦åè€Œèƒ½ç»™å‡ºæœ€å¥½çš„æ€§èƒ½ï¼Œå› æ­¤åœ¨å®žè·µä¸­ å‡ ä¹Žæ²¡æœ‰ä¸å‡åŒ€æ€§æˆ–ä¸Šä¸‹æ–‡ ã€‚ æˆ‘ä»¬è¯„ä¼°äº†C-HOGå‡ ä½•çš„ä¸¤ä¸ªå˜ä½“ï¼Œä¸€ä¸ªå…·æœ‰ å•ä¸ªåœ†å½¢ä¸­å¿ƒç»†èƒž ï¼ˆç±»ä¼¼äºŽ[14]çš„GLOHç‰¹å¾ï¼‰ï¼Œä»¥åŠä¸­å¿ƒç»†èƒžè¢«åˆ†æˆ è§’å½¢æ‰‡åŒºçš„å½¢çŠ¶ä¸Šä¸‹æ–‡ ã€‚ C-HOGçš„4ä¸ªå‚æ•°ï¼š the numbers of angular(è§’åº¦ç›’å­çš„ä¸ªæ•°ï¼‰ï¼› the numbers of radias(åŠå¾„ç›’å­ä¸ªæ•°) the radius of the central bin in pixelsï¼ˆä¸­å¿ƒä»“çš„åŠå¾„ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰ï¼‰ the expansion factor for subsequent (åŠå¾„çš„ä¼¸å±•å› å­ï¼‰ ä¸ºäº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæœ€ä½³çš„å‚æ•°è®¾ç½®ä¸ºï¼š4ä¸ªè§’åº¦ç›’å­ã€2ä¸ªåŠå¾„ç›’å­ã€ä¸­å¿ƒç›’å­åŠå¾„ä¸º4ä¸ªåƒç´ ã€ä¼¸å±•å› å­ä¸º2 4åƒç´ æ˜¯ä¸­å¤®binçš„æœ€ä½³åŠå¾„ï¼Œä½†3å’Œ5ç»™å‡ºç±»ä¼¼çš„ç»“æžœã€‚ C-HOGçœ‹èµ·æ¥å¾ˆåƒåŸºäºŽå½¢çŠ¶ä¸Šä¸‹æ–‡ï¼ˆè‹±è¯­ï¼šShape contextï¼‰çš„æ–¹æ³•ï¼Œä½†ä¸åŒä¹‹å¤„æ˜¯ï¼šC-HOGçš„åŒºé—´ä¸­åŒ…å«çš„ç»†èƒžå•å…ƒæœ‰å¤šä¸ªæ–¹å‘é€šé“ï¼Œè€ŒåŸºäºŽå½¢çŠ¶ä¸Šä¸‹æ–‡çš„æ–¹æ³•ä»…ä»…åªç”¨åˆ°äº†ä¸€ä¸ªå•ä¸€çš„è¾¹ç¼˜å­˜åœ¨æ•°ã€‚[4] Block Normalization schemesï¼šå¼•å…¥vè¡¨ç¤ºä¸€ä¸ªè¿˜æ²¡æœ‰è¢«å½’ä¸€åŒ–çš„å‘é‡ï¼Œå®ƒåŒ…å«äº†ç»™å®šåŒºé—´ï¼ˆblockï¼‰çš„æ‰€æœ‰ç›´æ–¹å›¾ä¿¡æ¯ã€‚vk è¡¨ç¤º v çš„ k é˜¶èŒƒæ•°ï¼Œè¿™é‡Œçš„ k={1,2}ã€‚ç”¨ e è¡¨ç¤ºä¸€ä¸ªå¾ˆå°çš„å¸¸æ•°ã€‚ä¸€å…±4ç§ä¸åŒçš„å—è§„èŒƒåŒ–schemes L2-morm, L2-Hys, å®ƒå¯ä»¥é€šè¿‡å…ˆè¿›è¡ŒL2-normï¼Œå¯¹ç»“æžœè¿›è¡ŒæˆªçŸ­ï¼ˆclippingï¼‰ï¼Œç„¶åŽå†é‡æ–°å½’ä¸€åŒ–å¾—åˆ°ã€‚ L1-norm, L1-sqrt,L1-norm followed by square root ä½œè€…å‘çŽ°ï¼šé‡‡ç”¨L2-Hys, L2-norm, å’Œ L1-sqrtæ–¹å¼æ‰€å–å¾—çš„æ•ˆæžœæ˜¯ä¸€æ ·çš„ï¼ŒL1-normç¨å¾®è¡¨çŽ°å‡ºä¸€ç‚¹ç‚¹ä¸å¯é æ€§ã€‚ Centre-surround normalization. Detector Window and ContextClassifieræœ€åŽä¸€æ­¥å°±æ˜¯æŠŠæå–çš„HOGç‰¹å¾è¾“å…¥åˆ°SVMåˆ†ç±»å™¨ä¸­ï¼Œå¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜è¶…å¹³é¢ä½œä¸ºå†³ç­–å‡½æ•°ã€‚ä½œè€…é‡‡ç”¨çš„æ–¹æ³•æ˜¯ï¼šä½¿ç”¨å…è´¹çš„SVMLightè½¯ä»¶åŒ…åŠ ä¸ŠHOGåˆ†ç±»å™¨æ¥å¯»æ‰¾æµ‹è¯•å›¾åƒä¸­çš„è¡Œäººã€‚ Discussion åœ¨ç”²é…¸æ¢¯åº¦å‰è¿›è¡Œä»»ä½•ç¨‹åº¦çš„å¹³æ»‘å¤„ç†éƒ½ä¼šæ¯æŽ‰HOGçš„ç»“æžœï¼Œå› ä¸ºè®¸å¤šå¯ä¾›çš„å›¾åƒä¿¡æ¯éƒ½æ˜¯ä»Žç»†å°ºåº¦çš„çªå‡ºè¾¹ç•Œå½¢æˆçš„ã€‚ è¯¦å•ï¼Œæ¢¯åº¦åº”è¯¥åœ¨å½“å‰é‡‘å­—å¡”å±‚çš„æœ€ç»†å¯ä¾›å°ºåº¦ä¸Šè¢«è®¡ç®—ï¼Œä¿®æ”¹æˆ–è€…ç”¨äºŽæ–¹å‘æŠ•ç¥¨å¹¶ä¸”åªæœ‰åœ¨é‚£ä¹‹åŽåœ¨æ¨¡ç³Šç©ºé—´ã€‚ å…¶æ¬¡ï¼Œå¼ºçš„å±€éƒ¨å¯¹æ¯”æ­£å¸¸åŒ–å¯¹äºŽè‰¯å¥½çš„ç»“æžœè‡³å…³é‡è¦ï¼Œä¼ ç»Ÿçš„ä¸­å¿ƒçŽ¯ç»•æ ·å¼æ–¹æ¡ˆä¸æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚ æ›´å¥½çš„ç»“æžœå¯ä»¥é€šè¿‡ç›¸å¯¹äºŽä¸åŒçš„å±€éƒ¨æ”¯æŒå¯¹æ¯ä¸ªå…ƒç´ ï¼ˆè¾¹ç¼˜ï¼Œå•å…ƒï¼‰è¿›è¡Œå‡ æ¬¡æ ‡å‡†åŒ–ï¼Œå¹¶å°†ç»“æžœä½œä¸ºç‹¬ç«‹ä¿¡å·æ¥å®žçŽ°ã€‚ Summary and Conclusions æˆ‘ä»¬ç ”ç©¶äº†å„ç§æè¿°ç¬¦å‚æ•°çš„å½±å“ï¼Œå¹¶å¾—å‡ºç»“è®ºï¼Œåœ¨é‡å æè¿°ç¬¦å—ä¸­çš„ ç²¾ç»†å°ºåº¦æ¢¯åº¦ï¼Œ ç²¾ç»†å®šå‘binningï¼Œ ç›¸å¯¹ç²—ç³™çš„ç©ºé—´binning é«˜è´¨é‡å±€éƒ¨å¯¹æ¯”åº¦å½’ä¸€åŒ– å¯¹äºŽè‰¯å¥½çš„æ€§èƒ½éƒ½æ˜¯é‡è¦çš„ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šFast Feature Pyramids for Object Detection?]]></title>
    <url>%2Fposts%2F2735857030%2F</url>
    <content type="text"><![CDATA[ç›¸å…³çŸ¥è¯†ç‚¹ Overcomplete Representations: Overcompleteï¼šSuch a complete system is overcomplete if removal of a $\phi {j}$ from the system results in a system (i.e., ${\phi {i}}_((i\in J\backslash {j))}$) that is still complete. In different research, such as signal processing and function approximation, overcompleteness can help researchers to achieve a more stable, more robust, or more compact decomposition than using a basis.[2] Image pyramidï¼šå½±å“é‡‘å­—å¡” å½±åƒé‡‘å­—å¡”ç”±åŽŸå§‹å½±åƒæŒ‰ä¸€å®šè§„åˆ™ç”Ÿæˆçš„ç”±ç»†åˆ°ç²—ä¸åŒåˆ†è¾¨çŽ‡çš„å½±åƒé›†ã€‚ æŒ‡åœ¨åŒä¸€çš„ç©ºé—´å‚ç…§ä¸‹ï¼Œæ ¹æ®ç”¨æˆ·éœ€è¦ä»¥ä¸åŒåˆ†è¾¨çŽ‡è¿›è¡Œå­˜å‚¨ä¸Žæ˜¾ç¤ºï¼Œå½¢æˆåˆ†è¾¨çŽ‡ç”±ç²—åˆ°ç»†ã€æ•°æ®é‡ç”±å°åˆ°å¤§çš„é‡‘å­—å¡”ç»“æž„ã€‚ å›¾åƒç¼–ç å’Œæ¸è¿›å¼å›¾åƒä¼ è¾“ ä»Žå›¾ä¸­å¯ä»¥çœ‹å‡º, ä»Žé‡‘å­—å¡”çš„åº•å±‚å¼€å§‹æ¯å››ä¸ªç›¸é‚»çš„åƒç´ ç»è¿‡é‡é‡‡æ ·ç”Ÿæˆä¸€ä¸ªæ–°çš„åƒç´ , ä¾æ­¤é‡å¤è¿›è¡Œ, ç›´åˆ°é‡‘å­—å¡”çš„é¡¶å±‚ã€‚é‡é‡‡æ ·çš„æ–¹æ³•ä¸€èˆ¬æœ‰ä»¥ä¸‹ä¸‰ç§: åŒçº¿æ€§æ’å€¼ã€æœ€ä¸´è¿‘åƒå…ƒæ³•ã€ä¸‰æ¬¡å·ç§¯æ³•ã€‚ é‡‘å­—å¡”æ˜¯ä¸€ç§èƒ½å¯¹æ …æ ¼å½±åƒæŒ‰é€çº§é™ä½Žåˆ†è¾¨çŽ‡çš„æ‹·è´æ–¹å¼å­˜å‚¨çš„æ–¹æ³•ã€‚é€šè¿‡é€‰æ‹©ä¸€ä¸ªä¸Žæ˜¾ç¤ºåŒºåŸŸç›¸ä¼¼çš„åˆ†è¾¨çŽ‡ï¼Œåªéœ€è¿›è¡Œå°‘é‡çš„æŸ¥è¯¢å’Œå°‘é‡çš„è®¡ç®—ï¼Œä»Žè€Œå‡å°‘æ˜¾ç¤ºæ—¶é—´ã€‚ Gradient Histograms: Abstract The computational bottleneck of many modern detectors is the computation of features at every scale of a finely-sampled image pyramid. The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Introduction Multi-orientation decompostion: å¤šå‘åˆ†è§£ï¼Œæ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æŠ€æœ¯ã€‚ åœ¨æ¯ä¸ªå°ºåº¦å’Œæ–¹å‘åˆ†åˆ«åˆ†æžå›¾åƒç»“æž„çš„æƒ³æ³•èµ·æºäºŽå¤šä¸ªæ¥æº: å“ºä¹³åŠ¨ç‰©è§†è§‰ç³»ç»Ÿç”Ÿç†å­¦çš„æµ‹é‡ æœ‰å…³è§†è§‰ä¿¡æ¯çš„ç»Ÿè®¡å’Œç¼–ç çš„åŽŸåˆ™æ€§æŽ¨ç† è°æ³¢åˆ†æž è°æ³¢åˆ†æžï¼ˆå¤šé€ŸçŽ‡æ»¤æ³¢) çµé•¿ç±»è§†è§‰ç³»ç»Ÿæ˜¾ç¤ºï¼šæ¡çº¹çš®å±‚ç»†èƒžï¼ˆç²—ç•¥çš„ç­‰ä»·äºŽå›¾åƒçš„å°æ³¢å±•å¼€ï¼‰åœ¨æ•°é‡ä¸Šè¶…è¿‡è§†ç½‘è†œç¥žç»èŠ‚ç»†èƒžï¼ˆå›¾åƒåƒç´ çš„è¿‘ä¼¼è¡¨ç¤ºï¼‰10^2åˆ°10^3. è¿™äº›è¡¨ç¤ºç›¸å¯¹äºŽè§†ç‚¹ï¼Œç…§æ˜Žå’Œå›¾åƒå˜å½¢çš„å˜åŒ–çš„é²æ£’æ€§æ˜¯Overcomplete Representations ä¼˜è¶Šæ€§èƒ½çš„ä¿ƒæˆå› ç´ ã€‚ ä¸å¹¸çš„æ˜¯ï¼Œæ›´é«˜çš„æ£€æµ‹æ­£ç¡®çŽ‡é€šå¸¸ä¼´éšç€æ›´é«˜çš„è®¡ç®—å¼€é”€ã€‚ åœ¨è®¡ç®—å¼€é”€å’Œä¸ºäº†æé«˜æ£€æµ‹å’Œé™ä½Žé”™è¯¯çŽ‡è€Œä½¿ç”¨æ›´å¤æ‚çš„è¡¨ç¤ºä¹‹é—´æ˜¯æ²¡æœ‰å¿…è¦åšæƒè¡¡çš„ã€‚ è‡ªç„¶å›¾åƒå…·æœ‰åˆ†å½¢ç»Ÿè®¡ï¼Œä½¿å¾—æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹æ¥æ›´å¯é çš„é¢„æµ‹å›¾åƒè·¨å°ºåº¦ç»“æž„ã€‚ æˆ‘ä»¬è¯æ˜Žäº†æˆ‘ä»¬æå‡ºçš„å¿«é€Ÿç‰¹å¾é‡‘å­—å¡”ä¸Žä¸‰ä¸ªä¸åŒçš„æ£€æµ‹æ¡†æž¶çš„æœ‰æ•ˆæ€§ï¼š ç§¯åˆ†é€šé“ç‰¹å¾ï¼ˆICFï¼‰ èšé›†é€šé“ç‰¹å¾ï¼ˆç§¯åˆ†é€šé“ç‰¹å¾çš„æ–°é¢–å˜ä½“ï¼‰ å¯å˜å½¢é›¶ä»¶æ¨¡åž‹ï¼ˆDPMï¼‰ Related Work Scale Space Theory: å°ºåº¦ç©ºé—´ç†è®º Cascades, coarse-to-fine search, distance transforms, etc., å…¨éƒ¨éƒ½å…³æ³¨äºŽå¯¹æå‰è®¡ç®—å¥½çš„å›¾åƒç‰¹å¾æ¥ä¼˜åŒ–åˆ†ç±»é€Ÿåº¦ã€‚ æœ¬æ–¹æ³•ä¸“æ³¨äºŽå¿«é€Ÿç‰¹å¾é‡‘å­—å¡”çš„æž„å»ºï¼Œå› æ­¤ä¸Žä¸Šé¢çš„æ–¹æ³•å¯ä»¥èµ·åˆ°äº’è¡¥çš„æ•ˆæžœã€‚ è¡Œäººæ£€æµ‹çš„æœ€ä½³æ‰§è¡Œæ–¹æ³•å’ŒPASCAL VOCæ˜¯åŸºäºŽå¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”çš„æ»‘åŠ¨çª—å£; å¿«é€Ÿç‰¹å¾é‡‘å­—å¡”éžå¸¸é€‚åˆäºŽè¿™ç§æ»‘åŠ¨çª—å£æ£€æµ‹å™¨ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Object Detection</tag>
        <tag>ç›®æ ‡æ£€æµ‹</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šPedestrian Detection - An Evaluation of the State of the Art]]></title>
    <url>%2Fposts%2F3091185356%2F</url>
    <content type="text"><![CDATA[çŸ¥è¯†ç‚¹ å¯¹æ•°æ­£æ€åˆ†å¸ƒï¼ˆlognormally distributedï¼‰ï¼šå¯¹æ•°ä¸ºæ­£æ€åˆ†å¸ƒçš„ä»»æ„éšæœºå˜é‡çš„æ¦‚çŽ‡åˆ†å¸ƒã€‚ å¦‚æžœ X æ˜¯æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œåˆ™ exp(X)ä¸ºå¯¹æ•°æ­£æ€åˆ†å¸ƒ. å¦‚æžœ Y æ˜¯å¯¹æ•°æ­£æ€åˆ†å¸ƒï¼Œåˆ™ ln(Y) ä¸ºæ­£æ€åˆ†å¸ƒã€‚ å¦‚æžœä¸€ä¸ªå˜é‡å¯ä»¥çœ‹ä½œæ˜¯è®¸å¤šå¾ˆå°ç‹¬ç«‹å› å­çš„ä¹˜ç§¯ï¼Œåˆ™è¿™ä¸ªå˜é‡å¯ä»¥çœ‹ä½œæ˜¯å¯¹æ•°æ­£æ€åˆ†å¸ƒã€‚ å¯¹æ•°æ­£æ€åˆ†å¸ƒçš„æ¦‚çŽ‡å¯†åº¦å‡½æ•°ä¸ºï¼š å¯¹æ•°å¹³å‡ï¼šå¯¹æ•°å¹³å‡ä¸Žå‡ ä½•å¹³å‡ç›¸ç­‰ï¼Œå¹¶ä¸”æ¯”ç®—æ•°å¹³å‡ï¼Œå¯¹äºŽå¯¹æ•°æ­£æ€åˆ†å¸ƒæ•°æ®çš„å…¸åž‹å€¼æ›´å…·ä»£è¡¨æ€§ äºŒä¸ªæ•°å­—çš„å¯¹æ•°å¹³å‡å°äºŽå…¶ç®—æœ¯å¹³å‡ï¼Œå¤§äºŽå‡ ä½•å¹³å‡ï¼Œè‹¥äºŒä¸ªæ•°å­—ç›¸ç­‰ï¼Œå¯¹æ•°å¹³å‡ä¼šç­‰äºŽç®—æ•°å¹³å‡åŠå‡ ä½•å¹³å‡ã€‚ Histogram of Oriented Gradients for Objection Detection.(HOG)æ­¥éª¤ï¼š Sampling positive images Sampling negative images Training a Linear SVM Performing hard-negative mining Re-training your Linear SVM using the hard-negative samples Evaluating your classifier on your test dataset, utilizing non-maximum suppression to ignore redundant, overlapping bounding boxes NMS:Non-maximum Suppression(éžæžå¤§å€¼æŠ‘åˆ¶):å¯çœ‹æˆä¸€ç§å±€éƒ¨æžå¤§å€¼æœç´¢ï¼Œè¿™é‡Œçš„å±€éƒ¨æžå¤§å€¼è¦æ¯”ä»–çš„é‚»åŸŸå€¼éƒ½è¦å¤§ã€‚è¿™é‡Œçš„é‚»åŸŸè¡¨ç¤ºæœ‰ä¸¤ä¸ªå‚æ•°ï¼šç»´åº¦å’Œn-é‚»åŸŸã€‚ LBP: Local Binary Patterns Abstract å•ç›®å›¾åƒçš„è¡Œäººæ£€æµ‹æ–¹æ³•æŒç»­çš„åœ¨å‘å±•ã€‚ å¤šç§æ•°æ®é›†+å¹¿æ³›å˜åŒ–çš„è¯„ä¼°æ–¹æ³•-&gt;å¯¼è‡´æ–¹æ³•ä¹‹é—´ç›´æŽ¥çš„æ¯”è¾ƒå¾ˆå›°éš¾ã€‚ ä¸‰ä¸ªè´¡çŒ®ï¼š æ•°æ®é›†ï¼› ç²¾ç‚¼çš„pre-imageè¯„ä¼°æ–¹æ³•ï¼› å¯¹çŽ°æœ‰state-of-artæ£€æµ‹å™¨è¿›è¡Œæ¯”è¾ƒè¯„ä¼°ã€‚ è¡Œäººæ£€æµ‹åœ¨ ä½Žåƒç´  å’Œ éƒ¨åˆ†é®æŒ¡ è¡Œäººæƒ…å†µä¸‹ä¾æ—§è¡¨çŽ°å¤±æœ›ã€‚ Introduction å¯¹çŽ°æœ‰è¡Œäººæ£€æµ‹æ–¹æ³•çš„ä¸€äº›ç–‘é—®ï¼š Do current detectors work well? What is the best ap- proach?â€ â€œWhat are the main failure modes? What are the most productive research directions? Contributions Data set. 350,000è¡Œäººæ ‡æ³¨æ¡†BB 250,000å¸§ é®æŒ¡å’Œæ—¶é—´ä¸Šç›¸ä¼¼çš„ä¹Ÿè¢«æ ‡æ³¨ã€‚ å¯¹è¡Œäººç­‰çº§ã€é®æŒ¡ã€ä½ç½®è¿›è¡Œäº†ç»Ÿè®¡ Evaluation methodology. Evaluation. è¯„ä¼°äº†16ä¸ªæœ‰ä»£è¡¨æ€§çš„å…ˆè¿›çš„è¡Œäººæ£€æµ‹å™¨ ä¸¤ä¸ªå›¢é˜Ÿå‘å¸ƒçš„surveysä¸Žä½œè€…çš„å·¥ä½œæ˜¯äº’è¡¥çš„ã€‚ Geronimoâ€”â€”å…ˆè¿›çš„å¸æœºåŠ©æ‰‹ç³»ç»Ÿä¸­çš„è¡Œäººæ£€æµ‹ã€‚ Enzweiler and Gavrilaâ€”â€”å‘å¸ƒDaimleræ£€æµ‹æ•°æ®é›† The Caltech Pedestrian Data SetData Collection and Ground Truthing å½“ä¸€ä¸ªæ ‡æ³¨å™¨åœ¨è‡³å°‘ä¸¤å¸§ä¸­åœ¨åŒä¸€ä¸ªè¡Œäººä¸Šæ ‡æ³¨äº†è¾¹ç•Œæ¡†ï¼Œåˆ™è¾¹ç•Œæ¡†åˆ©ç”¨3æ¬¡æ’å€¼åœ¨ä¸­é—´å¸§è¿›è¡Œæ ‡æ³¨ BB-full BB-vis: è¢«é®æŒ¡è¡Œäººå¯è§åŒºåŸŸæ ‡æ³¨æ¡† ä¸‰ç§æ ‡æ³¨ï¼š Person People Person? Data Set Statistics è¡Œäººçš„é«˜åº¦ã€å®½åº¦éƒ½ç±»ä¼¼å¯¹æ•°æ­£æ€åˆ†å¸ƒã€‚ å¦‚æžœå¤šå˜é‡ä¸­çš„æ¯ä¸ªå˜é‡ç¬¦åˆå¯¹æ•°æ­£æ€åˆ†å¸ƒï¼Œåˆ™è¿™äº›å˜é‡çš„çº¿æ€§ç»„åˆä¹Ÿç¬¦åˆæ­£æ€åˆ†å¸ƒã€‚ BB æ¨ªçºµæ¯” w/ h, log(w /h) = log(w)-log(h). ç”±äºŽè¡Œäººå§¿åŠ¿ï¼ˆæ‰‹ã€è‚˜ï¼‰çš„åŽŸå› ï¼Œä¼šå¯¼è‡´è¡Œäººå®½åº¦å˜åŒ–ã€‚ h=Hf/ d. H=1.8m, d=1800 /hm å¤§éƒ¨åˆ†è¡Œäººéƒ½è¢«è§‚å¯Ÿä¸ºmedium scaleï¼Œä¸ºäº†å®‰å…¨ç³»ç»Ÿï¼Œæ£€æµ‹ä¹Ÿå¿…é¡»å‘ç”Ÿåœ¨è¿™ä¸ªscaleã€‚ é€šè¿‡å¯¹é®æŒ¡æƒ…å†µçš„ç»Ÿè®¡ï¼Œæ€»ä½“æ¥è¯´ï¼Œé®æŒ¡æƒ…å†µè¿œè¿œæ²¡æœ‰ç»Ÿä¸€ï¼Œ åˆ©ç”¨è¿™ä¸ªå‘çŽ°å¯ä»¥æŒ¡ä½æé«˜è¡Œäººæ£€æµ‹å™¨çš„æ€§èƒ½ã€‚ ä¸ä»…é®æŒ¡æ˜¯é«˜åº¦ä¸ä¸€è‡´çš„ï¼Œ é®æŒ¡çš„ç±»åž‹ä¹Ÿæ˜¯æœ‰æ˜Žæ˜¾é¢å¤–çš„ç»“æž„ã€‚ é€šè¿‡å¯¹æ¯”ground truthå’ŒHOGæ£€æµ‹å™¨æ£€æµ‹å‡ºçš„è¡Œäººä½ç½®è¿›è¡ŒåŒæ ·çš„ç»Ÿè®¡å¯¹æ¯”ï¼Œæœ‰å¦‚ä¸‹çš„å›¾ï¼Œå¯ä»¥å‘çŽ°ï¼Œåˆ©ç”¨è¡Œäººä½ç½®è¿™ä¸€çº¦æŸæ¡ä»¶å¯ä»¥åˆç†çš„åŠ å¿«æ£€æµ‹ä½†æ˜¯åªèƒ½é€‚å½“çš„å‡å°‘å‡æ­£ä¾‹ã€‚ Training and Testing Data å››ç§è®­ç»ƒ/æµ‹è¯•æƒ…æ™¯ Scenario ext0: Scenario ext1: Scenario cal0: Scenario cal1: ä½œè€…åº”è¯¥åœ¨æ£€æµ‹å™¨å¼€å‘è¿‡ç¨‹ä¸­ä½¿ç”¨ ext0/cal0ï¼Œå¹¶ä¸”åªåœ¨å®Œæˆæ‰€æœ‰å‚æ•°åŽå† ext1/cal1ä¸‹è¿›è¡Œè¯„ä¼°ã€‚ Comparison of Pedestrian Data Sets Imaging setup. Data set size. Data set type. Pedestrian scale. Data set properties. Evaluation MethodologyFull Image Evaluation å¯¹é˜ˆå€¼å°äºŽ0.6çš„è¯„ä¼°å°±ä¸ç”¨å…³å¿ƒäº†ã€‚ å…·æœ‰æœ€é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹é¦–å…ˆè¢«åŒ¹é…ï¼›å¦‚æžœä¸€ä¸ªè¢«æ£€æµ‹åˆ°çš„BBåŒ¹é…åˆ°å¤šä¸ªground truthè¾¹ç•Œæ¡†ï¼Œåˆ™å…·æœ‰æœ€é«˜è¦†ç›–çŽ‡çš„åŒ¹é…å°†è¢«ä½¿ç”¨ã€‚ æ²¡æœ‰è¢«åŒ¹é…åˆ°çš„BBdtç®—ä½œå‡æ­£ä¾‹ï¼Œæ²¡æœ‰è¢«åŒ¹é…é“å¾·BBgtè¢«ç§°ä¸ºå‡è´Ÿä¾‹ã€‚ é€šè¿‡æ”¹å˜æ£€æµ‹ç½®ä¿¡åº¦çš„é˜ˆå€¼ï¼Œç”»å‡ºmiss rate-FPPIçš„æ›²çº¿å›¾æ¥æ¯”è¾ƒå„ä¸ªæ£€æµ‹å™¨ã€‚è¿™ç§å›¾æ¯”å‡†ç¡®çŽ‡-å¬å›žçŽ‡çš„å›¾æ›´å¥½ï¼Œå› ä¸ºå¯¹äºŽæ±½è½¦åº”ç”¨ï¼Œas typically there is an upper limit on the acceptable false positives per image rate independent of pedestrian density. åˆ©ç”¨ å¯¹æ•°å¹³å‡ é—æ¼çŽ‡ æ¥æ€»ç»“æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚åœ¨ï¼ˆ10^-2~10^0ï¼‰èŒƒå›´çš„å¯¹æ•°ç©ºé—´ä¸­ï¼Œé€šè¿‡9ä¸ªFPPIçŽ‡å¹³å‡è®¡ç®—miss rateæ¥å¾—åˆ° Filtering Ground Truth BBig: è¢«é€‰æ‹©å¿½ç•¥çš„Ground truth. è¢«å¿½ç•¥çš„åŒºåŸŸã€‚ å°†BBgtè®¾ä¸ºè¢«å¿½ç•¥å’Œä¸¢å¼ƒæŽ‰è¿™ä¸ªæ ·æœ¬æ˜¯ä¸ä¸€æ ·çš„ï¼›åŽè€…ä»£è¡¨è¿™ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå‡æ­£ä¾‹ã€‚ Filtering Detections è€ƒè™‘ä¸‰ç§å¯èƒ½çš„è¿‡æ»¤ç­–ç•¥ï¼š strict filtering: åœ¨åŒ¹é…ä¹‹å‰åˆ é™¤æ‰€é€‰èŒƒå›´ä¹‹å¤–çš„æ‰€æœ‰æ£€æµ‹ã€‚ postfiltering: åœ¨æ‰€é€‰è¯„ä»·èŒƒå›´å¤–çš„æ£€æµ‹å…è®¸ä¸ŽèŒƒå›´å†…çš„BBgtåŒ¹é…ã€‚ expanded filtering: ç±»ä¼¼äºŽä¸¥æ ¼è¿‡æ»¤ï¼Œé™¤äº†åœ¨è¯„ä¼°ä¹‹å‰åŽ»é™¤æ‰©å±•è¯„ä¼°èŒƒå›´ä¹‹å¤–çš„æ‰€æœ‰æ£€æµ‹ Expanded filtering åœ¨ strict filtering å’Œ postfilteringä¹‹é—´åšäº†å¾ˆå¥½çš„å¦¥åã€‚ åœ¨æ•´ä¸ªè¯„ä¼°å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨expanded filtering(r=1.25)ã€‚ Standardizing Aspect Ratios æ ‡å‡†åŒ–GTå’ŒDTçš„aspect ratioï¼Œè¿™æ ·åšä¼šä»Žæ£€æµ‹å™¨è®¾è®¡ä¸­åˆ é™¤æ— å…³çš„ä»»æ„é€‰æ‹©ï¼Œå¹¶æœ‰åŠ©äºŽæ€§èƒ½æ¯”è¾ƒã€‚ ä¸€èˆ¬æ¥è¯´ï¼ŒæŽ¢æµ‹å™¨çš„é•¿å®½æ¯”å–å†³äºŽå¼€å‘è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®é›†ï¼Œé€šå¸¸åœ¨è®­ç»ƒåŽé€‰æ‹©ã€‚ æˆ‘ä»¬å»ºè®®å°†æ‰€æœ‰BBæ ‡å‡†åŒ–ä¸º0.41çš„é•¿å®½æ¯”ï¼ˆCaltechæ•°æ®é›†ä¸­çš„å¯¹æ•° - å¹³å‡é•¿å®½æ¯”ï¼‰ã€‚ æˆ‘ä»¬ä¿æŒBBé«˜åº¦å’Œä¸­å¿ƒå›ºå®šï¼ŒåŒæ—¶è°ƒæ•´å®½åº¦. é‡è¦çš„æ˜¯æ£€æµ‹å™¨å’Œground truthçºµæ¨ªæ¯”åŒ¹é…ã€‚ Per-Window versus Full Image Evaluation PM è¯„ä¼°æ–¹æ³•é€šå¸¸ç”¨æ¥æ¯”è¾ƒåˆ†ç±»å™¨ï¼ˆæ£€æµ‹å™¨çš„è¿”åˆ©ï¼‰æˆ–è€…ç”¨æ¥è¯„ä¼°ç³»ç»Ÿå¯¹äºŽè‡ªåŠ¨å…´è¶£åŒºåŸŸç”Ÿæˆçš„æ€§èƒ½ã€‚ PWç»“æžœæ˜¯ä»Žå…¶ åŽŸå§‹å‡ºç‰ˆç‰© ä¸­äº§ç”Ÿçš„ã€‚ å…¨å›¾åƒç»“æžœæ˜¯é€šè¿‡è¯„ä¼°åŒä¸€è¡Œäººä½†åœ¨å…¶ åŽŸå§‹å›¾åƒä¸Šä¸‹æ–‡ ä¸­èŽ·å¾—çš„ã€‚ å°†ä¸€ä¸ªäºŒåˆ†ç±»è½¬åŒ–ä¸ºä¸€ä¸ªæ£€æµ‹å™¨æ‰€åšçš„é€‰æ‹©åŒ…æ‹¬ï¼š åŒ…æ‹¬ç©ºé—´å’Œå°ºåº¦è·¨åº¦ éžæœ€å¤§æŠ‘åˆ¶çš„é€‰æ‹©ã€‚ä¼šå½±å“å›¾åƒçš„æ€§èƒ½ã€‚ åœ¨PWè¯„ä¼°æœŸé—´æµ‹è¯•çš„çª—å£é€šå¸¸ä¸åŒäºŽåœ¨å…¨å›¾åƒæ£€æµ‹æœŸé—´æµ‹è¯•çš„çª—å£ï¼Œ å‡é˜³æ€§å¯èƒ½æ¥è‡ªå¯¹èº«ä½“éƒ¨ä½æˆ–ä¸æ­£ç¡®çš„å°ºåº¦æˆ–ä½ç½®çš„æ£€æµ‹ å‡é˜´æ€§å¯èƒ½æºäºŽè¢«æµ‹è¯•çš„çª—æˆ·å’ŒçœŸå®žçš„è¡Œäººä½ç½®æˆ–æ¥è‡ªNMSä¹‹é—´çš„è½»å¾®ä¸å¯¹å‡†ã€‚ æ£€æµ‹ç®—æ³•Survey of the State of the Art Papageorgiou and Poggio [16]æå‡ºäº†ç¬¬ä¸€ä¸ªæ»‘åŠ¨çª—å£æ£€æµ‹å™¨ã€‚å°†æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰åº”ç”¨äºŽå¤šå°ºåº¦Haarå°æ³¢çš„è¿‡åº¦å®Œå¤‡å­—å…¸ã€‚ Violaå’ŒJones( VJ )[44]åŸºäºŽè¿™äº›æƒ³æ³•ï¼Œå¼•å…¥äº†ç”¨äºŽå¿«é€Ÿç‰¹å¾è®¡ç®—çš„ç§¯åˆ†å›¾åƒå’Œç”¨äºŽæœ‰æ•ˆæ£€æµ‹çš„çº§è”ç»“æž„ï¼Œä»¥åŠåˆ©ç”¨AdaBoostè¿›è¡Œè‡ªåŠ¨ç‰¹å¾é€‰æ‹©ã€‚è¿™äº›æƒ³æ³•ç»§ç»­ä½œä¸ºçŽ°ä»£æŽ¢æµ‹å™¨çš„åŸºç¡€ã€‚ éšç€åŸºäºŽæ¢¯åº¦çš„ç‰¹å¾çš„é‡‡ç”¨å¸¦æ¥äº†å·¨å¤§çš„æ”¶ç›Šã€‚ å—SIFT [45]å¯å‘ï¼ŒDalalå’ŒTriggs [HOG][7]é€šè¿‡æ˜¾ç¤ºç›¸å¯¹äºŽåŸºäºŽå¼ºåº¦çš„ç‰¹å¾çš„å®žè´¨æ€§å¢žç›Šï¼Œæ™®åŠäº†ç”¨äºŽæ£€æµ‹çš„å®šå‘æ¢¯åº¦ç‰¹å¾çš„ç›´æ–¹å›¾ï¼ˆHOGï¼‰ã€‚ çŽ°åœ¨ï¼ŒHOGç‰¹å¾çš„å˜ä½“çš„æ•°é‡å·²ç»å¤§å¤§å¢žåŠ ï¼Œå‡ ä¹Žæ‰€æœ‰çŽ°ä»£æ£€æµ‹å™¨ä»¥æŸç§å½¢å¼åˆ©ç”¨å®ƒä»¬ã€‚ Shape featuresï¼ˆå½¢çŠ¶ç‰¹å¾ï¼‰ä¹Ÿæ˜¯ä¸€ä¸ªç”¨äºŽæ£€æµ‹ç»å¸¸ç”¨åˆ°çš„çº¿ç´¢. Boostingç”¨äºŽå­¦ä¹ å¤´éƒ¨ï¼Œèº¯å¹²ï¼Œè…¿éƒ¨å’Œå…¨èº«æ£€æµ‹å™¨. Shapelets: æ˜¯ä»Žå±€éƒ¨åŒºå—ä¸­çš„æ¢¯åº¦è¾¨åˆ«åœ°å­¦ä¹ çš„å½¢çŠ¶æè¿°ç¬¦. Boostingç”¨æ¥å°†å¤šä¸ªShapeletç»“åˆæˆä¸€ä¸ªæ•´ä½“çš„æ£€æµ‹å™¨ã€‚ Motionæ˜¯äººç±»æ„ŸçŸ¥çš„å¦ä¸€ä¸ªé‡è¦æç¤º; ç„¶è€Œï¼ŒæˆåŠŸåœ°å°†è¿åŠ¨ç‰¹å¾ç»“åˆåˆ°æ£€æµ‹å™¨ä¸­å·²è¯æ˜Žå¯¹äºŽç§»åŠ¨çš„ç›¸æœºå…·æœ‰æŒ‘æˆ˜æ€§ã€‚ è™½ç„¶æ²¡æœ‰è¿¹è±¡è¡¨æ˜Žå•ä¸ªç‰¹å¾ç”±äºŽHOGï¼Œä½†é™„åŠ ç‰¹å¾å¯ä»¥æä¾›ä¸€äº›äº’è¡¥ä¿¡æ¯ã€‚ Evaluated Detectors ç›´æŽ¥ä»Žä½œè€…å¤„å¾—åˆ°æå‰è®­ç»ƒå¥½çš„æ£€æµ‹å™¨ã€‚ è¿™äº›æ£€æµ‹å™¨é€šå¸¸éµå¾ªæ»‘åŠ¨çª—å£èŒƒä¾‹ï¼Œå…¶éœ€è¦å¯¹æ£€æµ‹çª—å£è¿›è¡Œç‰¹å¾æå–ï¼ŒäºŒåˆ†ç±»å’Œå¯†é›†å¤šå°ºåº¦æ‰«æï¼ŒéšåŽè¿›è¡Œéžæžå¤§å€¼æŠ‘åˆ¶ã€‚ Featuresï¼šå‡ ä¹Žæ‰€æœ‰çš„çŽ°ä»£æ£€æµ‹å™¨éƒ½ä½¿ç”¨äº†éƒ½å†™å½¢å¼çš„æ¢¯åº¦ç›´æ–¹å›¾ã€‚ Learningï¼šå› ä¸ºå®ƒä»¬çš„ç†è®ºä¿è¯ï¼Œå¯æ‰©å±•æ€§å’Œè‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒå‘é‡æœº[16]å’Œboosting[44]æ˜¯æœ€å—æ¬¢è¿Žçš„é€‰æ‹©ã€‚ Boostingè‡ªåŠ¨æ‰§è¡Œç‰¹å¾é€‰æ‹©ã€‚ä¸€äº›æ£€æµ‹å™¨ï¼ˆåœ¨â€œç‰¹å¾å­¦ä¹ â€åˆ—ä¸­ç”¨æ ‡è®°æŒ‡ç¤ºï¼‰åœ¨åˆ†ç±»å™¨è®­ç»ƒä¹‹å‰æˆ–ä¸Žåˆ†ç±»å™¨è®­ç»ƒä¸€èµ·å­¦ä¹ æ›´å°æˆ–ä¸­ç­‰å¤§å°çš„ç‰¹å¾é›†åˆã€‚ Detection detailsï¼šä¸¤ç§ä¸»è¦çš„éžæœ€å¤§æŠ‘åˆ¶æ–¹æ³•ï¼š Mean shift(MS)æ¨¡åž‹ä¼°è®¡ Pairwise max(PM)æŠ‘åˆ¶ï¼šæ ¹æ®å……åˆ†çš„é‡å ä¸¢å¼ƒå¯ä¿¡åº¦è¾ƒä½Žçš„æ¯å¯¹æ£€æµ‹ PM*ï¼šå…è®¸æ£€æµ‹åŽ»åŒ¹é…å¦ä¸€æ£€æµ‹çš„ä»»æ„å­åŒºåŸŸã€‚ Implementation notes Performance EvaluationPerformance on the Caltech Data Set Overallï¼šç»å¯¹æ€§èƒ½å¾ˆå¼±ã€‚ Scale Occlusion Reasonaleï¼šæ€§èƒ½åœ¨ä¸­ç­‰è§„æ¨¡æˆ–éƒ¨åˆ†å°é—­çš„è¡Œäººçš„æ£€æµ‹å¾ˆå·®ï¼Œè€Œå¯¹äºŽè¿œè·ç¦»æˆ–åœ¨é‡åº¦å°é—­çš„æƒ…å†µä¸‹ï¼Œå®ƒçš„æ€§èƒ½ç‰¹åˆ«å·®ã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬è¯„ä¼°è¶…è¿‡50åƒç´ é«˜çš„è¡Œäººåœ¨æ²¡æœ‰æˆ–éƒ¨åˆ†é®æŒ¡ï¼ˆè¿™äº›åœ¨æ²¡æœ‰å¾ˆå¤šä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹æ¸…æ™°å¯è§ï¼‰çš„æ€§èƒ½ã€‚ æˆ‘ä»¬å°†è¿™ç§°ä¸ºåˆç†çš„è¯„ä¼°è®¾ç½®ã€‚ Localization Evaluation on Multiple Data SetsStatistical Significanceï¼ˆç»Ÿè®¡æ˜¾è‘—æ€§ï¼‰ å…³é”®çš„æ´žå¯ŸåŠ›æ˜¯å°†æ¯ä¸ªæ•°æ®é›†ä¸Šçš„ç»å¯¹æ€§èƒ½è½¬æ¢ä¸ºç®—æ³•æŽ’åï¼Œä»Žè€Œæ¶ˆé™¤ä¸åŒæ•°æ®é›†éš¾åº¦çš„å½±å“ã€‚ æˆ‘ä»¬ä½¿ç”¨éžå¯¹æ•°Friedmanæ£€éªŒå’Œposthocåˆ†æžæ¥åˆ†æžç»Ÿè®¡å­¦æ˜¾ç€æ€§. å¯¹äºŽæˆ‘ä»¬çš„åˆ†æžï¼Œæˆ‘ä»¬ä½¿ç”¨ éžå‚æ•°Friedmanæµ‹è¯• ä»¥åŠ Shaffer posthoc test æˆ‘ä»¬åŸºäºŽå…¶å¯¹æ•°å¹³å‡ä¸¢å¤±çŽ‡ï¼ˆåœ¨åˆç†çš„è¯„ä¼°è®¾ç½®ä¸‹æµ‹è¯•ï¼‰å¯¹æ¯ä¸ªæ•°æ®æŠ˜å ä¸Šçš„æ£€æµ‹å™¨è¿›è¡ŒæŽ’åã€‚ è¯¥ç¨‹åºä¸º14ä¸ªæ£€æµ‹å™¨å¾—åˆ°åšæ€»å…±28ä¸ªæŽ’åã€‚ Runtime Analysis æ€»çš„æ¥è¯´ï¼Œè¿è¡Œæ—¶å’Œç²¾åº¦ä¹‹é—´ä¼¼ä¹Žæ²¡æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ã€‚ Discussion åº”è¯¥æ³¨æ„ï¼Œå•å¸§æ€§èƒ½æ˜¯æ•´ä¸ªç³»ç»Ÿæ€§èƒ½çš„ä¸‹é™ï¼Œè·Ÿè¸ªï¼Œä¸Šä¸‹æ–‡ä¿¡æ¯å’Œé¢å¤–ä¼ æ„Ÿå™¨çš„ä½¿ç”¨å¯ä»¥å¸®åŠ©å‡å°‘å‡è­¦æŠ¥å¹¶æé«˜æ£€æµ‹çŽ‡ï¼ˆå‚è§[2]ï¼‰ã€‚]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Review</tag>
        <tag>ç»¼è¿°</tag>
        <tag>Caltech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[è¡Œäººæ£€æµ‹è®ºæ–‡ç¬”è®°ï¼šPedestrian Detection - A Benchmark]]></title>
    <url>%2Fposts%2F4124170924%2F</url>
    <content type="text"><![CDATA[çŸ¥è¯†ç‚¹ kæŠ˜äº¤å‰éªŒè¯ Non-Maximum Suppressionï¼šéžæžå¤§å€¼æŠ‘åˆ¶ç®—æ³•ï¼Œéžæžå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰å¯ä»¥çœ‹åšæ˜¯æŠ‘åˆ¶ä¸æ˜¯æžå¤§å€¼çš„å…ƒç´ ï¼Œæœç´¢å±€éƒ¨çš„æžå¤§å€¼çš„æœç´¢é—®é¢˜ï¼ŒNMSæ˜¯è®¸å¤šè®¡ç®—æœºè§†è§‰ç®—æ³•çš„éƒ¨åˆ†ã€‚ è¿™ä¸ªå±€éƒ¨ä»£è¡¨çš„æ˜¯ä¸€ä¸ªé‚»åŸŸï¼Œé‚»åŸŸæœ‰ä¸¤ä¸ªå‚æ•°å¯å˜ï¼Œä¸€æ˜¯é‚»åŸŸçš„ç»´æ•°ï¼ŒäºŒæ˜¯é‚»åŸŸçš„å¤§å°ã€‚ åœ¨è¡Œäººæ£€æµ‹ä¸­ï¼Œæ»‘åŠ¨çª—å£ç»æå–ç‰¹å¾ï¼Œç»åˆ†ç±»å™¨åˆ†ç±»è¯†åˆ«åŽï¼Œæ¯ä¸ªçª—å£éƒ½ä¼šå¾—åˆ°ä¸€ä¸ªåˆ†æ•°ã€‚ä½†æ˜¯æ»‘åŠ¨çª—å£ä¼šå¯¼è‡´å¾ˆå¤šçª—å£ä¸Žå…¶ä»–çª—å£å­˜åœ¨åŒ…å«æˆ–è€…å¤§éƒ¨åˆ†äº¤å‰çš„æƒ…å†µã€‚è¿™æ—¶å°±éœ€è¦ç”¨åˆ°NMSæ¥é€‰å–é‚£äº›é‚»åŸŸé‡Œåˆ†æ•°æœ€é«˜ï¼ˆæ˜¯è¡Œäººçš„æ¦‚çŽ‡æœ€å¤§ï¼‰ï¼Œå¹¶ä¸”æŠ‘åˆ¶é‚£äº›åˆ†æ•°ä½Žçš„çª—å£ã€‚ Abstract å¼•è¿›äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†â€”â€”Caltechã€‚ æå‡ºäº†äº†ä¸ªæ›´é«˜çš„è¯„ä¼°æ ‡å‡†ã€‚ è¯æ˜Žäº†å¹³å¸¸ç”¨çš„é€ä¸ªçª—å£æ£€æµ‹çš„æ–¹æ³•æ˜¯æœ‰ç‘•ç–µçš„ï¼Œåœ¨å®Œæ•´çš„å›¾ç‰‡ä¸Šä¼šé¢„æµ‹å¤±è´¥ã€‚ è¡¡é‡äº†çŽ°æœ‰çš„æ£€æµ‹ç³»ç»Ÿã€‚ åˆ†æžäº†ä¸€èˆ¬çš„å¸¸è§å¤±è´¥æƒ…å†µã€‚ Introduction INRIAæ•°æ®é›†ã€‚ çŽ°æœ‰æ•°æ®é›†çš„ç¼ºé™·ã€‚ è´¡çŒ®ï¼ˆ4æ–¹é¢ï¼‰ã€‚ Dataset ä»‹ç»äº†Caltechæ•°æ®é›†çš„æ•°æ®å†…å®¹ï¼Œæ ‡è®°ç­‰ã€‚ Scale(ç­‰çº§ï¼ŒèŒƒå›´)æ ¹æ®è¡Œäººçš„å›¾ç‰‡å¤§å°ï¼Œå°†è¡Œäººåˆ†ä¸º3ä¸ªèŒƒå›´ï¼šnearï¼ˆ80æˆ–è€…æ›´å¤šåƒç´ ï¼‰ã€mediumï¼ˆ30-80åƒç´ ä¹‹é—´ï¼‰ã€farï¼ˆ30åƒç´ æˆ–æ›´å°‘ï¼‰ã€‚ å¤§çº¦68%çš„è¡Œäººä½äºŽä¸­ç­‰å¤§å°èŒƒå›´ã€‚ å¯¹äºŽmediumèŒƒå›´çš„åŠ æµ‹å¯¹äºŽæ±½è½¦åº”ç”¨æ˜¯ååˆ†é‡è¦çš„ã€‚ æˆ‘ä»¬åº”å½“åœ¨æ•´ä¸ªå·¥ä½œä¸­åˆ©ç”¨ner/ medium /farä¹‹é—´çš„åŒºåˆ«ã€‚ Occlusion(é®æŒ¡) é®æŒ¡çš„è¡Œäººé€šè¿‡ä¸¤ä¸ªæ¡†æ¥æ ‡æ³¨ã€‚ 29%çš„è¡Œäººä»Žæ¥æ²¡æœ‰è¢«æŒ¡ä½ 53%çš„å‘—æŒ¡åœ¨ä¸€éƒ¨åˆ†å¸§ 19%çš„åœ¨æ‰€æœ‰å¸§ä¸­éƒ½è¢«æŒ¡ Position(ä½ç½®)ï¼šç”±äºŽè§†ç‚¹å’Œåœ°è¡¨å½¢çŠ¶çš„åŽŸå› çº¦æŸç€è¡Œäººå€¼å‡ºçŽ°åœ¨å›¾ç‰‡çš„ç‰¹å®šåŒºåŸŸï¼Œç»è¿‡åˆ†æžï¼Œè¡Œäººæ–‡èŒæ›´åŠ é›†ä¸­è€Œä¸æ˜¯çªç„¶å‡ºçŽ°çš„ã€‚ æ•°æ®æ•æ‰äº†è¶…è¿‡11ç§åœºæ™¯:0-5ç”¨æ¥ä½œä¸ºè®­ç»ƒï¼Œ6-10ç”¨æ¥ä½œä¸ºæµ‹è¯• è®¾ç½®äº†ä¸‰ä¸ªå…·ä½“çš„è®­ç»ƒ/æµ‹è¯•åœºæ™¯ Scenario-Aï¼šåœ¨æ‰€æœ‰å¤–éƒ¨æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨ä¼šè¯6-10ä¸Šè¿›è¡Œæµ‹è¯•ã€‚è¿™æ ·å…è®¸åœ¨å·²ç»å­˜åœ¨çš„æ–¹æ³•ä¸Šä¸è¿›è¡Œé‡æ–°è®­ç»ƒå°±èƒ½è¿›è¡Œå¹¿æ³›çš„è°ƒæŸ¥ã€‚ Scenario-Bï¼šåˆ©ç”¨ä¼šè¯0-5è¿›è¡Œ6æŠ˜äº¤å‰éªŒè¯ï¼Œæ¯æ¬¡ä½¿ç”¨5ä¸ªsessionæ¥è¿›è¡Œè®­ç»ƒï¼Œç¬¬6ä¸ªè¿›è¡Œæµ‹è¯•ï¼Œç„¶åŽåœ¨éªŒè¯é›†ä¸Šèžåˆç»“æžœï¼Œåœ¨æ”¿ç­–è®­ç»ƒé›†ä¸Šæ±‡æŠ¥æ£€æµ‹å™¨çš„è¡¨çŽ°ã€‚ Scenario-Cï¼šç”¨0-5ä¼šè¯æ¥è®­ç»ƒï¼Œç”¨6-10ä¼šè¯æ¥æµ‹è¯•ã€‚ï¼ˆå®Œæ•´æµ‹è¯•ï¼‰ ä¸ŽçŽ°æœ‰çš„æ•°æ®é›†çš„æ¯”è¾ƒï¼š å¹¿æ³›ä½¿ç”¨çš„â€˜äººâ€™æ•°æ®é›†ï¼šMIT LabelMeçš„å­é›†å’ŒPASCAL VOCæ•°æ®é›†ã€‚ çŽ°æœ‰æ•°æ®é›†å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šä¸€ç±»æ˜¯äººæ•°æ®é›†åŒ…å«äº†äººçš„å„ç§å§¿åŠ¿ï¼Œå¦ä¸€ç±»æ˜¯è¡Œäººæ•°æ®é›†åŒ…å«äº†åž‚ç›´çš„äººï¼ˆç«™ç«‹æˆ–è€…è¡Œèµ°ï¼‰ï¼Œä½†ä¸»è¦æ˜¯ä»Žä¸€ä¸ªè¾ƒä¸ºé™åˆ¶çš„è§†ç‚¹è¿›è¡Œè§‚å¯Ÿçš„ã€‚ ä»Žæ‘„å½±å¸ˆå¤„æ”¶é›†çš„æ•°æ®é›†éƒ½å­˜åœ¨ é€‰æ‹©åå·® ï¼Œä½†æ˜¯ç›‘æŽ§è§†é¢‘æœ‰ç€æœ‰é™çš„èƒŒæ™¯ï¼Œç§»åŠ¨æ‹æ‘„çš„æ•°æ®ä¼šæžå¤§çš„æŽ’é™¤äº†é€‰æ‹©åå·®ã€‚ INRIAåå‘äºŽæ‰“çš„ï¼Œå¤§éƒ¨åˆ†æœªé®æŒ¡çš„è¡Œäºº å…¶ä»–ç›¸å…³çš„æ•°æ®é›†æœ‰ï¼šDCï¼ŒETH Caltechæ•°æ®é›†æœ€å…ˆè¿›å’Œé‡è¦çš„æ–¹é¢ï¼Œè€Œä¸”è¿™æ˜¯ç›®å‰ç¬¬ä¸€ä¸ªæ•°æ®é›†ä¸Žæ—¶é—´ç›¸å¯¹åº”çš„æ ‡æ³¨æ¡†å’Œè¯¦ç»†é®æŒ¡æ ‡ç­¾ã€‚ è¯„ä¼°æ–¹æ³• çŽ°æœ‰çš„å·²å»ºç«‹çš„è¯„ä¼°è¡Œäººæ£€æµ‹æ–¹æ³•æ˜¯æœ‰ç‘•ç–µçš„ã€‚ pre-window VS pre-image pre-windowï¼šé€çª—å£æ£€æµ‹å™¨åœ¨å›¾åƒä¸Šè¢«å¯†é›†æ‰«æå¹¶ä¸”é‚»è¿‘çš„æ£€æµ‹è¢«åˆå¹¶ï¼Œæ¯”å¦‚ä½¿ç”¨NMSã€‚ ä¸€ä¸ªå…¸åž‹çš„å‡è®¾æ˜¯ï¼šè¾ƒå¥½çš„pre-windowåˆ†æ•°ä¼šåœ¨ä¸€æ•´ä¸ªå›¾ç‰‡ä¸Šå¸¦æ¥æ›´å¥½çš„è¡¨çŽ°ï¼›ç„¶è€Œåœ¨å®žé™…ä¸­pre-windowè¡¨çŽ°åœ¨é¢„æµ‹pre-imageæ€§èƒ½æ—¶å¤±è´¥ã€‚ ä¸æ˜¯æ‰€æœ‰æ£€æµ‹ç³»ç»Ÿéƒ½æ˜¯åŸºäºŽåŽä¸œçª—å£çš„ï¼Œè€Œä¸”pre-windowæ–¹æ³•å¯¹è¿™ç±»ç³»ç»Ÿçš„è¯„ä¼°æ˜¯ä¸å¯èƒ½çš„ã€‚ Pre-image evaluation åˆ©ç”¨PASCALç‰©ä½“æ£€æµ‹æŒ‘æˆ˜ä¸­çš„ä¿®æ”¹è¿‡çš„schemeç‰ˆæœ¬è¿›è¡Œå•å¸§æ£€æµ‹ã€‚ ä¸€ä¸ªæ£€æµ‹ç³»ç»Ÿéœ€è¦è¾“å…¥ä¸€ä¸ªå›¾åƒå¹¶ä¸”ä¸ºæ¯ä¸ªæ£€æµ‹è¿”å›žä¸€ä¸ªè¾¹ç•Œæ¡†æˆ–è€…ä¸€ä¸ªåˆ†æ•°æˆ–è€…ä¸€ä¸ªç½®ä¿¡åº¦ã€‚è¿™ä¸ªç³»ç»Ÿåº”è¯¥å¯ä»¥æ‰§è¡Œå¤šç­‰çº§æ£€æµ‹ä»¥åŠå¿…è¦çš„NMSæˆ–è€…å…¶ä»–åŽæœŸå¤„ç†ã€‚ è¯„ä¼°åº”è¯¥åœ¨æœ€åŽç”Ÿæˆçš„è¢«æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ä¸­æ‰§è¡Œã€‚ PASCALä¼°è®¡ï¼šé‡å åŒºåŸŸå¿…é¡»è¶…è¿‡50%ï¼š ä¸ºäº†æ¯”è¾ƒæ–¹æ³•ï¼Œé€šè¿‡å˜åŒ–æ£€æµ‹ç½®ä¿¡åº¦çš„é˜ˆå€¼ï¼Œæˆ‘ä»¬ç”»å‡ºäº†çºµåæ ‡miss rateï¼Œæ¨ªåæ ‡æ¯å¼ å›¾åƒå‡æ­£ä¾‹ï¼ˆFPPIï¼‰çš„å›¾åƒã€‚å¯¹äºŽæŸäº›ä»»åŠ¡ï¼Œæ›´å€¾å‘äºŽä½¿ç”¨æŸ¥å‡†-å¬å›žæ›²çº¿ï¼Œæ¯”å¦‚æ±½è½¦åº”ç”¨ï¼Œå…¸åž‹çš„å·²ç»æœ‰ä¸€ä¸ªå¯æŽ¥å—çš„FPPIä¸Šé™ï¼Œå¹¶ä¸”ç‹¬ç«‹äºŽè¡Œäººè¡Œäººå¯†åº¦ã€‚ å¼•å…¥ignore regionsã€‚è¿™ä¸€åŒºåŸŸä¸éœ€è¦åŒ¹é…ï¼ŒåŒ¹é…ä¸Šä¸ç®—æ˜¯TPï¼Œæ²¡æœ‰åŒ¹é…ä¸Šä¹Ÿä¸ç®—FNã€‚ åªæœ‰å®Œæ•´çš„æ ‡æ³¨æ¡†æ‰èƒ½ç”¨æ¥åŒ¹é…ï¼Œä¸æ˜¯å¯è§çš„æ ‡æ³¨æ¡†ï¼Œç”šè‡³å¯¹äºŽéƒ¨åˆ†é®æŒ¡çš„è¡Œäººã€‚ Evaluation Results Overall Scale Occlusion Aspect ratio]]></content>
      <categories>
        <category>è®ºæ–‡ç¬”è®°</category>
      </categories>
      <tags>
        <tag>Pedestrian Detection</tag>
        <tag>è¡Œäººæ£€æµ‹</tag>
        <tag>Review</tag>
        <tag>ç»¼è¿°</tag>
        <tag>Caltech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å—æ¸…åŒ—å¤äº¤åŒ—èˆªå“ˆå·¥å¤§ä¸­ç§‘é™¢åŽç§‘ä¿ç ”è®°]]></title>
    <url>%2Fposts%2F3356325341%2F</url>
    <content type="text"><![CDATA[å‰è¨€7æœˆ23å·ä»Žä¸­ç§‘é™¢è½¯ä»¶æ‰€å‚åŠ å®Œå¤ä»¤è¥å›žæ¥ï¼Œæˆ‘çš„æ¼«é•¿çš„ä¿ç ”è·¯ä¹Ÿç®—æ˜¯å‘Šä¸€æ®µè½ã€‚ 8æœˆ12å·ä¸œè½¯å®žè®­ç»“æŸï¼Œ8æœˆ13å·åä¸Šå›žå®¶çš„ç«è½¦ï¼Œ8æœˆ14å·åˆ°å®¶ï¼Œç„¶åŽå°±ä¸€ç›´åƒå–ç¡åˆ°ä»Šå¤©ï¼Œæ‹¿å›žæ¥çš„å‡ æœ¬ä¹¦ä¹Ÿæ²¡çœ‹å‡ çœ¼ï¼Œæœ¬æ¥æ‰“ç®—ç€å›žæ¥ç»§ç»­å……å®žä¸€ä¸‹ï¼ŒåŽ»å¤‡æˆ˜9ï¼Œ10æœˆä»½çš„æŽ¨å…ï¼ŒçŽ°åœ¨çœ‹æ¥æ—¶é—´åˆéƒ½è’åºŸäº†â€¦â€¦å¼€å­¦è¿˜æ˜¯ä¹–ä¹–åˆ°å­¦æ ¡å§ï¼Œå†è¿™æ ·ä¸‹åŽ»ä¸€ç›´å¾…åœ¨å®¶æ„Ÿè§‰è¦æˆåºŸäººä¸€ä¸ªäº†ï¼Œæˆ‘è¿˜æ˜¯å–œæ¬¢å¿™ç¢Œå……å®žçš„æ„Ÿè§‰ã€‚ ä¸€ç›´æƒ³ç€è¦æŠŠè¿™æ¬¡å®è´µçš„ä¿ç ”ç»åŽ†è®°å½•ä¸€ä¸‹ï¼Œå¥½ç»™å­¦å¼Ÿå­¦å¦¹ä¸€ä¸ªå‚è€ƒã€‚å­¦å¼Ÿå­¦å¦¹ä»¬å¯ä»¥ç»“åˆè‡ªèº«æƒ…å†µï¼Œå¤§æ¦‚äº†è§£ä¸€ä¸‹ä¿ç ”æµç¨‹ï¼Œéƒ¨åˆ†å­¦æ ¡ä¿ç ”è€ƒæ ¸è¦æ±‚ï¼Œä»Žè€Œå°‘èµ°ä¸€äº›å¼¯è·¯ï¼ŒåŽ»åˆ°è‡ªå·±ç†æƒ³ä¸­çš„å­¦æ ¡ã€‚ ä¸ªäººåŸºæœ¬æƒ…å†µæŠŠæˆ‘çš„ä¸ªäººæƒ…å†µå¤§æ¦‚è¯´ä¸€ä¸‹ï¼Œå­¦å¼Ÿå­¦å¦¹å¯ä»¥å¯¹æ¯”è‡ªå·±æƒ…å†µï¼Œæœ‰ä¸ªå‚è€ƒã€‚ ç»©ç‚¹æŽ’åï¼š5/262 å››çº§ï¼š611åˆ† å…­çº§ï¼š503åˆ† ç§‘ç ”ç«žèµ›æƒ…å†µï¼šæ— ç§‘ç ”ï¼Œæ— è®ºæ–‡ï¼Œæ— å›½å¥–ï¼Œæ— åŠ±å¿—å¥–å­¦é‡‘ï¼Œæ— ACMï¼Œä»…æœ‰ä¸€ä¸ªè“æ¡¥å’Œç¾Žèµ›SPï¼ˆå…¶å®žæ²¡ä»€ä¹ˆä»·å€¼ï¼‰ï¼Œæ€»çš„æ¥è¯´ä¹Ÿå°±æ˜¯æˆç»©å¥½ä¸€ç‚¹ï¼Œä½†æœ‰æ—¶å€™é«˜çš„æˆç»©æŽ’åä¼šæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ•²é—¨ç –ã€‚ ä¸ºä»€ä¹ˆæˆ‘è¦ä¿ç ”æœ¬æ¥æˆ‘æ˜¯åšiOSå¼€å‘çš„ï¼Œæƒ³è¦æ¯•ä¸šåŽç›´æŽ¥æ‰¾å·¥ä½œï¼Œä¸å‡†å¤‡è¯»ç ”çš„ã€‚ä½†æ˜¯ç›´åˆ°å¤§ä¸‰ä¸Šå­¦æœŸçš„æ—¶å€™é€šè¿‡å’Œå­¦é•¿å­¦å§äº¤æµï¼Œæˆ‘æ‰äº†è§£åˆ°ä¿ç ”å¤ä»¤è¥è¿™ä¸€å›žäº‹ï¼Œç”±äºŽå­¦é•¿å­¦å§éƒ½åŽ»äº†å¾ˆå¥½çš„é«˜æ ¡è¯»ç ”ï¼Œè€Œä¸”å½“æ—¶æˆ‘çš„æŽ’åè¿˜ä¸é”™ï¼ŒäºŽæ˜¯æˆ‘æ€è€ƒäº†å¥½é•¿æ—¶é—´ï¼Œæƒè¡¡äº†è¯»ç ”å’Œæ‰¾å·¥ä½œçš„åˆ©å¼Šï¼Œæˆ‘å†³å®šæ¯•ä¸šåŽç»§ç»­è¯»ç ”ã€‚å¦‚æžœæœ‰åŒæ ·ç–‘æƒ‘çš„å­¦å¼Ÿå­¦å¦¹ï¼Œæˆ‘çš„å»ºè®®æ˜¯ï¼šèƒ½å‡ºå›½çš„è¯ï¼Œé‚£è‚¯å®šå‡ºå›½ï¼›èƒ½ä¿ç ”çš„è¯ï¼Œé‚£è‚¯å®šæœ€å¥½ä¸è¦æ”¾å¼ƒè¿™ä¸ªæ¥ä¹‹ä¸æ˜“çš„æœºä¼šï¼Œå½“ç„¶è¿™ä¹Ÿä¸æ˜¯ç»å¯¹çš„ã€‚ æˆ‘çš„ä¿ç ”è·¯æŠ¥åå‚åŠ è¿‡çš„å¤ä»¤è¥è¿™ä¸€éƒ¨åˆ†æ˜¯æˆ‘æŠ¥åç›¸åº”å­¦æ ¡å¤ä»¤è¥åŽï¼Œå¯¹æ–¹ç»™äºˆæˆ‘å…¥è¥èµ„æ ¼çš„å­¦æ ¡ï¼Œä»¥ä¸‹æ˜¯æŒ‰å‚åŠ é¡ºåºè®°å½•ï¼š 1. å—å¤§è®¡ç®—æœº ç½‘å€ï¼šå—äº¬å¤§å­¦è®¡ç®—æœºç³»2016â€œæœ¬ç§‘ç”Ÿå¼€æ”¾æ—¥â€ç”³è¯·æµç¨‹ æ—¶é—´ï¼š5æœˆ13æ—¥-5æœˆ15æ—¥ å…¥è¥æ¡ä»¶ï¼š985é™¢æ ¡çš„è¯ï¼Œç»©ç‚¹æŽ’åå‰5%åŸºæœ¬å¯ä»¥å…¥è¥ åƒä½è¡¥åŠ©ï¼šLAMDAå®žéªŒå®¤æŠ¥é”€è½¦ç¥¨ï¼Œä½å®¿è´¹ï¼Œä½†æ˜¯å—å¤§ä¸æŠ¥é”€è½¦ç¥¨ï¼Œä½†ç®¡åƒç®¡ä½ï¼Œä½çš„å¾ˆé«˜çº§çš„å®¾é¦†ï¼Œæ¡ä»¶ç‰¹åˆ«å¥½ã€‚ å‚è¥è®°å½•ï¼š å—å¤§çš„å¤ä»¤è¥æ˜¯å¼€çš„æœ€æ—©çš„ä¸€ä¸ªè®¡ç®—æœºå¤ä»¤è¥ï¼Œæ­£å› ä¸ºå¼€çš„æ—©ï¼Œå¾ˆå¤šåŒå­¦éƒ½è ¢è ¢æ¬²è¯•ï¼Œå¯¼è‡´å—å¤§å¤ä»¤è¥ä¼šæœ‰å¾ˆå¤šåŒå­¦æŠ¥åï¼Œè¿™æ¬¡æœ‰1000å¤šä¸ªæŠ¥åçš„ï¼Œä½†æ˜¯æœ€åŽå…¥è¥çš„åªæœ‰300äººï¼Œä½†åªè¦ç»©ç‚¹æŽ’åå‰5%åŸºæœ¬å¯ä»¥å…¥è¥ã€‚ å¦‚æžœä½ æƒ³è¦ä¹‹åŽä»Žäº‹â€æœºå™¨å­¦ä¹ ä¸Žæ•°æ®æŒ–æŽ˜â€œç›¸å…³é¢†åŸŸçš„ç§‘ç ”å·¥ä½œï¼Œé‚£ä¹ˆå—å¤§çš„LAMDAå®žéªŒå®¤æ˜¯ä¸€ä¸ªå†å¥½ä¸è¿‡çš„é€‰æ‹©äº†ï¼Œç”±å‘¨å¿—åŽæ•™æŽˆä½œä¸ºå¸¦å¤´äººï¼Œå—å¤§çš„è¿™ä¸ªå®žéªŒå®¤åœ¨å›½å†…å¤–ä¸ŠçŸ¥ååº¦å¾ˆé«˜ï¼Œç§‘ç ”èƒ½åŠ›ä¹Ÿå¾ˆåŽ‰å®³ã€‚ ä½†æ˜¯LAMDAå®žéªŒå®¤æ˜¯å•ç‹¬æ‹›ç”Ÿçš„ï¼Œæ¯å¹´ä¼šæœ‰ä¸¤æ‰¹ä¿ç ”ç”Ÿçš„ç”³è¯·ï¼Œæ‰€ä»¥è¦æƒ³ç”³è¯·LAMDAå®žéªŒå®¤ï¼Œè¿˜éœ€è¦åœ¨ç”³è¯·å—å¤§å¤ä»¤è¥ä¹‹å¤–å•ç‹¬ç”³è¯·è¿™ä¸ªå®žéªŒå®¤çš„é¢è¯•è€ƒæ ¸ã€‚ç”³è¯·çš„æ—¶å€™éœ€è¦ä¸€ä»½ç®€åŽ†ï¼Œä¸€ä»½ç ”ç©¶åŠ¨æœºè¯´æ˜Žï¼Œä¸€ä»½æˆç»©å•ï¼Œè¿™ä¸‰ä»½ææ–™æ˜¯è®©å¯¹æ–¹äº†è§£ä½ çš„å”¯ä¸€é€”å¾„ï¼Œæ‰€ä»¥éœ€è¦å¥½å¥½å‡†å¤‡æ¶¦è‰²ï¼Œè™½ç„¶æˆ‘æ˜¯åœ¨æˆªæ­¢æ—¥æœŸå‰ä¸€å¤©æ‰æ€¥æ€¥å¿™å¿™çš„æ‰æäº¤çš„ï¼Œä½†è¿˜æ˜¯è¿›å…¥äº†åˆé€‰ï¼Œæ‹¿åˆ°äº†LAMDAå®žéªŒå®¤çš„é¢è¯•èµ„æ ¼ã€‚LAMDAå®žéªŒå®¤ä¼šåœ¨å—å¤§å¤ä»¤è¥å‰ä¸€å¤©ç»„ç»‡é¢è¯•ï¼Œè€Œä¸”ç»™æŠ¥é”€å¾€è¿”è½¦ç¥¨åŠä¸€æ™šçš„ä½å®¿è´¹ï¼Œè¿˜æ˜¯å¾ˆä¸é”™çš„ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹LAMDAå¤§æ¦‚çš„é¢è¯•æµç¨‹åŠé—®é¢˜ã€‚åœ¨ç”³æŠ¥LAMDAå®žéªŒå®¤ä¹‹å‰ä¼šå¡«ä¸‰ä¸ªå¯¼å¸ˆå¿—æ„¿ï¼Œæˆ‘å½“æ—¶å¡«çš„å‘¨å¿—åŽã€å´å»ºé‘«ã€ä¿žæ‰¬ï¼Œä½†åˆ°äº†çŽ°åœºæ‰çŸ¥é“LAMDAä¼šæŠŠä½ çš„ææ–™åˆ†åˆ«é€ç»™æ‰€å¡«æŠ¥çš„ä¸‰ä¸ªè€å¸ˆï¼Œä»–ä»¬åˆ†åˆ«å†³å®šæ˜¯å¦å…è®¸ä½ å‚åŠ ä»–ä»¬æ¯ä¸ªäººçš„é¢è¯•ï¼Œå¦‚æžœæœ‰è€å¸ˆå…è®¸ä½ é¢è¯•ï¼Œé‚£ä¹ˆä½ å°±æ‹¿åˆ°äº†é¢è¯•èµ„æ ¼ï¼Œå¦åˆ™çš„è¯ï¼Œè¯´æ˜Žæ²¡æœ‰è€å¸ˆçœ‹ä¸Šä½ çš„ç®€åŽ†ï¼Œä½ ä¹Ÿå°±æ²¡æœ‰é¢è¯•èµ„æ ¼ã€‚æ‰€ä»¥åœ¨å¡«æŠ¥å¯¼å¸ˆçš„æ—¶å€™ï¼Œé™¤éžè‡ªå·±ç®€åŽ†ç‰¹åˆ«å…‰é²œï¼Œå¦åˆ™é‚£ç§ç‰¹åˆ«ç‰›è€å¸ˆå°±ä¸è¦å¡«äº†ï¼Œç›¸å½“äºŽæµªè´¹ä¸€ä¸ªæœºä¼šã€‚åœ¨é¢è¯•çš„æ—¶å€™ï¼Œä½ ä¼šå…ˆåŽ»é¢è¯•é€‰ä¸­ä½ çš„è€å¸ˆï¼Œé¢è¯•å®Œä¹‹åŽï¼Œä½ å…¶å®žå¯ä»¥å†åŽ»é¢è¯•å…¶ä»–è¯¥å®žéªŒå®¤çš„è€å¸ˆï¼Œä»Žè€Œå¢žåŠ ä½ è¿›å…¥è¯¥å®žéªŒå®¤çš„æœºä¼šï¼Œå³ä½¿ä½ å½“æ—¶æ²¡æœ‰æŠ¥ä»–çš„ç ”ç©¶ç”Ÿã€‚æˆ‘æ˜¯5æœˆ12å·å‚åŠ çš„é¢è¯•ï¼Œå½“æ—¶åªæœ‰å´å»ºé‘«è€å¸ˆç»™äº†æˆ‘é¢è¯•æœºä¼šï¼Œé¢è¯•å®Œä»–ä¹‹åŽæˆ‘åˆåŽ»æ‰¾äº†è©¹å¾·å·è€å¸ˆï¼Œæœ€åŽæˆ‘æ˜¯è¢«è©¹å¾·å·è€å¸ˆå½•å–ã€‚é¢è¯•å´å»ºé‘«è€å¸ˆçš„æ—¶å€™ï¼Œé—®é¢˜å¦‚ä¸‹ï¼š æ–¹å·®çš„è®¡ç®—æ–¹æ³•ï¼Œä»–ä¼šæå‰å†™å¥½ä¸€ä¸ªæ–¹å·®è¡¨è¾¾å¼é—®ä½ å¯¹ä¸å¯¹ï¼Œå¦‚æžœä¸å¯¹çš„è¯è¯·å†™å‡ºæ­£ç¡®çš„è¡¨è¾¾å¼ï¼› æ–¹å·®ä¸­çš„n-1å«ä¹‰ï¼› å¦‚æžœå†™ä¸€ä¸ªç¨‹åºè®¡ç®—æ–¹å·®ï¼Œé‚£ä¹ˆè®¡ç®—ä¸€æ¬¡å†…å­˜è®¿é—®å‡ æ¬¡ï¼› æœ¬ç§‘åšè¿‡çš„é¡¹ç›®ï¼Œé¡¹ç›®å†…å®¹ï¼› æœºå™¨å­¦ä¹ äº†è§£å¤šå°‘ï¼Œçœ‹è¿‡ä»€ä¹ˆï¼› äº†ä¸äº†è§£æœ¬äººæ˜¯åšä»€ä¹ˆç ”ç©¶çš„ã€‚ é¢è¯•è©¹å¾·å·è€å¸ˆçš„æ—¶å€™ï¼Œæˆ‘ä¸çŸ¥é“å…¶ä»–äººæ˜¯ä»€ä¹ˆæƒ…å†µï¼Œä½†æˆ‘æ˜¯å…¨ç¨‹è‹±æ–‡é¢è¯•ï¼Œé—®åˆ°çš„é—®é¢˜å¦‚ä¸‹ï¼Œæ³¨æ„ï¼šä»¥ä¸‹é—®é¢˜éœ€è¦è‹±æ–‡ä½œç­”ï¼Œå®žåœ¨è‹±è¯­å›žç­”ä¸äº†ï¼Œå¯ä»¥ä¸­æ–‡ï¼Œä¸å¿…æœ‰å¤ªå¤§åŽ‹åŠ›ï¼š è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ï¼› ä»‹ç»ä¸€ä¸‹åšè¿‡çš„é¡¹ç›®ï¼› ä»‹ç»ä¸€ä¸‹æ¢¯åº¦ä¸‹é™æ³•æ˜¯ä»€ä¹ˆï¼› ä»‹ç»ä¸€ä¸‹ç‰›é¡¿è¿­ä»£æ˜¯ä»€ä¹ˆï¼› ä»€ä¹ˆæ˜¯ç‰¹å¾å€¼ï¼Œç‰¹å¾å€¼çš„å«ä¹‰ï¼› å” å—‘ã€‚ é¢è¯•å®Œå½“å¤©æ™šä¸Šå°±ä¼šæœ‰é‚®ä»¶é€šçŸ¥æ˜¯å¦é¢è¯•é€šè¿‡ï¼Œæœ€åŽæˆ‘æ˜¯è¢«è©¹å¾·å·è€å¸ˆå½•å–ï¼Œä½†æ˜¯é€šè¿‡LAMDAé¢è¯•å¹¶ä¸ä»£è¡¨ä½ å°±èƒ½100%èƒ½è¿›å…¥LAMDAè¯»ç ”äº†ï¼Œæœ€é‡è¦çš„ä¸€å…³æ˜¯æ‹¿åˆ°å—å¤§å¤ä»¤è¥çš„ä¼˜ç§€è¥å‘˜ï¼Œåªæœ‰è¿™æ ·ï¼Œé€šè¿‡ä¸¤è½®è€ƒæ ¸æ‰èƒ½è¿›å…¥LAMDAã€‚ ä¸‹é¢è¯´ä¸€ä¸‹å—å¤§å¤ä»¤è¥çš„æµç¨‹ï¼Œä¸»è¦æ˜¯ä¸‰éƒ¨åˆ†ï¼šå„ä¸ªå®žéªŒå®¤ä»‹ç»ã€æœºè¯•ã€é¢è¯•ï¼Œå…¶ä¸­æœ€æœ€é‡è¦çš„æ˜¯æœºè¯•ï¼Œåªè¦æœºè¯•é€šè¿‡ï¼Œ90%å°±èƒ½æ‹¿åˆ°ä¼˜ç§€è¥å‘˜ã€‚ æœºè¯•è¿™æ¬¡ä¸€å…±4é“é¢˜ï¼Œä»¥å‰å¬è¯´6é“é¢˜ï¼Œåªè¦ACå‡ºå…¶ä¸­çš„ä¸¤é“é¢˜å°±è‚¯å®šæ²¡é—®é¢˜äº†ï¼Œå¤šåšæ— ç”¨ï¼Œæœ‰ç½šæ—¶ï¼Œè€ƒæ ¸æ–¹å¼ï¼šOJï¼Œé¢˜åž‹ï¼šç®—æ³•+æ•°æ®ç»“æž„ï¼Œéš¾åº¦ï¼šACMä¸€èˆ¬éš¾åº¦çš„é¢˜ã€‚è¿™æ¬¡çš„å…·ä½“é¢˜ç›®å¦‚ä¸‹ï¼š æœ€å¤§å­ä¸²å’Œï¼› æ— å‘å›¾æœ€é•¿è·¯å¾„ è¡¨è¾¾å¼æ±‚å€¼ï¼› ç»™ä¸€æ£µæ ‘æ±‚æœ€é•¿çš„è·¯å¾„ã€‚ é¢è¯•é—®é¢˜å¦‚ä¸‹ï¼ˆç”±äºŽåˆ†ç»„é¢è¯•ï¼Œæ¯ç»„æ²¡äººé—®é¢˜ä¸ä¸€æ ·ï¼‰ï¼š è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æ—¶é—´å¤æ‚åº¦ï¼› å¿«æŽ’çš„æ—¶é—´å¤æ‚åº¦ï¼› å¿«æŽ’æœ€åæ—¶é—´å¤æ‚åº¦ä¸ºä»€ä¹ˆæ˜¯$O(n^2)$ï¼Œå¦‚ä½•ä¼˜åŒ–å¿«æŽ’æœ€åæ—¶é—´å¤æ‚åº¦ï¼› çœ‹æˆç»©å•ï¼Œé—®å¦‚ä½•è¿›è¡Œæ–‡çŒ®æ£€ç´¢ è‹±æ–‡å›žç­”ï¼šå¦‚ä½•åˆ©ç”¨æ–‡çŒ®æ£€ç´¢çŸ¥è¯†åŽ»æ£€ç´¢ä¸€ä¸ªæœºå™¨å­¦ä¹ çš„é—®é¢˜ 15å·ä¸Šåˆé¢è¯•å®Œæ¯•ï¼Œæäº¤å®Œææ–™ï¼Œå¡«å®Œå¯¼å¸ˆå¿—æ„¿ï¼Œä¸‹åˆå°±å¯ä»¥èµ°äº†ï¼Œå¯¼å¸ˆå¿—æ„¿åŸºæœ¬åªæœ‰ç¬¬ä¸€å¿—æ„¿æœ‰ç”¨ï¼Œè€Œä¸”æœ‰äº›å¯¼å¸ˆæœ‰ä¸€ä¸ªç‚¹æ‹›æƒï¼ˆåæ­£æˆ‘ç›®å‰è²Œä¼¼åªçŸ¥é“é»„å®œåŽè€å¸ˆæœ‰ç‚¹æ‹›æƒï¼Œç‚¹æ‹›äº†æˆ‘èº«è¾¹å¥½å¤šåŒå­¦ï¼Œä½†ä»–ä»¬éƒ½æ‹’ç»äº†ã€‚ã€‚ã€‚ä»–æ˜¯æžå¤§æ•°æ®å¾ˆåŽ‰å®³çš„ä¸€ä¸ªè€å¸ˆï¼Œå¦‚æžœå¯¹è¿™æ–¹é¢æ„Ÿå…´è¶£ï¼Œæˆç»©æŽ’ååˆé å‰çš„è¯ï¼Œåƒä¸‡è®°ä½æ‰¾è¿™ä¸ªè€å¸ˆæŠ¥åï¼Œå¤šä¸€ä¸ªæœºä¼šï¼ï¼‰ã€‚ å—å¤§ä¹‹æ—…ä¹Ÿå°±è¿™æ ·ç»“æŸäº†ï¼ŒæŽ¥ä¸‹æ¥ä¼šåœ¨å®˜ç½‘ä¸Šå…¬å¸ƒä¼˜ç§€è¥å‘˜çš„åå•ã€‚ 2. å¤æ—¦è®¡ç®—æœº ç½‘å€ï¼š 2016å¹´å¤æ—¦å¤§å­¦è®¡ç®—æœºç§‘å­¦æŠ€æœ¯å­¦é™¢å’Œè½¯ä»¶å­¦é™¢ä¼˜ç§€å¤§å­¦ç”Ÿå¤ä»¤è¥æ´»åŠ¨æŠ¥åé€šçŸ¥ æ—¶é—´ï¼š7æœˆ4æ—¥~7æœˆ8æ—¥ å…¥è¥æ¡ä»¶ï¼šå¯¹äºŽä¸œåŒ—å¤§å­¦è®¡ç®—æœºè½¯ä»¶ä¸“ä¸šçš„åŒå­¦ï¼Œæ¯ä¸ªä¸“ä¸šåªä¼šç»™ä¸€ä¸ªå…¥è¥èµ„æ ¼ï¼Œæ‰€ä»¥æŽ’åæœ€é«˜çš„é‚£ä¸ªäººæ‰èƒ½å…¥è¥ åƒä½è¡¥åŠ©ï¼šæŠ¥é”€å•ç¨‹çš„è·¯è´¹ï¼ˆæ— è®ºä»€ä¹ˆä»¥ç¡¬å§ä¸ºå‡†ï¼‰ï¼Œç®¡åƒä½ï¼Œæ¡ä»¶éƒ½è¿˜ä¸é”™ã€‚ å‚è¥è®°å½•ï¼š å¤æ—¦å¤§å­¦è®¡ç®—æœºè™½ç„¶æŽ’åæ²¡æœ‰ä¸œå¤§è®¡ç®—æœºé«˜ï¼Œä½†æ˜¯æ¯•ç«Ÿå¤æ—¦ï¼Œè¿˜åœ¨ä¸Šæµ·ï¼Œæ‰€ä»¥è¿˜æ˜¯å¾ˆå€¼å¾—åŽ»è¯•ä¸€è¯•çš„ï¼Œä½†ä¸Šæµ·çš„å­¦æ ¡è²Œä¼¼éƒ½æ¯”è¾ƒâ€å‚²å¨‡â€œï¼Œç»™çš„åé¢çœŸçš„ç‰¹åˆ«å°‘ï¼Œè€ƒæ ¸ä¹Ÿæ˜¯å¾ˆä¸¥æ ¼çš„ï¼Œè¿™æ¬¡åŽ»äº†å¤æ—¦æ‰çŸ¥é“ä¸€å…±æœ‰600ä¸ªäººæŠ¥åå¤ä»¤è¥ï¼Œæœ€åŽåªæœ‰50ä¸ªäººå…¥è¥ï¼Œè€Œä¸”æœ€åŽåœ¨è¿™50ä¸ªäººä¸­åªä¼šå‘æ”¾14ä¸ªæ‹Ÿå½•å–ï¼Œæ‰€ä»¥è¿™ä¸ªä»Žè¿™ä¸ªå½•å–æ¯”ä¾‹å¯ä»¥çœ‹å‡ºç«žäº‰å¾ˆæ¿€çƒˆï¼Œè¿˜æ˜¯éœ€è¦è®¤çœŸçš„å‡†å¤‡ã€‚ å¤ä»¤è¥æ˜¯åœ¨å¤æ—¦å¤§å­¦å¼ æ±Ÿæ ¡åŒºä¸¾è¡Œï¼Œä¸ºæœŸ5å¤©ï¼Œä¸»è¦æ´»åŠ¨åŒ…æ‹¬ï¼š å­¦æœ¯æŠ¥å‘Šã€‚å°†é‚€è¯·åœ¨å­¦æœ¯ç ”ç©¶æ–¹é¢æœ‰å»ºæ ‘çš„æ•™å¸ˆè¿›è¡Œå­¦æœ¯æŠ¥å‘Šï¼Œä»‹ç»è®¡ç®—æœºç§‘å­¦æŠ€æœ¯å­¦é™¢å’Œè½¯ä»¶å­¦é™¢æœ€æ–°çš„ç ”ç©¶æ–¹å‘å’Œç ”ç©¶æˆæžœï¼Œä¸ºæœŸ2å¤©ï¼› è¯¾é¢˜ç»„çš„å­¦æœ¯è®¨è®ºã€‚è¿›å…¥æ„Ÿå…´è¶£çš„è¯¾é¢˜ç»„å’Œè€å¸ˆè¿›è¡Œè¿›ä¸€æ­¥çš„äº¤æµï¼Œå‚åŠ è¯¾é¢˜ç»„çš„ç§‘ç ”æ´»åŠ¨ï¼› å¯ä»¥æå‰è”ç³»å¯¼å¸ˆï¼Œè¶æ—©åŽ»æ‰¾è€å¸ˆå” ä¸€å” ï¼Œè®©ä»–è®¤è¯†ä½ ï¼Œäº†è§£ä½ ï¼Œè€Œæœ€å¥½åœ¨é¢è¯•ä¹‹å‰å°±å®šä¸‹å¯¼å¸ˆï¼Œå¦åˆ™é¢è¯•ä¼šå‡åˆ†ï¼› è€ƒæ ¸ã€‚ä¸Šåˆæœºè¯•ï¼Œä¸‹åˆé¢è¯•ï¼Œé¢è¯•çš„æ—¶å€™åˆ†ä¸¤ç»„ï¼Œæ¯ç»„5ä¸ªè€å¸ˆï¼Œè€å¸ˆæ‰‹ä¸­ä¼šæœ‰ä½ çš„æœºè¯•æˆç»©ï¼Œæ‰€ä»¥æœºè¯•å¥½çš„è¯ï¼Œç»™è€å¸ˆå°è±¡ä¼šå¾ˆå¥½ï¼Œä¹Ÿå°±æ˜¯è¯´åªè¦æœºè¯•åˆ†æ•°é«˜ï¼Œè¿›å¤æ—¦å°±å®¹æ˜“å¾ˆå¤šäº†ã€‚ å¤æ—¦æžè®¡ç®—æœºè§†è§‰å’Œåª’ä½“ï¼ˆè§†é¢‘ã€å›¾ç‰‡ï¼‰å¤§æ•°æ®åˆ†æžçš„å±…å¤šï¼ŒåŸºæœ¬å¾ˆå¤šè€å¸ˆéƒ½åœ¨å›´ç»•è¿™ä¸ªæ¥å±•å¼€ç§‘ç ”å·¥ä½œçš„ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹æœºè¯•ã€‚æœºè¯•è¿™æ¬¡å’Œä»¥å¾€å®Œå…¨ä¸ä¸€æ ·ï¼Œè™½ç„¶ä¹Ÿæ˜¯OJï¼Œä½†è¿™æ¬¡æ˜¯ç»™ä½ 3ä¸ªå¤§é¢˜ï¼Œæ¯ä¸ªå¤§é¢˜ä¸­æœ‰3ä¸ªå°é¢˜ï¼Œæ¯ä¸ªå°é¢˜ä¹‹é—´çš„åŒºåˆ«å°±æ˜¯çº¦æŸæ¡ä»¶å’Œæ•°æ®é‡çº§ä¸åŒï¼Œå¯¹åº”çš„é¢˜ç›®éš¾æ˜“ç¨‹åº¦ä¹Ÿæ˜¯ä¸ä¸€æ ·çš„ï¼Œæ‰€ä»¥å’ŒACMçš„é¢˜åž‹è¿˜ä¸å¤ªä¸€æ ·ã€‚å…·ä½“é¢˜ç›®è®°å¾—ä¸å¤ªæ¸…æ¥šï¼Œå¤§æ¦‚å¦‚ä¸‹ï¼š ç¬¬ä¸€é¢˜ç±»ä¼¼è¿·å®«é—®é¢˜ï¼Œåˆ©ç”¨BFSæ±‚è§£ï¼Œä¸€ä¸ªn*nä¸ªæ–¹æ ¼ç»„æˆçš„æ–¹é˜µï¼Œé‡Œé¢å¯èƒ½æœ‰è‹¥å¹²ä¸ªé—¨ï¼Œæ¯ä¸ªé—¨å¯¹åº”ç€ä¸€æŠŠé’¥åŒ™ï¼Œé’¥åŒ™ä¼šå‡ºçŽ°åœ¨æŸä¸ªæ–¹æ ¼ä¸­ï¼Œæ‰€ä»¥è¦æƒ³å¼€é—¨å°±å¿…é¡»å…ˆæŠŠé’¥åŒ™æ‹¿åˆ°ï¼Œä½ éœ€è¦ç»™å‡ºä»Žèµ·ç‚¹åˆ°ç»ˆç‚¹çš„å¯èƒ½è·¯å¾„ä¹‹å’Œï¼Œè¿·å®«ä¼šæœ‰å¤šç§å¤šæ ·ã€‚ä¸‰ä¸ªå°é—®åˆ†åˆ«æ˜¯ï¼š å¯¹äºŽ1*nçš„è¿·å®«ï¼Œæ±‚å‡ºé—®é¢˜çš„è§£ã€‚ å¯¹äºŽn*nçš„è¿·å®«ï¼Œæ²¡æœ‰é—¨ï¼Œæ±‚å‡ºé—®é¢˜çš„è§£ã€‚ å¯¹äºŽn*nçš„è¿·å®«ï¼Œæœ‰é—¨ï¼Œæ±‚å‡ºé—®é¢˜è§£ã€‚ ç¬¬äºŒé¢˜è²Œä¼¼æ˜¯è½¦è¿‡æ¡¥é—®é¢˜ï¼Œç”±äºŽæ¡¥æœ‰é™é«˜ï¼Œæ‰€ä»¥è½¦éœ€è¦æœ‰ä¸åŒçš„è£…è½½æ–¹æ¡ˆæ¥è¿‡ä¸åŒçš„æ¡¥ï¼Œè²Œä¼¼éœ€è¦æ±‚è§£å‡ºè£…è½½æ–¹æ¡ˆï¼Œè¿™ä¸ªé¢˜æ²¡æœ‰ä»”ç»†çœ‹ã€‚ ç¬¬ä¸‰é¢˜å¾ˆå¸¸è§„çš„ä¸€é“ACMå­—ç¬¦ä¸²é¢˜ç›®ï¼Œå…·ä½“é¢˜ç›®è®°ä¸å¤ªæ¸…ï¼Œä½†æ˜¯ä¸»è¦è€ƒå¯Ÿä½ åœ¨ç‰¹åˆ«å¤§çš„æ•°é‡çº§ä¸‹èƒ½å¦åœ¨è§„å®šæ—¶é—´å†…æ±‚å‡ºè§£ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹é¢è¯•ã€‚é¢è¯•åˆ†ä¸¤ç»„ï¼Œè€Œä¸”æœ‰ä¸“ä¸šé¢è¯•å’Œè‹±è¯­é¢è¯•ä¸¤ä¸ªçŽ¯èŠ‚ï¼Œæ¯ç»„åŒå­¦åˆ°ç›¸åº”çš„ç»„é¢è¯•ï¼Œé¢è¯•é—®é¢˜å¤§æ¦‚å¦‚ä¸‹ï¼š ä¸“ä¸šé¢è¯•ï¼š è‡ªæˆ‘ä»‹ç»ï¼› ä»‹ç»é¡¹ç›®ï¼Œåšè¿‡ä»€ä¹ˆï¼Œé¡¹ç›®å…·ä½“å†…å®¹æ˜¯ä»€ä¹ˆï¼› æœºå™¨å­¦ä¹ äº†è§£å¤šå°‘ï¼Œå¦‚ä½•å­¦ä¹ çš„ï¼› è¯´ä¸€ä¸‹ç¥žç»ç½‘ç»œçš„ä¼˜ç‚¹ç¼ºç‚¹ï¼› è‡ªæˆ‘æ„Ÿè§‰æœºè¯•åšçš„æ€Žä¹ˆæ ·ï¼› å­¦é™¢é™¢é•¿æ˜¯è°ï¼› é€‰å¥½å¯¼å¸ˆæ²¡æœ‰ã€‚ è‹±è¯­é¢è¯•ï¼š è‡ªæˆ‘ä»‹ç»ï¼› è¯´ä¸€ä¸‹åª’ä½“å¤§æ•°æ®æ˜¯ä»€ä¹ˆã€‚ é¢è¯•é—®é¢˜å¤§æ¦‚å¦‚ä¸Šï¼Œé¢è¯•è¿˜æ˜¯å¾ˆå¿«åœ°ï¼Œé¢è¯•å®ŒåŸºæœ¬å°±å¯ä»¥èµ°äº†ï¼Œå›žåŽ»ç­‰ç€é‚®ä»¶é€šçŸ¥æ˜¯å¦é€šè¿‡å³å¯ï¼Œæ²¡æœ‰é€šè¿‡çš„è¿˜å¯ä»¥ç»§ç»­ç”³æŠ¥9æœˆä»½çš„æŽ¨å…é¢è¯•ï¼Œè¿™æ¬¡æ˜¯å’Œæœ¬æ ¡å­¦ç”Ÿä¸€èµ·ç«žäº‰ï¼Œæ‰€ä»¥ç«žäº‰ä¼šæ›´åŠ æ¿€çƒˆã€‚è¿˜æ˜¯ä¸€å¥è¯ï¼šâ€å¾—æœºè¯•è€…å¾—å¤©ä¸‹â€œï¼Œè™½ç„¶ç«žäº‰æ¿€çƒˆï¼Œä½†æ˜¯åªè¦æœºè¯•åˆ†æ•°é«˜ï¼Œèƒœç®—è¿˜æ˜¯å¾ˆå¤§çš„ã€‚ 3. åŒ—èˆªè®¡ç®—æœº ç½‘å€ï¼šæŠ¥è€ƒ2017å¹´åŒ—èˆªè®¡ç®—æœºå­¦é™¢ç¡•å£«ç ”ç©¶ç”Ÿ 7æœˆ11~12æ—¥æš‘æœŸå®£ä¼ æ´»åŠ¨é€šçŸ¥ æ—¶é—´ï¼š7æœˆ11æ—¥~7æœˆ12æ—¥ å…¥è¥æ¡ä»¶ï¼šå¯¹äºŽ985å­¦æ ¡çš„å­¦ç”Ÿï¼Œç»©ç‚¹æŽ’åå‰5%åŸºæœ¬ä¼šæœ‰å…¥è¥èµ„æ ¼ åƒä½è¡¥åŠ©ï¼šä»€ä¹ˆéƒ½ä¸æŠ¥é”€ï¼ï¼ï¼ï¼ä¸è®ºåƒçš„ã€ä½çš„ï¼ï¼ï¼ï¼ å‚è¥è®°å½•ï¼š ä»Žå¤æ—¦å›žæ¥ä¸€å¤©åŽï¼Œæˆ‘å°±åˆ°äº†åŒ—èˆªå‚åŠ åŒ—èˆªè®¡ç®—æœºå¤ä»¤è¥ï¼ŒåŒ—èˆªå¬è¯´è¿™æ¬¡å…¥è¥çš„æœ‰500å¤šäººï¼Œæ‰€ä»¥ä¸åŒ…åƒä½å¾ˆæ­£å¸¸ï¼Œå› ä¸ºæ ¹æœ¬ç®¡ä¸è¿‡æ¥ã€‚ åŒ—èˆªå¤ä»¤è¥åªæœ‰ä¸¤å¤©ï¼Œç¬¬ä¸€å¤©æœºè¯•ï¼Œç¬¬äºŒå¤©é¢è¯•ï¼Œç©ºä½™æ—¶é—´å¯ä»¥æå‰æ‰¾ä¸€æ‰¾è”ç³»çš„è€å¸ˆã€‚åŒ—èˆªæœ‰ä¸€ä¸ªå…æœºè¯•æ”¿ç­–ï¼Œå°±æ˜¯æœ‰CCFï¼ˆè®¡ç®—æœºèŒä¸šèµ„æ ¼è®¤è¯è€ƒè¯•ï¼‰æˆç»©çš„åŒå­¦ï¼Œåªè¦æˆç»©åœ¨200åˆ†ä»¥ä¸Šï¼Œå¸¦ç€æˆç»©å•åŽ»å°±å¯ä»¥å…æœºè¯•ï¼Œè¿˜æ˜¯ä¸é”™çš„ï¼Œå¯ä»¥çœåŽ»æœºè¯•å¥½å¥½å‡†å¤‡é¢è¯•äº†ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹æœºè¯•ï¼ŒåŒ—èˆªæœºè¯•ä¸€å…±å°±ä¸¤ä¸ªé¢˜ï¼Œåˆ†ä¸¤åœºï¼Œä¸¤åœºé¢˜ç›®ä¸ä¸€æ ·ï¼Œåšå®Œåªä¼šæ˜¾ç¤ºæ˜¯å¦ç¼–è¯‘é€šè¿‡ï¼Œä¸ä¼šæœ‰ä»»ä½•é”™è¯¯æç¤ºä¿¡æ¯ï¼Œæ‰€ä»¥åšå®Œä½ ä¹Ÿä¸çŸ¥é“æ˜¯ä¸æ˜¯èƒ½æŠŠæ‰€æœ‰æ ·ä¾‹éƒ½é€šè¿‡ï¼Œæ¯”è¾ƒå‘ã€‚æˆ‘æ‰€å‚åŠ çš„é‚£åœºé¢˜ç›®å¦‚ä¸‹ï¼š æ‰¾å‡ºä¸€ä¸²æ•°å­—ä¸­ï¼Œè¿žç»­é€’å¢žå­ä¸²çš„æœ€å¤§ä¸ªæ•° å“ˆå¼—æ›¼æ ‘æž„é€ ï¼Œç¼–ç  åŒ—èˆªä¸åŒçš„æ˜¯æœºè¯•ä¸é€šè¿‡çš„è¯ï¼Œæ˜¯æ— æ³•å‚åŠ é¢è¯•ï¼Œè€Œä¸”é¢è¯•æ˜¯éœ€è¦äº¤100å—é’±çš„ã€‚é¢è¯•çš„è¯ï¼Œä½ éœ€è¦å­¦ä¼šåŽ»å¼•å¯¼è€å¸ˆï¼Œè®©ä»–åŽ»é—®ä½ çŸ¥é“çš„ä¸œè¥¿ï¼Œè¿™æ ·ä½ æ‰èƒ½æŠŠè‡ªå·±çš„ä¼˜åŠ¿å±•çŽ°å‡ºæ¥ã€‚ é¢è¯•ç»“æŸåŽï¼Œåƒä¸‡ä¸è¦èµ°ï¼Œå› ä¸ºæ™šä¸Šä¼šè´´å‡ºæ‹Ÿå½•å–åå•ï¼Œç¬¬äºŒå¤©è¿˜ä¼šç»™ä½ å‘æ‹Ÿå½•å–è¯æ˜Žï¼Œè¿™ä¸ªæ˜¯ä¸èƒ½ä»£é¢†çš„ï¼Œæ‰€ä»¥é¢è¯•ç»“æŸæœ€å¥½å…ˆåˆ«æ€¥ç€èµ°ï¼Œç­‰ä½ æ‹¿åˆ°æ‹Ÿå½•å–åå•ï¼Œå°±å¯ä»¥å®‰å®‰å¿ƒå¿ƒå›žå®¶äº†ã€‚ 4. å“ˆå·¥å¤§è®¡ç®—æœº ç½‘å€ï¼šæ²¡æœ‰é€šçŸ¥ï¼Œæˆ‘æ˜¯å½“æ—¶åŠ äº†ä¸€ä¸ªå“ˆå·¥å¤§ä¿ç ”ç¾¤æ‰çŸ¥é“å“ˆå·¥å¤§è®¡ç®—æœºçš„ä¿ç ”é¢è¯•å®‰æŽ’ï¼Œç¾¤å·ï¼š212632913 æ—¶é—´ï¼š7æœˆ17å· å…¥è¥æ¡ä»¶ï¼šæ„Ÿå…´è¶£éƒ½å¯ä»¥åŽ»é¢è¯• å‚è¥è®°å½•ï¼š å“ˆå·¥å¤§è®¡ç®—æœºæŽ¨å…é¢è¯•æ˜¯åˆ†é¢è¯•ç‚¹çš„ï¼Œå½“æ—¶åœ¨ä¸œå¤§æœ‰ä¸€ä¸ªé¢è¯•ç‚¹ï¼Œè€Œä¸”ä¸€ä¸¤å¤©åŽå°±ä¼šå‡ºç»“æžœå’Œä½ ç­¾æ‹Ÿå½•å–åˆåŒï¼Œä»Žè€Œçœä¸‹ä½ ä¸“é—¨è·‘åˆ°å“ˆå°”æ»¨é¢è¯•ï¼Œè¿˜æ˜¯å¾ˆäººæ€§åŒ–çš„ã€‚å“ˆå·¥å¤§é¢è¯•åˆ†ä¸‰ä¸ªè€å¸ˆåˆ†åˆ«é¢è¯•ï¼Œåˆ†åˆ«é¢è¯•ä¸‰ä¸ªæ–¹é¢ï¼šé€»è¾‘æ€ç»´ã€ä¸“ä¸šçŸ¥è¯†ã€åŠ¨æ‰‹èƒ½åŠ›ï¼Œè€å¸ˆéƒ½å¾ˆå’Œè”¼çš„ï¼Œæ ¹æœ¬ä¸ç”¨ç´§å¼ ã€‚ä¸‹é¢æ˜¯é¢è¯•é—®åˆ°çš„é—®é¢˜ï¼š é€»è¾‘æ€ç»´ ç»™ä½ ä¸€é“é€»è¾‘é¢˜ï¼Œè®©ä½ é€‰å‡ºæ­£ç¡®ç­”æ¡ˆï¼› å®¶ä¹¡æ˜¯å“ªå„¿ï¼Œæ¯•ç«Ÿæ˜¯åœ¨å“ˆå°”æ»¨ï¼Œæ€•æœ‰äº›åŒå­¦é€‚åº”ä¸äº†çŽ¯å¢ƒï¼› é«˜è€ƒæˆç»©ç­‰å” å—‘æ€§é—®é¢˜ã€‚ ä¸“ä¸šçŸ¥è¯† å¤§å­¦ä»€ä¹ˆç§‘ç›®å­¦çš„æ¯”è¾ƒå¥½ Bæ ‘æ˜¯ä»€ä¹ˆï¼Œä¸»è¦ä½œç”¨æ˜¯ä»€ä¹ˆï¼› Bæ ‘åœ¨æ•°æ®åº“ä¸­å¦‚ä½•åº”ç”¨ï¼› ç»™ä½ å¾ˆå¤šå­¦ç”Ÿçš„æˆç»©ï¼Œå¦‚ä½•åˆ©ç”¨Bæ ‘æ¥è¿›è¡Œæ£€ç´¢ï¼› åæ­£åŸºæœ¬å›´ç»•Bæ ‘ï¼Œå› ä¸ºæ˜¯æˆ‘å¼•å¯¼çš„è€å¸ˆåˆ°è¿™ä¸ªé—®é¢˜ä¸Šçš„ï¼› æœºå™¨å­¦ä¹ äº†è§£å¤šå°‘ã€‚ åŠ¨æ‰‹èƒ½åŠ› åšè¿‡çš„é¡¹ç›®ï¼› æ¶‰åŠåˆ°çš„ç®—æ³•æœ‰ä»€ä¹ˆã€‚ é¢è¯•å®Œä¸€ä¸¤å¤©åŸºæœ¬å°±ä¼šå‡ºç»“æžœï¼Œæˆ‘åœ¨ç­¾åè®®çš„æ—¶å€™ï¼Œè€å¸ˆæ˜¯è¿™æ ·å’Œæˆ‘è¯´çš„ï¼šè™½ç„¶æˆ‘ä»¬ä¸æƒ³æ‹›è½¯ä»¶å­¦é™¢çš„å­¦ç”Ÿï¼Œä½†æ˜¯å­¦æ ¡ç»™çš„è¦æ±‚æ˜¯ï¼šåªè¦æ˜¯985é™¢æ ¡çš„å­¦ç”Ÿï¼Œä½†å‡¡ä¸æ˜¯ç‰¹åˆ«å·®çš„ï¼Œå°±éƒ½æ‹›äº†å§ã€‚ã€‚ã€‚æ‰€ä»¥ï¼Œæƒ³è¦æŠ¥å“ˆå·¥å¤§æˆ–è€…æƒ³æ‰¾ä¸€ä¸ªä¿åº•çš„å­¦æ ¡ï¼Œæœ€å¥½ä¸è¦æ”¾å¼ƒè¿™ä¸ªæœºä¼šã€‚ 5. ä¸­ç§‘é™¢è½¯ä»¶æ‰€ ç½‘å€ï¼šä¸­å›½ç§‘å­¦é™¢å¤§å­¦2016å¹´å…¨å›½å¤§å­¦ç”Ÿâ€œè½¯ä»¶ä¸Žç½‘ç»œâ€å¤ä»¤è¥é€šçŸ¥ æ—¶é—´ï¼š7æœˆ18æ—¥-7æœˆ23æ—¥ å…¥è¥æ¡ä»¶ï¼šå¯¹äºŽä¸œåŒ—å¤§å­¦å­¦ç”Ÿï¼Œç»©ç‚¹æŽ’åå‰20%åŸºæœ¬éƒ½ä¼šæœ‰å…¥è¥èµ„æ ¼ åƒä½è¡¥åŠ©ï¼šæŠ¥é”€åŽ»ç¨‹è½¦ç¥¨ï¼Œæä¾›ä½å®¿ï¼ˆå­¦ç”Ÿå…¬å¯“ã€ä¸¤äººé—´ã€çŽ¯å¢ƒæ„Ÿè§‰ä¸å¥½ï¼‰ï¼Œç»™100å…ƒçš„é¥­å¡ï¼Œå¯åœ¨é£Ÿå ‚å’Œè¶…å¸‚æ¶ˆè´¹ã€‚ å‚è¥è®°å½•ï¼š åŽŸæœ¬æˆ‘å¹¶æ²¡æœ‰æŠ¥åè½¯ä»¶æ‰€çš„å¤ä»¤è¥ï¼Œåªæ˜¯æŠ¥åäº†è®¡ç®—æ‰€çš„å¤ä»¤è¥ï¼Œå› ä¸ºæˆ‘ä»¥ä¸ºä¸­ç§‘é™¢åªèƒ½æŠ¥åä¸€ä¸ªç ”ç©¶é™¢ã€‚ä½†æ˜¯è®¡ç®—æ‰€å¥½åƒä¸æ˜¯ç‰¹åˆ«æ¬¢è¿Žè½¯ä»¶ä¸“ä¸šçš„å­¦ç”Ÿï¼Œæ‰€ä»¥å¯¹äºŽè®¡ç®—æ‰€ï¼Œè½¯ä»¶å­¦é™¢å…¥è¥çš„åŒå­¦å±ˆæŒ‡å¯æ•°ï¼Œè€Œè®¡ç®—æœºå­¦é™¢å…¥è¥çš„åŒå­¦æœ‰åå‡ ä¸ªå§ï¼Œæœ€åŽæˆ‘ä¹Ÿæ²¡æœ‰å…¥è¥è®¡ç®—æ‰€ã€‚ æ²¡æœ‰å…¥è¥è®¡ç®—æ‰€çš„æˆ‘ä»¥ä¸ºæˆ‘çš„å¤ä»¤è¥å°±è¿™æ ·ç»“æŸäº†ï¼Œçœ‹ç€èº«è¾¹å¾ˆå¤šåŒå­¦åŽ»å‚åŠ è½¯ä»¶æ‰€çš„å¤ä»¤è¥ï¼Œæˆ‘å½“æ—¶çœŸçš„æ˜¯ç‰¹åˆ«åŽæ‚”ä¸ºä»€ä¹ˆè„‘å­çŸ­è·¯ä¸æŠ¥è½¯ä»¶æ‰€çš„å¤ä»¤è¥ã€‚ä½†æ˜¯åœ¨è½¯ä»¶æ‰€å¼€è¥çš„å‰ä¸€å¤©ï¼Œæˆ‘å’Œå¦ä¸€ä¸ªåŒæ ·æ²¡æœ‰æŠ¥åçš„åŒå­¦å¾—åˆ°æ¶ˆæ¯è¯´æ²¡æœ‰æŠ¥åå¯ä»¥åŽ»çŽ°åœºæŠ¥åï¼ŒäºŽæ˜¯æˆ‘ä»¬å½“å¤©æ™šä¸Šå¤´è„‘ä¸€çƒ­ï¼Œå°±ä¹°äº†åŽ»åŒ—äº¬çš„ç¡¬åº§ï¼Œè¿žå¤œååˆ°åŒ—äº¬ï¼Œå‡†å¤‡éœ¸é¢ã€‚åœ¨å‰ä¸€å¤©åŽ»åŒ—äº¬çš„è½¦ä¸Šï¼Œæˆ‘ä»¬æå‰è”ç³»äº†å‡ ä¸ªè€å¸ˆï¼Œè¯´æ˜Žäº†ä¸€ä¸‹è‡ªå·±æƒ…å†µã€‚ ç¬¬äºŒå¤©æ—©æ™¨åˆ°åŒ—äº¬åŽï¼Œæˆ‘ä»¬ç›´å¥”ä¸­ç§‘é™¢ã€‚ç”±äºŽæ²¡æœ‰ä»»ä½•è®¡åˆ’ï¼Œä¹Ÿä¸çŸ¥é“åŽ»äº†è”ç³»å“ªä¸ªè€å¸ˆï¼Œå¦‚ä½•ä¸´æ—¶æŠ¥åï¼Œå°±ä¸€ç›´åœ¨è½¯ä»¶æ‰€é‡Œé¢å‘†åç€ã€‚å¹¸è¿çš„æ˜¯ç›´åˆ°ä¸‹åˆï¼Œåœ¨åŒå­¦å’Œä¸€ä¸ªè½¯ä»¶æ‰€å­¦å§çš„å¸®åŠ©ä¸‹ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†è½¯ä»¶æ‰€ç ”ç©¶ç”ŸåŠžäº‹å¤„ä¸»ä»»æŽå½©ä¸½è€å¸ˆï¼Œæäº¤äº†éƒ¨åˆ†ææ–™ï¼ŒåŠžäº†æ‰‹ç»­ï¼Œé¢†äº†å…¬å¯“é’¥åŒ™ï¼Œæ‰ç®—æŠ¥äº†åã€‚ï¼ˆé¡ºä¾¿è¯´ä¸€å¥ï¼ŒæŽå½©ä¸½è€å¸ˆäººç‰¹åˆ«å¥½ï¼Œæœ‰ä»€ä¹ˆé—®é¢˜å¥¹éƒ½ä¼šå°½é‡å¸®å¿™çš„ï¼ï¼‰ç”±äºŽè½¯ä»¶æ‰€å¤ä»¤è¥æŒç»­åˆ°23å·ï¼Œè€Œæˆ‘å’Œå¦ä¸€ä¸ªåŒå­¦å½“æ—¶22å·è¿˜è¦åŽ»å‚åŠ åŽç§‘å¤ä»¤è¥ï¼Œæˆ‘ä»¬ç»è¿‡äº†é•¿æ—¶é—´çš„å¿ƒç†æ–—äº‰ï¼Œå†³å®šæ”¾å¼ƒåŽç§‘çš„å¤ä»¤è¥ã€‚è‡³æ­¤ï¼Œæˆ‘çš„è½¯ä»¶æ‰€å¤ä»¤è¥æ‰å¹¸è¿åœ°å¼€å§‹ï¼Œæ‰€ä»¥ï¼Œä¿ç ”è¿‡ç¨‹ä¸­çš„è®¸å¤šæœºä¼šéƒ½éœ€è¦åŽ»äº‰å–çš„ï¼Œè¿æ°”ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ï¼Œå³ä½¿æœ‰æ—¶å€™è§‰å¾—ä¸å¯èƒ½ï¼Œä¹Ÿè¦è¯•ä¸€è¯•ï¼Œè¯´ä¸å®šè¿æ°”å¥½å°±å¾—åˆ°äº†è¿™ä¸ªæœºä¼šï¼ ä¸‹é¢æ­£å¼ä»‹ç»ä¸€ä¸‹è½¯ä»¶æ‰€å¤ä»¤è¥ã€‚è½¯ä»¶æ‰€å¤ä»¤è¥ä¸ºæœŸ6å¤©ï¼Œæ¥æ¥å›žå›žåŸºæœ¬å°±ä¸€ä¸ªæ˜ŸæœŸäº†ã€‚è¿™6å¤©é‡Œï¼Œç¬¬ä¸€å¤©æŠ¥é“ï¼Œç„¶åŽæŽ¥ä¸‹æ¥ä¸¤å¤©ä¸€æ ·çš„å¬æŠ¥å‘Šï¼Œä½†æ˜¯åœ¨ç¬¬äºŒå¤©å¬æŠ¥å‘Šçš„ä¸‹åˆéœ€è¦å¡«æŠ¥ä¸¤ä¸ªå®žéªŒå®¤çš„å¿—æ„¿ï¼Œè¿™ä¸ªå¿—æ„¿å…¶å®žåªæœ‰ç¬¬ä¸€å¿—æ„¿æœ‰ç”¨ï¼Œå¡«å®Œå¿—æ„¿åŽä¼šå½“åœºç»Ÿè®¡äººæ•°ï¼Œçœ‹æœ‰æ²¡æœ‰æ‰Žå †ï¼Œå¦‚æžœæœ‰çš„è¯ï¼Œå¯ä»¥å½“åœºæ”¹å¿—æ„¿ï¼Œè®©æ¯ä¸ªå®žéªŒå®¤äººæ•°å°½é‡å‡è¡¡ã€‚å…³äºŽå„ä¸ªå®žéªŒå®¤çš„å¥½åï¼Œè¿™é‡Œæœ‰ä¸€ç¯‡æŒºå…¬æ­£çš„ä»‹ç»â€”â€”ä¸­ç§‘é™¢è½¯ä»¶æ‰€å„å®žéªŒå®¤æƒ…å†µç®€è¦ä»‹ç»ï¼Œæ€»çš„æ¥è¯´ï¼šè½¯å·¥ä¸­å¿ƒæœ€å¥½ï¼Œäººæœºæœ€ä¸å—æ¬¢è¿Žå§ï¼Œå­¦å¼Ÿå­¦å¦¹å¡«å¿—æ„¿çš„æ—¶å€™è¦æ³¨æ„ï¼Œå½“ç„¶æœ€å¥½çš„å®žéªŒå®¤æŠ¥çš„äººä¹Ÿæœ€å¤šï¼Œå½•å–æ¯”ä¾‹å½“ç„¶æ›´ä½Žã€‚æˆ‘å½“æ—¶æŠ¥åçš„æ˜¯å¤©åŸºå’Œå›½é‡ã€‚ æŠ¥å®Œå¿—æ„¿åŽï¼Œç¬¬äºŒå¤©å„ä¸ªå®žéªŒå®¤å°±éƒ½å¼€å§‹å„è‡ªçš„è€ƒæ ¸äº†ï¼Œæœ‰çš„æœ‰æœºè¯•ã€ç¬”è¯•ã€é¢è¯•ï¼Œæœ‰çš„åªæœ‰ç¬”è¯•å’Œé¢è¯•ï¼Œç”±äºŽæˆ‘æŠ¥çš„å¤©åŸºï¼Œé‚£ä¹ˆæˆ‘åªèƒ½è¯´ä¸€è¯´å¤©åŸºçš„è€ƒæ ¸æ–¹å¼äº†ã€‚å¤©åŸºåªæœ‰ç¬”è¯•å’Œé¢è¯•ï¼Œç¬”è¯•çš„è¯å…¶å®žè€ƒçš„éƒ½æ˜¯å¾ˆåŸºç¡€çš„ä¸œè¥¿ï¼ŒåŒ…æ‹¬OSã€è®¡ç½‘ã€æœºç»„ï¼ˆè€ƒäº†å¾ˆå¤šé€‰æ‹©ï¼‰ã€æ•°å­¦ã€æ•°æ®ç»“æž„ã€ç®—æ³•ç­‰ï¼Œå¹³å¸¸è®¤çœŸè€ƒè¯•çš„è¯ï¼ŒåŸºæœ¬æ²¡ä»€ä¹ˆé—®é¢˜ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹é¢è¯•ï¼Œé¢è¯•æœ€ä¸»è¦çš„å°±æ˜¯3åˆ†é’Ÿçš„ä¸ªäººä»‹ç»PPTï¼Œæ‰€æœ‰è€å¸ˆæé—®éƒ½æ˜¯é€šè¿‡ä½ çš„PPTæ¥æé—®ï¼Œæ‰€ä»¥è¿™ä¸ªPPTéœ€è¦åºŸè¯å°‘è¯´ï¼ŒæŠŠä½ æœ€ç²¾å½©çš„éƒ¨åˆ†è®²å‡ºæ¥ï¼Œä½†æ˜¯æ‰€æœ‰éƒ¨åˆ†éœ€è¦å°½é‡çœŸå®žï¼Œæœ€å¥½ä¸è¦ç»™è‡ªå·±æŒ–å‘è·³å°±å¯ä»¥äº†ï¼Œè‡ªæˆ‘ä»‹ç»å®Œä¼šæœ‰ä¸€ä¸ªè‹±æ–‡é—®ç­”é¢˜ç›®ï¼Œç„¶åŽå°±æ˜¯è€å¸ˆæé—®æ—¶é—´äº†ï¼Œæˆ‘è¢«é—®åˆ°çš„é—®é¢˜æœ‰ï¼š æœºå™¨å­¦ä¹ äº†è§£å“ªäº›ç®—æ³•ï¼› é€»è¾‘å›žå½’å’Œçº¿æ€§å›žå½’çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼› å¦‚æžœæƒ³è¦è¿›çŽ‹æµ©è€å¸ˆç»„ï¼ˆå› ä¸ºæˆ‘æå‰è”ç³»çš„è¿™ä¸ªè€å¸ˆï¼‰ï¼Œæƒ³åšä»€ä¹ˆï¼Ÿ è½¯ä»¶æ‰€é¢è¯•å¤§æ¦‚å°±æ˜¯è¿™æ ·äº†ï¼ŒæŽ¥ä¸‹æ¥å°±å¯ä»¥å›žåŽ»ç­‰å®˜ç½‘å…¬ç¤ºä¼˜ç§€è¥å‘˜äº†ã€‚è¿™æ¬¡çš„å½•å–æ¯”ä¾‹æ²¡æœ‰è¯´çš„é‚£ä¹ˆé«˜ï¼Œé™¤å›½é‡å®žéªŒå®¤å¾ˆå¤šè€å¸ˆå•ç‹¬æ‹›ç”Ÿæ¯”è¾ƒç‰¹æ®Šå¤–ï¼Œæ‰€æœ‰å®žéªŒå®¤åŸºæœ¬æ˜¯50%çš„å½•å–çŽ‡ã€‚ éœ€è¦æä¸€ä¸‹ï¼Œå¤©åŸºé‡Œé¢åªæœ‰çŽ‹æµ©è€å¸ˆçš„ç ”ç©¶ç»„è¿˜ä¸é”™ï¼Œå…¶ä»–çš„è¯å°±åƒä¸‡ä¸è¦è€ƒè™‘äº†ï¼ï¼ï¼ï¼ æŠ¥åæœªèƒ½å‚åŠ çš„å¤ä»¤è¥è¿™ä¸€éƒ¨åˆ†æ˜¯æˆ‘æŠ¥åç›¸åº”å­¦æ ¡å¤ä»¤è¥åŽï¼Œå¯¹æ–¹æ²¡æœ‰ç»™äºˆæˆ‘å…¥è¥èµ„æ ¼æˆ–è€…ç”±äºŽæŸäº›åŽŸå› æˆ‘æ²¡æœ‰åŽ»çš„å­¦æ ¡ã€‚ 1. æ¸…åŽè®¡ç®—æœº ç½‘å€ï¼šå…³äºŽä¸¾åŠž2016å¹´æš‘æœŸå…¨å›½ä¼˜ç§€å¤§å­¦ç”Ÿå¤ä»¤è¥çš„é¢„é€šçŸ¥ æ—¶é—´ï¼š7æœˆ16æ—¥ï¼7æœˆ18æ—¥ å…¥è¥æ¡ä»¶ï¼šæˆ‘è§‰å¾—åŸºæœ¬åªæœ‰ä¸“ä¸šç¬¬ä¸€å¯ä»¥åŽ»å§ï¼Œé™¤éžä½ åœ¨ç§‘ç ”ç«žèµ›ç‰¹åˆ«ä¼˜ç§€ï¼Œå¦åˆ™åŸºæœ¬æ²¡æˆã€‚æ³¨æ„è¿™ä¸ªåªèƒ½æ˜¯ç›´åšã€‚ å…·ä½“ä»‹ç»ï¼šå‚è€ƒä¿¡æ¯å®‰å…¨ç« åšäº¨å¤§ç¥žçš„æ—¥å¿—ï¼šå—å¤§ã€æ¸…åŽã€åŒ—å¤§ã€ä¸Šäº¤ã€ä¸­ç§‘é™¢ã€åŒ—èˆªç­‰é«˜æ ¡å¤ä»¤è¥ä¿é€ç»åŽ† 2. åŒ—å¤§ä¿¡ç§‘ ç½‘å€ï¼šåŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢å…³äºŽä¸¾åŠž2016å¹´ä¿¡æ¯å­¦ç§‘ä¼˜ç§€å¤§å­¦ç”Ÿå¤ä»¤è¥çš„é€šçŸ¥ï¼ˆç¬¬ä¸€è½®ï¼‰-åŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢ æ—¶é—´ï¼š7æœˆ13æ—¥-7æœˆ15æ—¥ å…¥è¥æ¡ä»¶ï¼šåŒ—å¤§ä¿¡ç§‘é™¤äº†å¯¹ç»©ç‚¹æŽ’åè¦æ±‚å‰5%å¤–ï¼Œè¿˜éœ€è¦æœ‰å¾ˆé«˜çš„ç»¼åˆç´ è´¨ï¼Œæ‰€ä»¥æˆç»©ä¸æ˜¯å”¯ä¸€å› ç´ ï¼Œè¿™æ¬¡å…¥è¥çš„è½¯ä»¶å·¥ç¨‹ä¸“ä¸šçš„åŒå­¦æœ‰ä¸¤ä¸ªï¼Œåˆ†åˆ«æŽ’åç¬¬2åå’Œç¬¬11åã€‚ å…·ä½“ä»‹ç»ï¼šå‚è€ƒç« åšäº¨å¤§ç¥žçš„æ—¥å¿—ï¼šå—å¤§ã€æ¸…åŽã€åŒ—å¤§ã€ä¸Šäº¤ã€ä¸­ç§‘é™¢ã€åŒ—èˆªç­‰é«˜æ ¡å¤ä»¤è¥ä¿é€ç»åŽ†ï¼Œè¿˜æœ‰èƒ¡å°‘æ™—å¤§ç¥žçš„ä¿ç ”ç»åŽ†ï¼ˆç›®å‰è¿˜æ²¡æœ‰é“¾æŽ¥ï¼Œæœ‰äº†çš„è¯æˆ‘ä¼šæ›´æ–°ï¼‰ 3. ä¸Šäº¤è®¡ç®—æœº ç½‘å€ï¼šä¸Šäº¤è®¡ç®—æœºæ²¡æœ‰å¤ä»¤è¥ï¼Œåªæœ‰ä¸€ä¸ªç›´ç¡•é¢è¯•ï¼Œè¿™ä¸ªæ˜¯æ²¡æœ‰ç½‘å€çš„ï¼Œä½†æ˜¯è¿™ä¸ªå’Œä¸Šäº¤è½¯ä»¶å¤ä»¤è¥æ˜¯åŒæ—¶å¼€å§‹æŠ¥åçš„ï¼Œå¯ä»¥å…³æ³¨ä¸€ä¸‹ï¼šå…³äºŽä¸Šæµ·äº¤é€šå¤§å­¦â€œ2017è½¯ä»¶å·¥ç¨‹ä¼˜æ‰å¤ä»¤è¥â€çš„é€šçŸ¥ æ—¶é—´ï¼šè²Œä¼¼æ˜¯7æœˆ2å·ï¼ŒæŒ¤ä¸å¤ªæ¸…æ¥šäº†ï¼Œåæ­£åªæœ‰ä¸€å¤©æ—¶é—´ï¼Œå¯ä»¥å½“å¤©åŽ»å½“å¤©å›žã€‚ å…¥è¥æ¡ä»¶ï¼šå‰é¢æœ‰æåˆ°ï¼Œä¸Šäº¤è®¡ç®—æœºåªç»™ä¸€ä¸ªä¸“ä¸šä¸€ä¸ªç›´ç¡•åé¢ã€ä¸€ä¸ªç›´åšåé¢ï¼Œæ‰€ä»¥è°åæ¬¡é«˜ï¼Œè°å°±æœ‰æœºä¼šåŽ»ï¼ˆä¹Ÿä¸ä¸€å®šï¼Œè¿˜æ˜¯æŠ¥åè¯•è¯•å§ï¼‰ã€‚ å…·ä½“ä»‹ç»ï¼šå¯¹äºŽæˆ‘ä¸ªäººæ¥è¯´ï¼Œæˆ‘å½“åˆä»¥ä¸ºæˆ‘èƒ½èŽ·å¾—é¢è¯•èµ„æ ¼ï¼Œå°±æå‰è”ç³»äº†å‡ ä¸ªè€å¸ˆï¼Œå…¶ä¸­å’Œç”³ç‘žæ°‘è€å¸ˆå’Œæœ±å…¶ç«‹è€å¸ˆåˆ†åˆ«è¿›è¡Œäº†è§†é¢‘é¢è¯•ï¼Œä»–ä»¬éƒ½åŒæ„åªè¦æˆ‘èŽ·å¾—ä¸Šäº¤ç›´ç¡•é¢è¯•èµ„æ ¼ï¼Œå‚åŠ è€ƒæ ¸ï¼Œå°±æ”¶æˆ‘ä½œä¸ºä»–ä»¬çš„ç ”ç©¶ç”Ÿï¼Œå¯æƒœæˆ‘å¹¶æ²¡æœ‰èŽ·å¾—ç›´ç¡•é¢è¯•èµ„æ ¼ï¼Œæ‰€ä»¥æ¯”è¾ƒé—æ†¾ã€‚ï¼ˆæœ±å…¶ç«‹è€å¸ˆè‹±æ–‡åæ˜¯Kenny Zhuï¼Œè¿™ä¸ªè€å¸ˆå¯èƒ½ä»Žå›½å¤–å›žæ¥çš„è€å¸ˆï¼Œæ‰€ä»¥ä»–å’Œæˆ‘Skypeçš„æ˜¯æ—¶å€™å…¨ç¨‹è‹±æ–‡äº¤æµï¼Œè¿˜æ˜¯éœ€è¦å‡†å¤‡ä¸€ä¸‹ï¼Œå…·ä½“è€ƒæ ¸æ–¹å¼å¯ä»¥å‚ç…§ç« åšäº¨å¤§ç¥žçš„æ—¥å¿—ä¸Šäº¤é‚£éƒ¨åˆ†ï¼šå—å¤§ã€æ¸…åŽã€åŒ—å¤§ã€ä¸Šäº¤ã€ä¸­ç§‘é™¢ã€åŒ—èˆªç­‰é«˜æ ¡å¤ä»¤è¥ä¿é€ç»åŽ†ï¼‰ 4. ä¸­ç§‘é™¢è®¡ç®—æ‰€ ç½‘å€ï¼šâ€œè®¡ç®—æœªæ¥â€å…¨å›½å¤§å­¦ç”Ÿè®¡ç®—æŠ€æœ¯æš‘æœŸç ”ä¿®ç­æ‹›ç”Ÿç®€ç«  æ—¶é—´ï¼š7æœˆ17-7æœˆ23æ—¥ å…¥è¥æ¡ä»¶ï¼šä¹‹å‰æåˆ°ï¼Œè®¡ç®—æ‰€ä¸å¤ªå–œæ¬¢æ”¶è½¯ä»¶å­¦é™¢çš„å­¦ç”Ÿï¼Œæ‰€ä»¥æ¯ä¸ªä¸“ä¸šåªç»™ä¸€ä¸¤ä¸ªåé¢ï¼Œè°åæ¬¡é«˜è°å°±å¯ä»¥åŽ» å…·ä½“ä»‹ç»ï¼šå‚è€ƒç« åšäº¨å¤§ç¥žçš„æ—¥å¿—ï¼šå—å¤§ã€æ¸…åŽã€åŒ—å¤§ã€ä¸Šäº¤ã€ä¸­ç§‘é™¢ã€åŒ—èˆªç­‰é«˜æ ¡å¤ä»¤è¥ä¿é€ç»åŽ† 5. åŽç§‘ ç½‘å€ï¼šå…³äºŽä¸¾åŠžâ€œ2016å¹´åŽä¸­ç§‘æŠ€å¤§å­¦è®¡ç®—æœºå­¦é™¢ä¼˜ç§€å¤§å­¦ç”Ÿå¤ä»¤è¥â€æ´»åŠ¨çš„é€šçŸ¥ æ—¶é—´ï¼š7æœˆ21-7æœˆ22æ—¥ å…¥è¥æ¡ä»¶ï¼š985æŽ’åå‰15%ï¼Œæˆ–è€…ä½ åœ¨ç«žèµ›æ–¹é¢æœ‰çªå‡ºè¡¨çŽ°+å¯ä»¥èŽ·å¾—ä¿ç ”èµ„æ ¼ å…·ä½“ä»‹ç»ï¼š åŽç§‘ç”±äºŽå’Œè½¯ä»¶æ‰€æ—¶é—´é‡äº†ï¼Œæ‰€ä»¥æˆ‘æ²¡æœ‰åŽ»ï¼Œæ®è¯´åŽç§‘åªæœ‰æœºè¯•ï¼Œ3é“é¢˜ï¼Œä¸€ä¸ªåŠå°æ—¶ï¼Œäººå·¥åˆ¤é¢˜ï¼Œæ¯”è¾ƒç®€å•ï¼Œ985çš„åŒå­¦åŽ»äº†åŸºæœ¬å¯ä»¥æ‹¿åˆ°ä¼˜ç§€è¥å‘˜ï¼Œä¹Ÿæ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚ ä¸€äº›ä½“ä¼šé€šè¿‡è¿™æ¬¡å¤ä»¤è¥ï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªä½“ä¼šï¼Œä¹Ÿå½“åšç»™å­¦å¼Ÿå­¦å¦¹çš„ä¸€äº›å»ºè®®å§ã€‚ ä¿ç ”ä¸åƒæƒ³è±¡ä¸­çš„é‚£ä¹ˆå®¹æ˜“ã€‚å¾ˆå¤š985é™¢æ ¡çš„åŒå­¦ä»¥ä¸ºåªè¦æˆç»©å¥½ï¼Œä¿ç ”åˆ°å¥½å­¦æ ¡å¾ˆå®¹æ˜“ï¼Œå…¶å®žå¹¶ä¸æ˜¯ï¼Œå› ä¸ºæœ‰å¾ˆå¤šä½ ä¸è®¤è¯†çš„äººï¼Œä»–ä»¬æ¯”ä½ å­¦æ ¡å¥½ï¼Œæˆç»©ä¼˜å¼‚ï¼Œç§‘ç ”ç«žèµ›ç»åŽ†ä¸°å¯Œã€‚æ‰€ä»¥æˆç»©å¹¶ä¸èƒ½ä»£è¡¨ä¸€åˆ‡ï¼Œå®ƒæœ€å¤šåªèƒ½æ˜¯ä¸€å—å„¿æ•²é—¨ç –ï¼ŒæŠŠä½ å¸¦åˆ°ä½ æƒ³è¿›çš„å¤ä»¤è¥ï¼Œä½†å½“ä½ è¿›å…¥å¤ä»¤è¥åŽï¼Œå†³å®šä½ æ°´å¹³çš„ä¸å•å•æ˜¯æˆç»©ï¼Œæ›´é‡è¦çš„æ˜¯ç»¼åˆç´ è´¨ï¼Œæ¯”å¦‚åŸºç¡€çŸ¥è¯†ã€ç¼–ç¨‹èƒ½åŠ›ã€è¯­è¨€è¡¨è¾¾èƒ½åŠ›ç­‰ç§ç§å› ç´ ã€‚å¦‚ä½•åˆ©ç”¨ä½ ä¸‰å¹´å­¦åˆ°çš„çŸ¥è¯†æ‹¿åˆ°ä¼˜ç§€è¥å‘˜æ‰æ˜¯å…³é”®ã€‚ä¸è¦æ€»æƒ³ç€æ‹¿æˆç»©è¯´äº‹ï¼Œtry to prove it! æŠ“ä½ä¸€åˆ‡å¯èƒ½çš„æœºä¼šã€‚ä¿ç ”çš„è·¯ä¸Šï¼Œä½ å¯èƒ½è§‰å¾—èº«å¿ƒä¿±ç–²ï¼Œå¯èƒ½è§‰å¾—è¿™ä¸ªæœºä¼šæ²¡ä»€ä¹ˆä»·å€¼ï¼Œå¯èƒ½è§‰å¾—è¿™ä¸ªæœºä¼šå“ªæœ‰é‚£ä¹ˆå®¹æ˜“èŽ·å¾—ï¼Œå¦‚æžœæ˜¯é‚£ä¹ˆä¹Ÿä¸ä¼šæ˜¯ç•™ç»™æˆ‘çš„ï¼Œæˆ‘è¿˜æ˜¯ä¸€éæ­‡ç€å§ã€‚ä½†æˆ‘æƒ³è¯´çš„æ˜¯ï¼Œåƒä¸‡ä¸è¦å› ä¸ºä½ çš„æ‡’æƒ°ï¼Œä½ çš„æƒ³å½“ç„¶ï¼Œè®©ä¸€ä¸ªåˆä¸€ä¸ªæœºä¼šä»Žä½ æ‰‹ä¸­æºœèµ°ï¼Œå› ä¸ºä»»ä½•äº‹æƒ…åªæœ‰å°è¯•åŽï¼Œä½ æ‰æœ‰èµ„æ ¼è¯„ä»·ï¼Œè€Œä¸”å¾ˆå¤šæ—¶å€™ï¼Œè¿™ä¸ªæœºä¼šå°±æ˜¯ä¸ºä½ å‡†å¤‡çš„ï¼Œä½ ä¸åŽ»äº‰å–ï¼Œä½ å°±ä¸€æ— æ‰€èŽ·ã€‚å°±åƒé˜¿å§†çš„ã€ŠLose yourselfã€‹æ­Œè¯æ‰€è¯´ï¼šLook, if you had one shot, or one opportunity to seize everything you ever wanted. In one moment, would you capture it, or just let it slip? æˆ‘æƒ³é€‰æ‹©å‰è€…æ€»æ˜¯æ²¡æœ‰é”™çš„ã€‚ æœºä¼šç•™æ˜¯ç»™æœ‰å‡†å¤‡çš„äººã€‚é€šè¿‡è¿™æ¬¡ä¿ç ”ï¼Œæˆ‘æ„Ÿå—æœ€æ·±çš„å°±æ˜¯æœºè¯•ï¼ŒçœŸçš„æ˜¯â€å¾—æœºè¯•è€…å¾—å¤©ä¸‹â€œã€‚æœºè¯•ä¸€ç›´æ˜¯æˆ‘çš„è–„å¼±ä¹‹å¤„ï¼Œè™½ç„¶åœ¨åŠªåŠ›åˆ·é¢˜æé«˜æœºè¯•æ°´å¹³ï¼Œä½†æ˜¯ç”±äºŽæˆ‘æ²¡æœ‰å‚åŠ è¿‡ACMï¼Œæ„è¯†åˆ°çš„æ—¶é—´æ™šï¼Œæ²¡æœ‰æ—¶é—´åŽ»å‡†å¤‡æœºè¯•ï¼Œæ‰€ä»¥çŸ­çŸ­çš„æ—¶é—´æ˜¯æ— æ³•æœ‰è´¨çš„é£žè·ƒï¼Œå¯¼è‡´æˆ‘åœ¨æœºè¯•ä¸Šæ‘”äº†ä¸€æ¬¡åˆä¸€æ¬¡ï¼Œâ€æˆåŠŸåœ°â€œä¸Žå¾ˆå¤šåˆ°æ‰‹çš„æœºä¼šå¤±ä¹‹äº¤è‡‚ï¼Œç—›æ‚”ä¸å·²ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›å­¦å¼Ÿå­¦å¦¹ä»¬ä¸€å®šè¦å¥½å¥½å‡†å¤‡æœºè¯•ï¼Œæ²¡äº‹å¤šåˆ·é¢˜ï¼ˆC/C++ï¼Œåƒä¸‡ä¸è¦ç”¨Javaï¼‰ï¼Œåˆ°æ—¶å€™æ‰ä¼šæœ‰ä¸´å±ä¸ä¹±ï¼Œç§’æ€ä¼—ç”Ÿçš„æ„Ÿè§‰ï¼Œåªè¦å¤ä»¤è¥æœºè¯•è¿‡äº†ï¼Œä½ ä¹Ÿå°±åŸºæœ¬æ²¡é—®é¢˜äº†ã€‚å½“ç„¶ï¼Œé¢è¯•ä¹Ÿæ˜¯è¦å¥½å¥½å‡†å¤‡çš„ï¼Œç»å¸¸å¤ä¹ å››å¤§ä¸“ä¸šè¯¾ï¼Œé«˜æ•°ã€é«˜ä»£ã€æ¦‚çŽ‡è®ºç­‰æ•°å­¦è¯¾ï¼Œè¿™æ ·åˆ°æ—¶å€™å¤§æ¦‚è¿‡ä¸€éå°±è¡Œäº†ã€‚è¿˜æœ‰ä¸€å¹´æ—¶é—´ï¼Œäº‰å–å¤šå‚åŠ ä¸€äº›ç§‘ç ”å’Œç«žèµ›ï¼Œè¿™æ˜¯å¾ˆåŠ åˆ†çš„ï¼Œå¦‚æžœä½ èƒ½é€šè¿‡è¿™äº›â€å¥—åˆ°â€œä¸€ä¸ªå¥½å¯¼å¸ˆï¼Œä½•ä¹è€Œä¸ä¸ºå‘¢ï¼æœ€åŽè¦è¯´çš„æ˜¯ï¼Œå°½æ—©ç¡®å®šä¸‹æ¥å°†æ¥è¯»ç ”çš„ç ”ç©¶æ–¹å‘ï¼Œæ—©ä¸€ç‚¹åŽ»çœ‹ä¸€äº›ç›¸å…³ä¸“ä¸šä¹¦ï¼Œäº‰å–åˆ©ç”¨å‰©ä¸‹çš„ä¸€å¹´æ—¶é—´è·Ÿè€å¸ˆåšä¸€åšç›¸å…³æ–¹å‘çš„ç§‘ç ”ï¼Œè¿™ä¼šå¯¹ä½ çš„ç®€åŽ†å¢žåŠ ä¸å°‘å…‰å½©ï¼So go for it!]]></content>
      <categories>
        <category>ç»éªŒ</category>
      </categories>
      <tags>
        <tag>ä¿ç ”</tag>
      </tags>
  </entry>
</search>
